<doc id="6557" url="https://en.wikipedia.org/wiki?curid=6557" title="Control unit">
Control unit

The control unit (CU) is a component of a computer's central processing unit (CPU) that directs the operation of the processor. It tells the computer's memory, arithmetic and logic unit and input and output devices how to respond to the instructions that have been sent to the processor.
It directs the operation of the other units by providing timing and control signals.
Most computer resources are managed by the CU. It directs the flow of data between the CPU and the other devices. John von Neumann included the control unit as part of the von Neumann architecture. In modern computer designs, the control unit is typically an internal part of the CPU with its overall role and operation unchanged since its introduction.
The simplest computers use a multicycle microarchitecture. These were the earliest designs. They are still popular in the very smallest computers, such as the embedded systems that operate machinery.
In a multicycle computer, the control unit often steps through the Von Neumann Cycle: Fetch the instruction, Fetch the operands, do the instruction, write the results. When the next instruction is placed in the control unit, it changes the behavior of the control unit to finish the instruction correctly. So, the bits of the instruction directly control the control unit, which in turn controls the computer.
The control unit may include a binary counter to tell the control unit's logic what step it should do.
Multicycle control units typically use both the rising and falling edges of their square-wave timing clock. They operate a step of their operation on each edge of the timing clock, so that a four-step operation completes in two clock cycles.
Many computers have two different types of unexpected events. An interrupt occurs because some type of input or output needs software attention in order to operate correctly. An exception is caused by the computer's operation. One crucial difference is that the timing of an interrupt cannot be predicted. Another is that some exceptions (e.g. a memory-not-available exception) can be caused by an instruction that needs to be restarted.
Control units can be designed to handle interrupts in one of two typical ways. If a quick response is most important, a control unit is designed to abandon work to handle the interrupt. In this case, the work in process will be restarted after the last completed instruction. If the computer is to be very inexpensive, very simple, very reliable, or to get more work done, the control unit will finish the work in process before handling the interrupt. Finishing the work is inexpensive, because it needs no register to record the last finished instruction. It is simple and reliable because it has the fewest states. It also wastes the least amount of work.
Exceptions can be made to operate like interrupts in very simple computers. If virtual memory is required, then a memory-not-available exception must retry the failing instruction.
It is common for multicycle computers to use more cycles. Sometimes it takes longer to take a conditional jump, because the program counter has to be reloaded. Sometimes they do multiplication or division instructions by a process something like binary long multiplication and division. Very small computers might do arithmetic one or a few bits at a time. Some computers have very complex instructions that take many steps.
Many medium-complexity computers pipeline instructions. This design is popular because of its economy and speed.
In a pipelined computer, instructions flow through the computer. This design has several stages. For example, it might have one stage for each step of the Von Neumann cycle. A pipelined computer usually has "pipeline registers" after each stage. These store the bits calculated by a stage so that the logic gates of the next stage can use the bits to do the next step. It is common for even numbered stages to operate on one edge of the square-wave clock, while odd-numbered stages operate on the other edge.
In a pipelined computer, the control unit arranges for the flow to start, continue, and stop as a program commands. The instruction data is usually passed in pipeline registers from one stage to the next, with a somewhat separated piece of control logic for each stage. The control unit also assures that the instruction in each stage does not harm the operation of instructions in other stages. For example, if two stages must use the same piece of data, the control logic assures that the uses are done in the correct sequence.
When operating efficiently, a pipelined computer will have an instruction in each stage. It is then working on all of those instructions at the same time. It can finish about one instruction for each cycle of its clock. When a program makes a decision, and switches to a different sequence of instructions, the pipeline sometimes must discard the data in process and restart. This is called a "stall." When two instructions could interfere, sometimes the control unit must stop processing a later instruction until an earlier instruction completes. This is called a "pipeline bubble" because a part of the pipeline is not processing instructions. Pipeline bubbles can occur when two instructions operate on the same register.
Interrupts and unexpected exceptions also stall the pipeline. If a pipelined computer abandons work for an interrupt, more work is lost than in a multicycle computer. Predictable exceptions do not need to stall. For example, if an exception instruction is used to enter the operating system, it does not cause a stall.
Speed? For the same speed of electronic logic, it can do more instructions per second than a multicycle computer. Also, even though the electronic logic has a fixed maximum speed, a pipelined computer can be made faster or slower by varying the number of stages in the pipeline. With more stages, each stage does less work, and so the stage has fewer delays from the logic gates.
Economy? A pipelined model of a computer often has the least logic gates per instruction per second, less than either a multicycle or out-of-order computer. Why? The average stage is less complex than a multicycle computer. An out of order computer usually has large amounts of idle logic at any given instant. Similar calculations usually show that a pipelined computer uses less energy per instruction.
However, a pipelined computer is usually more complex and more costly than a comparable multicycle computer. It typically has more logic gates, registers and a more complex control unit. In a like way, it might use more total energy, while using less energy per instruction. Out of order CPUs can usually do more instructions per second because they can do several instructions at once.
Control units use many methods to keep a pipeline full and avoid stalls. For example, even simple control units can assume that a backwards branch, to a lower-numbered, earlier instruction, is a loop, and will be repeated. So, a control unit with this design will always fill the pipeline with the backwards branch path. If a compiler can detect the most frequently-taken direction of a branch, the compiler can just produce instructions so that the most frequently taken branch is the preferred direction of branch. In a like way, a control unit might get hints from the compiler: Some computers have instructions that can encode hints from the compiler about the direction of branch.
Some control units do branch prediction: A control unit keeps an electronic list of the recent branches, encoded by the address of the branch instruction. This list has a few bits for each branch to remember the direction that was taken most recently.
Some control units can do speculative execution, in which a computer might have two or more pipelines, calculate both directions of a branch, then discard the calculations of the unused direction.
Results from memory can become available at unpredictable times because very fast computers cache memory. That is, they copy limited amounts of memory data into very fast memory. The CPU must be designed to process at the very fast speed of the cache memory. Therefore, the CPU might stall when it must access main memory directly. In modern PCs, main memory is as much as three hundred times slower than cache.
To help this, out-of-order CPUs and control units were developed to process data as it becomes available. (See next section)
But what if all the calculations are complete, but the CPU is still stalled, waiting for main memory? Then, a control unit can switch to an alternative thread of execution whose data has been fetched while the thread was idle. A thread has its own program counter, a stream of instructions and a separate set of registers. Designers vary the number of threads depending on current memory technologies and the type of computer. Typical computers such as PCs and smart phones usually have control units with a few threads, just enough to keep busy with affordable memory systems. Database computers often have about twice as many threads, to keep their much larger memories busy. Graphic processing units (GPUs) usually have hundreds or thousands of threads, because they have hundreds or thousands of execution units doing repetitive graphic calculations.
When a control unit permits threads, the software also has to be designed to handle them. In general-purpose CPUs like PCs and smartphones, the threads are usually made to look very like normal time-sliced processes. At most, the operating system might need some awareness of them. In GPUs, the thread scheduling usually cannot be hidden from the application software, and is often controlled with a specialized subroutine library.
A control unit can be designed to finish what it can. If several instructions can be completed at the same time, the control unit will arrange it. So, the fastest computers can process instructions in a sequence that can vary somewhat, depending on when the operands or instruction destinations become available. Most supercomputers and many PC CPUs use this method. The exact organization of this type of control unit depends on the slowest part of the computer.
When the execution of calculations is the slowest, instructions flow from memory into pieces of electronics called "issue units." An issue unit holds an instruction until both its operands and an execution unit are available. Then, the instruction and its operands are "issued" to an execution unit. The execution unit does the instruction. Then the resulting data is moved into a queue of data to be written back to memory or registers. If the computer has multiple execution units, it can usually do several instructions per clock cycle.
It is common to have specialized execution units. For example, a modestly priced computer might have only one floating-point execution unit, because floating point units are expensive. The same computer might have several integer units, because these are relatively inexpensive, and can do the bulk of instructions.
One kind of control unit for issuing uses an array of electronic logic, a "scoreboard"" that detects when an instruction can be issued. The "height" of the array is the number of execution units, and the "length" and "width" are each the number of sources of operands. When all the items come together, the signals from the operands and execution unit will cross. The logic at this intersection detects that the instruction can work, so the instruction is "issued" to the free execution unit. An alternative style of issuing control unit implements the Tomasulo algorithm, which reorders a hardware queue of instructions. In some sense, both styles utilize a queue. The scoreboard is an alternative way to encode and reorder a queue of instructions, and some designers call it a queue table.
With some additional logic, a scoreboard can compactly combine execution reordering, register renaming and precise exceptions and interrupts. Further it can do this without the power-hungry, complex content-addressable memory used by the Tomasulo algorithm.
If the execution is slower than writing the results, the memory write-back queue always has free entries. But what if the memory writes slowly? Or what if the destination register will be used by an "earlier" instruction that has not yet issued? Then the write-back step of the instruction might need to be scheduled. This is sometimes called "retiring" an instruction. In this case, there must be scheduling logic on the back end of execution units. It schedules access to the registers or memory that will get the results.
Retiring logic can also be designed into an issuing scoreboard or a Tomasulo queue, by including memory or register access in the issuing logic.
Out of order controllers require special design features to handle interrupts. When there are several instructions in progress, it is not clear where in the instruction stream an interrupt occurs. For input and output interrupts, almost any solution works. However, when a computer has virtual memory, an interrupt occurs to indicate that a memory access failed. This memory access must be associated with an exact instruction and an exact processor state, so that the processor's state can be saved and restored by the interrupt. A usual solution preserves copies of registers until a memory access completes.
Also, out of order CPUs have even more problems with stalls from branching, because they can complete several instructions per clock cycle, and usually have many instructions in various stages of progress. So, these control units might use all of the solutions used by pipelined processors.
Some computers translate each single instruction into a sequence of simpler instructions. The advantage is that an out of order computer can be simpler in the bulk of its logic, while handling complex multi-step instructions. x86 Intel CPUs since the Pentium Pro translate complex CISC x86 instructions to more RISC-like internal micro-operations.
In these, the "front" of the control unit manages the translation of instructions. Operands are not translated. The "back" of the CU is an out-of-order CPU that issues the micro-operations and operands to the execution units and data paths.
Many modern computers have controls that minimize power usage. In battery-powered computers, such as those in cell-phones, the advantage is longer battery life. In computers with utility power, the justification is to reduce the cost of power, cooling or noise.
Most modern computers use CMOS logic. CMOS wastes power in two common ways: By changing state, i.e. "active power," and by unintended leakage. The active power of a computer can be reduced by turning off control signals. Leakage current can be reduced by reducing the electrical pressure, the voltage, making the transistors with larger depletion regions or turning off the logic completely.
Active power is easier to reduce because data stored in the logic is not affected. The usual method reduces the CPU's clock rate. Most computer systems use this method. It is common for a CPU to idle during the transition to avoid side-effects from the changing clock.
Most computers also have a "halt" instruction. This was invented to stop non-interrupt code so that interrupt code has reliable timing. However, designers soon noticed that a halt instruction was also a good time to turn off a CPU's clock completely, reducing the CPU's active power to zero. The interrupt controller might continue to need a clock, but that usually uses much less power than the CPU.
These methods are relatively easy to design, and became so common that others were invented for commercial advantage. Many modern low-power CMOS CPUs stop and start specialized execution units and bus interfaces depending on the needed instruction. Some computers even arrange the CPU's microarchitecture to use transfer-triggered multiplexers so that each instruction only utilises the exact pieces of logic needed.
Theoretically, computers at lower clock speeds could also reduce leakage by reducing the voltage of the power supply. This affects the reliability of the computer in many ways, so the engineering is expensive, and it is uncommon except in relatively expensive computers such as PCs or cellphones.
Some designs can use very low leakage transistors, but these usually add cost. The depletion barriers of the transistors can be made larger to have less leakage, but this makes the transistor larger and thus both slower and more expensive. Some vendors use this technique in selected portions of an IC by constructing low leakage logic from large transistors that some processes provide for analog circuits. Some processes place the transistors above the surface of the silicon, in "fin fets", but these processes have more steps, so are more expensive. Special transistor doping materials (e.g. hafnium) can also reduce leakage, but this adds steps to the processing, making it more expensive. Some semiconductors have a larger band-gap than silicon. However, these materials and processes are currently (2020) more expensive than silicon.
Managing leakage is more difficult, because before the logic can be turned-off, the data in it must be moved to some type of low-leakage storage.
One common method is to spread the load to many CPUs, and turn off unused CPUs as the load reduces. The operating system's task switching logic saves the CPUs' data to memory. In some cases, one of the CPUs can be simpler and smaller, literally with fewer logic gates. So, it has low leakage, and it is the last to be turned off, and the first to be turned on. Also it then is the only CPU that requires special low-power features. A similar method is used in most PCs, which usually have an auxiliary embedded CPU that manages the power system. However, in PCs, the software is usually in the BIOS, not the operating system.
Some CPUs make use of a special type of flip-flop (to store a bit) that couples a fast, high-leakage storage cell to a slow, large (expensive) low-leakage cell. These two cells have separated power supplies. When the CPU enters a power saving mode (e.g. because of a halt that waits for an interrupt), data is transferred to the low-leakage cells, and the others are turned off. When the CPU leaves a low-leakage mode (e.g. because of an interrupt), the process is reversed.
Older designs would copy the CPU state to memory, or even disk, sometimes with specialized software. Very simple embedded systems sometimes just restart.
All modern CPUs have control logic to attach the CPU to the rest of the computer. In modern computers, this is usually a bus controller. When an instruction reads or writes memory, the control unit either controls the bus directly, or controls a bus controller. Many modern computers use the same bus interface for memory, input and output. This is called "memory-mapped I/O". To a programmer, the registers of the I/O devices appear as numbers at specific memory addresses. x86 PCs use an older method, a separate I/O bus accessed by I/O instructions.
A modern CPU also tends to include an interrupt controller. It handles interrupt signals from the system bus. The control unit is the part of the computer that responds to the interrupts.
There is often a cache controller to cache memory. The cache controller and the associated cache memory is often the largest physical part of a modern, higher-performance CPU. When the memory, bus or cache is shared with other CPUs, the control logic must communicate with them to assure that no computer ever gets out-of-date old data.
Many historic computers built some type of input and output directly into the control unit. For example, many historic computers had a front panel with switches and lights directly controlled by the control unit. These let a programmer directly enter a program and debug it. In later production computers, the most common use of a front panel was to an enter a small bootstrap program to read the operating system from disk. This was annoying. So, front panels were replaced by bootstrap programs in read-only memory.
Most PDP-8 models had a data bus designed to let I/O devices borrow the control unit's memory read and write logic. This reduced the complexity and expense of high speed I/O controllers, e.g. for disk.
The Xerox Alto had a multitasking microprogammable control unit that performed almost all I/O. This design provided most of the features of a modern PC with only a tiny fraction of the electronic logic. The dual-thread computer was run by the two lowest-priority microthreads. These performed calculations whenever I/O was not required. High priority microthreads provided (in decreasing priority) video, network, disk, a periodic timer, mouse, and keyboard. The microprogram did the complex logic of the I/O device, as well as the logic to integrate the device with the computer. For the actual hardware I/O, the microprogram read and wrote shift registers for most I/O, sometimes with resistor networks and transistors to shift output voltage levels (e.g. for video). To handle outside events, the microcontroller had microinterrupts to switch threads at the end of a thread's cycle, e.g. at the end of an instruction, or after a shift-register was accessed. The microprogram could be rewritten and reinstalled, which was very useful for a research computer.
Thus a program of instructions in memory will cause the CU to configure a CPU's data flows to manipulate the data correctly between instructions. This results in a computer that could run a complete program and require no human intervention to make hardware changes between instructions (as had to be done when using only punch cards for computations before stored programmed computers with CUs were invented).
Hardwired control units are implemented through use of combinational logic units, featuring a finite number of gates that can generate specific results based on the instructions that were used to invoke those responses. Hardwired control units are generally faster than the microprogrammed designs.
This design uses a fixed architecture—it requires changes in the wiring if the instruction set is modified or changed. It can be convenient for simple, fast computers.
A controller that uses this approach can operate at high speed; however, it has little flexibility. A complex instruction set can overwhelm a designer who uses ad hoc logic design.
The hardwired approach has become less popular as computers have evolved. Previously, control units for CPUs used ad hoc logic, and they were difficult to design.
The idea of microprogramming was introduced by Maurice Wilkes in 1951 as an intermediate level to execute computer program instructions. Microprograms were organized as a sequence of "microinstructions" and stored in special control memory. The algorithm for the microprogram control unit, unlike the hardwired control unit, is usually specified by flowchart description. The main advantage of the microprogram control unit is the simplicity of its structure. Outputs of the controller are organized in microinstructions and they can be easily replaced.
A popular variation on microcode is to debug the microcode using a software simulator. Then, the microcode is a table of bits. This is a logical truth table, that translates a microcode address into the control unit outputs. This truth table can be fed to a computer program that produces optimized electronic logic. The resulting control unit is almost as easy to design as microprogramming, but it has the fast speed and low number of logic elements of a hard wired control unit. The practical result resembles a Mealy machine or Richards controller.

</doc>
<doc id="6558" url="https://en.wikipedia.org/wiki?curid=6558" title="Cello">
Cello

The cello ( ; plural celli or cellos) or violoncello ( ; ) is a bowed (and occasionally plucked) string instrument of the violin family. Its four strings are usually tuned in perfect fifths: from low to high, C, G, D and A. Each string is an octave lower than the viola's four strings. Music for the cello is generally written in the bass clef, with tenor clef and treble clef used for higher-range passages.
Played by a "cellist" or "violoncellist", it enjoys a large solo repertoire with and without accompaniment, as well as numerous concerti. As a solo instrument, the cello uses its whole range, from bass to soprano, and in chamber music such as string quartets and the orchestra's string section, it often plays the bass part, where it may be reinforced an octave lower by the double basses. Figured bass music of the Baroque-era typically assumes a cello, viola da gamba or bassoon as part of the basso continuo group alongside chordal instruments such as organ, harpsichord, lute or theorbo. Cellos are found in many other ensembles, from modern Chinese orchestras to cello rock bands.
The name "cello" is derived from the ending of the Italian "violoncello", which means "little violone". Violone ("big viola") was a large-sized member of viol (viola da gamba) family or the violin (viola da braccio) family. The term "violone" today usually refers to the lowest-pitched instrument of the viols, a family of stringed instruments that went out of fashion around the end of the 17th century in most countries except England and, especially, France, where they survived another half-century before the louder violin family came into greater favour in that country as well. In modern symphony orchestras, it is the second largest stringed instrument (the double bass is the largest). Thus, the name "violoncello" contained both the augmentative "-one" ("big") and the diminutive "-cello" ("little"). By the turn of the 20th century, it had become common to shorten the name to 'cello, with the apostrophe indicating the missing stem. It is now customary to use "cello" without apostrophe as the full designation. "Viol" is derived from the root "viola", which was derived from Medieval Latin "vitula", meaning stringed instrument.
Cellos are tuned in fifths, starting with C (two octaves below middle C), followed by G, D, and then A. It is tuned in the same intervals as the viola, but an octave lower. Unlike the violin or viola but similar to the double bass, the cello has an endpin that rests on the floor to support the instrument's weight. The cello is most closely associated with European classical music. The instrument is a part of the standard orchestra, as part of the string section, and is the bass voice of the string quartet (although many composers give it a melodic role as well), as well as being part of many other chamber groups.
Among the most well-known Baroque works for the cello are Johann Sebastian Bach's six unaccompanied Suites. Other significant include Sonatas and Concertos by Vivaldi, and earlier works by Gabrieli, Geminiani, and Bononcini. As a basso continuo instrument basso continuo the cello may have been used in works by Francesca Caccini (1587–1641), Barbara Strozzi (1619–1677) with pieces such as "Il primo libro di madrigali, per 2–5 voci e basso continuo, op. 1" and Elisabeth Jacquet de La Guerre (1665–1729) who wrote six sonatas for violin and basso continuo.
From the Classical era, the two concertos by Joseph Haydn in C major and D major stand out, as do the five sonatas for cello and pianoforte of Ludwig van Beethoven, which span the important three periods of his compositional evolution. Other outstanding examples include the three Concerti by Carl Philipp Emanuel Bach, Capricci by dall'Abaco, and Sonatas by Flackton, Boismortier, and Luigi Boccherini. A "Divertimento for Piano, Clarinet, Viola and Cello" is among the surviving works by Duchess Anna Amalia of Brunswick-Wolfenbüttel (1739–1807).
Well-known works of the Romantic era include the Robert Schumann Concerto, the Antonín Dvořák Concerto as well as the two sonatas and the Double Concerto by Johannes Brahms. A review of compositions for cello in the Romantic era must include the German composer Fanny Mendelssohn (1805–1847) who wrote the Fantasy in G minor for cello and piano and a Capriccio in A-flat for cello. 
Compositions from the late-19th and early 20th century include three cello sonatas (including the Cello Sonata in C Minor written in 1880) by Dame Ethel Smyth (1858–1944), Edward Elgar's Cello Concerto in E minor, Claude Debussy's Sonata for Cello and Piano, and unaccompanied cello sonatas by Zoltán Kodály and Paul Hindemith. Pieces including cello were written by American Music Center founder Marion Bauer (1882–1955) (two trio sonatas for flute, cello and piano) and Ruth Crawford Seeger (1901–1953) (Diaphonic suite No. 2 for bassoon and cello).
The cello's versatility made it popular with many composers in this era, such as Sergei Prokofiev, Dmitri Shostakovich, Benjamin Britten, György Ligeti, Witold Lutoslawski and Henri Dutilleux. Polish composer Grażyna Bacewicz (1909–1969) was writing for cello in the mid 20th century with Concerto No. 1 for Cello and Orchestra (1951), Concerto No. 2 for Cello and Orchestra (1963) and in 1964 composed her Quartet for four cellos. 
Well-known cellists from the 20th century include Jacqueline du Pré, Pablo Casals, Yo-Yo Ma, Emanuel Feuermann, Guilhermina Suggia, Mstislav Rostropovich and Beatrice Harrison. Others include Raya Garbousova, Anner Bylsma, Zara Nelsova, Alfred Wallenstein, Han-Na Chang, Mischa Maisky, Hildur Gudnadottir, and Gregor Piatigorsky. See the comprehensive list of cellists here.
In the 2010s, the instrument is found in popular music, but was more commonly used in 1970s pop and disco music. Today it is sometimes featured in pop and rock recordings, examples of which are noted later in this article. The cello has also appeared in major hip-hop and R & B performances, such as singers Rihanna and Ne-Yo's 2007 performance at the American Music Awards. The instrument has also been modified for Indian classical music by Nancy Lesh and Saskia Rao-de Haas.
The violin family, including cello-sized instruments, emerged c. 1500 as family of instruments distinct from the viola da gamba family. The earliest depictions of the violin family, from northern Italy c. 1530, show three sizes of instruments, roughly corresponding to what we now call violins, violas, and cellos. Contrary to a popular misconception, the cello did not evolve from the viola da gamba, but existed alongside it for about two and a half centuries. The violin family is also known as the viola da braccio (meaning viola of the arm) family, a reference to the primary way the members of the family are held. This is to distinguish it from the viola da gamba (meaning viola of the leg) family, in which all the members are all held with the legs. The likely predecessors of the violin family include the lira da braccio and the rebec. The earliest surviving cellos are made by Andrea Amati, the first known member of the celebrated Amati family of luthiers.
The direct ancestor to the violoncello was the bass violin. Monteverdi referred to the instrument as "basso de viola da braccio" in "Orfeo" (1607). Although the first bass violin, possibly invented as early as 1538, was most likely inspired by the viol, it was created to be used in consort with the violin. The bass violin was actually often referred to as a "violone", or "large viola", as were the viols of the same period. Instruments that share features with both the bass violin and the "viola da gamba" appear in Italian art of the early 16th century.
The invention of wire-wound strings (fine wire around a thin gut core), around 1660 in Bologna, allowed for a finer bass sound than was possible with purely gut strings on such a short body. Bolognese makers exploited this new technology to create the cello, a somewhat smaller instrument suitable for solo repertoire due to both the timbre of the instrument and the fact that the smaller size made it easier to play virtuosic passages. This instrument had disadvantages as well, however. The cello's light sound was not as suitable for church and ensemble playing, so it had to be doubled by organ, theorbo or violone.
Around 1700, Italian players popularized the cello in northern Europe, although the bass violin (basse de violon) continued to be used for another two decades in France. Many existing bass violins were literally cut down in size to convert them into cellos according to the smaller pattern developed by Stradivarius, who also made a number of old pattern large cellos (the 'Servais'). The sizes, names, and tunings of the cello varied widely by geography and time. The size was not standardized until around 1750.
Despite similarities to the viola da gamba, the cello is actually part of the viola da braccio family, meaning "viol of the arm", which includes, among others, the violin and viola. Though paintings like Bruegel's "The Rustic Wedding", and Jambe de Fer in his "Epitome Musical" suggest that the bass violin had alternate playing positions, these were short-lived and the more practical and ergonomic "a gamba" position eventually replaced them entirely.
Baroque-era cellos differed from the modern instrument in several ways. The neck has a different form and angle, which matches the baroque bass-bar and stringing. Modern cellos have an endpin at the bottom to support the instrument (and transmit some of the sound through the floor), while Baroque cellos are held only by the calves of the player. Modern bows curve in and are held at the frog; Baroque bows curve out and are held closer to the bow's point of balance. Modern strings normally have a metal core, although some use a synthetic core; Baroque strings are made of gut, with the G and C strings wire-wound. Modern cellos often have fine-tuners connecting the strings to the tailpiece, which make it much easier to tune the instrument, but such pins are rendered ineffective by the flexibility of the gut strings used on Baroque cellos. Overall, the modern instrument has much higher string tension than the Baroque cello, resulting in a louder, more projecting tone, with fewer overtones.
Few educational works specifically devoted to the cello existed before the 18th century, and those that do exist contain little value to the performer beyond simple accounts of instrumental technique. One of the earliest cello manuals is Michel Corrette's "Méthode, thèorique et pratique pour apprendre en peu de temps le violoncelle dans sa perfection" (Paris, 1741).
Cellos are part of the standard symphony orchestra, which usually includes eight to twelve cellists. The cello section, in standard orchestral seating, is located on stage left (the audience's right) in the front, opposite the first violin section. However, some orchestras and conductors prefer switching the positioning of the viola and cello sections. The "principal" cellist is the section leader, determining bowings for the section in conjunction with other string principals, playing solos and leading entrances (when the section begins to play its part). Principal players always sit closest to the audience.
The cellos are a critical part of orchestral music; all symphonic works involve the cello section, and many pieces require cello soli or solos. Much of the time, cellos provide part of the low-register harmony for the orchestra. Often, the cello section plays the melody for a brief period, before returning to the harmony role. There are also cello concertos, which are orchestral pieces that feature a solo cellist accompanied by an entire orchestra.
There are numerous cello concertos – where a solo cello is accompanied by an orchestra – notably 25 by Vivaldi, 12 by Boccherini, at least three by Haydn, three by C. P. E. Bach, two by Saint-Saëns, two by Dvořák, and one each by Robert Schumann, Lalo, and Elgar. There were also some composers who, while not otherwise cellists, did write cello-specific repertoire, such as Nikolaus Kraft who wrote six cello concertos. Beethoven's Triple Concerto for Cello, Violin and Piano and Brahms' Double Concerto for Cello and Violin are also part of the concertante repertoire although in both cases the cello shares solo duties with at least one other instrument. Moreover, several composers wrote large-scale pieces for cello and orchestra, which are concertos in all but name. Some familiar "concertos" are Richard Strauss' tone poem "Don Quixote", Tchaikovsky's "Variations on a Rococo Theme", Bloch's "Schelomo" and Bruch's "Kol Nidrei".
In the 20th century, the cello repertoire grew immensely. This was partly due to the influence of virtuoso cellist Mstislav Rostropovich, who inspired, commissioned and premiered dozens of new works. Among these, Prokofiev's "Symphony-Concerto", Britten's "Cello Symphony", the concertos of Shostakovich and Lutosławski as well as Dutilleux's "Tout un monde lointain..." have already become part of the standard repertoire. Other major composers who wrote concertante works for him include Messiaen, Jolivet, Berio and Penderecki. In addition, Arnold, Barber, Glass, Hindemith, Honegger, Ligeti, Myaskovsky, Penderecki, Rodrigo, Villa-Lobos and Walton also wrote major concertos for other cellists, notably for Gaspar Cassadó, Aldo Parisot, Gregor Piatigorsky, Siegfried Palm and Julian Lloyd Webber.
There are also many sonatas for cello and piano. Those written by Beethoven, Mendelssohn, Chopin, Brahms, Grieg, Rachmaninoff, Debussy, Fauré, Shostakovich, Prokofiev, Poulenc, Carter, and Britten are particularly well known.
Other important pieces for cello and piano include Schumann's five "Stücke im Volkston" and transcriptions like Schubert's "Arpeggione Sonata" (originally for arpeggione and piano), César Franck's Cello Sonata (originally a violin sonata, transcribed by Jules Delsart with the composer's approval), Stravinsky's "Suite italienne" (transcribed by the composer – with Gregor Piatigorsky – from his ballet "Pulcinella") and Bartók's first rhapsody (also transcribed by the composer, originally for violin and piano).
There are pieces for cello solo, J. S. Bach's six Suites for Cello (which are among the best-known solo cello pieces), Kodály's Sonata for Solo Cello and Britten's three Cello Suites. Other notable examples include Hindemith's and Ysaÿe's Sonatas for Solo Cello, Dutilleux's "Trois Strophes sur le Nom de Sacher", Berio's "Les Mots Sont Allés", Cassadó's Suite for Solo Cello, Ligeti's Solo Sonata, Carter's two "Figment"s and Xenakis' "Nomos Alpha" and "Kottos".
The cello is a member of the traditional string quartet as well as string quintets, sextet or trios and other mixed ensembles.
There are also pieces written for two, three, four or more cellos; this type of ensemble is also called a "cello choir" and its sound is familiar from the introduction to Rossini's William Tell Overture as well as Zaccharia's prayer scene in Verdi's Nabucco. Tchaikovsky's 1812 Overture also starts with a cello ensemble, with four cellos playing the top lines and two violas playing the bass lines. As a self-sufficient ensemble, its most famous repertoire is Heitor Villa-Lobos' first of his Bachianas Brasileiras for cello ensemble (the fifth is for soprano and 8 cellos). Other examples are Offenbach's cello duets, quartet, and sextet, Pärt's Fratres for eight cellos and Boulez' "Messagesquisse" for seven cellos, or even Villa-Lobos' rarely played "Fantasia Concertante" (1958) for 32 cellos. The 12 cellists of the Berlin Philharmonic Orchestra (or "the Twelve" as they have since taken to being called) specialize in this repertoire and have commissioned many works, including arrangements of well-known popular songs.
The cello is less common in popular music than in classical music. Several bands feature a cello in their standard line-up, including Hoppy Jones of the Ink Spots and Joe Kwon of the Avett Brothers. The more common use in pop and rock is to bring the instrument in for a particular song. In the 1960s, artists such as the Beatles and Cher used the cello in popular music, in songs such as The Beatles' "Yesterday", "Eleanor Rigby" and "Strawberry Fields Forever", and Cher's "Bang Bang (My Baby Shot Me Down)". "Good Vibrations" by the Beach Boys includes the cello in its instrumental ensemble, which includes a number of instruments unusual for this sort of music. Bass guitarist Jack Bruce, who had originally studied music on a performance scholarship for cello, played a prominent cello part in "As You Said" on Cream's "Wheels of Fire" studio album (1968).
In the 1970s, the Electric Light Orchestra enjoyed great commercial success taking inspiration from so-called "Beatlesque" arrangements, adding the cello (and violin) to the standard rock combo line-up and in 1978 the UK based rock band, Colosseum II, collaborated with cellist Julian Lloyd Webber on the recording "Variations". Most notably, Pink Floyd included a cello solo in their 1970 epic instrumental "Atom Heart Mother". Bass guitarist Mike Rutherford of Genesis was originally a cellist and included some cello parts in their "Foxtrot" album.
Established non-traditional cello groups include Apocalyptica, a group of Finnish cellists best known for their versions of Metallica songs, Rasputina, a group of cellists committed to an intricate cello style intermingled with Gothic music, the Massive Violins, an ensemble of seven singing cellists known for their arrangements of rock, pop and classical hits, Von Cello, a cello fronted rock power trio, Break of Reality who mix elements of classical music with the more modern rock and metal genre, Cello Fury, a cello rock band that performs original rock/classical crossover music, and Jelloslave, a Minneapolis-based Cello duo with two percussionists. These groups are examples of a style that has become known as cello rock. The crossover string quartet bond also includes a cellist. Silenzium and Cellissimo Quartet are Russian (Novosibirsk) groups playing rock and metal and having more and more popularity in Siberia. Cold Fairyland from Shanghai, China is using a cello along a Pipa as the main solo instrument to create East meets West progressive (folk) rock.
More recent bands using the cello are Clean Bandit, Aerosmith, The Auteurs, Nirvana, Oasis, Smashing Pumpkins, James, Talk Talk, Phillip Phillips, OneRepublic, and the baroque rock band Arcade Fire. An Atlanta-based trio, King Richard's Sunday Best, also uses a cellist in their lineup. So-called "chamber pop" artists like Kronos Quartet, The Vitamin String Quartet and Margot and the Nuclear So and So's have also recently made cello common in modern alternative rock. Heavy metal band System of a Down has also made use of the cello's rich sound. The indie rock band The Stiletto Formal are known for using a cello as a major staple of their sound, similarly, the indie rock band Canada employs two cello players in their lineup. The orch-rock group, The Polyphonic Spree, which has pioneered the use of stringed and symphonic instruments, employs the cello in very creative ways for many of their "psychedelic-esque" melodies. The first wave screamo band "I Would Set Myself On Fire For You" featured a cello as well as a viola to create a more folk-oriented sound. The band, Panic! at the Disco uses a cello in their song, "Build God, Then We'll Talk". The lead vocalist of the band, Brendon Urie, also did the recording of the cello solo. The Lumineers added cellist Nela Pekarek to the band in 2010. She plays cello, sings harmony and duets.
In jazz, bassists Oscar Pettiford and Harry Babasin were among the first to use the cello as a solo instrument; both tuned their instrument in fourths, an octave above the double bass. Fred Katz (who was not a bassist) was one of the first notable jazz cellists to use the instrument's standard tuning and arco technique. Contemporary jazz cellists include Abdul Wadud, Diedre Murray, Ron Carter, Dave Holland, David Darling, Lucio Amanti, Akua Dixon, Ernst Reijseger, Fred Lonberg-Holm, Tom Cora and Erik Friedlander. Modern musical theatre pieces like Jason Robert Brown's The Last Five Years, Duncan Sheik's Spring Awakening, Adam Guettel's Floyd Collins, and Ricky Ian Gordon's My Life with Albertine use small string ensembles (including solo cellos) to a prominent extent.
In Indian Classical music Saskia Rao-de Haas is a well established soloist as well as playing duets with her sitarist husband Pt. Shubhendra Rao. Other cellists performing Indian classical music are: Nancy Lesh (Dhrupad) and Anup Biswas. Both Rao and Lesh play the cello sitting cross-legged on the floor.
The cello can also be used in bluegrass and folk music, with notable players including Ben Sollee of the Sparrow Quartet and the "Cajun cellist" Sean Grissom, as well as Vyvienne Long who, in addition to her own projects, has played for those of Damien Rice. Cellists such as Natalie Haas, Abby Newton and Liz Davis Maxfield have contributed significantly to the use of cello playing in Celtic folk music, often with the cello featured as a primary melodic instrument and employing the skills and techniques of traditional fiddle playing. Lindsay Mac is becoming well known for playing the cello like a guitar, with her cover of The Beatles' "Blackbird".
The cello is typically made from carved wood, although other materials such as carbon fiber or aluminum may be used. A traditional cello has a spruce top, with maple for the back, sides, and neck. Other woods, such as poplar or willow, are sometimes used for the back and sides. Less expensive cellos frequently have tops and backs made of laminated wood. Laminated cellos are widely used in elementary and secondary school orchestras and youth orchestras, because they are much more durable than carved wood cellos (i.e., they are less likely to crack if bumped or dropped) and they are much less expensive.
The top and back are traditionally hand-carved, though less expensive cellos are often machine-produced. The sides, or ribs, are made by heating the wood and bending it around forms. The cello body has a wide top bout, narrow middle formed by two C-bouts, and wide bottom bout, with the bridge and F holes just below the middle. The top and back of the cello has decorative border inlay known as purfling. While purfling is attractive, it is also functional: if the instrument is struck, the purfling can prevent cracking of the wood. A crack may form at the rim of the instrument, but spreads no further. Without purfling, cracks can spread up or down the top or back. Playing, traveling and the weather all affect the cello and can increase a crack if purfling is not in place. Less expensive instruments typically have painted purfling.
In the late 1920s and early 1930s, the Aluminum Company of America (Alcoa) as well as German luthier G.A. Pfretzschner produced an unknown number of aluminum cellos (in addition to aluminum double basses and violins). Cello manufacturer Luis & Clark constructs cellos from carbon fibre. Carbon fibre instruments are particularly suitable for outdoor playing because of the strength of the material and its resistance to humidity and temperature fluctuations. Luis & Clark has produced over 1000 cellos, some of which are owned by cellists such as Yo-Yo Ma and Josephine van Lier.
Above the main body is the carved neck. The neck has a curved cross-section on its underside, which is where the player's thumb runs along the neck during playing. The neck leads to a pegbox and the scroll, which are all normally carved out of a single piece of wood, usually maple. The fingerboard is glued to the neck and extends over the body of the instrument. The fingerboard is given a curved shape, matching the curve on the bridge. Both the fingerboard and bridge need to be curved so that the performer can bow individual strings. If the cello were to have a flat fingerboard and bridge, as with a typical guitar, the performer would only be able to bow the leftmost and rightmost two strings, or bow all the strings. The performer would not be able to play the inner two strings alone.
The nut is a raised piece of wood, fitted where the fingerboard meets the pegbox, in which the strings rest in shallow slots or grooves to keep them the correct distance apart. The pegbox houses four tapered tuning pegs, one for each string. The pegs are used to tune the cello by either tightening or loosening the string. The pegs are called "friction pegs", because they maintain their position by friction. The scroll is a traditional ornamental part of the cello and a feature of all other members of the violin family. Ebony is usually used for the tuning pegs, fingerboard, and nut, but other hardwoods, such as boxwood or rosewood, can be used. Black fittings on low-cost instruments are often made from inexpensive wood that has been blackened or "ebonized" to look like ebony, which is much harder and more expensive. Ebonised parts such as tuning pegs may crack or split, and the black surface of the fingerboard will eventually wear down to reveal the lighter wood underneath.
Historically, cello strings had cores made out of catgut, which, despite its name is made from dried out sheep or goat intestines. Most modern strings used in the 2010s are wound with metallic materials like aluminum, titanium and chromium. Cellists may mix different types of strings on their instruments. The pitches of the open strings are C, G, D, and A (black note heads in the playing range figure above), unless alternative tuning (scordatura) is specified by the composer. Some composers (e.g. Ottorino Respighi in the final movement of ‘’The Pines of Rome’’) ask that the low C be tuned down to a B-flat so that the performer can play a different low note on the lowest open string.
The tailpiece and endpin are found in the lower part of the cello. The tailpiece is the part of the cello to which the "ball ends" of the strings are attached by passing them through holes. The tailpiece is attached to the bottom of the cello. The tailpiece is traditionally made of ebony or another hard wood, but can also be made of plastic or steel on lower-cost instruments. It attaches the strings to the lower end of the cello, and can have one or more fine tuners. The fine tuners are used to make smaller adjustments to the pitch of the string. The fine tuners can increase the tension of each string (raising the pitch) or decrease the tension of the string (lowering the pitch). When the performer is putting on a new string, the fine tuner for that string is normally reset to a middle position, and then the peg is turned to bring the string up to pitch. The fine turners are used for subtle, minor adjustments to pitch, such as tuning a cello to the oboe's 440 Hz A note or to tune the cello to a piano.
The endpin or spike is made of wood, metal or rigid carbon fibre and supports the cello in playing position. The endpin can be retracted into the hollow body of the instrument when the cello is being transported in its case. This makes the cello easier to move about. When the performer wishes to play the cello, the endpin is pulled out to lengthen it. The endpin is locked into the player's preferred length with a screw mechanism. The adjustable nature of endpins enables performers of different ages and body sizes to adjust the endpin length to suit them. In the Baroque period the cello was held between the calves, as there was no endpin at that time. The endpin was "introduced by Adrien Servais 1845 to give the instrument greater stability". Modern endpins are retractable and adjustable; older ones were removed when not in use. (The word "endpin" sometimes also refers to the button of wood located at this place in all instruments in the violin family, but this is usually called "tailpin".) The sharp tip of the cello's endpin is sometimes capped with a rubber tip that protects the tip from dulling and prevents the cello from slipping on the floor. Many cellists use a rubber pad with a metal cup to keep the tip from slipping on the floor. A number of accessories to keep the endpin from slipping; these include ropes which attach to the chair leg and other devices.
The bridge holds the strings above the cello and transfers their vibrations to the top of the instrument and the soundpost inside (see below). The bridge is not glued, but rather held in place by the tension of the strings. The bridge is usually positioned by the cross point of the "f-hole" (i.e., where the horizontal line occurs in the "f"). The f-holes, named for their shape, are located on either side of the bridge, and allow air to move in and out of the instrument as part of the sound-production process. They probably actually stand for an old style medial S, for words related to Sound. The f-holes also act as access points to the interior of the cello for repairs or maintenance. Sometimes a small length of rubber hose containing a water-soaked sponge, called a Dampit, is inserted through the f-holes, and serves as a humidifier. This keeps the wood components of the cello from drying out.
Internally, the cello has two important features: a bass bar, which is glued to the underside of the top of the instrument, and a round wooden sound post, a solid wooden cylinder which is wedged between the top and bottom plates. The bass bar, found under the bass foot of the bridge, serves to support the cello's top and distribute the vibrations from the strings to the body of the instrument. The sound post, found under the treble side of the bridge, connects the back and front of the cello. Like the bridge, the sound post is not glued, but is kept in place by the tensions of the bridge and strings. Together, the bass bar and sound post transfer the strings' vibrations to the top (front) of the instrument (and to a lesser extent the back), acting as a diaphragm to produce the instrument's sound.
Cellos are constructed and repaired using hide glue, which is strong but reversible, allowing for disassembly when needed. Tops may be glued on with diluted glue, since some repairs call for the removal of the top. Theoretically, hide glue is weaker than the body's wood, so as the top or back shrinks side-to-side, the glue holding it lets go and the plate does not crack. Cellists repairing cracks in their cello do not use regular wood glue, because it cannot be steamed open when a repair has to be made by a luthier.
Traditionally, bows are made from pernambuco or brazilwood. Both come from the same species of tree ("Caesalpinia echinata"), but pernambuco, used for higher-quality bows, is the heartwood of the tree and is darker in color than brazilwood (which is sometimes stained to compensate). Pernambuco is a heavy, resinous wood with great elasticity, which makes it an ideal wood for instrument bows. Horsehair is stretched out between the two ends of the bow. The taut horsehair is drawn over the strings to produce the cello's characteristic tone. A small knob is twisted to increase or decrease the tension of the horsehair. The tension on the bow is released when the instrument is not being used. The amount of tension a cellist puts on the bow hair depends on the preferences of the player, the style of music being played, and for students, the preferences of their teacher.
Bows are also made from other materials, such as carbon fibre—stronger than wood—and fiberglass (often used to make inexpensive, lower-quality student bows). An average cello bow is long (shorter than a violin or viola bow) high (from the frog to the stick) and wide. The frog of a cello bow typically has a rounded corner like that of a viola bow, but is wider. A cello bow is roughly heavier than a viola bow, which in turn is roughly heavier than a violin bow. 
Bow hair is traditionally horsehair, though synthetic hair, in varying colors, is also used. Prior to playing, the musician tightens the bow by turning a screw to pull the frog (the part of the bow under the hand) back, and increase the tension of the hair. Rosin is applied by the player to make the hair sticky. Bows need to be re-haired periodically. Baroque style (1600–1750) cello bows were much thicker and were formed with a larger outward arch when compared to modern cello bows. The inward arch of a modern cello bow produces greater tension, which in turn gives off a louder sound.
The cello bow has also been used to play electric guitars. Jimmy Page pioneered its application on tracks such as "Dazed and Confused". The post-rock Icelandic band Sigur Rós's lead singer often plays a guitar using a cello bow.
In 1989, the German cellist Michael Bach began developing a curved bow, encouraged by John Cage, Dieter Schnebel, Mstislav Rostropovich and Luigi Colani: and since then many pieces have been composed especially for it. This curved bow ("BACH.Bow") is a convex curved bow which, unlike the ordinary bow, renders possible polyphonic playing on the various strings of the instrument. The solo repertoire for violin and cello by J. S. Bach the BACH.Bow is particularly suited to it: and it was developed with this in mind, polyphonic playing being required, as well as monophonic.
When a string is bowed or plucked, it vibrates and moves the air around it, producing sound waves. Because the string is quite thin, not much air is moved by the string itself, and consequently if the string was not mounted on a hollow body, the sound would be weak. In acoustic stringed instruments such as the cello, this lack of volume is solved by mounting the vibrating string on a larger hollow wooden body. The vibrations are transmitted to the larger body, which can move more air and produce a louder sound. Different designs of the instrument produces variations in the instrument’s vibrational patterns and thus changes the character of the sound produced. A string’s fundamental pitch can be adjusted by changing its stiffness, which depends on tension and length. Tightening a string stiffens it by increasing both the outward forces along its length and the net forces it experiences during a distortion. A cello can be tuned by adjusting the tension of its strings, by turning the tuning pegs mounted on its pegbox, and tension adjusters (fine tuners) on the tail piece.
A string's length also affects its fundamental pitch. Shortening a string stiffens it by increasing its curvature during a distortion and subjecting it to larger net forces. Shortening the string also reduces its mass, but does not alter the mass per unit length, and it is the latter ratio rather than the total mass which governs the frequency. The string vibrates in a standing wave whose speed of propagation is given by , where "T" is the tension and "m" is the mass per unit length; there is a node at either end of the vibrating length, and thus the vibrating length "l" is half a wavelength. Since the frequency of any wave is equal to the speed divided by the wavelength, we have frequency = . (Note that some writers, including Muncaster (cited below) use the Greek letter "μ" in place of "m".) Thus shortening a string increases the frequency, and thus the pitch. Because of this effect, you can raise and change the pitch of a string by pressing it against the fingerboard in the cello’s neck and effectively shortening it. Likewise strings with less mass per unit length, if under the same tension, will have a higher frequency and thus higher pitch than more massive strings. This is a prime reason why the different strings on all string instruments have different fundamental pitches, with the lightest strings having the highest pitches.
A played note of E or F-sharp has a frequency which is often very close to the natural resonating frequency of the body of the instrument, and if the problem is not addressed this can set the body into near resonance. This may cause an unpleasant sudden amplification of this pitch, and additionally a loud beating sound results from the interference produced between these nearby frequencies; this is known as the “wolf tone” because it is an unpleasant growling sound. The wood resonance appears to be split into two frequencies by the driving force of the sounding string. These two periodic resonances beat with each other. This wolf tone must be eliminated or significantly reduced for the cello to play the nearby notes with a pleasant tone. This can be accomplished by modifying the cello front plate, attaching a wolf eliminator (a metal cylinder or a rubber cylinder encased in metal), or moving the sound post.
When a string is bowed or plucked to produce a note, the fundamental note is accompanied by higher frequency overtones. Each sound has a particular recipe of frequencies that combine to make the total sound.
Playing the cello is done while seated with the instrument supported on the floor by the endpin. The left hand fingertips stop the strings on the fingerboard, determining the pitch of the fingered note. The right hand plucks or bows the strings to sound the notes. The left hand fingertips stop the strings along their length, determining the pitch of each fingered note. Stopping the string closer to the bridge results in higher-pitched sound, because the vibrating string length has been shortened. In the "neck" positions (which use just less than half of the fingerboard, nearest the top of the instrument), the thumb rests on the back of the neck; in "thumb position" (a general name for notes on the remainder of the fingerboard) the thumb usually rests alongside the fingers on the string and the side of the thumb is used to play notes. The fingers are normally held curved with each knuckle bent, with the fingertips in contact with the string. If a finger is required on two (or more) strings at once to play perfect fifths (in double stops or chords) it is used flat. In slower, or more expressive playing, the contact point can move slightly away from the nail to the pad of the finger, allowing a fuller vibrato.
Vibrato is a small oscillation in the pitch of a note, usually considered an expressive technique. Harmonics played on the cello fall into two classes; natural and artificial. Natural harmonics are produced by lightly touching (but not depressing) the string with the finger at certain places, and then bowing (or, rarely, plucking) the string. For example, the halfway point of the string will produce a harmonic that is one octave above the unfingered (open) string. Natural harmonics only produce notes that are part of the harmonic series on a particular string. Artificial harmonics (also called false harmonics or stopped harmonics), in which the player depresses the string fully with one finger while touching the same string lightly with another finger, can produce any note above middle C. 
Glissando (Italian for "sliding") is an effect played by sliding the finger up or down the fingerboard without releasing the string. This causes the pitch to rise and fall smoothly, without separate, discernible steps.
In cello playing, the bow is much like the breath of a wind instrument player. Arguably, it is the major factor in the expressiveness of the playing. The right hand holds the bow and controls the duration and character of the notes. The bow is drawn across the strings roughly halfway between the end of the fingerboard and the bridge, in a direction perpendicular to the strings. The bow is held and manipulated with all five fingers of the right hand, the thumb opposite the fingers and closer to the cellist's body. Tone production and volume of sound depend on a combination of several factors. The three most important ones are: bow speed, weight applied to the string, and point of contact of the bow hair with the string.
Double stops involve the playing of two notes at the same time. Two strings are fingered simultaneously, and the bow is drawn so as to sound them both at once. In pizzicato playing, the string is plucked directly with the fingers or thumb. Pizzicato is often abbreviated as "pizz.". Position of the hand is slightly over the finger board and away from the bridge.
A player using the col legno technique strikes or rubs the strings with the wood of the bow rather than the hair. In spiccato playing, the strings are not "drawn" by the bow hair but struck by it, while still retaining some horizontal motion, to generate a more percussive, crisp sound. In staccato, the player moves the bow a small distance and stops it on the string, making a short sound, the rest of the written duration being taken up by silence. 
Legato is a technique where the notes are smoothly connected without accents or breaks. It is noted by a slur (curved line) above or below – depending on their position on the staff – the notes of the passage that is to be played legato.
"Sul ponticello" ("on the bridge") refers to bowing closer to the bridge, while "sul tasto" ("on the fingerboard") calls for bowing nearer the end of the fingerboard. Sul tasto produces a more flute-like sound, with more emphasis on the fundamental frequency of the note, and softened overtones.
Standard-sized cellos are referred to as "full-size" or "" but are also made in smaller (fractional) sizes, including , , , , , , and . The fractions refer to volume rather than length, so a 1/2 size cello is much longer than half the length of a full size. The smaller cellos are identical to standard cellos in construction, range, and usage, but are simply scaled-down for the benefit of children and shorter adults.
Cellos in sizes larger than do exist, and cellists with unusually large hands may require such a non-standard instrument. Cellos made before approximately 1700 tended to be considerably larger than those made and commonly played today. Around 1680, changes in string-making technology made it possible to play lower-pitched notes on shorter strings. The cellos of Stradivari, for example, can be clearly divided into two models: the style made before 1702, characterized by larger instruments (of which only three exist in their original size and configuration), and the style made during and after 1707, when Stradivari began making smaller cellos. This later model is the design most commonly used by modern luthiers. The scale length of a cello is about . The new size offered fuller tonal projection and greater range of expression. The instrument in this form was able to contribute to more pieces musically and offered the possibility of greater physical dexterity for the player to develop technique.
There are many accessories for the cello.
Cellos are made by luthiers, specialists in building and repairing stringed instruments, ranging from guitars to violins. The following luthiers are notable for the cellos they have produced:
A person who plays the cello is called a "cellist". For a list of notable cellists, see the list of cellists and .
Specific instruments are famous (or become famous) for a variety of reasons. An instrument's notability may arise from its age, the fame of its maker, its physical appearance, its acoustic properties, and its use by notable performers. The most famous instruments are generally known for all of these things. The most highly prized instruments are now collector's items, and are priced beyond the reach of most musicians. These instruments are typically owned by some kind of organization or investment group, which may loan the instrument to a notable performer. (For example, the Davidov Stradivarius, which is currently in the possession of one of the most widely known living cellists, Yo-Yo Ma, is actually owned by the Vuitton Foundation.)
Some notable cellos:
"La Mariée", a 1950 painting by Marc Chagall which is prominently featured in the 1999 film "Notting Hill", portrays a goat playing a cello.

</doc>
<doc id="6559" url="https://en.wikipedia.org/wiki?curid=6559" title="Control store">
Control store

A control store is the part of a CPU's control unit that stores the CPU's microprogram. It is usually accessed by a microsequencer. A control store implementation whose contents are unalterable is known as a Read Only Memory (ROM) or Read Only Storage (ROS); one whose contents are alterable is known as a Writable Control Store (WCS).
Early control stores were implemented as a diode-array accessed via address decoders, a form of read-only memory. This tradition dates back to the "program timing matrix" on the MIT Whirlwind, first described in 1947. Modern VLSI processors instead use matrices of field-effect transistors to build the ROM and/or PLA structures used to control the processor as well as its internal sequencer in a microcoded implementation. IBM System/360 used a variety of techniques: CCROS (Card Capacitor Read-Only Storage) on the Model 30, TROS (Transformer Read-Only Storage) on the Model 40, and BCROS (Balanced Capacitor Read-Only Storage) on the Model 50.
Some computers were built using "writable microcode" — rather than storing the microcode in ROM or hard-wired logic, the microcode was stored in a RAM called a "writable control store" or "WCS". Such a computer is sometimes called a "Writable Instruction Set Computer" or "WISC". Many of these machines were experimental laboratory prototypes, such as the WISC CPU/16 and the RTX 32P.
The original System/360 models had read-only control store, but later System/360, System/370 and successor models loaded part or all of their microprograms from floppy disks or other DASD into a writable control store consisting of ultra-high speed random-access read-write memory. The System/370 architecture included a facility called Initial-Microprogram Load (IML or IMPL) that could be invoked from the console, as part of Power On Reset (POR) or from another processor in a tightly coupled multiprocessor complex. This permitted IBM to easily repair microprogramming defects in the field. Even when the majority of the control store is stored in ROM, computer vendors would often sell writable control store as an option, allowing the customers to customize the machine's microprogram. Other vendors, e.g., IBM, use the WCS to run microcode for emulator features and hardware diagnostics.
Other commercial machines that used writable microcode include the Burroughs Small Systems (1970s and 1980s), the Xerox processors in their Lisp machines and Xerox Star workstations, the DEC VAX 8800 ("Nautilus") family, and the Symbolics L- and G-machines (1980s). Some DEC PDP-10 machines stored their microcode in SRAM chips (about 80 bits wide x 2 Kwords), which was typically loaded on power-on through some other front-end CPU. Many more machines offered user-programmable writable control stores as an option (including the HP 2100, DEC PDP-11/60 and Varian Data Machines V-70 series minicomputers).
The Mentec M11 and Mentec M1 stored its microcode in SRAM chips, loaded on power-on through another CPU.
The Data General Eclipse MV/8000 ("Eagle") had a SRAM writable control store, loaded on power-on through another CPU.
WCS offered several advantages including the ease of patching the microprogram and, for certain hardware generations, faster access than ROMs could provide. User-programmable WCS allowed the user to optimize the machine for specific purposes.
Some CPU designs compile the instruction set to a writable RAM or FLASH inside the CPU (such as the Rekursiv processor and the Imsys Cjip), or an FPGA (reconfigurable computing).
Several Intel CPUs in the x86 architecture family have writable microcode, starting with the Pentium Pro in 1995.
This has allowed bugs in the Intel Core 2 microcode and Intel Xeon microcode to be fixed in software, rather than requiring the entire chip to be replaced.
Such fixes can be installed by Linux, FreeBSD, Microsoft Windows, or the motherboard BIOS.
The control store usually has a register on its outputs. The outputs that go back into the sequencer to determine the next address have to go through some sort of register to prevent the creation of a race condition. In most designs all of the other bits also go through a register. This is because the machine will work faster if the execution of the next microinstruction is delayed by one cycle. This register is known as a pipeline register. Very often the execution of the next microinstruction is dependent on the result of the current microinstruction, which will not be stable until the end of the current microcycle. It can be seen that either way, all of the outputs of the control store go into one big register. Historically it used to be possible to buy EPROMs with these register bits on the same chip.
The clock signal determining the clock rate, which is the cycle time of the system, primarily clocks this register.

</doc>
<doc id="6561" url="https://en.wikipedia.org/wiki?curid=6561" title="Columba">
Columba

Columba (, 'church dove'; Scots Gaelic: "Calum Cille", ; 7 December 521 – 9 June 597) was an Irish abbot and missionary evangelist credited with spreading Christianity in what is today Scotland at the start of the Hiberno-Scottish mission. He founded the important abbey on Iona, which became a dominant religious and political institution in the region for centuries. He is the patron saint of Derry. He was highly regarded by both the Gaels of Dál Riata and the Picts, and is remembered today as a Catholic saint and one of the Twelve Apostles of Ireland. In Ireland, he is commonly known as Colmcille.
Columba studied under some of Ireland's most prominent church figures and founded several monasteries in the country. Around 563 he and his twelve companions crossed to Dunaverty near Southend, Argyll, in Kintyre before settling in Iona in Scotland, then part of the Ulster kingdom of Dál Riata, where they founded a new abbey as a base for spreading Celtic Christianity among the northern Pictish kingdoms who were pagan. He remained active in Irish politics, though he spent most of the remainder of his life in Scotland. Three surviving early medieval Latin hymns may be attributed to him.
Columba was born to Fedlimid and Eithne of the Cenel Conaill in Gartan, a district beside Lough Gartan, in Tír Chonaill (mainly modern County Donegal) in the north of Ireland. On his father's side, he is claimed as being great-great-grandson of Niall of the Nine Hostages, a pseudo-historical Irish high king of the 5th century. He was baptised in Temple-Douglas, in the County Donegal parish of Conwal (midway between Gartan and Letterkenny), by his teacher and foster-uncle Cruithnechán. It is not known for sure if his name at birth was Colmcille or if he adopted this name later in life; Adomnán (Eunan) of Iona thought it was his birth name but other Irish sources have claimed his name at birth was Crimthann (meaning 'fox'). In the Irish language his name means 'dove', which is the same name as the Prophet Jonah (Jonah in Hebrew is also 'dove'), which Adomnán of Iona as well as other early Irish writers were aware of, although it is not clear if he was deliberately named after Jonah or not.
When sufficiently advanced in letters he entered the monastic school of Movilla, at Newtownards, under Finnian of Movilla who had studied at Ninian's "Magnum Monasterium" on the shores of Galloway. He was about twenty, and a deacon when, having completed his training at Movilla, he travelled southwards into Leinster, where he became a pupil of an aged bard named Gemman. On leaving him, Columba entered the monastery of Clonard, governed at that time by Finnian, noted for sanctity and learning. Here he imbibed the traditions of the Welsh Church, for Finnian had been trained in the schools of Saint David.
In early Christian Ireland the druidic tradition collapsed due to the spread of the new Christian faith. The study of Latin learning and Christian theology in monasteries flourished. Columba became a pupil at the monastic school at Clonard Abbey, situated on the River Boyne in modern County Meath. During the sixth century, some of the most significant names in the history of Celtic Christianity studied at the Clonard monastery. The average number of scholars under instruction at Clonard was said to be 300. Columba was one of twelve students of St Finnian who became known as the Twelve Apostles of Ireland. He became a monk and eventually was ordained a priest.
Another preceptor of Columba was St Mobhi, whose monastery at Glasnevin was frequented by such famous men as St Canice, St. Comgall, and St Ciarán. A pestilence which devastated Ireland in 544 caused the dispersion of Mobhi's disciples, and Columba returned to Ulster, the land of his kindred. He was a striking figure of great stature and powerful build, with a loud, melodious voice which could be heard from one hilltop to another. The following years were marked by the foundation of several important monasteries: Derry, at the southern edge of Inishowen; Durrow, County Offaly; Kells, County Meath; and Swords. While at Derry it is said that he planned a pilgrimage to Rome and Jerusalem, but did not proceed farther than Tours. Thence he brought a copy of those gospels that had lain on the bosom of St. Martin for the space of 100 years. This relic was deposited in Derry.
Some traditions assert that sometime around 560 Columba became involved in a quarrel with Finnian of Moville of Movilla Abbey over a psalter. Columba copied the manuscript at the scriptorium under Finnian, intending to keep the copy. Finnian disputed his right to keep it. There is a suggestion that this conflict resulted in the Battle of Cúl Dreimhne in Cairbre Drom Cliabh (now in County Sligo) in 561, during which many men were killed. Richard Sharpe, translator of Adomnán's Life of St. Columba (referenced in the bibliography below) makes a stern caution at this point against accepting the many references that link the battle and Columba's leaving of Ireland, even though there is evidence in the annals that Columba supported his own king against the high king. Political conflicts that had existed for some time resulted in the clan Neill's battle against King Diarmait at Cooldrevny in 561. An issue, for example, was the king's violation of the right of sanctuary belonging to Columba's person as a monk on the occasion of the murder of Prince Curnan, the Columba's kinsman. Prince Curnan of Connacht, who had fatally injured a rival in a hurling match and had taken refuge with Columba, was dragged from his protector's arms and slain by Diarmaid's men, in defiance of the rights of sanctuary.
A synod of clerics and scholars threatened to excommunicate him for these deaths, but Brendan of Birr spoke on his behalf. Eventually the process was deemed a miscarriage of justice. Columba's own conscience was uneasy, and on the advice of an aged hermit, Molaise, he resolved to expiate his sense of offence by departing Ireland. The term "exile" is used in some references. This, too, can be disputed, for the term "pilgrimage" is used more frequently in the literature about him. A marker at Stroove Beach on the Inishowen Peninsula commemorates the place where St. Columba set sail for Scotland. He left Ireland, but through the following years he would return several times in relationships with the communities he had founded there. Columba's copy of the psalter has been traditionally associated with the Cathach of St. Columba. In 574/5 during his return for the Synod of Drum Ceat he founded the monastery of Drumcliff in Cairbre, now County Sligo, near the battlefield.
In 563, he travelled to Scotland with twelve companions (said to include Odran of Iona) in a wicker currach covered with leather. According to legend he first landed on the Kintyre Peninsula, near Southend. However, being still in sight of his native land, he moved farther north up the west coast of Scotland. The island of Iona was made over to him by his kinsman Conall mac Comgaill King of Dál Riata, who perhaps had invited him to come to Scotland in the first place. However, there is a sense in which he was not leaving his native people, as the Ulster Gaels had been colonising the west coast of Scotland for the previous couple of centuries. Aside from the services he provided guiding the only centre of literacy in the region, his reputation as a holy man led to his role as a diplomat among the tribes. There are also many stories of miracles which he performed during his work to convert the Picts, the most famous being his encounter with an unidentified animal that some have equated with the Loch Ness Monster in 565. It is said that he banished a ferocious "water beast" to the depths of the River Ness after it had killed a Pict and then tried to attack Columba's disciple named Lugne (see Vita Columbae Book 2 below). He visited the pagan King Bridei, King of Fortriu, at his base in Inverness, winning Bridei's respect, although not his conversion. He subsequently played a major role in the politics of the country. He was also very energetic in his work as a missionary, and, in addition to founding several churches in the Hebrides, he worked to turn his monastery at Iona into a school for missionaries. He was a renowned man of letters, having written several hymns and being credited with having transcribed 300 books. One of the few, if not the only, times he left Scotland was towards the end of his life, when he returned to Ireland to found the monastery at Durrow.
Columba died in Iona on a Sunday, 9 June 597, and was buried by his monks in the abbey he created. In 794 the Vikings descended on Iona. Columba's relics were finally removed in 849 and divided between Scotland and Ireland. The parts of the relics which went to Ireland are reputed to be buried in Downpatrick, County Down, with Saint Patrick and Brigid of Kildare or at Saul Church neighbouring Downpatrick. (Names of Iona), Inchcolm and Eilean Chaluim Chille.
Colmcille is one of the three patron saints of Ireland, after Patrick and Brigid of Kildare.
Colmcille is the patron-saint of the city of Derry, where he founded a monastic settlement in c. 540. The name of the city in Irish is "Doire Colmcille" and is derived from the native oak trees in the area and the city's association with Colmcille. The Catholic Church of Saint Colmcille's Long Tower, and the Church of Ireland St Augustine's Church both claim to stand at the spot of this original settlement. The Church of Ireland Cathedral, St Columb's Cathedral, and the largest park in the city, St. Columb's Park, are named in his honour.
St. Columba's Primary School in Drumcondra is a girl's school named after the saint.
St. Colmcille's Primary School and St. Colmcille's Community School are two schools in Knocklyon, Dublin, named after him, with the former having an annual day dedicated to the saint on 9 June.
The town of Swords, Dublin was reputedly founded by Colmcille in 560 AD. St Colmcille's Boys’ National School and St. Colmcille's Girls’ National School, both located in the town of Swords, are also named after the Saint as is one of the local gaelic teams, Naomh Colmcille.
The Columba Press, a religious and spiritual book company based in Dublin, is named after Colmcille.
Aer Lingus, Ireland's national flag carrier has named one of its Airbus A330 aircraft in commemoration of the saint (reg: EI-DUO).
Columba is credited as being a leading figure in the revitalisation of monasticism. The Clan Malcolm/Clan McCallum claims its name from Columba and was reputedly founded by the descendants of his original followers. It is also said that Clan Robertson Clan Donnachaidh / Duncan are heirs of Columba. Clan MacKinnon may also have some claim to being spiritual descendants of St Columba as after he founded his monastery on Isle Iona, the MacKinnons were the abbots of the Church for centuries. This would also account for the fact that Clan MacKinnon is amongst the ancient clans of Scotland.
The cathedral of the Catholic Diocese of Argyll and the Isles is placed under the patronage of Saint Columba, as are numerous Catholic schools and parishes throughout the nation. The Scottish Episcopal Church, the Church of Scotland, and the Evangelical Lutheran Church of England also have parishes dedicated to him. The village of Kilmacolm in Renfrewshire is also derived from Colmcille's name.
St Columba's Hospice, a prominent hospice in Edinburgh, is named after the saint.
Columba currently has two poems attributed to him: "Adiutor Laborantium" and "Altus Prosator". Both poems are examples of Abecedarian hymns in Latin written while Columba was at the Iona Abbey.
The shorter of the two poems, "Adiutor Laborantium" consists of twenty-seven lines of eight syllables each, with each line following the format of an Abecedarian hymn using the Classical Latin alphabet save for lines 10-11 and 25–27. The content of the poem addresses God as a helper, ruler, guard, defender and lifter for those who are good and an enemy of sinners whom he will punish.
"Altus Prosator" consists of twenty-three stanzas sixteen syllables long, with the first containing seven lines and six lines in each subsequent stanza. It uses the same format and alphabet as "Adiutor Laborantium" except with each stanza starting with a different letter rather than each line. The poem tells a story over three parts split into the beginning of time, history of Creation, and the Apocalypse or end of time.
As of 2011, Canadians who are of Scottish ancestry are the third largest ethnic group in the country and thus Columba's name is to be found attached to Catholic, Anglican and Presbyterian parishes. This is particularly the case in eastern Canada, apart from French-speaking Quebec.
Throughout the US there are numerous parishes within the Catholic and Episcopalian denominations dedicated to Columba. Within the Protestant tradition the Presbyterian Church (which has its roots in Scottish Presbyterianism) also has parishes named in honour of Columba. There is even an Orthodox Church monastery dedicated to the saint in the Massachusetts town of Southbridge. Columba is the patron saint of the Roman Catholic Diocese of Youngstown, Ohio. The Cathedral there is named for him.
Iona College, a small Catholic liberal arts college in New Rochelle, New York, is named after the island on which Columba established his first monastery in Scotland, as is Iona College in Windsor, Ontario, Iona Presentation College, Perth, and Iona College Geelong in Charlemont, Victoria.
There are at least four pipe bands named for him; one each from Tullamore, Ireland, from Derry, Northern Ireland, from Kearny, New Jersey, and from Cape Cod, Massachusetts.
St. Columba's School one of the most prominent English-Medium schools in India run by the Irish Christian Brothers is also named after the saint.
The Munich GAA is named München Colmcilles.
Saint Columba's Feast Day, 9 June, has been designated as International Celtic Art Day. The Book of Kells and the Book of Durrow, great medieval masterpieces of Celtic art, are associated with Columba.
Benjamin Britten composed "A Hymn of St Columba" for choir and organ in 1962, setting a poem by the saint, on the occasion of the 1,400th anniversary of his voyage to Iona.
The main source of information about Columba's life is the Vita Columbae, a hagiography written in the style of "saint's lives" narratives that had become widespread throughout medieval Europe. Compiled and drafted by scribes and clergymen, these accounts were written in Latin and served as written collections of the deeds and miracles attributed to the saint, both during his or her life or after death. The canonization of a saint, especially one who had lived on the fringes of the medieval Christian world like Columba, required a well-written hagiography to be submitted to Rome, but popular belief and local cults of sainthood often led to the veneration of these men and women without official approval from the Church.
Writing a century after the death of Columba, the author Adomnán (also known as Eunan), served as the ninth Abbot of Iona until his death in 704. James Earle Fraser asserts that Adomnán drew extensively from an existing body of accounts regarding the life of Columba, including a Latin collection entitled "De uirtutibus sancti Columbae", composed c. 640 A.D. This earlier work is attributed to Cummene Find, who became the abbot of Iona and served as the leader of the monastic island community from 656 until his death in 668 A.D. or 669 A.D.
While the Vita Columbae often conflicts with contemporaneous accounts of various battles, figures, and dates, it remains the most important surviving work from early medieval Scotland and provides a wealth of knowledge regarding the Picts and other ethnic and political groups from this time period. The Vita also offers a valuable insight into the monastic practices of Iona and the daily life of the early medieval Gaelic monks.
The surviving manuscripts include:
Instead of relying on chronological order, Adomnán categorises the events recorded in the "Vita Columbae" into three different books: Columba's Prophecies, Columba's Miracles, and Columba's Apparitions.
In the first book, the author Adomnán lists Columba's prophetic revelations, which come as a result of the his ability to view the present and the future simultaneously. Most of the short chapters begin with Columba informing his fellow monks that a person will soon arrive on the island or an event will imminently occur.
In one notable instance, Columba appears in a dream to King Oswald of Northumbria, and announces the king's incoming victory against the King Catlon (Cadwallon of Wales) in the Battle of Heavenfield. The people of Britain promise to convert to Christianity and receive baptism after the conclusion of the war. This victory signals the re-Christianizing of pagan England, and establishes King Oswald as ruler of the entirety of Britain.
Columba's other prophecies include when he sends a man named Batain off to perform his penance, but then Columba turns to his friends and says Batain will instead return to Scotia and be killed by his enemies. Several of Saint Columba's prophecies reflect the scribal culture in which he was immersed, such his miraculous knowledge of the missing letter "I” from Baithene's psalter or when he prophecies that an eager man will knock over his inkhorn and spill its contents.
In the second book, Columba performs various miracles such as healing people with diseases, expelling malignant spirits, subduing wild beasts, calming storms, and even returning the dead to life. He also performs agricultural miracles that would hold a special significance to the common people of Ireland and the Britain such as when he casts a demon out of a pail and restores the spilt milk to its container.
The Vita contains a story that has been interpreted as the first reference to the Loch Ness Monster. According to Adomnán, Columba came across a group of Picts burying a man who had been killed by the monster. Columba saves a swimmer from the monster with the sign of the Cross and the imprecation, "Thou shalt go no further, nor touch the man; go back with all speed." The beast flees, terrified, to the amazement of the assembled Picts who glorified Columba's God. Whether or not this incident is true, Adomnan's text specifically states that the monster was swimming in the River Ness – the river flowing from the loch – rather than in Loch Ness itself.
In book three, Adomnán describes different apparitions of the Saint, both that Columba receives and those that are seen by others regarding him. He mentions that, "For indeed after the lapse of many years, ... St. Columba was excommunicated by a certain synod for some pardonable and very trifling reasons, and indeed unjustly" (P.79- 80).
In one of the accounts, Columba, in this period of excommunication, goes to a meeting held against him in Teilte. Brendán, despite of all the negative reactions among the seniors toward Columba, kisses him reverently and assures that Columba is the man of God and that he sees Holy Angels accompanying Columba on his journey through the plain.
In the last Chapter, Columba foresees his own death when speaking to his attendant: This day in the Holy Scriptures is called the Sabbath, which means rest. And this day is indeed a Sabbath to me, for it is the last day of my present laborious life, and on it I rest after the fatigues of my labours; and this night at midnight, which commenceth the solemn Lord's Day, I shall, according to the sayings of Scripture, go the way of our fathers. For already my Lord Jesus Christ deigneth to invite me; and to Him, I say, in the middle of this night shall I depart, at His invitation. For so it hath been revealed to me by the Lord himself. 
And when the bell strikes midnight, Columba goes to the church and kneels beside the altar. His attendant witnesses heavenly light in the direction of Columba, and angels join him in his passage to the Lord: And having given them his holy benediction in this way, he immediately breathed his last. After his soul had left the tabernacle of the body, his face still continued ruddy, and brightened in a wonderful way by his vision of the angels, and that to such a degree that he had the appearance, not so much of one dead, as of one alive and sleeping. 
Both the "Vita Columbae" and the Bede (672/673-735) record Columba's visit to Bridei. Whereas Adomnán just tells us that Columba visited Bridei, Bede relates a later, perhaps Pictish tradition, whereby Columba actually converts the Pictish king. Another early source is a poem in praise of Columba, most probably commissioned by Columba's kinsman, the King of the Uí Néill clan. It was almost certainly written within three or four years of Columba's death and is the earliest vernacular poem in European history. It consists of 25 stanzas of four verses of seven syllables each, called the Amra Coluim Chille.
Through the reputation of its venerable founder and its position as a major European centre of learning, Columba's Iona became a place of pilgrimage. Columba is historically revered as a warrior saint, and was often invoked for victory in battle.
His relics were finally removed in 849 and divided between Alba and Ireland. Relics of Columba were carried before Scottish armies in the reliquary made at Iona in the mid-8th century, called the Brecbennoch. Legend has it that the Brecbennoch was carried to the Battle of Bannockburn (24 June 1314) by the vastly outnumbered Scots army and the intercession of Columba helped them to victory. Since the 19th century the "Brecbennoch of St. Columba" has been identified with the Monymusk Reliquary, although this is now doubted by scholars.
In the Antiphoner of Inchcolm Abbey, the "Iona of the East" (situated on an island in the Firth of Forth), a 14th-century prayer begins "O Columba spes Scotorum..." "O Columbus, hope of the Scots".

</doc>
<doc id="6562" url="https://en.wikipedia.org/wiki?curid=6562" title="Conditional proof">
Conditional proof

A conditional proof is a proof that takes the form of asserting a conditional, and proving that the antecedent of the conditional necessarily leads to the consequent. 
The assumed antecedent of a conditional proof is called the conditional proof assumption (CPA). Thus, the goal of a conditional proof is to demonstrate that if the CPA were true, then the desired conclusion necessarily follows. The validity of a conditional proof does not require that the CPA be actually true, only that "if it were true" it would lead to the consequent.
Conditional proofs are of great importance in mathematics. Conditional proofs exist linking several otherwise unproven conjectures, so that a proof of one conjecture may immediately imply the validity of several others. It can be much easier to show a proposition's truth to follow from another proposition than to prove it independently.
A famous network of conditional proofs is the NP-complete class of complexity theory. There is a large number of interesting tasks, and while it is not known if a polynomial-time solution exists for any of them, it is known that if such a solution exists for any of them, one exists for all of them. Similarly, the Riemann hypothesis has many consequences already proven.
As an example of a conditional proof in symbolic logic, suppose we want to prove A → C (if A, then C) from the first two premises below:

</doc>
<doc id="6563" url="https://en.wikipedia.org/wiki?curid=6563" title="Conjunction introduction">
Conjunction introduction

Conjunction introduction (often abbreviated simply as conjunction and also called and introduction) is a valid rule of inference of propositional logic. The rule makes it possible to introduce a conjunction into a logical proof. It is the inference that if the proposition "p" is true, and proposition "q" is true, then the logical conjunction of the two propositions "p and q" is true. For example, if it is true that "it's raining", and it is true that "I'm inside", then it is true that "it's raining and I'm inside". The rule can be stated:
where the rule is that wherever an instance of "formula_2" and "formula_3" appear on lines of a proof, a "formula_4" can be placed on a subsequent line.
The "conjunction introduction" rule may be written in sequent notation:
where formula_2 and formula_3 are propositions expressed in some formal system, and formula_8 is a metalogical symbol meaning that formula_4 is a syntactic consequence if formula_2 and formula_3 are each on lines of a proof in some logical system;

</doc>
<doc id="6566" url="https://en.wikipedia.org/wiki?curid=6566" title="English in the Commonwealth of Nations">
English in the Commonwealth of Nations

The use of the English language in most current and former member countries of the Commonwealth of Nations was inherited from British colonisation. Mozambique is an exception – although English is widely spoken there, it is a former Portuguese colony which joined the Commonwealth in 1996. English is spoken as a first or second language in most of the Commonwealth. In a few countries, such as Cyprus and Malaysia, it does not have official status, but is widely used as a lingua franca.
Many regions, notably Australia, Brunei, Canada, Hong Kong, India, Ireland, Malaysia, New Zealand, Pakistan, Singapore, South Africa, Sri Lanka and the Caribbean, have developed their own native varieties of the language.
Written English as used in the current and former Commonwealth generally favours British spelling as opposed to American, with some exceptions in Canada, where there is a strong influence from neighbouring American English (collectively, the US and Canadian dialects form North American English). Few said countries besides Canada and Australia have produced their own variant comprehensive English dictionaries and style guides from major publishers, and rely on those produced in the United Kingdom, especially for formal writing.
The report of the Inter-Governmental Group on Criteria for Commonwealth Membership states that English is a symbol of Commonwealth heritage and unity.
Southern Hemisphere native varieties of English began to develop during the 18th century, with the colonisation of Australasia and South Africa. Australian English and New Zealand English are closely related to each other, and share some similarities with South African English (though it has unique influences from indigenous African languages, and Dutch influences it inherited along with the development of Afrikaans from Dutch). The vocabularies of these dialects draw from both British English (in the main) and American English (especially for recent terminology), as well as numerous native peculiarities.
Canadian English contains elements of British English and American English, as well as many Canadianisms and some French influences. It is the product of several waves of immigration and settlement, from Britain, Ireland, France, the United States, and around the world, over a period of almost two centuries. Modern Canadian English has taken significant vocabulary and spelling from the shared political and social institutions of Commonwealth countries.
Caribbean English is influenced by the English-based Creole varieties spoken, but they are not one and the same. There is a great deal of variation in the way English is spoken, with a "Standard English" at one end of a bipolar linguistic continuum and Creole languages at the other. These dialects have roots in 17th-century British and Irish English, and African languages, plus localised influences from other colonial languages including French, Spanish, and Dutch; unlike most native varieties of English, West Indian dialects often tend to be syllable-timed rather than stress-timed.
Second-language varieties of English in Africa and Asia have often undergone "indigenisation"; that is, each English-speaking community has developed (or is in the process of developing) its own standards of usage, often under the influence of local languages. These dialects are sometimes referred to as "New Englishes" (McArthur, p. 36); most of them inherited non-rhoticity from Southern British English.
Several dialects of West African English exist, with a lot of regional variation and some influence from indigenous languages. West African English tends to be syllable-timed, and its phoneme inventory is much simpler than that of Received Pronunciation; this sometimes affects mutual intelligibility with native varieties of English. A distinctive East African English, often with significant influences from Bantu languages such as Swahili, is spoken in countries such as Kenya or Tanzania, particularly in Nairobi and other cities where there is an expanding middle class, for whom English is increasingly being used in the home as the first language.
Small communities of native English speakers can be found in Zimbabwe, Botswana, and Namibia; the dialects spoken are similar to native South African English.
India has the largest English-speaking population in the Commonwealth, although comparatively few speakers of Indian English are first-language speakers. The same is true of English spoken in other parts of South Asia, e.g. Pakistani English, Sri Lankan English, and Bangladeshi English. South Asian English phonology is highly variable; stress, rhythm and intonation are generally different from those of native varieties. There are also several peculiarities at the levels of morphology, syntax and usage, some of which can also be found among educated speakers.
Southeast Asian English comprises Singapore English, Malaysian English, and Brunei English; it features some influence from Malay and Chinese languages, as well as Indian English.
Hong Kong ceased to be part of the Commonwealth in 1997. Nonetheless, the English language there still enjoys status as an official language.
Other languages:

</doc>
<doc id="6569" url="https://en.wikipedia.org/wiki?curid=6569" title="Charles McCarry">
Charles McCarry

Charles McCarry (June 14, 1930 – February 26, 2019) was an American writer, primarily of spy fiction, and a former undercover operative for the Central Intelligence Agency whom "The Wall Street Journal" described in 2013 as "the dean of American spy writers"; "The New Republic" magazine calls him "poet laureate of the CIA."; and Otto Penzler says he has produced some "poetic masterpieces". William Zinsser calls him a "political novelist:" Jonathan Yardley, Pulitzer Prize-winning critic for the "Washington Post", calls him a "'serious' novelist" whose work may include "the best novel ever written about life in high-stakes Washington, DC." P.J. O'Rourke called him "the best modern writer on the subject of intrigue." O'Rourke learned about McCarry from a working covert operative who called McCarry "very realistic."
His family came from The Berkshires area of western Massachusetts, McCarry was born in Pittsfield, and he lived in Virginia.
McCarry believed that "the best novels are about ordinary things: love, betrayal, death, trust, loneliness, marriage, fatherhood." He also said "if you write a political novel, you're writing what you believe instead of what you know."
McCarry said, "the themes of my novels have been ordinary things – love, death, betrayal and the American dream."
In a 1988 essay published in the Washington "Post", McCarry wrote, "[I]n 1973 when I turned in the manuscript of my novel "The Tears of Autumn", [the publisher] summoned me to New York and, in his office high above lower Park Avenue, banged the manuscript on his desk. ‘This book is talky, it's slow, and nobody is going to believe a goddamn word of the plot,’ he said. ‘Where's the car chase? Where's the torture scene? Where's the sex? Where's the good Russian? Do you call this a thriller?’ ‘No,’ I said. He didn't hear me."
McCarry wrote that: "After I resigned [from the CIA], intending to spend the rest of my life writing fiction and knowing what tricks the mind can play when the gates are thrown wide open, as they are by the act of writing, between the imagination and that part of the brain in which information is stored, I took the precaution of writing a closely remembered narrative of my clandestine experiences. After correcting the manuscript, I burned it.
What I kept for my own use was the atmosphere of secret life: How it worked on the five senses and what it did to the heart and mind. All the rest went up in flames, setting me free henceforth to make it all up. In all important matters, such as the creation of characters and the invention of plots, with rare and minor exceptions, that is what I have done. And, as might be expected, when I have been weak enough to use something that really happened as an episode in a novel, it is that piece of scrap, buried in a landfill of the imaginary, readers invariably refuse to believe."
Throughout McCarry's fiction are statements and descriptions such as "the average intelligence officer is a sort of latter-day Marcel Proust. He lies abed in a cork-lined room, hoping to profit by secrets that other people slip under the door."
Snippets from McCarry's CIA years can be found in his non-fiction writing for newspapers. For example, "In the early days of the cold war, a colleague of mine who had worked his way through college playing the saxophone was recruited by a certain United States intelligence agency. For his first assignment, he was posted to Cambodia and told to find an apartment near the royal palace, open the windows at night, and play “Muskrat Ramble.” Prince Sihanouk, the eccentric ruler of the country, was reputed to be an amateur musician who loved jazz and had his own band. Who knew but what he might hear that plaintive sax in the jungle night and invite the nice young American to come on over and sit in?"
A critic for "Tin House" magazine approaches McCarry through what the critic calls "the art of the sentence," citing as an example a description in the opening pages of McCarry's "The Secret Lovers": “The sun shone feebly through the overcast, like a lamp covered by a woman’s scarf in a shabby hotel room.”
A recurrent statement found in McCarry's non-fiction writing is that events in real life are so strange that if presented as fiction no one would believe them.
McCarry's novels were all republished in 2005—which means major critics revisited his work—some of which was more than a third-of-a-century old Rereading "The Tears of Autumn" one critic called it "a perfect spy novel."
McCarry said in 1995, "If I had to do it over again, I would have written novels about a pediatrician, anonymously." Why? Because he thinks of himself as a novelist, not a writer of spy fiction. And yet, almost all of his novels—including the non-Paul Christopher books—have a strong focus on espionage.
McCarry began his writing career in the United States Army as a correspondent for "Stars and Stripes". Afterwards, in the 1950s, serving as a speechwriter in the early Administration of President Dwight D. Eisenhower; a typical McCarry item was the 1953 Labor Day Proclamation, which read, in part, "Free American labor has won for itself the enjoyment of a standard of living unmatched in history. The contemporary world knows no comparison with it. There is only brutal contrast to it. To this, there is no more pitiful and dramatic testimony than the food which this free people has been able to send to feed hundreds of thousands suffering the peculiar torments of the proletarian paradise of Eastern Germany." In the late 1950s, he accepted a post with the CIA, for whom he traveled the globe as a deep cover operative—his son, Nathan McCarry, CEO of Pluribus International Corporation, in 2014 described his father's work for the CIA as "trying for the family." He left the CIA, in 1967, becoming a writer of spy novels McCarry rarely spoke or wrote directly about those years, saying simply, "For a decade at the height of the Cold War, I worked abroad under cover as an intelligence agent."
In the mid-to-late 1970s, several books by former CIA operatives helped trigger and fuel what became known as the U.S. Senate Church Committee hearings that resulted in legislation limiting the power and secrecy of the CIA. McCarry had been "outed"—publicly identified as a secret CIA operative—in 1975, but was never called to testify.
McCarry was an editor-at-large for "National Geographic" and contributed pieces to "The New York Times", "The Wall Street Journal", "The Washington Post", the "Saturday Evening Post," and other national publications.
In as essay published by the "Washington Post", he said that "for a writer in America, going out to dinner is like living as an American in Europe: Total strangers think they can say anything they like to you."
Ten of McCarry's novels involve the life story of a fictional character named Paul Christopher, who — in McCarry's telling — grew up in pre-Nazi Germany, and later served in the Marines and became an operative for a U.S. government entity that is clearly the Central Intelligence Agency.
These books are, in order of publication:
Alternately, in chronological order of events depicted:
The Paul Christopher novels, together and separately, resemble a Christopher Nolan movie in that time sequences become jumbled; e.g. only as Paul Christopher becomes an old man do readers learn about his parents and childhood.
One critic notes that “As far as recurring characters go, one must look to John Updike’s ‘Rabbit’ Angstrom books or Philip Roth's Nathan Zuckerman novels for equivalents in the scope and breadth of what McCarry accomplishes with one character and his movements through the events of the twentieth century.” 
"It’s tempting to say that Charles McCarry’s "The Tears of Autumn" is the greatest espionage novel ever written by an American, if only because it’s hard to conceive of one that could possibly be better. But since no one can claim to have read every America espionage novel ever written, let’s just say that "The Tears of Autumn" is a perfect spy novel, and that its hero, Paul Christopher, should by all rights be known the world over as the thinking man’s James Bond — and woman’s too."—Brendan Bernard, "The Great American Spy Novel," March 31, 2005', LA Weekly"
""Old Boys" is a large yarn that will make yummy reading between long looks at Nantucket Sound this summer. (And a boffo movie in the right hands.) But it is a tale that travels from the outlandish to the absurd. As long as readers don't expect the taut realism we have come to expect from the man, they'll be fine. If they're looking for vintage McCarry, though, this will produce unhappy campers. The book does not approach his better grownup fiction. It is not in the same league, for example, with "The Miernik Dossier", the small gem that made McCarry's career. Rather, it is something of a "Treasure Island" for lovers of spook fiction, a near-juvenile adventure that entrances adults who know better with fabulous writing. What they do get is a fleeting reprise of McCarry's great creation, Paul Christopher. Christopher, the spy whom many first met in McCarry's bestseller "The Tears of Autumn", is now an opaque older man and an ascetic survivor of a Chinese prison camp."--Sam Allis, "McCarry's thriller 'Old Boys' is a trip past believable," Boston "Globe", July 26, 2004.
McCarry's most recent work has been cited for its "postmodern skepticism" and "epistemic aporia"--"literary reconstruction that profess to unmask" state-sponsored secrecy. These judgments are based on the work of Robert Snyder.
In 2007, novelist and former presidential speechwriter Patrick Andersson wrote that “a new generation of American spy novelists soon began [in the 1970s] to produce a body of work that has surpassed that of current British writers. The four most important are Charles McCarry, Robert Littell, Daniel Silva, and Alan Furst” 
--"...the most credible account of President Kennedy’s assassination. You will believe it’s what really happened."--"New York" magazine on "Tears of Autumn"—In "Lucky Bastards", JFK seems to have an illegitimate son. In real life, no such person is known to exist.
--In "Tears", Paul Christopher wakes up ten days after the JFK killing and intuitively and instantly knows "who had arranged the death of the President"—the family and followers of recently assassinated South Vietnamese leader Ngo Dinh Diem and his two brothers. In real life, the wife of one of Diem's murdered brothers attracted media attention for predicting the JFK assassination ("Anything that happens in Vietnam will find its equivalent in the United States"), and later telling reporters that JFK had got what he deserved.
--McCarry was a top aide to Henry Cabot Lodge, traveling with him as chief speechwriter in 1960, for example, when Lodge was the Republican Party's vice presidential candidate. After losing the election, Lodge served as U.S. Ambassador to South Vietnam under JFK, and in that capacity played an active role in the plot to assassinate Diem—which McCarry used as the center of action in "The Tears of Autumn".
Note: In McCarry's fiction, the CIA is called "the Outfit."
—Computer algorithms that analyses media content and specify—with accuracy—when a physical war between two countries will break out. "The Better Angels", 1979.—Terrorist suicide bombers appear in "Better Angels" (1979); the "New York Times" first reported this form of terrorism in 1983, when describing the Lebanese civil war. Suicide terrorists use fully loaded passenger planes as weapons in "Better Angels"—which did not occur in real life until September 11, 2001.
--Suicide bombers begin to blow themselves up at American iconic sites like the Alamo. The Lincoln Memorial and Rotunda of the U.S. Capitol soon follow.—On June 10. 2004, the "Wall Street Journal" published a review entitled, "He Has Seen The Future: It's in His Work; Charles McCarry's novels keep coming true. And his new book is about the end of the world."—Someone who thinks he is JFK's "love child" becomes President of the U.S..--"Lucky Bastard"
--"ARK" (2004) has people equipped with "artificial hornets as their primary defensive weapon;" as of 2017, experts discuss the impending possibility of "drones the size of bumblebees that could be programmed to kill certain people, or certain categories of people, by grabbing their skulls with tiny metal talons and drilling into their head."—Worsening and more frequent earthquakes and severe storms like hurricanes threaten society in "Ark".
--Soviet KGB has long-term operative control over a person who becomes President of the U.S.-- "Lucky Bastard"—A thirty-person expedition (15 men and 15 women) lands on Ganymede, one of Jupiter's moons--"The Better Angels", p. 164.
After the collapse of the USSR, McCarry turned to China in "The Shanghai Factor", "Old Boys", "Second Sight" and "Last Supper".
—Jacob Heilbrunn writes in the "N.Y. Times" (2006): "McCarry never succumbs to a bogus moral equivalence in which Western operatives are as nefarious as their Communist counterparts. He instructs us that the real problem is not so much moral quicksand as incompetent scheming. At a moment when the C.I.A.'s travails are evoking nostalgia for a golden age when it supposedly operated effectively, McCarry offers a useful reminder that such an era never existed."
--"The truth, once discovered, is of no use: people deny what they have done, forget what they had believed, and make the same mistakes over and over again."—Paul Christopher is eating dinner with a beautiful young woman in wartime Saigon. They discuss the morality of killing. "So you believe in nothing," she says to him. "I believe in consequences," he responds.--"Tears of Autumn"
--"You think the truth will make men free. But it only makes them angry."--"Tears of Autumn".
McCarry challenged accepted wisdom about JFK by hypothesizing that Kennedy caused his own death; asserting that efforts to force Richard Nixon from the White House constituted a coup.; and giving Ronald Reagan credit for triggering the collapse of the Soviet Union.
Paul Christopher as a central character never is older than his forties—see "Tears of Autumn"—which is the same as McCarry was when he wrote it; after Tears, Christopher spends twenty (unseen) years at hard labor in a remote Chinese prison camp, and then is a minor character in his own rescue.
The novelist Alan Furst has written in "The Book of Spies" that "[Graham] Greene, [John] le Carré, [Somerset] Maugham, and McCarry write with a kind of cloaked anger, a belief that the world is a place where political power is maintained by treachery and betrayal..." In its subtitle, Furst's book calls such writing "literary espionage."
"Your name is the one key thing that cannot be taken from you," says Jan Scruggs, founder of the Vietnam Veterans Memorial, "It captures who you are and what happens to you throughout your life." In Existentialist literature, lack of a name—or of a full name—symbolizes human aloneness; the hero of Franz Kafka's "The Trial", for example is "Michael K.," and the hero of Ralph Ellison's
"Invisible Man" has no name at all. Named characters fill McCarry's last three novels, but each book's hero (in one case, heroine) never has a name; one has a "funny name" that is used for payroll and administrative paperwork, but is fictitious and meaningless. While McCarry's heroes with no name are different people in each story, the Man with No Name in three Clint Eastwood movies from the mid-1960s is the same person.
The film "Wrong is Right" (1982), starring Sean Connery, was loosely based on McCarry's novel, "The Better Angels" (1979).
McCarry was an admirer of the work of W. Somerset Maugham, especially the stories. He was also an admirer of Richard Condon, author of "The Manchurian Candidate" (1959), "Prizzi's Honor" (1982), and numerous other novels.
--Stories include: In March 1981, shortly after taking office, Ronald Reagan was shot; Secretary of State Haig appeared in the White House press room and announced, "I am in charge here!"
Otto Penzler, ed.:
Note: The fictional Paul Christopher had several books of poetry published before he joined the CIA;

</doc>
<doc id="6571" url="https://en.wikipedia.org/wiki?curid=6571" title="Cimbri">
Cimbri

The Cimbri (Greek Κίμβροι, "Kímbroi"; Latin "Cimbri") were an ancient tribe. They are generally believed to have been a Germanic tribe originating in Jutland, but Celtic influences have also been suggested.
Together with the Teutones and the Ambrones, they fought the Roman Republic between 113 and 101 BC. The Cimbri were initially successful, particularly at the Battle of Arausio, in which a large Roman army was routed, after which they raided large areas in Gaul and Hispania. In 101 BC, during an attempted invasion of Italy, the Cimbri were decisively defeated by Gaius Marius, and their king, Boiorix, was killed. Some of the surviving captives are reported to have been among the rebelling gladiators in the Third Servile War.
The origin of the name "Cimbri" is unknown. One etymology is PIE ' "inhabitant", from ' "home" (> English "home"), itself a derivation from "" "live" (> Greek , Latin "sinō"); then, the Germanic "*himbra-" finds an exact cognate in Slavic "sębrъ" "farmer" (> Croatian, Serbian "sebar", Russian сябёр "syabyor").
The name has also been related to the word "kimme" meaning "rim", i.e., "the people of the coast". Finally, since Antiquity, the name has been related to that of the Cimmerians.
Himmerland (Old Danish "Himbersysel") is generally thought to preserve their name; "Cimbri" with a "c" would be an older form without Grimm's law (PIE "k" > Germ. "h"). Alternatively, Latin "c-" represents an attempt to render the unfamiliar Proto-Germanic "h" = (Latin "h" was but was becoming silent in common speech at the time), perhaps due to Celtic-speaking interpreters (a Celtic intermediary would also explain why Germanic "*Þeuðanōz" became Latin "Teutones").
Because of the similarity of the names, the Cimbri have been at times associated with Cymry, the Welsh name for themselves. However, "Cymry" is derived from Brittonic "*Kombrogi", meaning "compatriots", and is linguistically unrelated to Cimbri.
The Cimbri are generally believed to have been a Germanic tribe originating in Jutland. Though Celtic origins have been suggested, this is controversial.
Archaeologists have not found any clear indications of a mass migration from Jutland in the early Iron Age. The Gundestrup Cauldron, which was deposited in a bog in Himmerland in the 2nd or 1st century BC, shows that there was some sort of contact with southeastern Europe, but it is uncertain if this contact can be associated with the Cimbrian expedition.
Advocates for a northern homeland point to Greek and Roman sources that associate the Cimbri with the Jutland peninsula. According to the "Res gestae" (ch. 26) of Augustus, the Cimbri were still found in the area around the turn of the 1st century AD:
The contemporary Greek geographer Strabo testified that the Cimbri still existed as a Germanic tribe, presumably in the "Cimbric peninsula" (since they are said to live by the North Sea and to have paid tribute to Augustus):
On the map of Ptolemy, the "Kimbroi" are placed on the northernmost part of the peninsula of Jutland, i.e., in the modern landscape of Himmerland south of Limfjorden (since Vendsyssel-Thy north of the fjord was at that time a group of islands).
Some time before 100 BC many of the Cimbri, as well as the Teutons and Ambrones, migrated south-east. After several unsuccessful battles with the Boii and other Celtic tribes, they appeared 113 BC in Noricum, where they invaded the lands of one of Rome's allies, the Taurisci.
On the request of the Roman consul Gnaeus Papirius Carbo, sent to defend the Taurisci, they retreated, only to find themselves deceived and attacked at the Battle of Noreia, where they defeated the Romans. Only a storm, which separated the combatants, saved the Roman forces from complete annihilation.
Now the road to Italy was open, but they turned west towards Gaul. They came into frequent conflict with the Romans, who usually came out the losers. In Commentarii de Bello Gallico the Aduaticii—Belgians of Cimbrian origin—repeatedly sided with Rome's enemies. In 109 BC, they defeated a Roman army under the consul Marcus Junius Silanus, who was the commander of Gallia Narbonensis. In 107 BC they defeated another Roman army under the consul Gaius Cassius Longinus, who was killed at the Battle of Burdigala (modern day Bordeaux) against the Tigurini, who were allies of the Cimbri.
It was not until 105 BC that they planned an attack on the Roman Republic itself. At the Rhône, the Cimbri clashed with the Roman armies. Discord between the Roman commanders, the proconsul Quintus Servilius Caepio and the consul Gnaeus Mallius Maximus, hindered Roman coordination and so the Cimbri succeeded in first defeating the legate Marcus Aurelius Scaurus and later inflicted a devastating defeat on Caepio and Maximus at the Battle of Arausio. The Romans lost as many as 80,000 men, according to Livy; Mommsen (in his "History of Rome") thought that excluded auxiliary cavalry and non-combatants who brought the total loss closer to 112,000. Other estimates are much smaller, but by any account a large Roman army was routed.
Rome was in panic, and the "terror cimbricus" became proverbial. Everyone expected to soon see the "new Gauls" outside of the gates of Rome. Desperate measures were taken: contrary to the Roman constitution, Gaius Marius, who had defeated Jugurtha, was elected consul and supreme commander for five years in a row (104–100 BC).
In 104–103 BC, the Cimbri had turned to the Iberian Peninsula where they pillaged far and wide, until they were confronted by a coalition of Celtiberians. Defeated, the Cimbri returned to Gaul, where they joined their allies, the Teutons. During this time, C. Marius had the time to prepare and, in 102 BC, he was ready to meet the Teutons and the Ambrones at the Rhône. These two tribes intended to pass into Italy through the western passes, while the Cimbri and the Tigurines were to take the northern route across the Rhine and later across the Central Eastern Alps.
At the estuary of the Isère, the Teutons and the Ambrones met Marius, whose well-defended camp they did not manage to overrun. Instead, they pursued their route, and Marius followed them. At Aquae Sextiae, the Romans won two battles and took the Teuton king Teutobod prisoner.
The Cimbri had penetrated through the Alps into northern Italy. The consul Quintus Lutatius Catulus had not dared to fortify the passes, but instead he had retreated behind the river Po, and so the land was open to the invaders. The Cimbri did not hurry, and the victors of Aquae Sextiae had the time to arrive with reinforcements. At the Battle of Vercellae, at the confluence of the river Sesia with the Po, in 101 BC, the long voyage of the Cimbri also came to an end.
It was a devastating defeat, two chieftains, Lugius and Boiorix, died on the field, while the other chieftains Caesorix and Claodicus were captured. The women killed both themselves and their children in order to avoid slavery. The Cimbri were annihilated, although some may have survived to return to the homeland where a population with this name was residing in northern Jutland in the 1st century AD, according to the sources quoted above. Some of the surviving captives are reported to have been among the rebelling gladiators in the Third Servile War.
However, Justin's epitome of Trogus, 38.4, has Mithridates the Great state that the Cimbri are ravaging Italy while the Social War is going on, i.e. at some time in 90–88 BCE, thus more than a decade later, after having sent ambassadors to the Cimbri to request military aid; judging from the context they must then have been living in North Eastern Europe at the time.
According to Julius Caesar, the Belgian tribe of the Atuatuci "was descended from the Cimbri and Teutoni, who, upon their march into our province and Italy, set down such of their stock and stuff as they could not drive or carry with them on the near (i.e. west) side of the Rhine, and left six thousand men of their company there as guard and garrison" ("Gall." 2.29, trans. Edwards). They founded the city of Atuatuca in the land of the Belgic Eburones, whom they dominated. Thus Ambiorix king of the Eburones paid tribute and gave his son and nephew as hostages to the Atuatuci ("Gall." 6.27). In the first century AD, the Eburones were replaced or absorbed by the Germanic Tungri, and the city was known as Atuatuca Tungrorum, i.e. the modern city of Tongeren.
The population of modern-day Himmerland claims to be the heirs of the ancient Cimbri. The adventures of the Cimbri are described by the Danish Nobel Prize–winning author Johannes V. Jensen, himself born in Himmerland, in the novel "Cimbrernes Tog" (1922), included in the epic cycle "Den lange Rejse" (English "The Long Journey", 1923). The so-called Cimbrian bull ("Cimbrertyren"), a sculpture by Anders Bundgaard, was erected on 14 April 1937 in a central town square in Aalborg, the capital of the region of North Jutland.
A German ethnic minority speaking the Cimbrian language, having settled in the mountains between Vicenza, Verona, and Trento in Italy (also known as Seven Communities), is also called the . For hundreds of years this isolated population and its present 4,400 inhabitants have claimed to be the direct descendants of the Cimbri retreating to this area after the Roman victory over their tribe. However, it is more likely that Bavarians settled here in the Middle Ages. Most linguists remain committed to the hypothesis of a medieval (11th to 12th century AD) immigration to explain the presence of small German-speaking communities in the north of Italy. Some genetic studies seem to prove a Celtic, not Germanic, descent for most inhabitants in the region that is reinforced by Gaulish toponyms such as those ending with the suffix "-ago" < Celtic "-*ako(n)" (e.g. Asiago is clearly the same place name as the numerous variants – Azay, Aisy, Azé, Ezy – in France, all of which derive from "*Asiacum" < Gaulish "*Asiāko(n)"). On the other hand, the original place names in the region, from the specifically localized language known as 'Cimbro' are still in use alongside the more modern names today. These indicate a different origin (e.g., Asiago is known also by its original Cimbro name of "Sleghe"). The Cimbrian origin myth was popularized by humanists in the 14th century.
Despite these connections to southern Germany, belief in a Himmerland origin persisted well into modern times. On one occasion in 1709, for instance, Frederick IV of Denmark paid the region's inhabitants a visit and was greeted as their king. The population, which kept its independence during the time of the Venice Republic, was later severely devastated by World War I. As a result, many Cimbri have left this mountainous region of Italy, effectively forming a worldwide diaspora.
The Cimbri are depicted as ferocious warriors who did not fear death. The host was followed by women and children on carts. Aged women, priestesses, dressed in white sacrificed the prisoners of war and sprinkled their blood, the nature of which allowed them to see what was to come.
Strabo gives this vivid description of the Cimbric folklore:
If the Cimbri did in fact come from Jutland, evidence that they practiced ritualistic sacrifice may be found in the Haraldskær Woman discovered in Jutland in the year 1835. Noosemarks and skin piercing were evident and she had been thrown into a bog rather than buried or cremated. Furthermore, the Gundestrup cauldron, found in Himmerland, may be a sacrificial vessel like the one described in Strabo's text. In style, the work looks like Thracian silver work, while many of the engravings are Celtic objects.
A major problem in determining whether the Cimbri were speaking a Celtic language or a Germanic language is that, at that time, the Greeks and Romans tended to refer to all groups to the north of their sphere of influence as Gauls, Celts, or Germani rather indiscriminately. Caesar seems to be one of the first authors to distinguish the two groups, and he had a political motive for doing so (it was an argument in favour of the Rhine border). Yet, one cannot always trust Caesar and Tacitus when they ascribe individuals and tribes to one or the other category, although Caesar made clear distinctions between the two cultures. Most ancient sources categorize the Cimbri as a Germanic tribe, but some ancient authors include the Cimbri among the Celts.
There are few direct testimonies to the language of the Cimbri: referring to the Northern Ocean (the Baltic or the North Sea), Pliny the Elder states: "Philemon says that it is called Morimarusa, i.e. the Dead Sea, by the Cimbri, until the promontory of Rubea, and after that Cronium." The contemporary Gaulish terms for "sea" and "dead" appear to have been "mori" and "*maruo-"; compare their well-attested modern Insular Celtic cognates "muir" and "marbh" (Irish), "môr" and "marw" (Welsh), and "mor" and "marv" (Breton). The same word for "sea" is also known from Germanic, but with an "a" (*"mari-"), whereas a cognate of "marbh" is unknown in all dialects of Germanic. Yet, given that Pliny had not heard the word directly from a Cimbric informant, it cannot be ruled out that the word is in fact Gaulish instead.
The known Cimbri chiefs have Celtic names, including Boiorix (which may mean "King of the Boii" or, more literally, "King of Strikers"), Gaesorix (which means "Spear King"), and Lugius (which may be named after the Celtic god Lugus). Other evidence to the language of the Cimbri is circumstantial: thus, we are told that the Romans enlisted Gaulish Celts to act as spies in the Cimbri camp before the final showdown with the Roman army in 101 BC.
Jean Markale wrote that the Cimbri were associated with the Helvetii, and more especially with the indisputably Celtic Tigurini. These associations may link to a common ancestry, recalled from two hundred years previous, but that is not certain. Henri Hubert states "All these names are Celtic, and they cannot be anything else". Some authors take a different perspective.
Countering the argument of a Celtic origin is the literary evidence that the Cimbri originally came from northern Jutland, an area with no Celtic placenames, instead only Germanic ones. This does not rule out Cimbric Gallicization during the period when they lived in Gaul. Boiorix, who may have had a Celtic if not a Celticized Germanic name, was king of the Cimbri after they moved away from their ancestral home of northern Jutland. Boiorix and his tribe lived around Celtic peoples during his era as J. B. Rives points out in his introduction to Tacitus' "Germania"; furthermore, the name "Boiorix" can be seen as having either Proto-Germanic or Celtic roots.

</doc>
<doc id="6576" url="https://en.wikipedia.org/wiki?curid=6576" title="Cleveland Browns">
Cleveland Browns

The Cleveland Browns are a professional American football team based in Cleveland. Named after original coach and co-founder Paul Brown, they compete in the National Football League (NFL) as a member club of the American Football Conference (AFC) North division. The Browns play their home games at FirstEnergy Stadium, which opened in 1999, with administrative offices and training facilities in Berea, Ohio. The Browns' official club colors are brown, orange, and white. They are unique among the 32 member franchises of the NFL in that they do not have a logo on their helmets.
The franchise was founded in 1945 by Brown and businessman Arthur B. McBride as a charter member of the All-America Football Conference (AAFC). The Browns dominated the AAFC, compiling a 47–4–3 record in the league's four seasons and winning its championship in each. When the AAFC folded after the 1949 season, the Browns joined the NFL along with the San Francisco 49ers and the original Baltimore Colts. The team won a championship in their inaugural NFL season, as well as in the 1954, 1955, and 1964 seasons, and in a feat unequaled in any of the North American major professional sports, played in their league championship game in each of the Browns' first ten years of existence. From 1965 to 1995, they qualified to play in the NFL playoffs 14 times, but did not win another championship or play in the Super Bowl during that period.
In 1995, owner Art Modell, who had purchased the Browns in 1961, announced plans to move the team to Baltimore. After threats of legal action from the city of Cleveland and fans, a compromise was reached in early 1996 that allowed Modell to establish the Baltimore Ravens as a new franchise while retaining the contracts of all Browns personnel. The Browns' intellectual property, including team name, logos, training facility, and history, were kept in trust and the franchise was regarded by the NFL as suspended, with a new team to be established by 1999 either by expansion or relocation. The Browns were announced as an expansion team in 1998 and resumed play in 1999.
Since resuming operations in 1999, the Browns have struggled to find success. They have had only two winning seasons (in 2002 and 2007), one playoff appearance (2002), and no playoff wins, winning only approximately thirty percent of their games in total. The franchise has also been noted for a lack of stability with head coaches (10 full time and two interim since 1999), and quarterbacks (30 different starters since 1999), along with the longest active playoff drought in the NFL at 17 seasons.
The history of the Cleveland Browns American football team began in 1944 when taxi-cab magnate Arthur B. "Mickey" McBride secured a Cleveland franchise in the newly formed All-America Football Conference (AAFC). Paul Brown was the team's namesake and first coach. The Browns began play in 1946 in the AAFC. The Browns won each of the league's four championship games before the league dissolved in 1949. The team then moved to the more established National Football League (NFL), where it continued to dominate. Between 1950 and 1955, Cleveland reached the NFL championship game every year, winning three times.
McBride and his partners sold the team to a group of Cleveland businessmen in 1953 for a then-unheard-of $600,000. Eight years later, the team was sold again, this time to a group led by New York advertising executive Art Modell. Modell fired Brown before the 1963 season, but the team continued to win behind running back Jim Brown. The Browns won the championship in 1964 and reached the title game the following season, losing to the Green Bay Packers.
When the AFL and NFL merged before the 1970 season, Cleveland became part of the new American Football Conference (AFC). While the Browns made it back to the playoffs in 1971 and 1972, they fell into mediocrity through the mid-1970s. A revival of sorts took place in 1979 and 1980, when quarterback Brian Sipe engineered a series of last-minute wins and the Browns came to be called the "Kardiac Kids". Under Sipe, however, the Browns did not make it past the first round of the playoffs. Quarterback Bernie Kosar, whom the Browns drafted in 1985, led the team to three AFC Championship games in the late 1980s but lost each time to the Denver Broncos.
In 1995, Modell announced he was relocating the Browns to Baltimore, sowing a mix of outrage and bitterness among Cleveland's dedicated fan base. Negotiations and legal battles led to an agreement where Modell would be allowed to take his personnel to Baltimore as an expansion franchise, called the Baltimore Ravens, but would leave Cleveland the Browns' colors, logos and heritage for a reactivated Browns franchise that would take the field no later than 1999.
After three years of inactivity while Cleveland Stadium was demolished and FirstEnergy Stadium was built on its site, the Browns was reactivated and started play again in 1999 under new owner Al Lerner. The Browns struggled throughout the 2000s and 2010s, posting a record of 101–234–1 () since their 1999 return. The Browns have only posted two winning seasons and one playoff appearance (2002) since returning to the NFL. The team's struggles have been magnified since 2012, when the Lerner family sold the team to businessman Jimmy Haslam. In six seasons under Haslam’s ownership, the Browns went through four head coaches and four general managers, none of whom had found success. In 2016 and 2017 under head coach Hue Jackson, the Browns went 1–31 () (including a winless 0–16 season in 2017), the worst two-year stretch in NFL history, and received the number one overall draft pick in both of those years.
The Browns are the only National Football League team without a helmet logo. The logoless helmet serves as the Browns' official logo. The organization has used several promotional logos throughout the years; players' numbers were painted on the helmets from 1957 to 1960; and an unused "CB" logo was created in 1965, But for much of their history, the Browns' helmets have been an unadorned burnt orange color with a top stripe of dark brown (officially called "seal brown") divided by a white stripe.
The team has had various promotional logos throughout the years, such as the "Brownie Elf" mascot or a Brown "B" in a white football. While Art Modell did away with the Brownie Elf in the mid-1960s, believing it to be too childish, its use has been revived under the current ownership. The popularity of the Dawg Pound section at First Energy Stadium has led to a brown and orange dog being used for various Browns functions. But overall, the orange, logo-less helmet continues as the primary trademark of the Cleveland Browns.
On February 24, 2015, the team unveiled its new logos and word marks, the only differences being minor color changes to the helmet with the helmet design remaining largely as is.
The original designs of the jerseys, pants, and socks remained mostly the same, but the helmets went through many significant revisions throughout the years. The Browns uniforms saw their first massive change prior to the 2015 season.
Jerseys:
Pants:
Socks:
Helmet: Solid white (1946–1949); solid white for day games and solid orange for night games (1950–1951); orange with a single white stripe (1952–1956); orange with a single white stripe and brown numerals on the sides (1957–1959); orange with a brown-white-brown stripe sequence and brown numerals on the sides (1960); orange with a brown-white-brown stripe sequence (1961–1995 and 1999–present).
Over the years, the Browns have had on-and-off periods of wearing white for their home games, particularly in the 1970s and 80s, as well as in the early 2000s after the team returned to the league. Until recently, when more NFL teams have started to wear white at home at least once a season, the Browns were the only non-subtropical team north of the Mason-Dixon line to wear white at home on a regular basis.
Secondary numerals (called "TV numbers") first appeared on the jersey sleeves in 1961. Over the years, there have been minor revisions to the sleeve stripes, the first occurring in 1968 (brown jerseys worn in early season) and 1969 (white and brown jerseys) when stripes began to be silk screened onto the sleeves and separated from each other to prevent color bleeding. However, the basic five-stripe sequence has remained intact (with the exception of the 1984 season). A recent revision was the addition of the initials "AL" to honor team owner Al Lerner who died in 2002; this was removed in 2013 upon Jimmy Haslam assuming ownership of the team.
Orange pants with a brown-white-brown stripe sequence were worn from 1975 to 1983 and become symbolic of the "Kardiac Kids" era. The orange pants were worn again occasionally in 2003 and 2004.
Other than the helmet, the uniform was completely redesigned for the 1984 season. New striping patterns appeared on the white jerseys, brown jerseys and pants. Solid brown socks were worn with brown jerseys and solid orange socks were worn with white jerseys. Brown numerals on the white jerseys were outlined in orange. White numerals on the brown jerseys were double outlined in brown and orange. (Orange numerals double outlined in brown and white appeared briefly on the brown jerseys in one pre-season game.) However, this particular uniform set was not popular with the fans, and in 1985 the uniform was returned to a look similar to the original design. It remained that way until 1995.
In 1999, the expansion Browns adopted the traditional design with two exceptions: first, the TV numbers, previously on the sleeves, were moved to the shoulders; and second, the orange-brown-orange pants stripes were significantly widened.
Experimentation with the uniform design began in 2002. An alternate orange jersey was introduced that season as the NFL encouraged teams to adopt a third jersey, and a major design change was made when solid brown socks appeared for the first time since 1984 and were used with white, brown and orange jerseys. Other than 1984, striped socks (matching the jersey stripes) had been a signature design element in the team's traditional uniform. The white striped socks appeared occasionally with the white jerseys in 2003–2005 and 2007.
Experimentation continued in 2003 and 2004 when the traditional orange-brown-orange stripes on the white pants were replaced by two variations of a brown-orange-brown sequence, one in which the stripes were joined (worn with white jerseys) and the other in which they were separated by white (worn with brown jerseys). The joined sequence was used exclusively with both jerseys in 2005. In 2006, the traditional orange-brown-orange sequence returned.
Additionally in 2006, the team reverted to an older uniform style, featuring gray face masks; the original stripe pattern on the brown jersey sleeves (The white jersey has had that sleeve stripe pattern on a consistent basis since the 1985 season.) and the older, darker shade of brown.
The Browns wore brown pants for the first time in team history on August 18, 2008, preseason game against the New York Giants. The pants contain no stripes or markings. The team had the brown pants created as an option for their away uniform when they integrated the gray facemask in 2006. They were not worn again until the Browns "family" scrimmage on August 9, 2009 with white-striped socks. The Browns have continued to wear the brown pants throughout the 2009 season. Browns quarterback Brady Quinn supported the team's move to wearing the brown pants full-time, claiming that the striped pattern on the white pants "prohibit[ed] mobility".
However, the fans generally did not like the brown pants, and after being used for only one season, the team returned to their white shirt-on-white pants in 2010. Coach Eric Mangini told "The Plain Dealer" the Browns won't use the brown pants anymore. "It wasn't very well-received," Mangini said. "I hope we can get to the point where we can wear fruit on our heads and people wouldn't notice." At the time, the brown pants weren't officially dropped by the team, but simply not used.
The Browns chose to wear white at home for the 2011 season, and wound up wearing white for all 16 games as when they were on the road, the home team would wear their darker colored uniform.
The Browns brought back the brown pants in their home game against the Buffalo Bills on October 3, 2013 on "Thursday Night Football", pairing them with the brown jerseys. It marked the first time the team wore an all-brown combination in team history.
On April 14, 2015, the Cleveland Browns unveiled their new uniform combinations, consisting of the team's colors of orange, brown and white.
The Browns brought back the all-brown look for the NFL Color Rush program in 2016, minus the white elements. In 2018 the uniform was worn at home three times. For the 2019 season, the Browns promoted the Color Rush uniform to their primary home uniform and will wear it for six home games as well as any away game in which the home team chooses to wear white (although for the Week 3 game against the Los Angeles Rams, the Browns wore all-orange socks instead of brown. For the two remaining home games, the browns will wear their previous brown home uniforms as alternate uniforms.
The club unveiled a new uniform design on April 15, 2020. The new uniform design pays homage to the Browns' classic uniform design from years past.
The Browns have rivalries with all three of their AFC North opponents. In addition, the team has had historical rivalries with the Denver Broncos, Buffalo Bills, and Detroit Lions.
The team's biggest rival in the AAFC was the San Francisco 49ers, though this has cooled and in some cases turned into a friendly relationship, as the Browns now play in the AFC and the 49ers play in the NFC. Additionally, many 49ers personnel helped the Browns relaunch in 1999 as well as former team President Mike Holmgren having started his NFL career in San Francisco. Also, 49ers owners John York and Denise DeBartolo York reside in Youngstown, southeast of Cleveland. Former long-time veteran placekicker and fan favorite, Phil Dawson, signed with the 49ers in 2014, along with backup quarterback Colt McCoy.
Often called the "Turnpike Rivalry", the Browns' biggest rival has long been the Pittsburgh Steelers. Former Browns owner Art Modell scheduled home games against the Steelers on Saturday nights from 1964 to 1970 to help fuel the rivalry. The rivalry has also been fueled by the proximity of the two teams, number of championships both teams have won, players and personnel having played and/or coached for both sides, and personal bitterness. The teams have played twice annually since 1950, making it the oldest rivalry in the AFC and the fifth-oldest rivalry in the NFL. Though the Browns dominated this rivalry early in the series (winning the first eight meetings and posting a 31–9 record in the 1950s and 1960s), the Steelers went 15–5 in the 1970s and 34–6–1 since the Browns returned to the league in 1999. The Steelers have been particularly dominant in Pittsburgh, posting a 42–6 record when hosting the Browns since 1970, including to winning streaks of 16 games (1970–85, 2004–present).
The Steelers currently hold a 76–59–1 lead. The Browns and Steelers met in the playoffs in and , with the Steelers winning both meetings. Though the rivalry has cooled in Pittsburgh due to the Modell move as well as the Browns' poor play since 1999, the Steelers still remain the top rival for Cleveland.
Originally conceived due to the personal animosity between Paul Brown and Art Modell, the "Battle of Ohio" between the Browns and the Cincinnati Bengals has been fueled by the sociocultural differences between Cincinnati and Cleveland, a shared history between the two teams, and similar team colors, as Brown used the exact shade of orange for the Bengals that he used for the Browns. (Though this has changed since then, as the Bengals now use a brighter shade of orange.) Modell, in fact, moved the Browns to the AFC after the AFL–NFL merger in order to have a rivalry with the Bengals. The rivalry has also produced two of the eight highest-scoring games in NFL history. Cincinnati has the all-time edge 51–43. While the Bengals have a 27–16 edge since the Browns returned to the NFL in 1999, the Browns-Bengals series has been more competitive than the Browns' series with their other division rivals.
Created as a result of the Browns' relocation to Baltimore, the rivalry between the Browns and Baltimore Ravens was more directed at Art Modell than the team itself, and is simply considered a divisional game in Baltimore. This matchup is more bitter for Cleveland than the others due to the fact that the draft picks for 1995 to 1998 resulted in the rosters that won the Super Bowl for the Ravens in 2000. Had the Browns stayed in Cleveland, these teams (drafted by general manager Ozzie Newsome) might have given the Browns the title after a 35-year drought. This bitterness was compounded when the Ravens won their second Super Bowl in 2012. The Ravens lead the overall series 32–11. The two teams have not met in the playoffs.
The Detroit Lions rivalry began in the 1950s, when the Browns and Lions played each other in four NFL championships. The Lions won three of those championships, while the Browns won one. This was arguably one of the NFL's best rivalries in the 1950s. Since the NFL-AFL merger of 1970, the teams have met much less frequently with the Browns' move to the AFC. From 2002 to 2014, the two teams played an annual preseason game known as the "Great Lakes Classic".
The Bills rivalry had its roots back to the days of the AAFC, when there was a team from Buffalo with the same name in that league. The Browns and AAFC Bills played six games, including a league championship game, before the Browns were selected to merge into the NFL and the Bills left out. After the current incarnation of the Bills joined the NFL, the Browns and Bills have played each other from time to time. Though the Browns and Bills are in different AFC divisions, a mellow rivalry defined by mutual respect has since developed between the teams due to the similarities between Buffalo and Cleveland and shared misfortune between the teams. Despite this "rivalry" being known for ugly games, such as an 8–0 Browns win played in a blizzard in 2007 and a 6–3 Browns win in 2009 in which Browns quarterback Derek Anderson only completed 2 of 17 passes, there have been some competitive moments between the Bills and Browns as well, such as a playoff game in 1990 and two games with playoff-implications in 2007 and 2014.
The Browns fans' respect for the Bills is partly due to Bills founding owner Ralph Wilson being one of only two NFL owners to vote against the decision to move the original Browns team to Baltimore.
The Browns had a brief rivalry with the Denver Broncos that arose from three AFC Championship Games from 1986 to 1989. In the 1986 AFC Championship, quarterback John Elway led The Drive to secure a tie in the waning moments at Cleveland Municipal Stadium; the Broncos went on to win in 23–20 in overtime. One year later, the two teams met again in the 1987 AFC Championship game at Mile High Stadium. Denver took a 21–3 lead, but Browns' quarterback Bernie Kosar threw four touchdown passes to tie the game at 31–31 halfway through the 4th quarter. After a long drive, John Elway threw a 20-yard touchdown pass to running back Sammy Winder to give Denver a 38–31 lead. Cleveland advanced to Denver's 8-yard line with 1:12 left, but Broncos' safety Jeremiah Castille stripped Browns' running back Earnest Byner of the football at the 2-yard line—a play that has been called The Fumble by Browns' fans. The Broncos recovered it, gave Cleveland an intentional safety, and went on to win 38–33. The two teams met yet again in the 1989 AFC Championship at Mile High Stadium, which the Broncos easily won by a score of 37–21.
A 2006 study conducted by "Bizjournal" determined that Browns fans are the most loyal fans in the NFL. The study, while not scientific, was largely based on fan loyalty during winning and losing seasons, attendance at games, and challenges confronting fans (such as inclement weather or long-term poor performance of their team). The study noted that Browns fans filled 99.8% of the seats at Cleveland Browns Stadium during the last seven seasons, despite a combined record of 36–76 over that span.
Perhaps the most visible Browns fans are those that can be found in the Dawg Pound. Originally the name for the bleacher section located in the open (east) end of old Cleveland Municipal Stadium, the current incarnation is likewise located in the east end of FirstEnergy Stadium and still features hundreds of orange and brown clad fans sporting various canine-related paraphernalia. The fans adopted that name in 1984 after members of the Browns defense used it to describe the team's defense.
Retired cornerback Hanford Dixon, who played his entire career for the Browns (1981–1989), is credited with naming the Cleveland Browns defense 'The Dawgs' in the mid-1980s. Dixon and teammates Frank Minnifield and Eddie Johnson would bark at each other and to the fans in the bleachers at the Cleveland Stadium to fire them up. It was from Dixon's naming that the "Dawg Pound" subsequently took its title. The fans adopted that name in the years after. Due to this nickname, since the team's revival the Browns have used a bulldog as an alternate logo.
The most prominent organization of Browns fans is the "Browns Backers Worldwide" (BBW). The organization has approximately 305,000 members and Browns Backers clubs can be found in every major city in the United States, and in a number of military bases throughout the world, with the largest club being in Phoenix, Arizona. In addition, the organization has a sizable foreign presence in places as far away as Egypt, Australia, Japan, Sri Lanka, and McMurdo Station in Antarctica. According to The Official Fan Club of the Cleveland Browns, the two largest international fan clubs are in Alon Shvut, West Bank and Niagara, Canada, with Alon Shvut having 129 members and Niagara having 310.
Following former Browns owner Randy Lerner's acquisition of English soccer club Aston Villa, official Villa outlets started selling Cleveland Browns goods such as jerseys and NFL footballs. This has raised interest in England and strengthened the link between the two sporting clubs. Aston Villa supporters have set up an organization known as the Aston (Villa) Browns Backers of Birmingham.
The Cleveland Browns were the favorite team of Elvis Presley. This was because his friend Gene Hickerson – with whom he had played football in their common youth in Memphis – was contracted by the Browns in 1957 and played there during his entire career until 1973. Also defender Bobby Franklin, who had played from 1960 to 1966 for the Browns, was a friend of Presley. WWE Hall of Fame wrestler and commentator Jerry "The King" Lawler – though he has spent most of his life in Memphis – spent part of his childhood in the Cleveland area and is a fan of the Browns. Fellow WWE wrestlers The Miz and Dolph Ziggler (both Cleveland natives) are also fans. Another fan of the team is baseball legend Hank Aaron. Other famous Browns fans include LeBron James, Arsenio Hall, Drew Carey, Patricia Heaton (her father, Chuck Heaton, was a sportswriter for "The Plain Dealer", which covered the Browns and wrote two books about the team), Terri Garr, Martin Mull, Condoleezza Rice, Two-time UFC Heavyweight Champion Stipe Miocic, Valerie Bertinelli (her husband is from the Northeast Ohio area, and she starred in "Hot in Cleveland"), Machine Gun Kelly, Paul Adelstein, Iron Chef, Tom Holland, Michael Symon, C. J. McCollum, and Brad Paisley.
The Cleveland Browns have the fourth largest number of players enshrined in the Pro Football Hall of Fame with a total of 17 enshrined players elected based on their performance with the Browns, and nine more players or coaches elected who spent at least one year with the Browns franchise. No Browns players were inducted in the inaugural induction class of 1963. Otto Graham was the first Browns player to be enshrined as a member of the class of 1965, and the most recent Browns player to be included in the Pro Football Hall of Fame is Mac Speedie, who was a member of the class of 2020. All of the Browns' Pro Football Hall of Fame inductees thus far have been from the pre-1996 incarnation; no members of the Hall of Fame played for the Browns after 1999.
The Cleveland Browns legends program honors former Browns who made noteworthy contributions to the history of the franchise. In addition to all the Hall of Famers listed above, the Legends list includes:
Beginning in 2010, the Browns established a Ring of Honor, honoring the greats from the past by having their names displayed around the upper deck of FirstEnergy Stadium. The inaugural class in the Browns Ring of Honor was unveiled during the home opener on September 19, 2010, and featured the 16 Hall of Famers listed above who went into the Hall of Fame as Browns. In 2018, Joe Thomas was entered into the Ring of Honor with the number 10,363 – commemorating his NFL record of consecutive snaps played on offense. In 2019, four-time Pro Bowl linebacker Clay Matthews was entered into the Ring of Honor.
Numerous Browns players and staff have had statues made in their honor:
In and around First Energy Stadium
In and around Cleveland
WKNR (850 AM), WKRK-FM (92.3 FM), and WNCX (98.5 FM) serve as co-flagship stations for the Cleveland Browns Radio Network. Play-by-play announcer Jim Donovan calls games on-site alongside color analyst Doug Dieken, a former Browns left tackle, and sideline reporter Nathan Zegura – who made news when he had to serve an eight-game suspension due to arguing with officials during a game in 2018. WKRK-FM personality Ken Carman and WKNR personalities Tony Rizzo & Je'Rod Cherry host the network pregame show, while WKRK-FM personalities Jeff Phelps and Dustin Fox host the network postgame show.
WEWS-TV (TV channel 5) serves as the broadcast TV home of the Browns, airing year-round team programming as well as non-network preseason games. SportsTime Ohio (STO) is the cable outlet for the team, airing various Browns related programming during the season, STO had previously served as the team's cable outlet from its founding in 2006 until 2014.
The Browns in-house production team won a pair of Lower Great Lakes Emmy Awards in 2005. One was for a primetime special honoring the 1964 NFL Championship team ("The 1964 Championship Show") and one was for a commercial spot ("The Paperboy").
The Browns have (either directly or indirectly) been featured in various movies and TV shows over the years. Notable examples include:

</doc>
<doc id="6579" url="https://en.wikipedia.org/wiki?curid=6579" title="Carbine">
Carbine

A carbine ( or ) is a long gun firearm with a shorter barrel rather than a standard rifle or musket. Most carbines are shortened versions of full-length rifles, shooting the same type of ammunition, while others fire generally lower-powered ammunition, including types designed for pistols.
The smaller size and lighter weight of carbines make them easier to handle. They are typically issued to high-mobility troops such as special-operations soldiers and paratroopers, as well as to mounted, artillery, logistics, or other non-infantry personnel whose roles do not require full-sized rifles, although there is a growing tendency for carbines to be issued to front-line soldiers to offset the increasing weight of other issued equipment. An example of this is the US Army's M4 carbine, which is standard issue.
The name comes from its first users — cavalry troopers called "carabiniers", from the French "carabine", from Old French "carabin" (soldier armed with a musket), whose origin is unclear. One theory connects it to an "ancient engine of war" called a "calabre"; another connects it to Medieval Latin "Calabrinus" 'Calabrian'; yet another, "less likely", to "escarrabin", gravedigger, from the scarab beetle.
The carbine was originally developed for cavalry.
The start of early modern warfare about the 16th century had infantry armed with firearms, prompting cavalry to do the same, even though reloading muzzle loading firearms while moving mounted was highly impractical. Some cavalry, such as the German Reiters, added one or more pistols, while other cavalry, such as harquebusiers, tried various shorter, lightened versions of the infantry arquebus weapons – the first carbines. But these weapons were still difficult to reload while mounted, and the saber often remained main weapon of such cavalry. Dragoons and other mounted infantry that dismounted for battles usually adopted standard infantry firearms, though some favored versions that were less encumbering when riding – something that could be arranged to hang clear of the rider's elbows and horse's legs.
While more portable, carbines had the general disadvantages of less accuracy and power than the longer guns of the infantry. During Napoleonic warfare, pistol and carbine-armed cavalry generally transitioned into traditional melee cavalry or dragoons.
Carbines found increased use outside of standard cavalry and infantry, such as support and artillery troops, who might need to defend themselves from attack but would be hindered by keeping full-sized weapons with them continuously; a common title for many short rifles in the late 19th century was "artillery carbine".
As the rifled musket replaced the smoothbore firearms for infantry in the mid 19th century, carbine versions were also developed; this was often developed separately from the infantry rifles and, in many cases, did not even use the same ammunition, which made for supply difficulties.
A notable weapon developed towards the end of the American Civil War by the Union was the Spencer carbine, one of the first breechloading, repeating weapons. It had a spring-powered, removable tube magazine in the buttstock which held seven rounds and could be reloaded by inserting spare tubes. It was intended to give the cavalry a replacement weapon which could be fired from horseback without the need for awkward reloading after each shot – although it saw service mostly with dismounted troopers, as was typical of cavalry weapons during that war.
In the late 19th century, it became common for a number of nations to make bolt-action rifles in both full-length and carbine versions. One of the most popular and recognizable carbines were the lever-action Winchester carbines, with several versions available firing revolver cartridges. This made it an ideal choice for cowboys and explorers, as well as other inhabitants of the American West, who could carry a revolver and a carbine, both using the same ammunition.
The Lee Enfield Cavalry Carbine (LEC) a shortened version of the standard British Army infantry rifle was introduced in 1896, although it did not become the standard British cavalry weapon until 1903.
In the decades following World War I, the standard battle rifle used by armies around the world had been growing shorter, either by redesign or by the general issue of carbine versions instead of full-length rifles. This move was initiated by the US Model 1903 Springfield, which was originally produced in 1907 with a short 24-inch barrel, providing a short rifle that was longer than a carbine but shorter than a typical rifle, so it could be issued to all troops without need for separate versions. Other nations followed suit after World War I, when they learned that their traditional long-barreled rifles provided little benefit in the trenches and merely proved a hindrance to the soldiers. Examples include the Russian Model 1891 rifle, originally with an barrel, later shortened to in 1930, and to in 1938, the German Mauser Gewehr 98 rifles went from in 1898 to in 1935 as the "Karabiner 98k" (K98k or Kar98k), or "short carbine". The barrel lengths in rifles used by the United States did not change between the bolt-action M1903 rifle of World War I and the World War II M1 Garand rifle, because the barrel on the M1903 was still shorter than even the shortened versions of the Model 1891 and Gewehr 98. The US M1 carbine was more of a traditional carbine in that it was significantly shorter and lighter, with a barrel, than the M1 Garand rifle, and that it was intended for rear-area troops who couldn't be hindered with full-sized rifles but needed something more powerful and accurate than a Model 1911 pistol (although this didn't stop soldiers from using them on the front line). Contrary to popular belief, and even what some books claim, in spite of both being designated "M1", the M1 Carbine was "not" a shorter version of the .30-06 M1 Garand, as is typical for most rifles and carbines, but a wholly different design firing a smaller, less-powerful cartridge. The "M1" designates each as the first model in the new US designation system, which no longer used the year of introduction, but a sequential series of numbers starting at "1": the M1 "Carbine" and M1 "Rifle".
The United Kingdom also developed a "Jungle Carbine" version of their Lee–Enfield service rifle, featuring a shorter barrel, flash suppressor, and manufacturing modifications designed to decrease the rifle's weight. Officially titled "Rifle, No. 5 Mk I", it was introduced in the closing months of World War II, but it did not see widespread service until the Korean War, the Mau Mau Uprising, and the Malayan Emergency as well the Vietnam War.
A shorter weapon was more convenient when riding in a truck, armored personnel carrier, helicopter, or aircraft, and also when engaged in close-range combat. Based on the combat experience of World War II, the criteria used for selecting infantry weapons began to change. Unlike previous wars, which were often fought mainly from fixed lines and trenches, World War II was a highly mobile war, often fought in cities, forests, or other areas where mobility and visibility were restricted. In addition, improvements in artillery made moving infantry in open areas even less practical than it had been.
The majority of enemy contacts were at ranges of less than , and the enemy was exposed to fire for only short periods of time as they moved from cover to cover. Most rounds fired were not aimed at an enemy combatant, but instead fired in the enemy's direction to keep them from moving and firing back (see suppressive fire). These situations did not require a heavy rifle, firing full-power rifle bullets with long-range accuracy. A less-powerful weapon would still produce casualties at the shorter ranges encountered in actual combat, and the reduced recoil would allow more shots to be fired in the short amount of time an enemy was visible. The lower-powered round would also weigh less, allowing a soldier to carry more ammunition. With no need of a long barrel to fire full-power ammunition, a shorter barrel could be used. A shorter barrel made the weapon weigh less, was easier to handle in tight spaces, and was easier to shoulder quickly to fire a shot at an unexpected target. Full-automatic fire was also considered a desirable feature, allowing the soldier to fire short bursts of three to five rounds, increasing the probability of a hit on a moving target.
The Germans had experimented with selective-fire carbines firing rifle cartridges during the early years of World War II. These were determined to be less than ideal, as the recoil of full-power rifle cartridges caused the weapon to be uncontrollable in full-automatic fire. They then developed an intermediate-power cartridge round, which was accomplished by reducing the power and the length of the standard 7.92×57mm Mauser rifle cartridge to create the 7.92×33mm "Kurz" (Short) cartridge. A selective-fire weapon was developed to fire this shorter cartridge, eventually resulting in the Sturmgewehr 44, later translated as "assault rifle" (also frequently called "machine carbines" by Allied intelligence, a quite accurate assessment, in fact). Very shortly after World War II, the USSR would adopt a similar weapon, the ubiquitous AK-47, the first model in the famed Kalashnikov-series, which became the standard Soviet infantry weapon, and which has been produced and exported in extremely large numbers up through the present day. Although the United States had developed the M2 Carbine, a selective-fire version of the M1 Carbine during WW2, the .30 Carbine cartridge was closer to a pistol round in power, making it more of a submachine gun than an assault rifle. It was also adopted only in very small numbers and issued to few troops (the semi-automatic M1 carbine was produced in a 10-to-1 ratio to the M2), while the AK47 was produced by the millions and was standard-issue to all Soviet troops, as well as those of many other nations. The US was slow to follow suit, insisting on retaining a full-power, 7.62×51mm NATO rifle, the M14 (although this "was" selective fire), until too-hastily adopting the 5.56mm M16 rifle in the mid-1960s, with initially poor results due to the rapidity of its introduction (but later to become a highly successful line of rifles and carbines).
In the 1950s, the British developed the .280 British, an intermediate cartridge, and a select-fire bullpup assault rifle to fire it, the EM-2. They pressed for the US to adopt it so it could become a NATO-standard round, but the US insisted on retaining a full-power, .30 caliber round. This forced NATO to adopt the 7.62×51mm NATO round (which in reality is only slightly different ballistically to the .308 Winchester), to maintain commonality. The British eventually adopted the 7.62mm FN FAL, and the US adopted the 7.62mm M14. These rifles are both what is known as "battle rifles" and were a few inches shorter than the standard-issue rifles they replaced (22" barrel as opposed to 24" for the M1 Garand), although they were still full-powered rifles, with selective fire capability. These can be compared to the even shorter, less-powerful assault rifle, which might be considered the "carbine branch of weapons development", although indeed, there are now carbine variants of many of the assault rifles which had themselves seemed quite small and light when adopted.
By the 1960s, after becoming involved in War in Vietnam, the US did an abrupt about-face and decided to standardize on the intermediate 5.56×45mm round (based on the .223 Remington varmint cartridge) fired from the new, lightweight M16 rifle, leaving NATO to hurry and catch up. Many of the NATO countries couldn't afford to re-equip so soon after the recent 7.62mm standardization, leaving them armed with full-power 7.62mm battle rifles for some decades afterwards, although by this point, the 5.56mm has been adopted by almost all NATO countries and many non-NATO nations as well. This 5.56mm NATO round was even lighter and smaller than the Soviet 7.62×39mm AK-47 cartridge, but possessed higher velocity. In U.S. service, the M16 assault rifle replaced the M14 as the standard infantry weapon, although the M14 continued to be used by designated marksmen. Although at 20", the barrel of the M16 was shorter than that of the M14, it was still designated a "rifle" rather than a "carbine", and it was still longer than the AK, which used a 16" barrel. (The SKS – an interim, semi-automatic, weapon adopted a few years before the AK-47 was put into service – was designated a carbine, even though its 20" barrel was significantly longer than the AK series' 16.3". This is because of the Kalashnikov's revolutionary nature, which altered the old paradigm. Compared to previous rifles, particularly the Soviets' initial attempts at semi-automatic rifles, such as the 24" SVT-40, the SKS was significantly shorter. The Kalashnikov altered traditional notions and ushered in a change in what was considered a "rifle" in military circles.)
In 1974, shortly after the introduction of the 5.56mm NATO, the USSR began to issue a new Kalashnikov variant, the AK-74, chambered in the small-bore 5.45×39mm cartridge, which was a standard 7.62×39mm necked down to take a smaller, lighter, faster bullet. It soon became standard issue in Soviet nations, although many of the nations with export Kalashnikovs retained the larger 7.62×39mm round. In 1995, the People's Republic of China adopted a new 5.8×42mm cartridge to match the modern trend in military ammunition, replacing the previous 7.62×39mm and 5.45×39mm round as standard.
Later, even lighter carbines variants of many of these short-barreled assault rifles came to be adopted as the standard infantry weapon. In much modern tactical thinking, only a certain number of soldiers now need to retain longer-range weapons, these serving as designated marksmen. The rest can carry lighter, shorter-ranged weapons for close-quarters combat and suppressive fire. This is basically a more extreme extension of the idea that brought the original assault rifle. Another factor is that with the increasing weight of technology, sighting systems, ballistic armor, etc., the only way to reduce the burden on the modern soldier was to equip them with a smaller, lighter weapon. Also, modern soldiers rely a great deal on vehicles and helicopters to transport them around the battle area, and a longer weapon can be a serious hindrance to entering and exiting these vehicles. Development of lighter assault rifles continued, matched by developments in even lighter carbines. In spite of the short barrels of the new assault rifles, carbines variants like the 5.45×39mm AKS-74U and Colt Commando were being developed for use when mobility was essential and a submachine gun wasn't sufficiently powerful. The AKS-74U featured an extremely short 8.1" barrel which necessitated redesigning and shortening the gas-piston and integrating front sights onto the gas tube; the Colt Commando was a bit longer, at 11.5". Neither was adopted as standard issue, although the US did later adopt the somewhat-longer M4 carbine, with a 14.5" barrel.
By the 1990s, the US had adopted the M4 carbine, a derivative of the M16 family which fired the same 5.56mm cartridge but was lighter and shorter (in overall length and barrel length), resulting in marginally reduced range and power, although offering better mobility and lighter weight to offset the weight of equipment and armor that a modern soldier has to carry.
However, in spite of the benefits of the modern carbine, many armies are experiencing a certain backlash against the universal equipping of soldiers with carbines and lighter rifles in general, and are equipping selected soldiers, usually called Designated Marksmen, or DM, with higher-power rifles. Another problem comes from the loss of muzzle velocity caused by the shorter barrel, which when coupled with the typical small, lightweight bullets, causes effectiveness to be diminished; a 5.56mm gets its lethality from its high velocity, and when fired from the 14.5" M4 carbine, its power, penetration, and range are diminished. Thus, there has been a move towards adopting a slightly more powerful round tailored for high performance from both long and short barrels. The US has done experiments regarding adopting a new, slightly larger and heavier caliber such as the 6.5mm Grendel or 6.8mm Remington SPC, which are heavier and thus retain more effectiveness at lower muzzle velocities, but has for the time decided to retain the 5.56mm NATO round as standard issue.
While the US Army adopted the M4 carbine in the 1990s, the US Marine Corps retained their 20" barrel M16A4 rifles long afterwards, citing the increased range and effectiveness over the carbine version; officers were required to carry an M4 carbine rather than an M9 pistol, as Army officers do. Due to the Marine Corps emphasis on being riflemen, the lighter carbine was considered a suitable compromise between a rifle and a pistol. Marines with restricted mobility such as vehicle operators, or a greater need for mobility such as squad leaders, were also issued M4 carbines. In July 2015, the Marine Corps approved the M4 carbine for standard issue to front-line Marines, replacing the M16A4 rifle. The rifles will be issued to support troops while the carbines go to the front-line Marines, in a reversal of the traditional roles of "rifles for the front line, carbines for the rear".
Special forces need to perform fast, decisive operations, frequently airborne or boat-mounted. A pistol, though light and quick to operate, is viewed as not having enough power, firepower, or range. A submachine gun has selective fire, but firing a pistol cartridge and having a short barrel and sight radius, it is not accurate or powerful enough at longer ranges. Submachine guns also tend to have poorer armor and cover penetration than rifles and carbines firing rifle ammunition. Consequently, carbines have gained wide acceptance among SOCOM, UKSF, and other communities, having relatively light weight, large magazine capacity, selective fire, and much better range and penetration than a submachine gun.
The smaller size and relative lighter weight of carbines makes them easier to handle in close-quarter situations such as urban engagements, when deploying from military vehicles, or in any situation where space is confined. The disadvantages of carbines relative to rifles include inferior long-range accuracy and a shorter effective range. These comparisons refer to carbines (short-barreled rifles) of the same power and class as the regular full-sized rifles.
Compared to submachine guns, carbines have a greater effective range and are capable of penetrating helmets and body armor when used with armor piercing ammunition. However, submachine guns are still used by military special forces and police SWAT teams for close quarters battle (CQB) because they are "a pistol caliber weapon that's easy to control, and less likely to over-penetrate the target." Also, carbines are harder to maneuver in tight encounters where superior range and stopping power at distance are not great considerations.
Firing the same ammunition as standard-issue rifles or pistols gives carbines the advantage of standardization over those personal defense weapons (PDWs) that require proprietary cartridges.
The modern usage of the term carbine covers much the same scope as it always had, namely lighter weapons (generally rifles) with barrels up to 20 inches in length. These weapons can be considered carbines, while rifles with barrels longer than 20 inches are generally not considered carbines unless specifically named so. Conversely, many rifles have barrels "shorter" than 20", yet aren't considered carbines. The AK series rifles has an almost universal barrel length of 16.3", well within carbine territory, yet has always been considered a rifle, perhaps because it was designed as such and not shortened from a longer weapon. Modern carbines use ammunition ranging from that used in light pistols up to powerful rifle cartridges, with the usual exception of high-velocity magnum cartridges. In the more powerful cartridges, the short barrel of a carbine has significant disadvantages in velocity, and the high residual pressure, and frequently still-burning powder and gases, when the bullet exits the barrel results in substantially greater muzzle blast. Flash suppressors are a common, partial solution to this problem, although even the best flash suppressors are hard put to deal with the excess flash from the still-burning powder leaving the short barrel (and they also add several inches to the length of the barrel, diminishing the purpose of having a short barrel in the first place). The shorter the barrel, the more difficult it is to hide the flash; the AKS-74U has a complex, effective muzzle-booster/flash suppressor, yet it still suffers from extreme muzzle flash.
The typical carbine is the pistol-caliber carbine. These first appeared soon after metallic cartridges became common. These were developed as "companions" to the popular revolvers of the day, firing the same cartridge but allowing more velocity and accuracy than the revolver. These were carried by cowboys, lawmen, and others in the Old West. The classic combination would be a Winchester lever-action carbine and a Colt Single Action Army revolver in .44-40 or .38-40. During the 20th century, this trend continued with more modern and powerful smokeless revolver cartridges, in the form of Winchester and Marlin lever action carbines chambered in .38 Special/.357 Magnum and .44 Special/.44 Magnum.
Modern equivalents include the Ruger Police Carbine, which uses the same magazine as the Ruger pistols of the same caliber, and the (discontinued) Marlin Camp Carbine, which, in .45 ACP, used M1911 magazines. The Ruger Model 44 and Ruger Deerfield Carbine were both carbines chambered in .44 Magnum. The Beretta Cx4 Storm shares magazines with many Beretta pistols and is designed to be complementary to the Beretta Px4 Storm pistol. The Hi-Point 995TS are popular, economical and reliable alternatives to other pistol caliber carbines in the United States, and their magazines can be used in the Hi-Point C-9 pistol. Another example is the Kel-Tec SUB-2000 series chambered in either 9mm Luger or .40 S&W, which can be configured to accept Glock, Beretta, S&W, or SIG pistol magazines. The SUB-2000 also has the somewhat unusual (although not unique) ability to fold in half.
The primary advantage of a carbine over a pistol using the same ammunition is controllability. The combination of firing from the shoulder, longer sight-radius, 3 points of contact (firing hand, support hand & shoulder), and precision offer a significantly more user-friendly platform. Carbines like the Kel-Tec SUB-2000, Hi Point 995TS and Beretta Cx4 Storm have the ability to mount user friendly optics, lights and lasers thanks to them having accessory rails, which make target acquisition and engagement much easier.
The longer barrel can offer increased velocity and, with it, greater energy and effective range due to the propellant having more time to burn. However, loss in bullet velocity can happen where the propellant is utilised before the bullet reaches the muzzle, combined with the friction from the barrel on the bullet. As long guns, pistol-caliber carbines may be less legally restricted than handguns in some jurisdictions. Compared to carbines chambered in intermediate or rifle calibers, such as .223 Remington and 7.62×54mmR, pistol-caliber carbines generally experience less of an increase in external ballistic properties as a result of the propellant. The drawback is that one loses the primary benefits of a handgun, i.e. portability and concealability, resulting in a weapon almost the size of, but less accurate than, a long-gun, but not much more powerful than a pistol.
Also widely produced are semi-automatic and typically longer-barreled derivatives of select-fire submachine guns, such as the FN PS90, HK USC, KRISS Vector, Thompson carbine, CZ Scorpion S1 Carbine and the Uzi carbine. In order to be sold legally in many countries, the barrel must meet a minimum length (16" in the USA). So the original submachine gun in given a legal-length barrel and made into a semi-automatic, transforming it into a carbine. Though less common, pistol-caliber conversions of centerfire rifles like the AR-15 are commercially available.
Some handguns used to come from the factory with mounting lugs for a shoulder stock, notably including the "Broomhandle" Mauser C96, Luger P.08, and Browning Hi-Power. In the case of the first two, the pistol could come with a hollow wooden stock that doubled as a holster.
Carbine conversion kits are commercially available for many other pistols, including M1911 and most Glocks. These can either be simple shoulder stocks fitted to a pistol or full carbine conversion kits, which are at least long and replace the pistol's barrel with one at least long for compliance with the US law. In the US, fitting a shoulder stock to a handgun with a barrel less than 16" long legally turns it into a short-barreled rifle, which is in violation of the National Firearms Act.
Under the National Firearms Act of 1934, firearms with shoulder stocks or originally manufactured as a rifle and barrels less than in length are classified as short-barreled rifles. Short-barreled rifles are restricted similarly to short-barreled shotguns, requiring a $200 tax paid prior to manufacture or transfer – a process which can take several months. Because of this, firearms with barrels of less than and a shoulder stock are uncommon. A list of firearms not covered by the NFA due to their antique status may be found here or due to their "Curio and Relic" status may be found here; these lists includes a number of carbines with barrels less than the minimum legal length and firearms that are "primarily collector's items and are not likely to be used as weapons and, therefore, are excluded from the provisions of the National Firearms Act." Machine guns, as their own class of firearm, are not subject to requirements of other class firearms.
Distinct from simple shoulder stock kits, full carbine conversion kits are not classified as short-barreled rifles. By replacing the pistol barrel with one at least in length and having an overall length of at least , a carbine converted pistol may be treated as a standard rifle under Title I of the Gun Control Act of 1968 (GCA). However, certain "Broomhandle" Mauser C96, Luger, and Browning Hi-Power Curio & Relic pistols with their originally issued stock attached only may retain their pistol classification.
Carbines without a stock and not originally manufactured as a rifle are not classified as rifles or short barreled rifles. A carbine manufactured under in length without a forward vertical grip will be a pistol and, state law notwithstanding, can be carried concealed without creating an unregistered Any Other Weapon. A nearly identical carbine with an overall length of or greater is simply an unclassified firearm under Title I of the Gun Control Act of 1968, as the Any Other Weapon catch-all only applies to firearms under or that have been concealed. However, a modification intending to fire from the shoulder and bypass the regulation of short-barreled rifles is considered the unlawful possession and manufacture of an unregistered short-barreled rifle.
In some historical cases, the term "machine carbine" was the official title for submachine guns, such as the British Sten and Australian Owen guns. The semiautomatic-only version of the Sterling submachine gun was also officially called a "carbine". The original Sterling semi-auto would be classed a "short barrel rifle" under the U.S. National Firearms Act, but fully legal long-barrel versions of the Sterling have been made for the U.S. collector market.

</doc>
<doc id="6583" url="https://en.wikipedia.org/wiki?curid=6583" title="Chinese cuisine">
Chinese cuisine

Chinese cuisine is an important part of Chinese culture, which includes cuisine originating from the diverse regions of China, as well as from Overseas Chinese who have settled in other parts of the world. Because of the Chinese diaspora and historical power of the country, Chinese cuisine has influenced many other cuisines in Asia, with modifications made to cater to local palates. Chinese food staples such as rice, soy sauce, noodles, tea, and tofu, and utensils such as chopsticks and the wok, can now be found worldwide.
The preference for seasoning and cooking techniques of Chinese provinces depend on differences in historical background and ethnic groups. Geographic features including mountains, rivers, forests and deserts also have a strong effect on the local available ingredients, considering that the climate of China varies from tropical in the south to subarctic in the northeast. Imperial, royal and noble preference also plays a role in the change of Chinese cuisines. Because of imperial expansion and trading, ingredients and cooking techniques from other cultures are integrated into Chinese cuisines over time.
The most praised "Four Major Cuisines" are Chuan, Lu, Yue and Huaiyang, representing West, North, South and East China cuisine correspondingly. The modern "Eight Cuisines" of China are Anhui (), Cantonese (), Fujian (), Hunan (), Jiangsu (), Shandong (), Sichuan (), and Zhejiang () cuisines.
Color, smell and taste are the three traditional aspects used to describe Chinese food, as well as the meaning, appearance and nutrition of the food. Cooking should be appraised with respect to the ingredients used, knifework, cooking time and seasoning.
Chinese society greatly valued gastronomy, and developed an extensive study of the subject based on its traditional medical beliefs. Chinese culture initially centered around the North China Plain. The first domesticated crops seem to have been the foxtail and broomcorn varieties of millet, while rice was cultivated in the south. By 2000 BC, wheat had arrived from western Asia. These grains were typically served as warm noodle soups instead of baked into bread as in Europe. Nobles hunted various wild game and consumed mutton, pork and dog as these animals were domesticated. Grain was stored against famine and flood and meat was preserved with salt, vinegar, curing, and fermenting. The flavor of the meat was enhanced by cooking it in animal fats though this practice was mostly restricted to the wealthy.
By the time of Confucius in the late Zhou, gastronomy had become a high art. Confucius discussed the principles of dining: "The rice would never be too white, the meat would never be too finely cut... When it was not cooked right, man would not eat. When it was cooked bad, man would not eat. When the meat was not cut properly, man would not eat. When the food was not prepared with the right sauce, man would not eat. Although there are plenty of meats, they should not be cooked more than staple food. There is no limit for alcohol, before a man gets drunk." During Shi Huangdi's Qin dynasty, the empire expanded into the south. By the time of the Han dynasty, the different regions and cuisines of China's people were linked by major canals and leading to a greater complexity in the different regional cuisines. Not only is food seen as giving "qi", energy, but food is also about maintaining yin and yang. The philosophy behind it was rooted in the "I Ching" and Chinese traditional medicine: food was judged for color, aroma, taste, and texture and a good meal was expected to balance the Four Natures ('hot', warm, cool, and 'cold') and the Five Tastes (pungent, sweet, sour, bitter, and salty). Salt was used as a preservative from early times, but in cooking was added in the form of soy sauce, and not at the table. 
By the Later Han period (2nd century), writers frequently complained of lazy aristocrats who did nothing but sit around all day eating smoked meats and roasts.
During the Han dynasty, the Chinese developed methods of food preservation for military rations during campaigns such as drying meat into jerky and cooking, roasting, and drying grain.
Chinese legends claim that the roasted, flat bread shaobing was brought back from the "Xiyu" (the Western Regions, a name for Central Asia) by the Han dynasty General Ban Chao, and that it was originally known as hubing (, lit. "barbarian bread"). The shaobing is believed to be descended from the hubing. Shaobing is believed to be related to the Persian "nan" and Central Asian "nan", as well as the Middle Eastern pita. Foreign westerners made and sold sesame cakes in China during the Tang dynasty.
During the Southern and Northern Dynasties non-Han people like the Xianbei of Northern Wei introduced their cuisine to northern China, and these influences continued up to the Tang dynasty, popularizing meat like mutton and dairy products like goat milk, yogurts, and Kumis among even Han people. It was during the Song dynasty that Han Chinese developed an aversion to dairy products and abandoned the dairy foods introduced earlier.
The Han Chinese rebel Wang Su who received asylum in the Xianbei Northern Wei after fleeing from Southern Qi, at first could not stand eating dairy products like goat's milk and meat like mutton and had to consume tea and fish instead, but after a few years he was able to eat yogurt and lamb, and the Xianbei Emperor asked him which of the foods of China (Zhongguo) he preferred, fish vs mutton and tea vs yogurt.
The great migration of Chinese people south during the invasions preceding and during the Song dynasty increased the relative importance of southern Chinese staples such as rice and congee. Su Dongpo has improved the red braised pork as Dongpo pork.
The Yuan and Qing dynasties introduced Mongolian and Manchu cuisine, warm northern dishes that popularized hot pot cooking. During the Yuan dynasty many Muslim communities emerged in China, who practiced a porkless cuisine now preserved by Hui restaurants throughout the country. Yunnan cuisine is unique in China for its cheeses like Rubing and Rushan cheese made by the Bai people, and its yogurt, the yogurt may have been due to a combination of Mongolian influence during the Yuan dynasty, the Central Asian settlement in Yunnan, and the proximity and influence of India and Tibet on Yunnan.
As part of the last leg of the Columbian Exchange, Spanish and Portuguese traders began introducing foods from the New World to China through the port cities of Canton and Macau. Mexican chili peppers became essential ingredients in Sichuan cuisine and calorically-dense potatoes and corn became staple foods across the northern plains.
During the Qing Dynasty, Chinese gastronomes such as Yuan Mei focused upon a primary goal of extracting the maximum flavor of each ingredient. As noted in his culinary work the "Suiyuan shidan", however, the fashions of cuisine at the time were quite varied and in some cases were flamboyantly ostentatious, especially when the display served also a formal ceremonial purpose, as in the case of the Manchu Han Imperial Feast.
As the pace of life increases in modern China, fast food like fried noodles, fried rice and "gaifan" (dish over rice) become more and more popular.
There are a variety of styles of cooking in China, but Chinese chefs have classified eight regional cuisines according to their distinct tastes and local characteristics. A number of different styles contribute to Chinese cuisine but perhaps the best known and most influential are Cantonese cuisine, Shandong cuisine, Jiangsu cuisine (specifically Huaiyang cuisine) and Sichuan cuisine. These styles are distinctive from one another due to factors such as availability of resources, climate, geography, history, cooking techniques and lifestyle. One style may favour the use of garlic and shallots over chili and spices, while another may favour preparing seafood over other meats and fowl. Jiangsu cuisine favours cooking techniques such as braising and stewing, while Sichuan cuisine employs baking. Zhejiang cuisine focuses more on serving fresh food and is more like Japanese food. Fujian cuisine is famous for its delicious seafood and soups and the precise use of scintillating spices. Hunan cuisine is famous for its hot and sour taste. Anhui cuisine incorporates wild food for an unusual taste and is wilder than Fujian cuisine. 
Based on the raw materials and ingredients used, the method of preparation and cultural differences, a variety of foods with different flavors and textures are prepared in different regions of the country. Many traditional regional cuisines rely on basic methods of preservation such as drying, salting, pickling and fermentation.
In addition, the "rice theory" attempts to describe cultural differences between north and south China; in the north, noodles are more consumed due to wheat being widely grown whereas in the south, rice is more preferred as it has historically been more cultivated there.
Chinese ancestors successfully planted millet, rice, and other grains about 9,000 and 8,000 years ago. As for wheat, another staple, it took another three or four thousand years. For the first time, grains provided people with a steady supply of food. Because of the lack of food, Chinese people have to adapt to the new eating habits. The meat was scarce at that time, so people cooked with small amounts of meat and rice or noodles. 
Rice is a major staple food for people from rice farming areas in southern China. Steamed rice, usually white rice, is the most commonly eaten form. People in southern China also like to use rice to make congee as breakfast. Rice is also used to produce beer, baijiu and vinegars. Glutinous rice ("sticky rice") is a variety of rice used in specialty dishes such as lotus leaf rice and glutinous rice balls.
In wheat-farming areas in Northern China, people largely rely on flour-based food, such as noodles, "bing" (bread), "jiaozi" (a kind of Chinese dumplings), and "mantou" (a type of steamed buns).
Chinese noodles come dry or fresh in a variety of sizes, shapes and textures and are often served in soups or fried as toppings. Some varieties, such as Shou Mian (寿面, literally noodles of longevity), is an avatar of long life and good health according to Chinese traditions. Noodles can be served hot or cold with different toppings, with broth, and occasionally dry (as is the case with mi-fen). Noodles are commonly made with rice flour or wheat flour, but other flours such as soybean are also used in minor groups.
Tofu is made of soybeans and is another popular food product that supplies protein. The production process of tofu varies from region to region, resulting in different kinds of tofu with a wide range of texture and taste. Other products such as soy milk, soy paste, soy oil, and fermented soy sauce are also important in Chinese cooking.
There are many kinds of soybean products, including tofu skin, smoked tofu, dried tofu, and fried tofu.
Stinky tofu is fermented tofu. Like blue cheese or durian, it has a very distinct, potent and strong smell, and is an acquired taste. Hard stinky tofu is often deep-fried and paired with soy sauce or salty spice. Soft stinky tofu are usually used as a spread on steamed buns.
Doufuru is another type of fermented tofu that has a salty taste. Doufuru can be pickled together with soy beans, red yeast rice or chili to create different color and flavor. This is more of a pickled type of tofu and is not as strongly scented as stinky tofu. Doufuru has the consistency of slightly soft blue cheese, and a taste similar to Japanese miso paste, but less salty. Doufuru can be used as a spread on steamed buns, or paired with rice congee.
Apart from vegetables that can be commonly seen, some unique vegetables used in Chinese cuisine include baby corn, bok choy, snow peas, Chinese eggplant, Chinese broccoli, and straw mushrooms. Other vegetables including bean sprouts, pea vine tips, watercress, lotus roots, water chestnuts, and bamboo shoots are also used in different cuisines of China.
Because of different climate and soil conditions, cultivars of green beans, peas, and mushrooms can be found in rich variety.
A variety of dried or pickled vegetables are also processed, especially in drier or colder regions where fresh vegetables were hard to get out of season.
Seasonings such as fresh ginger root, garlic, scallion, cilantro and sesame are widely used in many regional cuisines. Sichuan peppercorns, star anise, cinnamon, fennel, cloves and white peppers are also used in different regions.
To add extra flavors to dishes, many Chinese cuisines also contain dried Chinese mushrooms, dried baby shrimp, dried tangerine peel, and dried Sichuan chillies.
When it comes to sauces, China is home to soy sauce, which is made from fermented soybeans and wheat. A number of sauces are also based on fermented soybeans, including hoisin sauce, ground bean sauce and yellow bean sauce. There are also different sauces preferred by regional cuisines, oyster sauce, fish sauce and furu (fermented tofu) are also widely used. Vinegar also has a variety with different flavors: clear rice vinegar, Chinkiang black rice vinegar, Shanxi vinegar, Henghe vinegar etc.
Generally, seasonal fruits serve as the most common form of dessert consumed after dinner.
Dim sum (點心), originally means small portion of food, can refer to dessert, pastries. Later to avoid the disambiguation, tian dian (甜點) and gao dian (糕點) are used to describe desserts and pastries.
Chinese desserts are sweet foods and dishes that are served with tea, usually during the meal, or at the end of meals in Chinese cuisine.
Besides served as a dim sum along with tea, pastries are used for celebration of traditional festivals. The most famous one is moon cake, used to celebrate the Mid-Autumn Festival.
A wide variety of Chinese desserts are available, mainly including steamed and boiled sweet snacks. Bing is an umbrella term for all breads in Chinese, also including pastries and sweets. These are baked wheat flour based confections, with different stuffings including red bean paste, jujube and various of others. Su (酥) is another kind of pastry made with more amount of oil, making the confection more friable. Chinese candies and sweets, called "táng" (糖) are usually made with cane sugar, malt sugar, honey, nuts and fruit. Gao or Guo are rice based snacks that are typically steamed and may be made from glutinous or normal rice.
Another cold dessert is called "baobing", which is shaved ice with sweet syrup. Chinese jellies are known collectively in the language as "ices". Many jelly desserts are traditionally set with agar and are flavored with fruits, though gelatin based jellies are also common in contemporary desserts.
Chinese dessert soups are typically sweet and served hot.
There are also western pastries in China, like mille-feuille, crème brûlée and cheesecake, but they are generally not as popular because the Chinese preference of dessert is mildly sweet and less oily.
Many types of street foods, which vary from region to region, can be eaten as snacks or light dinner. Prawn crackers are an often-consumed snack in Southeast China.
Chinese in earlier dynasties evidently drank milk and ate dairy products, although not necessarily from cows, but perhaps "koumiss" (fermented mare's milk) or goat's milk.
Many Chinese have until recently avoided milk, partly because pasturage for milk producers in a monsoon rice ecology is not economic, and partly because of the high rate of lactose intolerance among the Chinese population. As such the use of dairy products in Chinese cuisine has historically been rare, with regional exceptions such as the "double skin milk" dessert in Guangdong Province or the Rubing (milk cake) cheese in Yunnan. Today ice cream is commonly available and popular throughout China.
Cold dishes are usually served before the main meal. Besides salad and pickles as appetizers, they can range from jelly, beancurd, noodle salad, cooked meat and sausages, to jellyfish or cold soups.
Chinese sausages vary from region to region. The most common sausage is made of pork and pork fat. Flavor is generally salty-sweet in Southern China. In other parts of China, sausages are salted to be preserved. Chinese sausage is prepared in many different ways, including oven-roasting, stir-fry, and steaming.
In some part of South China, soups are served between the cold dishes and the main dishes. In other parts of China, soups are served between the main dish and staple foods, before desserts or fruit salad. There are many traditional Chinese soups, such as wonton soup, herbal chicken soup, hot and sour soup, winter melon soup and so on.
Tea plays an important role in Chinese dining culture. Baijiu and huangjiu as strong alcoholic beverages are preferred by many people as well. Wine is not so popular as other drinks in China that are consumed whilst dining, although they are usually available in the menu.
As well as with dim sum, many Chinese drink their tea with snacks such as nuts, plums, dried fruit (in particular jujube), small sweets, melon seeds, and waxberry. China was the earliest country to cultivate and drink tea, which is enjoyed by people from all social classes. Tea processing began after the Qin and Han Dynasties.
The different types of Chinese tea include black, white, green, yellow, oolong, and dark tea. Chinese tea is often classified into several different categories according to the species of plant from which it is sourced, the region in which it is grown, and the method of production used. Some of these types are green tea, oolong tea, black tea, scented tea, white tea, and compressed tea. There are four major tea plantation regions: Jiangbei, Jiangnan, Huanan and the southwestern region. Well known types of green tea include Longjing, Huangshan, Mao Feng, Bilochun, Putuofeng Cha, and Liu'an Guapian. China is the world's largest exporter of green tea.
One of the most ubiquitous accessories in modern China, after a wallet or purse and an umbrella, is a double-walled insulated glass thermos with tea leaves in the top behind a strainer.
The importance of "baijiu" ( "white liquor") in China (99.5% of its alcoholic market) makes it the most-consumed alcoholic spirit in the world. It dates back to the introduction of distilling during the Song dynasty; can be made from wheat, corn, or rice; and is usually around 120 proof (60% ABV). The most ubiquitous brand is the cheap Er guo tou, but Mao Tai is the premium "baijiu". Other popular brands Kang, Lu Zhou Te Qu, and Wu Liang Ye.
"Huangjiu" ( "yellow liquor") is not distilled and is a strong rice wine (10–15% ABV). Popular brands include Shaoxing Lao Jiu, Shaoxing Hua Diao, and Te Jia Fan.
While fermented grain beverages have been brewed in China for over 9,000 years, it has been long overshadowed by stronger alcohol like Baijiu and Huangjiu.
Chinese herb tea, also known as "medicinal herbal tea", is a kind of tea made from Chinese medicinal herbs.
Soy milk, almond milk, walnut milk and coconut milk are also drunk during the meal in different regions. In some parts of China, hawthorn and jujube juice are preferred. A small shot of fruit vinegar is served as an appetizer in Shanxi.
Where there are historical immigrant Chinese populations, the style of food has evolved and been adapted to local tastes and ingredients, and modified by the local cuisine, to greater or lesser extents. This has resulted in a deep Chinese influence on other national cuisines such as Cambodian cuisine, Filipino cuisine, Thai cuisine and Vietnamese cuisine. There are also a large number of forms of fusion cuisine, often popular in the country in question. Some, such as ramen (Japanese Chinese cuisine) have become popular internationally.
Deep fried meat combined with sweet and sour sauce as a cooking style receives an enormous preference outside of China. Therefore, many similar international Chinese cuisines are invented based on sweet and sour sauce, including Sweet and sour chicken (Europe and North America), Manchurian chicken (India) or "tangsuyuk" (South Korea). The Hawaiian pizza was inspired by Chinese sweet and sour flavors.
Apart from the host country, the dishes developed in overseas Chinese cuisines are heavily dependent on the cuisines derived from the origin of the Chinese immigrants. In Korean Chinese cuisine, the dishes derive primarily from Shandong cuisine while Filipino Chinese cuisine is strongly influenced by Fujian cuisine. The large population having Chinese ancestors in the United States operates many restaurants, has developed distinctive dishes (such as chop suey) based originally on Cantonese cuisine, while those are not popular among Chinese-American people.
According to the report released by China's largest on-demand service platform in 2018, there are over 600,000 Chinese restaurants overseas. The report also pointed out that hotpot is the most popular food in the foreign market. Sichuan cuisine and some Chinese snacks and fast food followed in second and third place, respectively.
Guests at a meal should greet the host and other guests after arriving at the banquet.
The Chinese dining etiquette has that youths should not sit at the table before the elders. If the guest of honor or most senior member is not seated, other people are not allowed to be seated.
Youths should not start eating before the elders start eating. When eating with a bowl, one should not hold it with its bottom part, because it resembles the act of begging. Chopsticks are the main eating utensils for Chinese food, which can be used to cut and pick up food. When someone taking a break from eating at the table, they should not put the chopstick into the rice vertically, because it resembles the Chinese traditional funeral tribute, which involves putting chopstick inside a bowl of rice vertically. It is considered inappropriate to use knives on the dining table. Chopsticks should not be waved around in the air or played with. Food should first be taken from the plate in front. It is considered impolite to stare at a plate. Watching TV, using mobile phones or doing other activities while eating is considered a bad habit. If an older person puts food in a younger person's bowl, the younger person should thank them.
In Chinese philosophy, food is frequently used as the message that the author is trying to convey. A Chinese philosophy I Ching says, “Gentlemen use eating as a way to attain happiness. They should be aware of what they say, and refrain from eating too much." 
In Chinese folk religion, ancestor veneration is conducted by offering food to ancestors and Chinese festivals involve the consumption and preparation of specific foods which have symbolic meanings attached to them. Specific religions in China have their own cuisines such as the Taoist diet, Buddhist cuisine and Chinese Islamic Cuisine. The Kaifeng Jews in Henan province once had their own Chinese Jewish cuisine but the community has largely died out in the modern era and not much is known about the specifics of their cuisine but they did influence foods eaten in their region and some of their dishes remain.

</doc>
<doc id="6585" url="https://en.wikipedia.org/wiki?curid=6585" title="Constantin Brâncuși">
Constantin Brâncuși

Constantin Brâncuși (; February 19, 1876 – March 16, 1957) was a Romanian sculptor, painter and photographer who made his career in France. Considered a pioneer of modernism, one of the most influential sculptors of the 20th-century, Brâncuși is called the patriarch of modern sculpture. As a child he displayed an aptitude for carving wooden farm tools. Formal studies took him first to Bucharest, then to Munich, then to the École des Beaux-Arts in Paris from 1905 to 1907. His art emphasizes clean geometrical lines that balance forms inherent in his materials with the symbolic allusions of representational art. Brâncuși sought inspiration in non-European cultures as a source of primitive exoticism, as did Paul Gauguin, Pablo Picasso, André Derain and others. However, other influences emerge from Romanian folk art traceable through Byzantine and Dionysian traditions.
Brâncuși grew up in the village of Hobiţa, Gorj, near Târgu Jiu, close to Romania's Carpathian Mountains, an area known for its rich tradition of folk crafts, particularly woodcarving. Geometric patterns of the region are seen in his later works.
His parents Nicolae and Maria Brâncuși were poor peasants who earned a meager living through back-breaking labor; from the age of seven, Constantin herded the family's flock of sheep. He showed talent for carving objects out of wood, and often ran away from home to escape the bullying of his father and older brothers.
At the age of nine, Brâncuși left the village to work in the nearest large town. At 11 he went into the service of a grocer in Slatina; and then he became a domestic in a public house in Craiova where he remained for several years. When he was 18, Brâncuși created a violin by hand with materials he found around his workplace. Impressed by Brâncuși's talent for carving, an industrialist enrolled him in the Craiova School of Arts and Crafts ("școala de arte și meserii"), where he pursued his love for woodworking, graduating with honors in 1898.
He then enrolled in the Bucharest School of Fine Arts, where he received academic training in sculpture. He worked hard, and quickly distinguished himself as talented. One of his earliest surviving works, under the guidance of his anatomy teacher, Dimitrie Gerota, is a masterfully rendered écorché (statue of a man with skin removed to reveal the muscles underneath) which was exhibited at the Romanian Athenaeum in 1903. Though just an anatomical study, it foreshadowed the sculptor's later efforts to reveal essence rather than merely copy outward appearance.
In 1903, Brâncuși traveled to Munich, and from there to Paris. In Paris, he was welcomed by the community of artists and intellectuals brimming with new ideas. He worked for two years in the workshop of Antonin Mercié of the École des Beaux-Arts, and was invited to enter the workshop of Auguste Rodin. Even though he admired the eminent Rodin he left the Rodin studio after only two months, saying, "Nothing can grow under big trees."
After leaving Rodin's workshop, Brâncuși began developing the revolutionary style for which he is known. His first commissioned work, "The Prayer", was part of a gravestone memorial. It depicts a young woman crossing herself as she kneels, and marks the first step toward abstracted, non-literal representation, and shows his drive to depict "not the outer form but the idea, the essence of things." He also began doing more carving, rather than the method popular with his contemporaries, that of modeling in clay or plaster which would be cast in metal, and by 1908 he worked almost exclusively by carving.
In the following few years he made many versions of "Sleeping Muse" and "The Kiss", further simplifying forms to geometrical and sparse objects.
His works became popular in France, Romania and the United States. Collectors, notably John Quinn, bought his pieces, and reviewers praised his works. In 1913 Brâncuși's work was displayed at both the Salon des Indépendants and the first exhibition in the U.S. of modern art, the Armory Show.
In 1920, he developed a notorious reputation with the entry of "Princess X" in the Salon. The phallic appearance of this large, gleaming bronze piece scandalized the Salon and, despite Brâncuși's explanation that it was simply meant to represent the essence of womanhood, removed it from the exhibition. "Princess X" was revealed to be Princess Marie Bonaparte, direct descendant of the younger brother of Napoleon Bonaparte. The sculpture has been interpreted by some as symbolizing her obsession with the penis and her lifelong quest to achieve vaginal orgasm, with the help of Sigmund Freud.
Around this time Brâncuși began crafting the bases for his sculptures with much care and originality because he considered them important to the works themselves.
One of his major groups of sculptures involved the "Bird in Space" — simple abstract shapes representing a bird in flight. The works are based on his earlier "Măiastra" series. In Romanian folklore the Măiastra is a beautiful golden bird who foretells the future and cures the blind. Over the following 20 years, Brâncuși made multiple versions of "Bird in Space" out of marble or bronze. Athena Tacha Spear's book, "Brâncuși's Birds," (CAA monographs XXI, NYU Press, New York, 1969), first sorted out the 36 versions and their development, from the early "Măiastra", to the "Golden Bird" of the late teens, to the "Bird in Space", which emerged in the early 1920s and which Brâncuși developed throughout his life.
One of these versions caused a major controversy in 1926, when photographer Edward Steichen purchased it and shipped it to the United States. Customs officers did not accept the "Bird" as a work of art and assessed customs duty on its import as an industrial item. After protracted court proceedings, this assessment was overturned, thus confirming the Bird's status as a duty-exempt work of art. The ruling also established the important principle that "art" does not have to involve a realistic representation of nature, and that it was legitimate for it to simply represent an abstract concept – in this case "flight".
His work became increasingly popular in the U.S, where he visited several times during his life. Worldwide fame in 1933 brought him the commission of building a meditation temple, the Temple of Deliverance, in India for the Maharajah of Indore, Yeshwant Rao Holkar. Holkar had commissioned three "L'Oiseau dans l'Espace"—in bronze, black and white marble—previously, but when Brâncuși went to India in 1937 to complete the plans and begin construction, the Mahrajah was away and, supposedly, lost interest in the project which was to be an homage to his wife, the Maharani Margaret Holkar, who had died when he returned. Of the three birds, the bronze one is in the collection of the Norton Simon Museum in Pasadena, California, and the two marble birds are currently in the permanent collection of the National Gallery of Australia in Canberra, Australia.
In 1938, he finished the World War I monument in Târgu-Jiu where he had spent much of his childhood. "Table of Silence", "The Gate of the Kiss", and "Endless Column" commemorate the courage and sacrifice of Romanians who in 1916 defended Târgu Jiu from the forces of the Central Powers. The restoration of this ensemble was spearheaded by the World Monuments Fund and was completed in 2004.
The Târgu Jiu ensemble marks the apex of his artistic career. In his remaining 19 years he created less than 15 pieces, mostly reworking earlier themes, and while his fame grew he withdrew. In 1955 "Life" magazine reported, "Wearing white pajamas and a yellow gnome-like cap, Brâncuși today hobbles about his studio tenderly caring for and communing with the silent host of fish, birds, heads, and endless columns which he created."
Brâncuși was cared for in his later years by a Romanian refugee couple. He became a French citizen in 1952 in order to make the caregivers his heirs, and to bequeath his studio and its contents to the Musée National d'Art Moderne in Paris.
Brâncuși always dressed in the simple ways the Romanian peasants did. His studio was reminiscent of the houses of the peasants from his native region: there was a big slab of rock as a table and a primitive fireplace, similar to those found in traditional houses in his native Oltenia, while the rest of the furniture was made by him out of wood. Brâncuși would cook his own food, traditional Romanian dishes, with which he would treat his guests.
Brâncuși held a large spectrum of interests, from science to music. He was a good violinist and he would sing old Romanian folk songs, often expressing by them his feelings of homesickness. After the installment of communism, he never considered moving back permanently to his native Romania, but he did visit it eight times.
His circle of friends included artists and intellectuals in Paris such as Amedeo Modigliani, Ezra Pound, Henri Pierre Roché, Guillaume Apollinaire, Louise Bourgeois, Pablo Picasso, Man Ray, Marcel Duchamp, Henri Rousseau, Peggy Guggenheim, Tristan Tzara and Fernand Léger. He was an old friend of Romany Marie, who was also Romanian, and referred Isamu Noguchi to her café in Greenwich Village.
Although surrounded by the Parisian avant-garde, Brâncuși never lost contact with Romania and had friends from the community of Romanian artists and intellectuals living in Paris, including Benjamin Fondane, George Enescu, Theodor Pallady, Camil Ressu, Nicolae Dărăscu, Panait Istrati, Traian Vuia, Eugène Ionesco, Emil Cioran, Natalia Dumitresco and Paul Celan. Another Romanian scholar wrote on Brancusi, Mircea Eliade.
Brâncuși held a particular interest in mythology, especially Romanian mythology, folk tales, and traditional art (which also had a strong influence on his works), but he became interested in African and Mediterranean art as well.
A talented handyman, he built his own phonograph and made most of his furniture, utensils, and doorways. His worldview valued "differentiating the essential from the ephemeral," with Plato, Lao-Tzu, and Milarepa as influences. Reportedly, he had a copy of the first ever translation from the Tibetan into French of Jacques Bacot's Le poete tibetain Milarepa: ses crimes, ses épreuves, son Nirvana that he kept by his bedside. He identified closely with Milarepa's mountain existence since Brancusi himself came from the Carpathian Mountains of Romania and he often thought of he was a reincarnation of Milarepa. He was a saint-like idealist and near ascetic, turning his workshop into a place where visitors noted the deep spiritual atmosphere. However, particularly through the 1910s and 1920s, he was known as a pleasure seeker and merrymaker in his bohemian circle. He enjoyed cigarettes, good wine, and the company of women. He had one child, John Moore, with the New Zealand pianist Vera Moore, whom he never acknowledged.
Brâncuși died on March 16, 1957, aged 81. He was buried in the Cimetière du Montparnasse in Paris. This cemetery also displays statues that Brâncuși carved for deceased artists.
In 1962, Georg Olden used Brâncuși's "Bird in Space" as the inspiration behind his design of the Clio Award statuette.
At his death Brâncuși left 1200 photographs and 215 sculptures. He bequeathed part of his collection to the French state on condition that his workshop be rebuilt as it was on the day he died. This reconstruction of his studio, adjacent to the Pompidou Centre, is open to the public. Brâncuși's studio inspired Swedish architect Klas Anshelm's design of the Malmö Konsthall, which opened in 1975.
Brâncuși was elected posthumously to the Romanian Academy in 1990.
Google commemorated his 135th birthday with a Doodle in 2011 consisting of seven of his works.
Brâncuși's works are housed in the National Museum of Art of Romania (Bucharest), the Museum of Modern Art (New York) and other museums around the world. The Philadelphia Museum of Art holds the largest collection of Brâncuși sculptures in the United States.
In 2015 the Romanian Parliament declared February 19 "The Brâncuși Day", a working holiday in Romania.
A metro station in Bucharest is named after Brâncuși.
Brâncuși's piece "Madame L.R." sold for €29.185 million ($37.2 million) in 2009, setting a record price for a sculpture sold at auction.
In May 2018, "La Jeune Fille Sophistiquée" ("Portrait de Nancy Cunard"), a polished bronze on a carved marble base (1932), sold for US$71 million (with fees) at Christie's New York, setting a world record auction price for the artist.
Both "Bird in Space" and "Sleeping Muse I" are sculptures of animate objects; however, unlike ones from Ancient Greece or Rome, or those from the High Renaissance period, these works of art are more abstract in style.
"Bird in Space" is a series from the 1920s. One of these, constructed in 1925 using wood, stone, and marble (Richler 178) stands around 72 inches tall and consists of a narrow feather standing erect on a wooden base. Similar models, but made from materials such as bronze, were also produced by Brâncuși and placed in exhibitions.
"Sleeping Muse I" has different versions as well; one, from 1909 to 1910, is made of marble and measures 6 ¾ in. in height (Adams 549). This is a model of a head, without a body, with markings to show features such as hair, nose, lips, and closed eyes. In "A History of Western Art", Adams says that the sculpture has "an abstract, curvilinear quality and a smooth contour that create an impression of elegance" (549). The qualities which produce the effect can particularly be seen in the shape of the eyes and in the set of the mouth.

</doc>
<doc id="6586" url="https://en.wikipedia.org/wiki?curid=6586" title="Claus Sluter">
Claus Sluter

Claus Sluter (1340s in Haarlem – 1405 or 1406 in Dijon) was a Dutch sculptor. He was the most important northern European sculptor of his age and is considered a pioneer of the "northern realism" of the Early Netherlandish painting that came into full flower with the work of Jan van Eyck and others in the next generation.
The name "Claes de Slutere van Herlam" is inscribed in the Register of the Corporation of Stonemasons and Sculptors of Brussels around the years 1379/1380. He then moved to the Burgundian capital of Dijon, where from 1385 to 1389 he was the assistant of Jean de Marville, court sculptor to Philip the Bold, Duke of Burgundy. From 1389 to his death he was court sculptor himself, with the rank of "valet de chambre". He was succeeded by his nephew Claus de Werve.
Sluter's most significant work is the so-called "Well of Moses" (1395–1403), or the Great Cross. It was created for the Carthusian monastery of Champmol, which was founded by Philip the Bold right outside Dijon in 1383. For many years, the top portion was thought to have included (along with Christ on a cross), sculptures of the Virgin and John the Evangelist. However it was more likely just Christ, with Mary Magdalene kneeling at the foot of the cross. The cross, and whatever was on the terrace below, was destroyed at some point after 1736 and before 1789, probable because the roof of the building protecting the monument collapsed. Some fragments from the original Cross are preserved in the Musée Archéologique de Dijon. Life-sized figures representing Old Testament prophets and kings (Moses, David, Daniel, Jeremiah, Zachariah, and Isaiah) stand around the base, holding phylacteries and books inscribed with verses from their respective texts, which were interpreted in the Middle Ages as typological prefigurations of the sacrifice of Christ. The work's physical structure, in which the Old Testament figures support those of the New Dispensation, literalizes the typological iconography. The pedestal surmounts a hexagonal fountain. The entire monument is executed in limestone quarried from Tonnerre and Asnières.
A few steps away from The Well of Moses one finds the portal of the former mortuary chapel of Champmol. The portal consists of three sculptural groups by Sluter: a standing Madonna and Child at the trumeau; the duke and St. John, his patron saint, at the left jamb and the duchess and her patron saint, Catherine, at the right one. Sluter was also responsible for the main part of the work on Philip's tomb, which (restored and partly reconstructed) has been moved to the Museum of Fine Arts which is housed in the former ducal palace in Dijon.
Sluter was one of the sculptors of the pleurants, or mourners, which occupy niches below the tombs of Philip the Bold, his wife Margaret, and John the Fearless.

</doc>
<doc id="6587" url="https://en.wikipedia.org/wiki?curid=6587" title="Cadillac, Michigan">
Cadillac, Michigan

For the car manufacturer, see Cadillac, for other uses, see Cadillac (disambiguation)
Cadillac is a city in the U.S. state of Michigan. The city is the county seat of Wexford County. The population was 10,355 at the 2010 census. Today US 131, M-55 and M-115 have a junction at this city. The geographic center of Michigan is approximately five miles (8.05 km) north-northwest of Cadillac.
Cadillac became the county seat after the so-called "Battle of Manton". Local officials engaged in a show of force to enforce the controversial state legislative decision to move the county seat from Manton.
European explorers and fur traders visited this area from the 18th century, most of them initially French and French-Canadians who traded with regional Native Americans. More permanent communities were not established until the late 19th century. Initial settlements developed from logging camps and the logging industry.
In 1871, the first sawmill began operations at Cadillac. Originally called the Pioneer Mill, it was built by John R. Yale. That same year, George A. Mitchell, a prominent Cadillac banker and railroad entrepreneur, and Adam Gallinger, a local carpenter, formed the Clam Lake Canal Improvement and Construction Company. Two years later, the Clam Lake Canal was constructed between Big and Little Clam lakes, known as present-day lakes Mitchell and Cadillac. Sawmill owners used the canal to transport timber from Big Clam Lake to the mills and railroad sites on Little Clam Lake. The Grand Rapids and Indiana Railroad (|G.R. & I. Railroad) had reached the area in 1872.
This settlement was originally named Clam Lake and was incorporated as a village in 1874. George Mitchell was elected as the first mayor. The village was incorporated as a city in 1877 and renamed Cadillac, after Antoine Laumet de La Mothe, sieur de Cadillac, a French colonist who started the first permanent settlement at Detroit in 1701.
The Wexford County seat of government, originally located in Sherman, was moved to Manton in 1881, as the result of a compromise between the feuding residents of Cadillac and Sherman. Cadillac partisans, however, won the county seat by a county-wide vote in April 1882. The day following the election, a sheriff's posse left the city for Manton by special train to seize the county records. After they arrived and collected a portion of the materials, however, an angry crowd confronted the Cadillac men and drove them out of town.
When the sheriff returned to Cadillac, he encountered a force consisting of several hundred armed men; this group reportedly included a brass band. The Sheriff's force, some of whom may have been intoxicated, traveled back to Manton to seize the remaining records. Although Manton residents confronted the Cadillac men and barricaded the courthouse, the posse successfully seized the documents. They returned to Cadillac in dubious glory.
In 1878, Ephraim Shay perfected his Shay locomotive, which was particularly effective in its ability to climb steep grades, maneuver sharp turns, and accommodate imperfections in railroad tracks. Cadillac was home to the Michigan Iron Works Company, which manufactured the Shay locomotive for a short time in the early 1880s. The lumber industry continued to dominate the city, attracting a large immigrant labor force, most of whom were Swedish. (Later Cadillac made sister city arrangements with Mölnlycke, Sweden, and Rovaniemi, Finland).
In 1899, the Cadillac Club formed, the forerunner of the Cadillac Area Chamber of Commerce. Gradually, various manufacturing firms found success in Cadillac.
By the early 20th century, with the lumber depleted, the timber industry was in decline. Industrial development soon dominated the local economy, and it continues to do so today. Cadillac's range of industries includes the manufacture of pleasure boats, automotive parts, water-well components, vacuum cleaners, and rubber products.
In 1936, the U.S. Forest Service and the Civilian Conservation Corps developed the Caberfae Ski Area during the Great Depression as an investment in future economic development. This resulted in promotion of this area as a tourist center. Caberfae remains in operation today, as the oldest ski resort in the midwest. Tourism and outdoor recreation have since become an important sector of Cadillac's economy.
In the summer, tourists travel to the city and region for boating, fishing, hiking, mountain biking, and camping. During the fall, hunting and color tours are popular. The winter is possibly the busiest season; the area can be found packed with downhill skiers, cross-country skiers, ice-fishers, snow-shoers and–most of all-snowmobilers. The North American Snowmobile Festival (NASF) is held on frozen Lake Cadillac every winter.
Thirsty's, a gas station on M-55 west of Cadillac, was the home of Samantha or "Sam The Bear" from the 1970s through the late 1990s, when Sam died of old age. Sam was the only brown bear in captivity in the US at the time to hibernate naturally. Sam lived in a large cage in front of the gas station and was fed ice cream cones by tourists every summer.
In October 1975 the rock group Kiss visited Cadillac and performed at the Cadillac High School gymnasium. They played the concert to honor the Cadillac High School football team. In previous years, the team had compiled a record of sixteen consecutive victories, but the 1974 squad opened the season with two losses. The assistant coach, Jim Neff, an English teacher and rock'n'roll fan, thought to inspire the team by playing Kiss music in the locker room. He also connected the team's game plan, K-I-S-S or "Keep It Simple Stupid", with the band. The team went on to win seven straight games and their conference co-championship. After learning of their association with the team's success, the band decided to visit the school and play for the homecoming game.
Cadillac maintains a number of state historic landmarks. Most are marked with a green "Michigan Historical Marker" sign, which includes a description of the landmark. Six sites with the city are marked: Cadillac Carnegie Library, Charles T. Mitchell House, Clam Lake Canal, Cobbs & Mitchell Building, Cobbs & Mitchell No. 1, and the Shay Locomotive (pictured at the right). Two more are in the near Cadillac area: Caberfae Ski Resort and Greenwood Disciples of Christ Church; and another two are in surrounding Wexford County, marking Battle of Manton and the First Wexford County Court House.
According to the United States Census Bureau, the city has a total area of , of which is land and is water.
The Lake Cadillac is entirely within the city limits. The larger, Lake Mitchell is nearby on the west side of the city, with of shoreline within the city's municipal boundary. The lakes were connected by a stream which was replaced in 1873 by the Clam Lake Canal. The canal was featured on Ripley's Believe It or Not in the 1970s due to the phenomenon that in winter the canal freezes before the lakes and then after the lakes freeze, the canal thaws and remains unfrozen for the rest of the winter.
Cadillac is located at the eastern edge of what is now managed as the Manistee National Forest. The surrounding area is heavily wooded, with mixed hardwood and conifer forests. Christmas tree farming has been important to the area agricultural industry. Cadillac was chosen in 1988 to donate the holiday tree installed at the lawn of the U.S. Capitol building in Washington, D.C.
The area surrounding Cadillac is primarily rural, and is considered to be part of Northern Michigan. Given the small size of nearby communities, the city is a major commercial and industrial hub of the region.
The commercial center of the city is located on the eastern edge of Lake Cadillac. Most downtown buildings range from two to five stories in height. Many face Mitchell Street, the city's tree-lined main street and traditional corridor of travel through town. The downtown contains a movie theater, gift shops, restaurants, a bookstore, specialty food stores, jewelers, clothing retailers, and various other businesses.
The Courthouse Hill Historic District, recognized in April 2005, lies adjacent to the city's commercial center. The District contains a number of large Victorian-style residences built by the lumber barons and businessmen who helped develop the city in the 1870s. Population and building density is highest in this area.
On the western bank of Lake Cadillac, where M-55 intersects M-115, is what is locally referred to as Cadillac West. This is a small commercial district, bordering Mitchell State Park and the two lakes; it caters mostly to tourists. It contains a number of motels and restaurants.
Along the northern and southern stretches of the lake are the main residential areas of the city. They are generally of low to moderate density, characterized primarily by single-family structures.
Cadillac experiences a typical northern Michigan climate, undergoing temperate seasonal changes, influenced by the presence of Lake Michigan and the inevitable lake effect. Winters are generally cold with large amounts of snowfall. Summers are warm. The average high temperature in July is 80 °F (27 °C) and the average low is in February, at 9 °F (−13 °C). Summer temperatures can exceed 90 °F (32 °C), and winter temperatures can drop below 0 °F (−18 °C). Average annual rainfall is 30 inches (76 cm), and average annual snowfall is 81 inches (206 cm) . Snowfall typically occurs between the months of November and March. According to the Köppen climate classification system, Cadillac has a humid continental climate, abbreviated "Dfb" on climate maps.
Cadillac has two superfund sites, according to the U.S. Environmental Protection Agency. One is located at 1100 Wright Street, the former site of Kysor Industrial Corp, which operations resulted in toxic wastes. The other is located at 1002 6th Street, the former site of Northernaire Plating. Its operations also produced hazardous wastes, which produced contamination.
As of the census of 2010, there were 10,355 people, 4,280 households, and 2,625 families residing in the city. The population density was . There were 4,927 housing units at an average density of . The racial makeup of the city was 95.6% White, 0.5% African American, 0.6% Native American, 1.0% Asian, 0.4% from other races, and 1.8% from two or more races. Hispanic or Latino of any race were 1.8% of the population.
There were 4,280 households, of which 32.9% had children under the age of 18 living with them, 39.2% were married couples living together, 16.4% had a female householder with no husband present, 5.7% had a male householder with no wife present, and 38.7% were non-families. 32.0% of all households were made up of individuals, and 14% had someone living alone who was 65 years of age or older. The average household size was 2.34 and the average family size was 2.90.
The median age in the city was 36.5 years. 24.7% of residents were under the age of 18; 10% were between the ages of 18 and 24; 24.4% were from 25 to 44; 23.8% were from 45 to 64; and 17.1% were 65 years of age or older. The gender makeup of the city was 47.4% male and 52.6% female.
As of the census of 2000, there were 10,000 people, 4,118 households, and 2,577 families residing in the city. The population density was 1,466.0 per square mile (566.1/km). There were 4,466 housing units at an average density of 654.7 per square mile (252.8/km). The racial makeup of the city was 96.55% White, 0.21% Black or African American, 0.92% Native American, 0.63% Asian, 0.03% Pacific Islander, 0.28% from other races, and 1.38% from two or more races. 1.18% of the population were Hispanic or Latino of any race.
There were 4,118 households, out of which 32.2% had children under the age of 18 living with them, 43.9% were married couples living together, 14.2% had a female householder with no husband present, and 37.4% were non-families. 31.8% of all households were made up of individuals, and 14.4% had someone living alone who was 65 years of age or older. The average household size was 2.37 and the average family size was 2.96.
In the city, the population was spread out, with 26.2% under the age of 18, 9.6% from 18 to 24, 27.9% from 25 to 44, 19.6% from 45 to 64, and 16.7% who were 65 years of age or older. The median age was 36 years. For every 100 females, there were 91.4 males. For every 100 females age 18 and over, there were 84.4 males.
The median income for a household in the city was $29,899, and the median income for a family was $36,825. Males had a median income of $29,773 versus $21,283 for females. The per capita income for the city was $16,801. About 10.9% of families and 13.7% of the population were below the poverty line, including 15.4% of those under age 18 and 13.3% of those age 65 or over.
Cadillac was incorporated as a city in 1877. It is a home rule city with a Council-Manager form of government-one.
Current council members are Shari Spoelman, Antoinette Schippers, Arthur Stevens, James Dean and Carla Filkins (mayor). The present City Manager is Marcus Peccia.
Cadillac is located in Michigan's 2nd congressional district, represented by Republican Bill Huizenga.
Manufacturing has been the greatest employer in Cadillac since the logging industry. More than 26% of the city's labor force is employed in manufacturing. Three industrial parks are located within the city limits, comprising 7% of the total land use in Cadillac. Their operations generate 47% of the city's tax base. Much of the city's economic performance is determined by the fortunes of local industry.
The center of the city is generally perceived to have a "small-town-feel". In the summer, the downtown fills with tourists, many from southern Michigan. The city center is one block from Lake Cadillac. For visitors by boat who dock at the public docks, it is nearly as accessible by boat as it is by car. The city's immediate proximity to two lakes, as well as Manistee National Forest, Pere Marquette State Forest, Mitchell State Park and a number of major highways, has established tourism as a significant sector of the local economy.
During the winter months, Lake Cadillac and Lake Mitchell freeze over and the city becomes covered with snow. Cadillac is connected to a number of trail systems popular with winter recreation enthusiasts. The city integrates unusually well into the corridors of travel created by snowmobilers.
Cadillac is also known as Chestnut Town, USA. The local area has a relatively high number of American chestnut trees, planted by pioneers from New York and Pennsylvania who settled in western Michigan. A blight in the early 20th century killed nearly every American Chestnut tree, but those in western Michigan had developed a mysterious resistance and survived.
According to the city's 2019 "Comprehensive Annual Financial Report", the principal employers in the city were:
Cadillac's public education system has a total of 10 schools, with approximately 3,100 students and 166 teachers with a student:teacher ratio of 19.1:1. Cadillac has 4 private primary and secondary schools with approximately 394 students, 20 teachers and a student:teacher ratio of 20:1.
The city has two high schools: Cadillac High School and Innovation High School. The area also has a junior high school, covering grades 7 and 8, located adjacent to the high school, and a middle school, Mackinaw Trail Middle School, covering grades 5 and 6. There are four elementary schools, Forest View Elementary, Franklin Elementary, Kenwood Elementary, and Lincoln Elementary.
Cadillac also has an alternative high school, located in the building that formerly housed Cooley Elementary School. Adult high school and GED courses are offered there as well. As a whole, the programs at Cooley are part of a curriculum that aids individuals in overcoming the exceptional obstacles to their educational and workforce goals.
Vocational career training is available to high school students free of charge in Cadillac and nearby schools at Wexford-Missaukee Independent School District (ISD) Career Tech Center (formerly Wexford-Missaukee Vocational Center or Voc-Tech). Students are bussed for part of the day to the Career Tech Center from their respective schools and receive credits toward high school graduation. Students are also able to earn certification in a chosen trade. Courses include:
Cosmetology is offered through the Career Tech Center, but at an off-campus location in downtown Cadillac. Adults can attend the vocational or cosmetology school with tuition or financial aid for certification.
Cadillac hosts the Wexford-Missaukee ISD Special Education for residents of the two counties who are in need of special services. This school is on the same campus as the Career Tech Center.
The class of 2006 was the largest class to go through Cadillac Public Schools.
Cadillac offers several options for private religious education.
Cadillac Heritage Christian offers nondenominational Christian education from pre-K through 12th grade. It is a coed school with 98 students and a teacher:student ratio of 1:11. Graduating classes are typically between 3–12 students.
Northview Adventist School has 16 students in grades 1–10 as of 2020. It is a coed Seventh Day Adventist School. They operate in a one-room format, with one teacher that doubles as the principal, and one or two teachers assistants. They also have a multitude of volunteers that runs a library, band, and physical education, among other things. They do not participate in competitive sports.
Noah's Ark Day School is a small alternative non-denominational Christian school for students in pre-K through first grade only. It is coed with 42 students and 1 teacher.
Cadillac's largest and most well-known private school is St. Ann School, a coed private Roman Catholic school with 236 students in grades pre-K through 7. The teacher:student ratio is 1:26. St. Ann is a member of the National Catholic Education Association. No Catholic high school education is offered at St. Ann School, and students typically attend public school for grades 8–12.
Northwoods Aviation, located at Wexford County Airport, offers training programs for piloting and servicing aircraft. Northwoods Aviation also offers primary instruction for those interested in sport pilot, private, and commercial certificates.
The Cadillac Institute of Cosmetology (formerly Cadillac Academy of Beauty) is a full service teaching salon in downtown Cadillac that offers training for general cosmetologists and specialized technicians to high school students through a partnership with Wexford-Missaukee Intermediate School District. Training is also available to adult students though private courses on a tuition basis. Upon completion of the program, students are qualified to take the state board exam to become a licensed cosmetologist or specialty technician.
The Baker College-Cadillac campus occupies just outside the City of Cadillac. The school has an enrollment of more than 1,300 students and offers Associate's and bachelor's degrees, in addition to professional certifications.
Cadillac is situated as the confluence of three highways: US 131, M-55 and M-115. Prior to 2001, the northern end of the freeway portion of US 131 was located at the southern entrance to Cadillac. With the construction of a bypass, the US 131 freeway was extended around the east side of the city. The former route of the highway through downtown Cadillac was redesignated as BUS US 131. In the city, BUS US 131 is named Mitchell Street, after George Mitchell, but may be referred to as main street.
The city is serviced by rail via the Great Lakes Central Railroad. This is primarily a freight line, although passenger service is expected in the future.
The White Pine Trail's northern terminus is in Cadillac. The trail, which stretches and originates from Comstock Park, follows an abandoned railroad bed into the center of the city. The trail is paved from the village of Leroy 16 miles north to Cadillac.

</doc>
<doc id="6589" url="https://en.wikipedia.org/wiki?curid=6589" title="COINTELPRO">
COINTELPRO

COINTELPRO (syllabic abbreviation derived from COunter INTELligence PROgram) (1956–1979, and beyond) is a series of covert and illegal projects conducted by the United States Federal Bureau of Investigation (FBI) aimed at surveilling, infiltrating, discrediting, and disrupting American political organizations. FBI records show that COINTELPRO resources targeted groups and individuals that the FBI deemed subversive, including feminist organizations, the Communist Party USA, anti–Vietnam War organizers, the Ku Klux Klan, activists of the civil rights movement or Black Power movement (e.g. Martin Luther King Jr., the Nation of Islam, and the Black Panther Party), environmentalist and animal rights organizations, the American Indian Movement (AIM), independence movements (such as Puerto Rican independence groups like the Young Lords), and a variety of organizations that were part of the broader New Left.
In 1971 in San Diego, the FBI financed, armed, and controlled an extreme right-wing group of former members of the Minutemen anti-communist para-military organization, transforming it into a group called the Secret Army Organization that targeted groups, activists, and leaders involved in the Anti-War Movement, using both intimidation and violent acts.
The FBI has used covert operations against domestic political groups since its inception; however, covert operations under the official COINTELPRO label took place between 1956 and 1971. COINTELPRO tactics are still used to this day and have been alleged to include discrediting targets through psychological warfare; smearing individuals and groups using forged documents and by planting false reports in the media; harassment; wrongful imprisonment; and illegal violence, including assassination. According to a senate report, the FBI's motivation was "protecting national security, preventing violence, and maintaining the existing social and political order".
Beginning in 1969, leaders of the Black Panther Party were targeted by the COINTELPRO and "neutralized" by being assassinated, imprisoned, publicly humiliated or falsely charged with crimes. Some of the Black Panthers affected included Fred Hampton, Mark Clark, Zayd Shakur, Geronimo Pratt, Mumia Abu-Jamal, and Marshall Conway. Common tactics used by COINTELPRO were perjury, witness harassment, witness intimidation, and withholding of evidence.
FBI Director J. Edgar Hoover issued directives governing COINTELPRO, ordering FBI agents to "expose, disrupt, misdirect, discredit, or otherwise neutralize" the activities of these movements and especially their leaders. Under Hoover, the agent in charge of COINTELPRO was William C. Sullivan. Attorney General Robert F. Kennedy personally authorized some of the programs. Although Kennedy only gave written approval for limited wiretapping of Martin Luther King's phones "on a trial basis, for a month or so", Hoover extended the clearance so his men were "unshackled" to look for evidence in any areas of King's life they deemed worthy.
Centralized operations under COINTELPRO officially began in August 1956 with a program designed to "increase factionalism, cause disruption and win defections" inside the Communist Party USA (CPUSA). Tactics included anonymous phone calls, Internal Revenue Service (IRS) audits, and the creation of documents that would divide the American communist organization internally. An October 1956 memo from Hoover reclassified the FBI's ongoing surveillance of black leaders, including it within COINTELPRO, with the justification that the movement was infiltrated by communists. In 1956, Hoover sent an open letter denouncing Dr. T. R. M. Howard, a civil rights leader, surgeon, and wealthy entrepreneur in Mississippi who had criticized FBI inaction in solving recent murders of George W. Lee, Emmett Till, and other African Americans in the South. When the Southern Christian Leadership Conference (SCLC), an African-American civil rights organization, was founded in 1957, the FBI began to monitor and target the group almost immediately, focusing particularly on Bayard Rustin, Stanley Levison, and eventually Martin Luther King Jr.
After the 1963 March on Washington for Jobs and Freedom, Hoover singled out King as a major target for COINTELPRO. Under pressure from Hoover to focus on King, Sullivan wrote:
In the light of King's powerful demagogic speech. ... We must mark him now if we have not done so before, as the most dangerous Negro of the future in this nation from the standpoint of communism, the Negro, and national security.
Soon after, the FBI was systematically bugging King's home and his hotel rooms, as they were now aware that King was growing in stature daily as the most prominent leader of the civil rights movement.
In the mid-1960s, King began to publicly criticize the Bureau for giving insufficient attention to the use of terrorism by white supremacists. Hoover responded by publicly calling King the most "notorious liar" in the United States. In his 1991 memoir "Washington Post", journalist Carl Rowan asserted that the FBI had sent at least one anonymous letter to King encouraging him to commit suicide. Historian Taylor Branch documents an anonymous November 21, 1964 "suicide package" sent by the FBI that contained audio recordings obtained through tapping King's phone and placing bugs throughout various hotel rooms over the past two years, and that was created two days after the announcement of King's impending Nobel Peace Prize. The tape, which was prepared by FBI audio technician John Matter, documented a series of King's sexual indiscretions combined with a letter telling him: "There is only one way out for you. You better take it before your filthy, abnormal, fraudulent self is bared to the nation". King was subsequently informed that the audio would be released to the media if he did not acquiesce and commit suicide prior to accepting his Nobel Peace Prize. When King refused to satisfy their coercion tactics, FBI Associate Director, Cartha D. DeLoach, commenced a media campaign offering the surveillance transcript to various news organizations, including "Newsweek" and "Newsday". And even by 1969, as has been noted elsewhere, "[FBI] efforts to 'expose' Martin Luther King Jr. had not slackened even though King had been dead for a year. [The Bureau] furnished ammunition to opponents that enabled attacks on King's memory, and ... tried to block efforts to honor the slain leader."
During the same period the program also targeted Malcolm X. While an FBI spokesman has denied that the FBI was "directly" involved in Malcolm's murder in 1965, it is documented that the Bureau worked to "widen the rift" between Malcolm and Elijah Muhammad through infiltration and the "sparking of acrimonious debates within the organization", rumor-mongering, and other tactics designed to foster internal disputes, which ultimately led to Malcolm's assassination. The FBI heavily infiltrated Malcolm's Organization of Afro-American Unity in the final months of his life. The Pulitzer Prize-winning asserts that most of the men who plotted Malcolm's assassination were never apprehended and that the full extent of the FBI's involvement in his death cannot be known.
Amidst the urban unrest of July–August 1967, the FBI began "COINTELPRO–BLACK HATE", which focused on King and the SCLC, as well as the Student Nonviolent Coordinating Committee (SNCC), the Revolutionary Action Movement (RAM), the Deacons for Defense and Justice, Congress of Racial Equality (CORE), and the Nation of Islam. BLACK HATE established the Ghetto Informant Program and instructed 23 FBI offices to "disrupt, misdirect, discredit, or otherwise neutralize the activities of black nationalist hate type organizations".
A March 1968 memo stated the program's goal was to "prevent the coalition of militant black nationalist groups"; to "Prevent the RISE OF A 'MESSIAH' who could unify ... the militant black nationalist movement"; "to pinpoint potential troublemakers and neutralize them before they exercise their potential for violence [against authorities]."; to "Prevent militant black nationalist groups and leaders from gaining RESPECTABILITY, by discrediting them to ... both the responsible community and to liberals who have vestiges of sympathy..."; and to "prevent the long-range GROWTH of militant black organizations, especially among youth". Dr. King was said to have potential to be the "messiah" figure, should he abandon nonviolence and integrationism, and Stokely Carmichael was noted to have "the necessary charisma to be a real threat in this way" as he was portrayed as someone who espoused a much more militant vision of "black power". While the FBI was particularly concerned with leaders and organizers, they did not limit their scope of target to the heads of organizations. Individuals such as writers were also listed among the targets of operations.
This program coincided with a broader federal effort to prepare military responses for urban riots and began increased collaboration between the FBI, Central Intelligence Agency, National Security Agency, and the Department of Defense. The CIA launched its own domestic espionage project in 1967 called Operation CHAOS. A particular target was the Poor People's Campaign, a national effort organized by King and the SCLC to occupy Washington, DC. The FBI monitored and disrupted the campaign on a national level, while using targeted smear tactics locally to undermine support for the march. The Black Panther Party was another targeted organization, wherein the FBI collaborated to destroy the party from the inside out.
Overall, COINTELPRO encompassed disruption and sabotage of the Socialist Workers Party (1961), the Ku Klux Klan (1964), the Nation of Islam, the Black Panther Party (1967), and the entire New Left social/political movement, which included antiwar, community, and religious groups (1968). A later investigation by the Senate's Church Committee (see below) stated that "COINTELPRO began in 1956, in part because of frustration with Supreme Court rulings limiting the Government's power to proceed overtly against dissident groups." Official congressional committees and several court cases have concluded that COINTELPRO operations against communist and socialist groups exceeded statutory limits on FBI activity and violated constitutional guarantees of freedom of speech and association.
The program was secret until 1971, when the Citizens' Commission to Investigate the FBI burgled an FBI field office in Media, Pennsylvania, took several dossiers, and exposed the program by passing this material to news agencies. The boxing match known as the Fight of the Century between Muhammad Ali and Joe Frazier in March 1971 provided cover for the activist group to successfully pull off the burglary; Muhammad Ali was himself a COINTELPRO target due to his involvement with the Nation of Islam and the anti-war movement. Many news organizations initially refused to publish the information. Within the year, Director J. Edgar Hoover declared that the centralized COINTELPRO was over, and that all future counterintelligence operations would be handled on a case-by-case basis.
Additional documents were revealed in the course of separate lawsuits filed against the FBI by NBC correspondent Carl Stern, the Socialist Workers Party, and a number of other groups. In 1976 the Select Committee to Study Governmental Operations with Respect to Intelligence Activities of the United States Senate, commonly referred to as the "Church Committee" after its chairman, Senator Frank Church of Idaho, launched a major investigation of the FBI and COINTELPRO. Many released documents have been partly or entirely redacted.
The Final Report of the Select Committee castigated the conduct of the intelligence community in its domestic operations (including COINTELPRO) in no uncertain terms:
The Church Committee documented a history of the FBI exercising political repression as far back as World War I, through the 1920s, when agents were charged with rounding up "anarchists, communists, socialists, reformists and revolutionaries" for deportation. The domestic operations were increased against political and anti-war groups from 1936 through 1976.
The intended effect of the FBI's COINTELPRO was to "expose, disrupt, misdirect, or otherwise neutralize" groups that the FBI officials believed were "subversive" by instructing FBI field operatives to:
At its inception, the program's main target was the Communist Party.
In an interview with the BBC's Andrew Marr in February 1996, Noam Chomsky—a political activist and MIT professor of linguistics—spoke about the purpose and the targets of COINTELPRO, saying:
COINTELPRO was a program of subversion carried out not by a couple of petty crooks but by the national political police, the FBI, under four administrations... by the time it got through, I won't run through the whole story, it was aimed at the entire new left, at the women's movement, at the whole black movement, it was extremely broad. Its actions went as far as political assassination.
According to the Church Committee:
While the declared purposes of these programs were to protect the "national security" or prevent violence, Bureau witnesses admit that many of the targets were nonviolent and most had no connections with a foreign power. Indeed, nonviolent organizations and individuals were targeted because the Bureau believed they represented a "potential" for violence—and nonviolent citizens who were against the war in Vietnam were targeted because they gave "aid and comfort" to violent demonstrators by lending respectability to their cause.
The imprecision of the targeting is demonstrated by the inability of the Bureau to define the subjects of the programs. The Black Nationalist program, according to its supervisor, included "a great number of organizations that you might not today characterize as black nationalist but which were in fact primarily black". Thus, the nonviolent Southern Christian Leadership Conference was labeled as a Black Nationalist-"Hate Group".
Furthermore, the actual targets were chosen from a far broader group than the titles of the programs would imply. The CPUSA program targeted not only Communist Party members but also sponsors of the National Committee to Abolish the House Un-American Activities Committee and civil rights leaders allegedly under Communist influence or deemed to be not sufficiently "anti-Communist". The Socialist Workers Party program included non-SWP sponsors of anti-war demonstrations which were cosponsored by the SWP or the Young Socialist Alliance, its youth group. The Black Nationalist program targeted a range of organizations from the Panthers to SNCC to the peaceful Southern Christian Leadership Conference, and included every Black Student Union and many other black student groups. New Left targets ranged from the SDS to the InterUniversity Committee for Debate on Foreign Policy, from Antioch College ("vanguard of the New Left") to the New Mexico Free University and other "alternate" schools, and from underground newspapers to students' protesting university censorship of a student publication by carrying signs with four-letter words on them.
Examples of surveillance, spanning all presidents from FDR to Nixon, both legal and illegal, contained in the Church Committee report:
Groups that were known to be targets of COINTELPRO operations include:
The COINTELPRO operators targeted multiple groups at once and encouraged splintering of these groups from within. In letter-writing campaigns (wherein false letters were sent on behalf of members of parties), the FBI ensured that groups would not unite in their causes. For instance, they launched a campaign specifically to alienate the Black Panther Party from the Mau Maus, Young Lords, Young Patriots and SDS. These racially diverse groups had been building alliances, in part due to charismatic leaders such as Fred Hampton and his attempts to create a "Rainbow Coalition". The FBI was concerned with ensuring that groups could not gain traction through unity, specifically across racial lines. One of the main ways of targeting these groups was to arouse suspicion between the different parties and causes. In this way the bureau took on a divide and conquer offensive.
The COINTELPRO documents show numerous cases of the FBI's intentions to prevent and disrupt protests against the Vietnam War. Many techniques were used to accomplish this task. "These included promoting splits among antiwar forces, encouraging red-baiting of socialists, and pushing violent confrontations as an alternative to massive, peaceful demonstrations." One 1966 COINTELPRO operation tried to redirect the Socialist Workers Party from their pledge of support for the antiwar movement.
The FBI has said that it no longer undertakes COINTELPRO or COINTELPRO-like operations. However, critics have claimed that agency programs in the spirit of COINTELPRO targeted groups such as the Committee in Solidarity with the People of El Salvador, the American Indian Movement, Earth First!, and the anti-globalization movement.
According to attorney Brian Glick in his book "War at Home", the FBI used five main methods during COINTELPRO:
The FBI specifically developed tactics intended to heighten tension and hostility between various factions in the black power movement, for example between the Black Panthers and the US Organization. For instance, the FBI sent a fake letter to the US Organization exposing a supposed Black Panther plot to murder the head of the US Organization, Ron Karenga. They then intensified this by spreading falsely attributed cartoons in the black communities pitting the Black Panther Party against the US Organization. This resulted in numerous deaths, among which were San Diego Black Panther Party members John Huggins, Bunchy Carter and Sylvester Bell. Another example of the FBI's anonymous letter writing campaign is how they turned the Blackstone Rangers head, Jeff Fort, against former ally Fred Hampton, by stating that Hampton had a hit on Fort. They also were instrumental in developing the rift between Black Panther Party leaders Eldridge Cleaver and Huey Newton, as executed through false letters inciting the two leaders of the Black Panther Party.
Dhoruba Bin Wahad, a former Black Panther, reflects on how these tactics made him feel, saying he had a combat mentality and felt like he was at war with the government. When asked about why he thinks the Black Panthers were targeted he said, "In the United States, the equivalent of the military was the local police. During the early sixties, at the height of the civil rights movement, and the human rights movement, the police in the United States became increasingly militaristic. They began to train out of military bases in the United States. The Law Enforcement Assistance Act supplied local police with military technology, everything from assault rifles to army personnel carriers. In his opinion, the Counterintelligence Program went hand-in-hand with the militarization of the police in the Black community, with the militarization of police in America."
The FBI also conspired with the police departments of many U.S. cities (San Diego, Los Angeles, San Francisco, Oakland, Philadelphia, Chicago) to encourage repeated raids on Black Panther homes—often with little or no evidence of violations of federal, state, or local laws—which resulted directly in the police killing many members of the Black Panther Party, most notably Chicago Black Panther Party Chairman Fred Hampton on December 4, 1969. Before the death of Hampton, long-term infiltrator, William O'Neal, shared floor plans of his apartment with the COINTELPRO team. He then gave Hampton a dose of secobarbital that rendered Hampton unconscious during the raid on his home.
In order to eliminate black militant leaders whom they considered dangerous, the FBI is believed to have worked with local police departments to target specific individuals, accuse them of crimes they did not commit, suppress exculpatory evidence and falsely incarcerate them. Elmer "Geronimo" Pratt, a Black Panther Party leader, was incarcerated for 27 years before a California Superior Court vacated his murder conviction, ultimately freeing him. Appearing before the court, an FBI agent testified that he believed Pratt had been framed, because both the FBI and the Los Angeles Police Department knew he had not been in the area at the time the murder occurred.
Some sources claim that the FBI conducted more than 200 "black bag jobs", which were warrantless surreptitious entries, against the targeted groups and their members.
In 1969 the FBI special agent in San Francisco wrote Hoover that his investigation of the Black Panther Party had concluded that in his city, at least, the Panthers were primarily engaged in feeding breakfast to children. Hoover fired back a memo implying the agent's career goals would be directly affected by his supplying evidence to support Hoover's view that the Black Panther Party was "a violence-prone organization seeking to overthrow the Government by revolutionary means".
Hoover supported using false claims to attack his political enemies. In one memo he wrote: "Purpose of counterintelligence action is to disrupt the Black Panther Party and it is immaterial whether facts exist to substantiate the charge."
In one particularly controversial 1965 incident, white civil rights worker Viola Liuzzo was murdered by Ku Klux Klansmen, who gave chase and fired shots into her car after noticing that her passenger was a young black man; one of the Klansmen was Gary Thomas Rowe, an acknowledged FBI informant. The FBI spread rumors that Liuzzo was a member of the Communist Party and had abandoned her children to have sexual relationships with African Americans involved in the civil rights movement. FBI records show that J. Edgar Hoover personally communicated these insinuations to President Johnson.
FBI informant Rowe has also been implicated in some of the most violent crimes of the 1960s civil rights era, including attacks on the Freedom Riders and the 1963 Birmingham, Alabama 16th Street Baptist Church bombing.
The FBI also financed, armed, and controlled an extreme right-wing group of former Minutemen, transforming it into a group called the Secret Army Organization that targeted groups, activists, and leaders involved in the Anti-War Movement, using both intimidation and violent acts.
Hoover ordered preemptive action "to pinpoint potential troublemakers and neutralize them before they exercise their potential for violence."
The final report of the Church Committee concluded:
Too many people have been spied upon by too many Government agencies and too much information has been illegally collected. The Government has often undertaken the secret surveillance of citizens on the basis of their political beliefs, even when those beliefs posed no threat of violence or illegal acts on behalf of a hostile foreign power. The Government, operating primarily through secret and biased informants, but also using other intrusive techniques such as wiretaps, microphone "bugs", surreptitious mail opening, and break-ins, has swept in vast amounts of information about the personal lives, views, and associations of American citizens. Investigations of groups deemed potentially dangerous—and even of groups suspected of associating with potentially dangerous organizations—have continued for decades, despite the fact that those groups did not engage in unlawful activity.
Groups and individuals have been assaulted, repressed, harassed and disrupted because of their political views, social beliefs and their lifestyles. Investigations have been based upon vague standards whose breadth made excessive collection inevitable. Unsavory, harmful and vicious tactics have been employed—including anonymous attempts to break up marriages, disrupt meetings, ostracize persons from their professions, and provoke target groups into rivalries that might result in deaths. Intelligence agencies have served the political and personal objectives of presidents and other high officials. While the agencies often committed excesses in response to pressure from high officials in the Executive branch and Congress, they also occasionally initiated improper activities and then concealed them from officials whom they had a duty to inform.
Governmental officials—including those whose principal duty is to enforce the law—have violated or ignored the law over long periods of time and have advocated and defended their right to break the law.
The Constitutional system of checks and balances has not adequately controlled intelligence activities. Until recently the Executive branch has neither delineated the scope of permissible activities nor established procedures for supervising intelligence agencies. Congress has failed to exercise sufficient oversight, seldom questioning the use to which its appropriations were being put. Most domestic intelligence issues have not reached the courts, and in those cases when they have reached the courts, the judiciary has been reluctant to grapple with them.
While COINTELPRO was officially terminated in April 1971, domestic espionage continued. Between 1972 and 1974, it is documented that the Bureau planted over 500 bugs without a warrant and opened over 2,000 pieces of personal mail. More recent targets of covert action include the American Indian Movement (AIM), Earth First!, and Committees in Solidarity with the People of El Salvador. Documents released under the FOIA show that the FBI tracked the late David Halberstam—a Pulitzer Prize-winning journalist and author—for more than two decades. "Counterterrorism" guidelines implemented during the Reagan administration have been described as allowing a return to COINTELPRO tactics. Some radical groups accuse factional opponents of being FBI informants or assume the FBI is infiltrating the movement. COINTELPRO survivor Filiberto Ojeda Rios was killed by the FBI's hostage rescue team in 2005, his death described by a United Nations special committee as an assassination.
Environmentalist Eric McDavid convicted on arson charges was released after documents emerged demonstrating that the FBI informant in his Earth Liberation Front group provided crucial leadership, information, and material without which the crime could not have been committed, repeating the same pattern of behaviour of COINTELPRO. It has been claimed these sorts of practices have become widespread in FBI counter-terrorism cases targeting left wing politics and Muslims in the 2009 Bronx terrorism plot and others.
Authors such as Ward Churchill, Rex Weyler, and Peter Matthiessen allege that the federal government intended to acquire uranium deposits on the Lakota tribe's reservation land, and that this motivated a larger government conspiracy against AIM activists on the Pine Ridge reservation. Others believe COINTELPRO continues and similar actions are being taken against activist groups. Caroline Woidat says that, with respect to Native Americans, COINTELPRO should be understood within a historical context in which "Native Americans have been viewed and have viewed the world themselves through the lens of conspiracy theory." Other authors argue that while some conspiracy theories related to COINTELPRO are unfounded, the issue of ongoing government surveillance and repression is real. FBI Agent Richard G. Held is known to have increased FBI support for the Guardians of the Oglala Nation (GOON) squads accused of the assault and murder of hundreds of AIM supporters. The Bureau refused to investigate the 64 cases of homicide directly linked to GOON, but committed its resources overwhelmingly to prosecute AIM.
In April 2018, the "Atlanta Black Star" characterized the FBI as still engaging in COINTELPRO behavior by surveilling the Black Lives Matter movement. Internal documents dated as late as 2017 showed that the FBI had surveilled the movement. In 2014, the FBI tracked a Black Lives Matter activist using surveillance tactics which "The Intercept" found "reminiscent of a rich American history of targeting black Americans," including COINTELPRO. This practice, along with the imprisonment of black activists for their views, has been associated with the new FBI designation of "Black Identity Extremists."
Defending Rights & Dissent, a civil liberties group, cataloged known instances of First Amendment abuses and political surveillance by the FBI since 2010. The organization found that the feds devoted disproportionate resources to spy on peaceful left-leaning civil society groups, including Occupy Wall Street, economic justice advocates, racial justice movements, environmentalists, Abolish ICE, and various anti-war movements. During the effort to violently target Occupy Wall Street, the FBI and the DHS conducted their operations against activists in coordination with banks, the local police, and the New York Stock Exchange.

</doc>
<doc id="6590" url="https://en.wikipedia.org/wiki?curid=6590" title="Cruise missile">
Cruise missile

A cruise missile is a guided missile used against terrestrial targets, that remains in the atmosphere and flies the major portion of its flight path at approximately constant speed. Cruise missiles are designed to deliver a large warhead over long distances with high precision. Modern cruise missiles are capable of travelling at supersonic or high subsonic speeds, are self-navigating, and are able to fly on a non-ballistic, extremely low-altitude trajectory.
The idea of an "aerial torpedo" was shown in the British 1909 film "The Airship Destroyer", where flying torpedoes controlled wirelessly are used to bring down airships bombing London.
In 1916, American aviator Lawrence Sperry built and patented an "aerial torpedo", the Hewitt-Sperry Automatic Airplane, a small biplane carrying a TNT charge, a Sperry autopilot and a barometric altitude control. Inspired by these experiments, the United States Army developed a similar flying bomb called the Kettering Bug. Germany had also flown trials with remote-controlled aerial gliders "(Torpedogleiter)" built by Siemens-Schuckert beginning in 1916.
In the period between the World Wars the UK developed the Larynx (Long Range Gun with Lynx Engine), which underwent a few flight tests in the 1920s.
In the Soviet Union, Sergei Korolev headed the GIRD-06 cruise missile project from 1932 to 1939, which used a rocket-powered boost-glide bomb design. The 06/III (RP-216) and 06/IV (RP-212) contained gyroscopic guidance systems. The vehicle was designed to boost to 28 km altitude and glide a distance of 280 km, but test flights in 1934 and 1936 only reached an altitude of 500 meters.
In 1944, Germany deployed the first operational cruise missiles in World War II. The V-1, often called a flying bomb, contained a gyroscope guidance system and was propelled by a simple pulsejet engine, the sound of which gave it the nickname of "buzz bomb" or "doodlebug". Accuracy was sufficient only for use against very large targets (the general area of a city), while the range of 250 km was significantly lower than that of a bomber carrying the same payload. The main advantages were speed (although not sufficient to outperform contemporary propeller-driven interceptors) and expendability. The production cost of a V-1 was only a small fraction of that of a V-2 supersonic ballistic missile, carrying a similar-sized warhead. Unlike the V-2, the initial deployments of the V-1 required stationary launch ramps which were susceptible to bombardment. Nazi Germany, in 1943, also developed the Mistel composite aircraft program, which can be seen as a rudimentary air-launched cruise missile, where a piloted fighter-type aircraft was mounted atop an unpiloted bomber-sized aircraft that was packed with explosives to be released while approaching the target. Bomber-launched variants of the V-1 saw limited operational service near the end of the war, with the pioneering V-1's design reverse-engineered by the Americans as the Republic-Ford JB-2 cruise missile.
Immediately after the war the United States Air Force had 21 different guided missile projects, including would-be cruise missiles. All but four were cancelled by 1948, — the Air Materiel Command BANSHEE, the SM-62 Snark, the SM-64 Navaho, and the MGM-1 Matador. The BANSHEE design was similar to Operation Aphrodite; like Aphrodite, it failed, and was cancelled in April 1949. Concurrently, the US Navy's Operation: BUMBLEBEE, was conducted at Topsail Island, North Carolina, from c. 1 June 1946, to 28 July 1948. Operation: BUMBLEBEE produced proof-of-concept technologies that influenced the US military's other missile projects.
During the Cold War period both the United States and the Soviet Union experimented further with the concept, deploying early cruise missiles from land, submarines and aircraft. The main outcome of the United States Navy submarine missile project was the SSM-N-8 Regulus missile, based upon the V-1.
The United States Air Force's first operational surface-to-surface missile was the winged, mobile, nuclear-capable MGM-1 Matador, also similar in concept to the V-1. Deployment overseas began in 1954, first to West Germany and later to the Republic of China (Taiwan) and South Korea. On 7 November 1956, U.S. Air Force deployed Matador units in West Germany, whose missiles were capable of striking targets in the Warsaw Pact, from their fixed day-to-day sites to unannounced dispersed launch locations. This alert was in response to the crisis posed by the Soviet attack on Hungary which suppressed the Hungarian Revolution of 1956.
Between 1957 and 1961 the United States followed an ambitious and well-funded program to develop a nuclear-powered cruise missile, Supersonic Low Altitude Missile (SLAM). It was designed to fly below the enemy's radar at speeds above Mach 3 and carry hydrogen bombs that it would drop along its path over enemy territory. Although the concept was proven sound and the 500 megawatt engine finished a successful test run in 1961, no airworthy device was ever completed. The project was finally abandoned in favor of ICBM development.
While ballistic missiles were the preferred weapons for land targets, heavy nuclear and conventional weapon tipped cruise missiles were seen by the USSR as a primary weapon to destroy United States naval carrier battle groups. Large submarines (for example, Echo and Oscar classes) were developed to carry these weapons and shadow United States battle groups at sea, and large bombers (for example, Backfire, Bear, and Blackjack models) were equipped with the weapons in their air-launched cruise missile (ALCM) configuration.
Cruise missiles generally consist of a guidance system, payload, and aircraft propulsion system, housed in an airframe with small wings and empennage for flight control. Payloads usually consist of a conventional warhead or a nuclear warhead. Cruise missiles tend to be propelled by jet engine, with turbofan engines in particular being preferred due to their greater efficiency at low altitude and subsonic speed.
Guidance systems also vary greatly. Low-cost systems use a radar altimeter, barometric altimeter and clock to navigate a digital strip map. More advanced systems use inertial guidance, satellite guidance and terrain contour matching (TERCOM). Use of an automatic target recognition (ATR) algorithm/device in the guidance system increases accuracy of the missile. The Standoff Land Attack Missile features an ATR unit from General Electric.
Cruise missiles can be categorized by size, speed (subsonic or supersonic), and range, and whether launched from land, air, surface ship, or submarine. Often versions of the same missile are produced for different launch platforms; sometimes air- and submarine-launched versions are a little lighter and smaller than land- and ship-launched versions.
Guidance systems can vary across missiles. Some missiles can be fitted with any of a variety of navigation systems (Inertial navigation, TERCOM, or satellite navigation). Larger cruise missiles can carry either a conventional or a nuclear warhead, while smaller ones carry only conventional warheads.
A hypersonic speed cruise missile would travel at least five times the speed of sound (Mach 5).
These missiles travel faster than the speed of sound, usually using ramjet engines. The range is typically 100–500 km, but can be greater. Guidance systems vary.
Examples:
The United States, Russia, India, United Kingdom, Iran, South Korea, Israel, China and Pakistan have developed several long-range subsonic cruise missiles. These missiles have a range of over and fly at about . They typically have a launch weight of about and can carry either a conventional or a nuclear warhead. Earlier versions of these missiles used inertial navigation; later versions use much more accurate TERCOM and DSMAC systems. Most recent versions can use satellite navigation.
Examples:
These missiles are about the same size and weight and fly at similar speeds to the above category. Guidance systems vary.
Examples:
These are subsonic missiles which weigh around and have a range of up to .
Examples:
The most common mission for cruise missiles is to attack relatively high-value targets such as ships, command bunkers, bridges and dams. Modern guidance systems permit accurate attacks.
The United States Air Force (USAF) deploys an air-launched cruise missile, the AGM-86 ALCM. The Boeing B-52 Stratofortress is the exclusive delivery vehicle for the AGM-86 and AGM-129 ACM. Both missile types are configurable for either conventional or nuclear warheads.
The USAF adopted the AGM-86 for its bomber fleet while AGM-109 was adapted to launch from trucks and ships and adopted by the USAF and Navy. The truck-launched versions, and also the Pershing II and SS-20 Intermediate Range Ballistic Missiles, were later destroyed under the bilateral INF (Intermediate Range Nuclear Forces) treaty with the USSR.
The British Royal Navy (RN) also operates cruise missiles, specifically the U.S.-made Tomahawk, used by the RN's nuclear submarine fleet. UK conventional warhead versions were first fired in combat by the RN in 1999, during the Kosovo War (the United States fired cruise missiles in 1991). The Royal Air Force uses the Storm Shadow cruise missile on its Tornado GR4 aircraft. It is also used by France, where it is known as SCALP EG, and carried by the Armée de l'Air's Mirage 2000 and Rafale aircraft.
India and Russia have jointly developed the supersonic cruise missile BrahMos. There are three versions of the Brahmos: ship/land-launched, air-launched and sub-launched. The ship/land-launched version were operational as of late 2007. The Brahmos has the capability to attack targets on land. Russia also continues to operate other cruise missiles: the SS-N-12 Sandbox, SS-N-19 Shipwreck, SS-N-22 Sunburn and SS-N-25 Switchblade. Germany and Spain operate the Taurus missile while Pakistan has made the Babur missile, a variant of the US Tomahawk missile. Both the People's Republic of China and the Republic of China (Taiwan) have designed several cruise missile variants, such as the well-known C-802, some of which are capable of carrying biological, chemical, nuclear, and conventional warheads.
China has CJ-10 land attack cruise missile which is capable of carrying a nuclear warhead.
The French Force de Frappe nuclear forces include both land and sea-based bombers with Air-Sol Moyenne Portée high speed medium range nuclear cruise missiles. Two models are in use, ASMP and a newer ASMP-A. Approximately 60 nuclear missiles are in service, 50 land based and 10 sea-based. 
India in 2017 successfully flight-tested its indigenous Nirbhay ('Fearless') land-attack cruise missile, which can deliver nuclear warheads to a strike range of 1,000-km
The Israel Defense Forces reportedly deploy the medium-range air-launched Popeye Turbo ALCM and the Popeye Turbo SLCM medium-long range cruise missile with nuclear warheads on Dolphin class submarines. 
Pakistan currently has four cruise missile systems: the air-launched Ra'ad; the ground and underwater launched Babur; ship-launched Harbah missile and surface launched Zarb missile. Both, Ra'ad and Babur, can carry nuclear warheads between 10 and 25 kt, and deliver them to targets at a range of and respectively. Babur has been in service with the Pakistan Army since 2010.
Russia has Kh-55SM cruise missiles, with similar to United States' AGM-129 range of 3000 km, but are able to carry a more powerful warhead of 200 kt. They are equipped with a TERCOM system which allows them to cruise at an altitude lower than 110 meters at subsonic speeds while obtaining a CEP accuracy of 15 meters with an Inertial navigation system. They are air-launched from either Tupolev Tu-95s, Tupolev Tu-22Ms, or Tupolev Tu-160s, each able to carry 16 for the Tu-95, 12 for the Tu-160, and 4 for the Tu-22M. A stealth version of the missile, the Kh-101 is in development. It has similar qualities as the Kh-55, except that its range has been extended to 5,000 km, equipped with a 1,000 kg conventional warhead, and has stealth features which reduces its probability of intercept.
After the collapse of the Soviet Union, the most recent cruise missile developed was the Kalibr missile which entered production in the early 1990s and officially inducted into the Russian arsenal in 1994. However, it only saw its combat debut on 7 October 2015, in Syria as a part of the Russian military campaign in Syria. The missile has been used 14 more times in combat operations in Syria since its debut.
In the late 1950s and early 1960s, the Soviet Union was attempting to develop cruise missiles. In this short time frame, the Soviet Union was working on nearly ten different types of cruise missiles. However, due to resources, most of the initial types of cruise missiles developed by the Soviet Union were Sea- Launched Cruise Missiles or Submarine-Launched Cruise Missiles (SLCMs). The SS-N-1 cruise missile was developed to have different configurations to be fired from a submarine or a ship. However, as the time progressed, the Soviet Union began to work on air launched cruise missiles as well (ALCM). These ACLM missiles were typically delivered via bombers designated as "Blinders" or "Backfire". The missiles in this configuration were called the AS-1, and AS-2 with eventual new variants with more development time. The main purpose of Soviet-based cruise missiles was to have defense and offensive mechanisms against enemy ships; in other words most of the Soviet cruise missiles were anti-ship missiles. the 1980s the Soviet Union had developed an arsenal of cruise missiles nearing 600 platforms which consisted of land, sea, and air delivery systems.
The United States has deployed four nuclear cruise missiles at one time or another.
Currently cruise missiles are among the most expensive of single-use weapons, up to several million dollars apiece. One consequence of this is that its users face difficult choices in target allocation, to avoid expending the missiles on targets of low value. For instance, during the 2001 strikes on Afghanistan the United States attacked targets of very low monetary value with cruise missiles, which led many to question the efficiency of the weapon. However, proponents of the cruise missile counter that the same argument applies to other types of UAVs: they are cheaper than human pilots when total training and infrastructure costs are taken into account, not to mention the risk of loss of personnel. As demonstrated in Libya in 2011 and prior conflicts, cruise missiles are much more difficult to detect and intercept than other aerial assets (reduced radar cross-section, infrared and visual signature due to smaller size), suiting them to attacks against static air defense systems.

</doc>
<doc id="6591" url="https://en.wikipedia.org/wiki?curid=6591" title="Crete">
Crete

Crete (, , , "," ";" Egyptian: 𓎡𓆑𓍘𓅱𓈉, "keftiu;" , ; ) is the largest and most populous of the Greek islands, the 88th largest island in the world and the fifth largest island in the Mediterranean Sea, after Sicily, Sardinia, Cyprus and Corsica. It bounds the southern border of the Aegean sea. Crete lies approximately south of the Greek mainland. It has an area of and a coastline of 1,046 km (650 mi).
Crete and a number of islands and islets that surround it constitute the Region of Crete (), which is the southernmost of the 13 top-level administrative units of Greece, and the fifth most populous of Greece‘s regions. Its capital and largest city is Heraklion, located on the north shore of the island. , the region had a population of 623,065. The Dodecanese are located to the northeast of Crete, while the Cyclades are situated to the north, separated by the Sea of Crete. The Peloponnese is to the region's northwest.
Humans have inhabited the island since at least 130,000 years ago, during the Paleolithic age. Crete was the centre of Europe's first advanced civilization, the Minoans, from 2700 to 1420 BC. The Minoan civilization was overrun by the Mycenaean civilization from mainland Greece. Crete was later ruled by Rome, then successively by the Byzantine Empire, Andalusian Arabs, the Venetian Republic, and the Ottoman Empire. In 1898 Crete, whose people had for some time wanted to join the Greek state, achieved independence from the Ottomans, formally becoming the Cretan State. Crete became part of Greece in December 1913.
The island is mostly mountainous, and its character is defined by a high mountain range crossing from west to east. It includes Crete's highest point, Mount Ida, and the range of the White Mountains (Lefka Ori) with 30 summits above 2000 metres in altitude and the Samaria Gorge, a World Biosphere Reserve. Crete forms a significant part of the economy and cultural heritage of Greece, while retaining its own local cultural traits (such as its own poetry and music). The Nikos Kazantzakis airport at Heraklion and the Daskalogiannis airport at Chania serve international travelers. The palace of Knossos, a Bronze Age settlement and ancient Minoan city, is also located in Heraklion.
The earliest references to the island of Crete come from texts from the Syrian city of Mari dating from the 18th century BC, where the island is referred to as "Kaptara". This is repeated later in Neo-Assyrian records and the Bible ("Caphtor"). It was known in ancient Egyptian as "Keftiu" or "kftı͗w", strongly suggesting a similar Minoan name for the island.
The current name "Crete" is first attested in the 15th century BC in Mycenaean Greek texts, written in Linear B, through the words "ke-re-te" (*"Krētes"; later Greek: , plural of ) and "ke-re-si-jo" (*"Krēsijos"; later Greek: , "Cretan"). In Ancient Greek, the name Crete () first appears in Homer's "Odyssey".
In Latin, the name of the island became . The original Arabic name of Crete was ( < , but after the Emirate of Crete's establishment of its new capital at (modern Iraklion), both the city and the island became known as () or (), which gave Latin, Italian, and Venetian "Candia", from which were derived French "Candie" and English "Candy" or "Candia". Under Ottoman rule, in Ottoman Turkish, Crete was called ().
Crete is the largest island in Greece and the fifth largest island in the Mediterranean Sea. It is located in the southern part of the Aegean Sea separating the Aegean from the Libyan Sea.
The island has an elongated shape: it spans from east to west, is at its widest point, and narrows to as little as (close to Ierapetra). Crete covers an area of , with a coastline of ; to the north, it broaches the Sea of Crete (); to the south, the South Cretian Sea (); in the west, the Myrtoan Sea, and toward the east the Karpathian Sea. It lies approximately south of the Greek mainland.
Crete is mountainous, and its character is defined by a high mountain range crossing from west to east, formed by six different groups of mountains:
These mountains lavish Crete with valleys, such as Amari valley, fertile plateaus, such as Lasithi plateau, Omalos and Nidha; caves, such as Gourgouthakas, Diktaion, and Idaion (the birthplace of the ancient Greek god Zeus); and a number of gorges.
Mountains in Crete are the object of tremendous fascination both for locals and tourists. The mountains have been seen as a key feature of the island's distinctiveness, especially since the time of Romantic travellers' writing. Contemporary Cretans distinguish between highlanders and lowlanders; the former often claim to reside in places affording a higher/better climatic but also moral environment. In keeping with the legacy of Romantic authors, the mountains are seen as having determined their residents' 'resistance' to past invaders which relates to the oft-encountered idea that highlanders are 'purer' in terms of less intermarriages with occupiers. For residents of mountainous areas, such as Sfakia in western Crete, the aridness and rockiness of the mountains is emphasised as an element of pride and is often compared to the alleged soft-soiled mountains of others parts of Greece or the world.
The island has a number of gorges, such as the Samariá Gorge, Imbros Gorge, Kourtaliotiko Gorge, Ha Gorge, Platania Gorge, the Gorge of the Dead (at Kato Zakros, Sitia) and Richtis Gorge and (Richtis) waterfall at Exo Mouliana in Sitia.
The rivers of Crete include the Ieropotamos River, the Koiliaris, the Anapodiaris, the Almiros, the Giofyros, and Megas Potamos. There are only two freshwater lakes in Crete: Lake Kournas and Lake Agia, which are both in Chania regional unit. Lake Voulismeni at the coast, at Aghios Nikolaos, was formerly a freshwater lake but is now connected to the sea, in Lasithi. Three artificial lakes created by dams also exist in Crete: the lake of Aposelemis Dam, the lake of Potamos Dam, and the lake of Mpramiana Dam.
A large number of islands, islets, and rocks hug the coast of Crete. Many are visited by tourists, some are only visited by archaeologists and biologists. Some are environmentally protected. A small sample of the islands includes:
Off the south coast, the island of Gavdos is located south of Hora Sfakion and is the southernmost point of Europe.
Crete straddles two climatic zones, the Mediterranean and the North African, mainly falling within the former. As such, the climate in Crete is primarily Mediterranean. The atmosphere can be quite humid, depending on the proximity to the sea, while winter is fairly mild. Snowfall is common on the mountains between November and May, but rare in the low-lying areas. While some mountain tops are snow-capped for most of the year, near the coast snow only stays on the ground for a few minutes or hours. However, a truly exceptional cold snap swept the island in February 2004, during which period the whole island was blanketed with snow. During the Cretan summer, average temperatures reach the high 20s-low 30s Celsius (mid 80s to mid 90s Fahrenheit), with maxima touching the upper 30s-mid 40s.
The south coast, including the Mesara Plain and Asterousia Mountains, falls in the North African climatic zone, and thus enjoys significantly more sunny days and high temperatures throughout the year. There, date palms bear fruit, and swallows remain year-round rather than migrate to Africa. The fertile region around Ierapetra, on the southeastern corner of the island, is renowned for its exceptional year-round agricultural production, with all kinds of summer vegetables and fruit produced in greenhouses throughout the winter. Western Crete (Chania province) receives more rain and the soils there suffer more erosion compared to the Eastern part of Crete.
Crete is the most populous island in Greece with a population of more than 600,000 people. Approximately 42% live in Crete's main cities and towns whilst 45% live in rural areas.
Crete with its nearby islands form the Crete Region (, , ), one of the 13 regions of Greece which were established in the 1987 administrative reform. Under the 2010 Kallikratis plan, the powers and authority of the regions were redefined and extended. The region is based at Heraklion and is divided into four regional units (pre-Kallikratis prefectures). From west to east these are: Chania, Rethymno, Heraklion, and Lasithi. These are further subdivided into 24 municipalities.
The region's governor is, since 1 January 2011, Stavros Arnaoutakis, who was elected in the November 2010 local administration elections for the Panhellenic Socialist Movement.
Heraklion is the largest city and capital of Crete. Chania was the capital until 1971. The principal cities are:
The economy of Crete is predominantly based on services and tourism. However, agriculture also plays an important role and Crete is one of the few Greek islands that can support itself independently without a tourism industry. The economy began to change visibly during the 1970s as tourism gained in importance. Although an emphasis remains on agriculture and stock breeding, because of the climate and terrain of the island, there has been a drop in manufacturing, and an observable expansion in its service industries (mainly tourism-related). All three sectors of the Cretan economy (agriculture/farming, processing-packaging, services), are directly connected and interdependent. The island has a per capita income much higher than the Greek average, whereas unemployment is at approximately 4%, one-sixth of that of the country overall.
As in many regions of Greece, viticulture and olive groves are significant; oranges, citrons and avocadoes are also cultivated. Until recently there were restrictions on the import of bananas to Greece, therefore bananas were grown on the island, predominantly in greenhouses. Dairy products are important to the local economy and there are a number of speciality cheeses such as mizithra, anthotyros, and kefalotyri.
The Gross domestic product (GDP) of the region was €9.4 billion in 2018, accounting for 5.1% of Greek economic output. GDP per capita adjusted for purchasing power was €17,800 or 59% of the EU27 average in the same year. The GDP per employee was 68% of the EU average. Crete is the region in Greece with the fifth highest GDP per capita.
The island has three significant airports, Nikos Kazantzakis at Heraklion, the Daskalogiannis airport at Chania and a smaller one in Sitia. The first two serve international routes, acting as the main gateways to the island for travellers. There is a long-standing plan to replace Heraklion airport with a completely new airport at Kastelli, where there is presently an air force base.
The island is well served by ferries, mostly from Athens, by ferry companies such as Minoan Lines and ANEK Lines.
Although the road network leads almost everywhere, there is a lack of modern highways, although this is gradually changing with the completion of the northern coastal spine highway. In addition, a European study has been devised from European Union to promote a modern highway that will connect the North and the South parts of the island via a tunnel. According to the study the project should be include 15.7 km of section of road between the villages Agia Varvara and Agia Deka in central Crete, benefits both tourists and local people by improving the accessibility to the southern part of the island and lessen the accidents. The new road section forms part of the route between Messara in the south and Crete's capital city Heraklion, which provides the island's airport and principal sea port link with mainland Greece. Traffic speeds on the new road will increase by 19 km/hour (from 29 km/hours to 48 km/hour), which should reduce journey times between Messara and Heraklion by 55 minutes. The scheme is also expected to improve road safety by cutting the number of accidents along the route. Building works include construction of three road tunnels, five bridges and three junctions. This project is expected to create 44 jobs during the implementation phase. 
The investment falls under Greece's "Improvement of Accessibility" Operational Programme. The programme aims to improve the country's transport infrastructures as well as its international connections. It will therefore have a key role to play in making Greece's remote and landlocked regions more accessible and economically attractive. This Operational Programme works to link Greece's more prosperous and less developed regions, which should help to promote greater territorial cohesion.
Total investment for the project "Completion of construction of the section of Ag. Varvara - Ag. Deka (Kastelli) (22+170 km to 37+900 km) of the vertical road axis Irakleio – Messara in the prefecture of Irakleio, Kriti" is EUR 102 273 321, of which the EU's European Regional Development Fund is contributing EUR 86 932 323 from the Operational Programme "Improvement of Accessibility" for the 2007 to 2013 programming period. Work falls under the priority "Road Transport – trans-European and trans-regional route network of the regions on the Convergence objective".
Also, during the 1930s there was a narrow-gauge industrial railway in Heraklion, from Giofyros in the west side of the city to the port. There are now no railway lines on Crete. The government is planning the construction of a line from Chania to Heraklion via Rethymno.
Newspapers have reported that the Ministry of Mercantile Marine is ready to support the agreement between Greece, South Korea, Dubai Ports World and China for the construction of a large international container port and free trade zone in southern Crete near Tympaki; the plan is to expropriate 850 ha of land. The port would handle 2 million containers per year, but the project has not been universally welcomed because of its environmental, economic and cultural impact. As of January 2013, the project has still not been confirmed, although there is mounting pressure to approve it, arising from Greece's difficult economic situation.
There are plans for underwater cables going from mainland Greece to Israel and Egypt passing by Crete and Cyprus: EuroAfrica Interconnector and EuroAsia Interconnector. They would connect Crete electrically with mainland Greece, ending energy isolation of Crete. Now Hellenic Republic covers for Crete electricity costs difference of around €300 million per year.
Hominids settled in Crete at least 130,000 years ago. In the later Neolithic and Bronze Age periods, under the Minoans, Crete had a highly developed, literate civilization. It has been ruled by various ancient Greek entities, the Roman Empire, the Byzantine Empire, the Emirate of Crete, the Republic of Venice and the Ottoman Empire. After a brief period of independence (1897–1913) under a provisional Cretan government, it joined the Kingdom of Greece. It was occupied by Nazi Germany during the Second World War.
In 2002, the paleontologist Gerard Gierlinski discovered fossil footprints left by ancient human relatives 5,600,000 years ago.
The first human settlement in Crete dates before 130,000 years ago, during the Paleolithic age. Settlements dating to the aceramic Neolithic in the 7th millennium BC, used cattle, sheep, goats, pigs and dogs as well as domesticated cereals and legumes; ancient Knossos was the site of one of these major Neolithic (then later Minoan) sites. Other neolithic settlements include those at Kephala, Magasa, and Trapeza.
Crete was the centre of Europe's first advanced civilization, the Minoan (). This civilization wrote in the undeciphered script known as Linear A. Early Cretan history is replete with legends such as those of King Minos, Theseus and the Minotaur, passed on orally via poets such as Homer. The volcanic eruption of Thera may have been the cause of the downfall of the Minoan civilization.
In 1420 BC, the Minoan civilization was overrun by the Mycenaean civilization from mainland Greece. The oldest samples of writing in the Greek language, as identified by Michael Ventris, is the Linear B archive from Knossos, dated approximately to 1425–1375 BC.
After the Bronze Age collapse, Crete was settled by new waves of Greeks from the mainland. A number of city states developed in the Archaic period. There was very limited contact with mainland Greece, and Greek historiography shows little interest in Crete, and as a result, there are very few literary sources.
During the 6th to 4th centuries BC, Crete was comparatively free from warfare. The Gortyn code (5th century BC) is evidence for how codified civil law established a balance between aristocratic power and civil rights.
In the late 4th century BC, the aristocratic order began to collapse due to endemic infighting among the elite, and Crete's economy was weakened by prolonged wars between city states. During the 3rd century BC, Gortyn, Kydonia (Chania), Lyttos and Polyrrhenia challenged the primacy of ancient Knossos.
While the cities continued to prey upon one another, they invited into their feuds mainland powers like Macedon and its rivals Rhodes and Ptolemaic Egypt. In 220 BC the island was tormented by a war between two opposing coalitions of cities. As a result, the Macedonian king Philip V gained hegemony over Crete which lasted to the end of the Cretan War (205–200 BC), when the Rhodians opposed the rise of Macedon and the Romans started to interfere in Cretan affairs.
In the 2nd century BC Ierapytna (Ierapetra) gained supremacy on eastern Crete.
Crete was involved in the Mithridatic Wars, initially repelling an attack by Roman general Marcus Antonius Creticus in 71 BC. Nevertheless, a ferocious three-year campaign soon followed under Quintus Caecilius Metellus, equipped with three legions and Crete was finally conquered by Rome in 69 BC, earning for Metellus the title "Creticus". Gortyn was made capital of the island, and Crete became a Roman province, along with Cyrenaica that was called Creta et Cyrenaica. Archaeological remains suggest that Crete under Roman rule witnessed prosperity and increased connectivity with other parts of the Empire. In the 2nd century AD, at least three cities in Crete (Lyttos, Gortyn, Hierapytna) joined the Panhellenion, a league of Greek cities founded by the emperor Hadrian. When Diocletian redivided the Empire, Crete was placed, along with Cyrene, under the diocese of Moesia, and later by Constantine I to the diocese of Macedonia.
Crete was separated from Cyrenaica . It remained a province within the eastern half of the Roman Empire, usually referred to as the Eastern Roman (Byzantine) Empire after the establishment of a second capital in Constantinople by Constantine in 330. Crete was subjected to an attack by Vandals in 467, the great earthquakes of 365 and 415, a raid by Slavs in 623, Arab raids in 654 and the 670s, and again in the 8th century. In , the Emperor Leo III the Isaurian transferred the island from the jurisdiction of the Pope to that of the Patriarchate of Constantinople.
In the 820s, after 900 years as a Roman, and then Eastern Roman (Byzantine) island, Crete was captured by Andalusian Muladis led by Abu Hafs, who established the Emirate of Crete. The Byzantines launched a campaign that took most of the island back in 842 and 843 under Theoktistos. Further Byzantine campaigns in 911 and 949 failed. In 960/1, Nikephoros Phokas' campaign completely restored Crete to the Byzantine Empire, after a century and a half of Arab control.
In 961, Nikephoros Phokas returned the island to Byzantine rule after expelling the Arabs. Extensive efforts at conversion of the populace were undertaken, led by John Xenos and Nikon "the Metanoeite". The reconquest of Crete was a major achievement for the Byzantines, as it restored Byzantine control over the Aegean littoral and diminished the threat of Saracen pirates, for which Crete had provided a base of operations.
In 1204, the Fourth Crusade seized and sacked the imperial capital of Constantinople. Crete was initially granted to leading Crusader Boniface of Montferrat in the partition of spoils that followed. However, Boniface sold his claim to the Republic of Venice, whose forces made up the majority of the Crusade. Venice's rival the Republic of Genoa immediately seized the island and it was not until 1212 that Venice secured Crete as a colony.
From 1212, during Venice's rule, which lasted more than four centuries, a Renaissance swept through the island as is evident from the plethora of artistic works dating to that period. Known as The Cretan School or Post-Byzantine Art, it is among the last flowerings of the artistic traditions of the fallen empire. The most notable representatives of this Cretan renaissance were the painter El Greco and the writers Nicholas Kalliakis (1645–1707), Georgios Kalafatis (professor) (–1720), Andreas Musalus (–1721) and Vitsentzos Kornaros.
Under the rule of the Catholic Venetians, the city of Candia was reputed to be the best fortified city of the Eastern Mediterranean. The three main forts were located at Gramvousa, Spinalonga, and Fortezza at Rethymnon. Other fortifications include the Kazarma fortress at Sitia. In 1492, Jews expelled from Spain settled on the island. In 1574–77, Crete was under the rule of Giacomo Foscarini as Proveditor General, Sindace and Inquisitor. According to Starr's 1942 article, the rule of Giacomo Foscarini was a Dark Age for Jews and Greeks. Under his rule, non-Catholics had to pay high taxes with no allowances. In 1627, there were 800 Jews in the city of Candia, about seven percent of the city's population. Marco Foscarini was the Doge of Venice during this time period.
The Ottomans conquered Crete in 1669, after the siege of Candia. Many Greek Cretans fled to other regions of the Republic of Venice after the Ottoman–Venetian Wars, some even prospering such as the family of Simone Stratigo (c. 1733 – c. 1824) who migrated to Dalmatia from Crete in 1669. Islamic presence on the island, aside from the interlude of the Arab occupation, was cemented by the Ottoman conquest. Most Cretan Muslims were local Greek converts who spoke Cretan Greek, but in the island's 19th-century political context they came to be viewed by the Christian population as Turks. Contemporary estimates vary, but on the eve of the Greek War of Independence (1830), as much as 45% of the population of the island may have been Muslim. A number of Sufi orders were widespread throughout the island, the Bektashi order being the most prevalent, possessing at least five tekkes. Many Cretan Turks fled Crete because of the unrest, settling in Turkey, Rhodes, Syria, Libya and elsewhere. By 1900, 11% of the population was Muslim. Those remaining were relocated in the 1924 population exchange between Greece and Turkey.
During Easter of 1770, a notable revolt against Ottoman rule, in Crete, was started by Daskalogiannis, a shipowner from Sfakia who was promised support by Orlov's fleet which never arrived. Daskalogiannis eventually surrendered to the Ottoman authorities. Today, the airport at Chania is named after him.
Crete was left out of the modern Greek state by the London Protocol of 1830, and soon it was yielded to Egypt by the Ottoman sultan. Egyptian rule was short-lived and sovereignty was returned to the Ottoman Empire by the Convention of London on 3 July 1840.
Heraklion was surrounded by high walls and bastions and extended westward and southward by the 17th century. The most opulent area of the city was the northeastern quadrant where all the elite were gathered together. The city had received another name under the rule of the Ottomans, "the deserted city". The urban policy that the Ottoman applied to Candia was a two-pronged approach. The first was the religious endowments. It made the Ottoman elite contribute to building and rehabilitating the ruined city. The other method was to boost the population and the urban revenue by selling off urban properties. According to Molly Greene (2001) there were numerous records of real-estate transactions during the Ottoman rule. In the deserted city, minorities received equal rights in purchasing property. Christians and Jews were also able to buy and sell in the real-estate market.
The Cretan Revolt of 1866–1869 or Great Cretan Revolution () was a three-year uprising against Ottoman rule, the third and largest in a series of revolts between the end of the Greek War of Independence in 1830 and the establishment of the independent Cretan State in 1898. A particular event which caused strong reactions among the liberal circles of western Europe was the "Holocaust of Arkadi". The event occurred in November 1866, as a large Ottoman force besieged the Arkadi Monastery, which served as the headquarters of the rebellion. In addition to its 259 defenders, over 700 women and children had taken refuge in the monastery. After a few days of hard fighting, the Ottomans broke into the monastery. At that point, the abbot of the monastery set fire to the gunpowder stored in the monastery's vaults, causing the death of most of the rebels and the women and children sheltered there.
Following the repeated uprisings in 1841, 1858, 1889, 1895 and 1897 by the Cretan people, who wanted to join Greece, the Great Powers decided to restore order and in February 1897 sent in troops. The island was subsequently garrisoned by troops from Great Britain, France, Italy and Russia; Germany and Austro-Hungary withdrawing from the occupation in early 1898. During this period Crete was governed through a committee of admirals from the remaining four Powers. In March 1898 the Powers decreed, with the very reluctant consent of the Sultan, that the island would be granted autonomy under Ottoman suzerainty in the near future.
In September 1898 an outbreak of rioting in Candia, modern Heraklion, left over 500 Cretan Christians, and 14 British servicemen, dead. As a result, the Admirals ordered the expulsion of all Ottoman troops and administrators from the island, a move that was ultimately completed by early November. The decision to grant autonomy to the island was enforced and a High Commissioner, Prince George of Greece, appointed, arriving to take up his post in December 1898. The flag of the Cretan State was chosen by the Powers, with the white star representing the Ottoman suzerainty over the island.
In 1905, disagreements between Prince George and minister Eleftherios Venizelos 
over the question of the "enosis" (union with Greece), such as the Prince's autocratic style of government, resulted in the Theriso revolt, one of the leaders being Eleftherios Venizelos.
Prince George resigned as High Commissioner and was replaced by Alexandros Zaimis, a former Greek prime minister, in 1906. In 1908, taking advantage of domestic turmoil in Turkey as well as the timing of Zaimis's vacation away from the island, the Cretan deputies unilaterally declared union with Greece.
With the break out of the First Balkan War, the Greek government declared that Crete was now Greek territory. This was not recognised internationally until 1 December 1913.
During World War II, the island was the scene of the famous Battle of Crete in May 1941. The initial 11-day battle was bloody and left more than 11,000 soldiers and civilians killed or wounded. As a result of the fierce resistance from both Allied forces and civilian Cretan locals, the invasion force suffered heavy casualties, and Adolf Hitler forbade further large-scale paratroop operations for the rest of the war. During the initial and subsequent occupation, German firing squads routinely executed male civilians in reprisal for the death of German soldiers; civilians were rounded up randomly in local villages for the mass killings, such as at the Massacre of Kondomari and the Viannos massacres. Two German generals were later tried and executed for their roles in the killing of 3,000 of the island's inhabitants.
Crete was one of the most popular holiday destinations in Greece. 15% of all arrivals in Greece come through the city of Heraklion (port and airport), while charter journeys to Heraklion seven years ago made up 20% of all charter flights in Greece. Overall, more than two million tourists visited Crete some years back, when the increase in tourism was reflected in the number of hotel beds, rising by 53% in the period between 1986 and 1991.
Today, the island's tourism infrastructure caters to all tastes, including a very wide range of accommodation; the island's facilities take in large luxury hotels with their complete facilities, swimming pools, sports and recreation, smaller family-owned apartments, camping facilities and others. Visitors reach the island via two international airports in Heraklion and Chania and a smaller airport in Sitia (international charter and domestic flights starting May 2012) or by boat to the main ports of Heraklion, Chania, Rethimno, Agios Nikolaos and Sitia.
Popular tourist attractions include the archaeological sites of the Minoan civilisation, the Venetian old city and port of Chania, the Venetian castle at Rethymno, the gorge of Samaria, the islands of Chrysi, Elafonisi, Gramvousa, Spinalonga and the Palm Beach of Vai, which is the largest natural palm forest in Europe.
Crete has an extensive bus system with regular services across the north of the island and from north to south. There are two regional bus stations in Heraklion. Bus routes and timetables can be found on KTEL website.
Crete's mild climate attracts interest from northern Europeans who want a holiday home or residence on the island. EU citizens have the right to freely buy property and reside with little formality. A growing number of real estate companies cater to mainly British immigrants, followed by German, Dutch, Scandinavian and other European nationalities wishing to own a home in Crete. The British immigrants are concentrated in the western regional units of Chania and Rethymno and to a lesser extent in Heraklion and Lasithi.
The area has a large number of archaeological sites, including the Minoan sites of Knossos, Malia (not to be confused with the town of the same name), Petras and Phaistos, the classical site of Gortys, and the diverse archaeology of the island of Koufonisi, which includes Minoan, Roman, and World War II era ruins (nb. due to conservation concerns, access to the latter has been restricted for the last few years, so it is best to check before heading to a port).
There are a number of museums throughout Crete. The Heraklion Archaeological Museum displays most of the archaeological finds from the Minoan era and was reopened in 2014.
Helen Briassoulis proposed in the "Journal of Sustainable Tourism" that Crete is a victim of external tourist systems applying pressure to it to develop at an unhealthy rate, and that informal, internal systems within the country are forced to adapt. According to her, these forces have strengthened in 3 stages: from the period from 1960–1970, 1970–1990, and 1990 to the present. During this first period, tourism was a largely positive force, pushing modern developments like running water and electricity onto the largely rural countryside. However, beginning in the second period and especially in the third period leading up to the present day, tourist companies became more pushy with deforestation and pollution of Crete's natural resources. The country is then pulled into an interesting parity, where these companies only upkeep those natural resources that are directly essential to their industry.
Crete is isolated from mainland Europe, Asia, and Africa, and this is reflected in the diversity of the fauna and flora. As a result, the fauna and flora of Crete have many clues to the evolution of species. There are no animals that are dangerous to humans on the island of Crete in contrast to other parts of Greece. Indeed, the ancient Greeks attributed the lack of large mammals such as bears, wolves, jackals, and venomous snakes, to the labour of Hercules (who took a live Cretan bull to the Peloponnese). Hercules wanted to honor the birthplace of Zeus by removing all "harmful" and "venomous" animals from Crete. Later, Cretans believed that the island was cleared of dangerous creatures by the Apostle Paul, who lived on the island of Crete for two years, with his exorcisms and blessings. There is a natural history museum, the Natural History Museum of Crete, operating under the direction of the University of Crete and two aquariums – Aquaworld in Hersonissos and Cretaquarium in Gournes, displaying sea creatures common in Cretan waters.
Dwarf elephants, dwarf hippopotamus, dwarf mammoths, dwarf deer, and giant flightless owls were native to Pleistocene Crete.
Mammals of Crete include the vulnerable kri-kri, "Capra aegagrus cretica" that can be seen in the national park of the Samaria Gorge and on Thodorou, Dia and Agioi Pantes (islets off the north coast), the Cretan wildcat and the Cretan spiny mouse. Other terrestrial mammals include subspecies of the Cretan marten, the Cretan weasel, the Cretan badger, the long-eared hedgehog, and the edible dormouse.
The Cretan shrew, a type of white-toothed shrew is considered endemic to the island of Crete because this species of shrew is unknown elsewhere. It is a relic species of the "crocidura" shrews of which fossils have been found that can be dated to the Pleistocene era. In the present day it can only be found in the highlands of Crete. It is considered to be the only surviving remnant of the endemic species of the Pleistocene Mediterranean islands.
Bat species include: Blasius's horseshoe bat, the lesser horseshoe bat, the greater horseshoe bat, the lesser mouse-eared bat, Geoffroy's bat, the whiskered bat, Kuhl's pipistrelle, the common pipistrelle, Savi's pipistrelle, the serotine bat, the long-eared bat, Schreibers' bat and the European free-tailed bat.
A large variety of birds includes eagles (can be seen in Lasithi), swallows (throughout Crete in the summer and all the year in the south of the island), pelicans (along the coast), and common cranes (including Gavdos and Gavdopoula). The Cretan mountains and gorges are refuges for the endangered lammergeier vulture. Bird species include: the golden eagle, Bonelli's eagle, the bearded vulture or lammergeier, the griffon vulture, Eleanora's falcon, peregrine falcon, lanner falcon, European kestrel, tawny owl, little owl, hooded crow, alpine chough, red-billed chough, and the Eurasian hoopoe.
Tortoises can be seen throughout the island. Snakes can be found hiding under rocks. Toads and frogs reveal themselves when it rains.
Reptiles include the Aegean wall lizard, Balkan green lizard, common chameleon, ocellated skink, snake-eyed skink, moorish gecko, Turkish gecko, Kotschy's gecko, spur-thighed tortoise, and the Caspian turtle.
There are four species of snake on the island and these are not dangerous to humans. The four species include the leopard snake (locally known as Ochendra), the Balkan whip snake (locally called Dendrogallia), the dice snake (called Nerofido in Greek), and the only venomous snake is the nocturnal cat snake which has evolved to deliver a weak venom at the back of its mouth to paralyse geckos and small lizards, and is not dangerous to humans.
Sea turtles include the green turtle and the loggerhead turtle which are both threatened species. The loggerhead turtle nests and hatches on north-coast beaches around Rethymno and Chania, and south-coast beaches along the gulf of Mesara.
Amphibians include the European green toad, American bullfrog (introduced), European tree frog, and the Cretan marsh frog (endemic).
Crete has an unusual variety of insects. Cicadas, known locally as "Tzitzikia", make a distinctive repetitive "tzi tzi" sound that becomes louder and more frequent on hot summer days. Butterfly species include the swallowtail butterfly. Moth species include the hummingbird moth. There are several species of scorpion such as Euscorpius carpathicus whose venom is generally no more potent than a mosquito bite.
River crabs include the semi-terrestrial "Potamon potamios" crab. Edible snails are widespread and can cluster in the hundreds waiting for rainfall to reinvigorate them.
Apart from terrestrial mammals, the seas around Crete are rich in large marine mammals, a fact unknown to most Greeks at present, although reported since ancient times. Indeed, the Minoan frescoes depicting dolphins in Queen's Megaron at Knossos indicate that Minoans were well aware of and celebrated these creatures. Apart from the famous endangered Mediterranean monk seal, which lives in almost all the coasts of the country, Greece hosts whales, sperm whales, dolphins and porpoises. These are either permanent residents of the Mediterranean or just occasional visitors. The area south of Crete, known as the Greek Abyss, hosts many of them. Squid and octopus can be found along the coast and sea turtles and hammerhead sharks swim in the sea around the coast. The Cretaquarium and the Aquaworld Aquarium, are two of only three aquariums in the whole of Greece. They are located in Gournes and Hersonissos respectively. Examples of the local sealife can be seen there.
Some of the fish that can be seen in the waters around Crete include: scorpion fish, dusky grouper, east Atlantic peacock wrasse, five-spotted wrasse, weever fish, common stingray, brown ray, mediterranean black goby, pearly razorfish, star-gazer, painted comber, damselfish, and the flying gurnard.
The Minoans contributed to the deforestation of Crete. Further deforestation occurred in the 1600s "so that no more local supplies of firewood were available".
Common wildflowers include: camomile, daisy, gladiolus, hyacinth, iris, poppy, cyclamen and tulip, among others. There are more than 200 different species of wild orchid on the island and this includes 14 varieties of "Ophrys cretica". Crete has a rich variety of indigenous herbs including common sage, rosemary, thyme, and oregano. Rare herbs include the endemic Cretan dittany. and ironwort, "Sideritis syriaca", known as Malotira (Μαλοτήρα). Varieties of cactus include the edible prickly pear. Common trees on the island include the chestnut, cypress, oak, olive tree, pine, plane, and tamarisk. Trees tend to be taller to the west of the island where water is more abundant.
There are a number of environmentally protected areas. One such area is located at the island of Elafonisi on the coast of southwestern Crete. Also, the palm forest of Vai in eastern Crete and the Dionysades (both in the municipality of Sitia, Lasithi), have diverse animal and plant life. Vai has a palm beach and is the largest natural palm forest in Europe. The island of Chrysi, south of Ierapetra, has the largest naturally-grown "Juniperus macrocarpa" forest in Europe. Samaria Gorge is a World Biosphere Reserve and Richtis Gorge is protected for its landscape diversity.
Crete has a strong association with Ancient Greek Gods but is also connected with the Minoan civilisation.
According to Greek Mythology, The Diktaean Cave at Mount Dikti was the birthplace of the god Zeus. The Paximadia islands were the birthplace of the goddess Artemis and the god Apollo. Their mother, the goddess Leto, was worshipped at Phaistos. The goddess Athena bathed in Lake Voulismeni. The ancient Greek god Zeus launched a lightning bolt at a giant lizard that was threatening Crete. The lizard immediately turned to stone and became the island of Dia. The island can be seen from Knossos and it has the shape of a giant lizard. The islets of Lefkai were the result of a musical contest between the Sirens and the Muses. The Muses were so anguished to have lost that they plucked the feathers from the wings of their rivals; the Sirens turned white and fell into the sea at Aptera ("featherless") where they formed the islands in the bay that were called Lefkai (the islands of Souda and Leon). Heracles, in one of his labors, took the Cretan bull to the Peloponnese. Europa and Zeus made love at Gortys and conceived the kings of Crete: Rhadamanthys, Sarpedon, and Minos.
The labyrinth of the Palace of Knossos was the setting for the myth of Theseus and the Minotaur in which the Minotaur was slain by Theseus. Icarus and Daedalus were captives of King Minos and crafted wings to escape. After his death King Minos became a judge of the dead in Hades, while Rhadamanthys became the ruler of the Elysian fields.
Crete has its own distinctive Mantinades poetry. The island is known for its Mantinades-based music (typically performed with the Cretan lyra and the laouto) and has many indigenous dances, the most noted of which is the Pentozali. Since the 1980s and certainly in the 90s onwards there has been a proliferation of Cultural Associations that teach dancing (in Western Crete many focus on rizitiko singing). These Associations often perform in official events but also become stages for people to meet up and engage in traditionalist practices. The topic of tradition and the role of Cultural Associations in reviving it is very often debated throughout Crete.
Cretan authors have made important contributions to Greek literature throughout the modern period; major names include Vikentios Kornaros, creator of the 17th-century epic romance "Erotokritos" (Greek Ερωτόκριτος), and, in the 20th century, Nikos Kazantzakis. In the Renaissance, Crete was the home of the Cretan School of icon painting, which influenced El Greco and through him subsequent European painting.
Crete is also famous for its traditional cuisine. The nutritional value of the Cretan cuisine was discovered by the American epidemiologist Ancel Keys in the 1960, being later often mentioned by epidemiologists as one of the best examples of the Mediterranean diet.
Cretans are fiercely proud of their island and customs, and men often don elements of traditional dress in everyday life: knee-high black riding boots ("stivania"), "vráka" breeches tucked into the boots at the knee, black shirt and black headdress consisting of a fishnet-weave kerchief worn wrapped around the head or draped on the shoulders ("sariki"). Men often grow large mustaches as a mark of masculinity.
Cretan society is known in Greece and internationally for family and clan vendettas which persist on the island to date. Cretans also have a tradition of keeping firearms at home, a tradition lasting from the era of resistance against the Ottoman Empire. Nearly every rural household on Crete has at least one unregistered gun. Guns are subject to strict regulation from the Greek government, and in recent years a great deal of effort to control firearms in Crete has been undertaken by the Greek police, but with limited success.
Crete has many football clubs playing in the local leagues. During the 2011–12 season, OFI Crete, which plays at Theodoros Vardinogiannis Stadium (Iraklion), and Ergotelis F.C., which plays at the Pankritio Stadium (Iraklion) were both members of the Greek Superleague. During the 2012–13 season, OFI Crete, which plays at Theodoros Vardinogiannis Stadium (Iraklion), and Platanias F.C., which plays at the Perivolia Municipal Stadium, near Chania, are both members of the Greek Superleague.
Notable people from Crete include:

</doc>
<doc id="6592" url="https://en.wikipedia.org/wiki?curid=6592" title="Cyclades">
Cyclades

The Cyclades (; ) are an island group in the Aegean Sea, southeast of mainland Greece and a former administrative prefecture of Greece. They are one of the island groups which constitute the Aegean archipelago. The name refers to the islands "around" ("cyclic", κυκλάς) the sacred island of Delos. The largest island of the Cyclades is Naxos, however the most populated one is Syros.
The significant Late Neolithic and Early Bronze Age Cycladic culture is best known for its schematic, flat sculptures carved out of the islands' pure white marble centuries before the great Middle Bronze Age Minoan civilization arose in Crete to the south. (These figures have been looted from burials to satisfy a thriving Cycladic antiquities market since the early 20th century.)
A distinctive Neolithic culture amalgamating Anatolian and mainland Greek elements arose in the western Aegean before 4000 BCE, based on emmer and wild-type barley, sheep and goats, pigs, and tuna that were apparently speared from small boats (Rutter). Excavated sites include Chalandriani, Phylakopi, Skarkos, Saliagos and Kephala (on Kea) with signs of copperworking, Each of the small Cycladic islands could support no more than a few thousand people, though Late Cycladic boat models show that fifty oarsmen could be assembled from the scattered communities (Rutter), and when the highly organized palace-culture of Crete arose, the islands faded into insignificance, with the exception of Delos, which retained its archaic reputation as a sanctuary throughout antiquity and until the emergence of Christianity.
The first archaeological excavations of the 1880s were followed by systematic work by the British School at Athens and by Christos Tsountas, who investigated burial sites on several islands in 1898–1899 and coined the term "Cycladic civilization". Interest lagged, then picked up in the mid-20th century, as collectors competed for the modern-looking figures that seemed so similar to sculpture by Jean Arp or Constantin Brâncuși. Sites were looted and a brisk trade in forgeries arose. The context for many of these Cycladic figurines has been mostly destroyed and their meaning may never be completely understood. 
Another intriguing and mysterious object is that of the Cycladic frying pans. More accurate archaeology has revealed the broad outlines of a farming and seafaring culture that had emigrated from Anatolia c. 5000 BCE. Early Cycladic culture evolved in three phases, between c. 3300 – 2000 BCE, when it was increasingly swamped in the rising influence of Minoan Crete. The culture of mainland Greece contemporary with Cycladic culture is known as the Helladic period.
In recent decades the Cyclades have become popular with European and other tourists, and as a result there have been problems with erosion, pollution, and water shortages.
The Cyclades includes about 220 islands, the major ones being Amorgos, Anafi, Andros, Antiparos, Delos, Ios, Kea, Kimolos, Kythnos, Milos, Mykonos, Naxos, Paros, Folegandros, Serifos, Sifnos, Sikinos, Syros, Tinos, and Thira or Santoríni. There are also many minor islands including Donousa, Eschati, Gyaros, Irakleia, Koufonisia, Makronisos, Rineia, and Schoinousa. The name "Cyclades" refers to the islands forming a circle ("circular islands") around the sacred island of Delos. Most of the smaller islands are uninhabited.
Ermoupoli on Syros is the chief town and administrative center of the former prefecture.
The islands are peaks of a submerged mountainous terrain, with the exception of two volcanic islands, Milos and Santorini. The climate is generally dry and mild, but with the exception of Naxos the soil is not very fertile; agricultural produce includes wine, fruit, wheat, olive oil, and tobacco. Lower temperatures are registered in higher elevations and these areas do not usually see wintry weather.
The Cyclades are bounded to the south by the Sea of Crete.
The Cyclades Prefecture () was one of the prefectures of Greece. As a part of the 2011 Kallikratis government reform, the prefecture was abolished, and its territory was divided into nine regional units of the South Aegean region:
The prefecture was subdivided into the following municipalities and communities. These have been reorganised at the 2011 Kallikratis reform as well. 
"Note:" Provinces no longer hold any legal status in Greece.
Local specialities of the Cyclades include:

</doc>
<doc id="6596" url="https://en.wikipedia.org/wiki?curid=6596" title="Computer vision">
Computer vision

Computer vision is an interdisciplinary scientific field that deals with how computers can gain high-level understanding from digital images or videos. From the perspective of engineering, it seeks to understand and automate tasks that the human visual system can do.
Computer vision tasks include methods for acquiring, processing, analyzing and understanding digital images, and extraction of high-dimensional data from the real world in order to produce numerical or symbolic information, e.g. in the forms of decisions. Understanding in this context means the transformation of visual images (the input of the retina) into descriptions of the world that make sense to thought processes and can elicit appropriate action. This image understanding can be seen as the disentangling of symbolic information from image data using models constructed with the aid of geometry, physics, statistics, and learning theory.
The scientific discipline of computer vision is concerned with the theory behind artificial systems that extract information from images. The image data can take many forms, such as video sequences, views from multiple cameras, multi-dimensional data from a 3D scanner or medical scanning device. The technological discipline of computer vision seeks to apply its theories and models to the construction of computer vision systems.
Sub-domains of computer vision include scene reconstruction, event detection, video tracking, object recognition, 3D pose estimation, learning, indexing, motion estimation, visual servoing, 3D scene modeling, and image restoration.
Computer vision is an interdisciplinary field that deals with how computers can be made to gain high-level understanding from digital images or videos. From the perspective of engineering, it seeks to automate tasks that the human visual system can do. "Computer vision is concerned with the automatic extraction, analysis and understanding of useful information from a single image or a sequence of images. It involves the development of a theoretical and algorithmic basis to achieve automatic visual understanding." As a scientific discipline, computer vision is concerned with the theory behind artificial systems that extract information from images. The image data can take many forms, such as video sequences, views from multiple cameras, or multi-dimensional data from a medical scanner. As a technological discipline, computer vision seeks to apply its theories and models for the construction of computer vision systems.
In the late 1960s, computer vision began at universities which were pioneering artificial intelligence. It was meant to mimic the human visual system, as a stepping stone to endowing robots with intelligent behavior. In 1966, it was believed that this could be achieved through a summer project, by attaching a camera to a computer and having it "describe what it saw".
What distinguished computer vision from the prevalent field of digital image processing at that time was a desire to extract three-dimensional structure from images with the goal of achieving full scene understanding. Studies in the 1970s formed the early foundations for many of the computer vision algorithms that exist today, including extraction of edges from images, labeling of lines, non-polyhedral and polyhedral modeling, representation of objects as interconnections of smaller structures, optical flow, and motion estimation.
The next decade saw studies based on more rigorous mathematical analysis and quantitative aspects of computer vision. These include the concept of scale-space, the inference of shape from various cues such as shading, texture and focus, and contour models known as snakes. Researchers also realized that many of these mathematical concepts could be treated within the same optimization framework as regularization and Markov random fields.
By the 1990s, some of the previous research topics became more active than the others. Research in projective 3-D reconstructions led to better understanding of camera calibration. With the advent of optimization methods for camera calibration, it was realized that a lot of the ideas were already explored in bundle adjustment theory from the field of photogrammetry. This led to methods for sparse 3-D reconstructions of scenes from multiple images. Progress was made on the dense stereo correspondence problem and further multi-view stereo techniques. At the same time, variations of graph cut were used to solve image segmentation. This decade also marked the first time statistical learning techniques were used in practice to recognize faces in images (see Eigenface). Toward the end of the 1990s, a significant change came about with the increased interaction between the fields of computer graphics and computer vision. This included image-based rendering, image morphing, view interpolation, panoramic image stitching and early light-field rendering.
Recent work has seen the resurgence of feature-based methods, used in conjunction with machine learning techniques and complex optimization frameworks. 
The advancement of Deep Learning techniques has brought further life to the field of computer vision. The accuracy of deep learning algorithms on several benchmark computer vision data sets for tasks ranging from classification, segmentation and optical flow has surpassed prior methods. 
Areas of artificial intelligence deal with autonomous planning or deliberation for robotic systems to navigate through an environment. A detailed understanding of these environments is required to navigate through them. Information about the environment could be provided by a computer vision system, acting as a vision sensor and providing high-level information about the environment and the robot.
Artificial intelligence and computer vision share other topics such as pattern recognition and learning techniques. Consequently, computer vision is sometimes seen as a part of the artificial intelligence field or the computer science field in general.
Computer vision is often considered to be part of information engineering.
Solid-state physics is another field that is closely related to computer vision. Most computer vision systems rely on image sensors, which detect electromagnetic radiation, which is typically in the form of either visible or infra-red light. The sensors are designed using quantum physics. The process by which light interacts with surfaces is explained using physics. Physics explains the behavior of optics which are a core part of most imaging systems. Sophisticated image sensors even require quantum mechanics to provide a complete understanding of the image formation process. Also, various measurement problems in physics can be addressed using computer vision, for example motion in fluids.
A third field which plays an important role is neurobiology, specifically the study of the biological vision system. Over the last century, there has been an extensive study of eyes, neurons, and the brain structures devoted to processing of visual stimuli in both humans and various animals. This has led to a coarse, yet complicated, description of how "real" vision systems operate in order to solve certain vision-related tasks. These results have led to a sub-field within computer vision where artificial systems are designed to mimic the processing and behavior of biological systems, at different levels of complexity. Also, some of the learning-based methods developed within computer vision ("e.g." neural net and deep learning based image and feature analysis and classification) have their background in biology.
Some strands of computer vision research are closely related to the study of biological vision – indeed, just as many strands of AI research are closely tied with research into human consciousness, and the use of stored knowledge to interpret, integrate and utilize visual information. The field of biological vision studies and models the physiological processes behind visual perception in humans and other animals. Computer vision, on the other hand, studies and describes the processes implemented in software and hardware behind artificial vision systems. Interdisciplinary exchange between biological and computer vision has proven fruitful for both fields.
Yet another field related to computer vision is signal processing. Many methods for processing of one-variable signals, typically temporal signals, can be extended in a natural way to processing of two-variable signals or multi-variable signals in computer vision. However, because of the specific nature of images there are many methods developed within computer vision which have no counterpart in processing of one-variable signals. Together with the multi-dimensionality of the signal, this defines a subfield in signal processing as a part of computer vision.
Beside the above-mentioned views on computer vision, many of the related research topics can also be studied from a purely mathematical point of view. For example, many methods in computer vision are based on statistics, optimization or geometry. Finally, a significant part of the field is devoted to the implementation aspect of computer vision; how existing methods can be realized in various combinations of software and hardware, or how these methods can be modified in order to gain processing speed without losing too much performance. Computer vision is also used in fashion ecommerce, inventory management, patent search, furniture, and the beauty industry.
The fields most closely related to computer vision are image processing, image analysis and machine vision. There is a significant overlap in the range of techniques and applications that these cover. This implies that the basic techniques that are used and developed in these fields are similar, something which can be interpreted as there is only one field with different names. On the other hand, it appears to be necessary for research groups, scientific journals, conferences and companies to present or market themselves as belonging specifically to one of these fields and, hence, various characterizations which distinguish each of the fields from the others have been presented.
Computer graphics produces image data from 3D models, computer vision often produces 3D models from image data. There is also a trend towards a combination of the two disciplines, "e.g.", as explored in augmented reality.
The following characterizations appear relevant but should not be taken as universally accepted::
Photogrammetry also overlaps with computer vision, e.g., stereophotogrammetry vs. computer stereo vision.
Applications range from tasks such as industrial machine vision systems which, say, inspect bottles speeding by on a production line, to research into artificial intelligence and computers or robots that can comprehend the world around them. The computer vision and machine vision fields have significant overlap. Computer vision covers the core technology of automated image analysis which is used in many fields. Machine vision usually refers to a process of combining automated image analysis with other methods and technologies to provide automated inspection and robot guidance in industrial applications. In many computer-vision applications, the computers are pre-programmed to solve a particular task, but methods based on learning are now becoming increasingly common. Examples of applications of computer vision include systems for:
One of the most prominent application fields is medical computer vision, or medical image processing, characterized by the extraction of information from image data to diagnose a patient. An example of this is detection of tumours, arteriosclerosis or other malign changes; measurements of organ dimensions, blood flow, etc. are another example. It also supports medical research by providing new information: "e.g.", about the structure of the brain, or about the quality of medical treatments. Applications of computer vision in the medical area also includes enhancement of images interpreted by humans—ultrasonic images or X-ray images for example—to reduce the influence of noise.
A second application area in computer vision is in industry, sometimes called machine vision, where information is extracted for the purpose of supporting a manufacturing process. One example is quality control where details or final products are being automatically inspected in order to find defects. Another example is measurement of position and orientation of details to be picked up by a robot arm. Machine vision is also heavily used in agricultural process to remove undesirable food stuff from bulk material, a process called optical sorting.
Military applications are probably one of the largest areas for computer vision. The obvious examples are detection of enemy soldiers or vehicles and missile guidance. More advanced systems for missile guidance send the missile to an area rather than a specific target, and target selection is made when the missile reaches the area based on locally acquired image data. Modern military concepts, such as "battlefield awareness", imply that various sensors, including image sensors, provide a rich set of information about a combat scene which can be used to support strategic decisions. In this case, automatic processing of the data is used to reduce complexity and to fuse information from multiple sensors to increase reliability.
One of the newer application areas is autonomous vehicles, which include submersibles, land-based vehicles (small robots with wheels, cars or trucks), aerial vehicles, and unmanned aerial vehicles (UAV). The level of autonomy ranges from fully autonomous (unmanned) vehicles to vehicles where computer-vision-based systems support a driver or a pilot in various situations. Fully autonomous vehicles typically use computer vision for navigation, "e.g." for knowing where it is, or for producing a map of its environment (SLAM) and for detecting obstacles. It can also be used for detecting certain task specific events, "e.g.", a UAV looking for forest fires. Examples of supporting systems are obstacle warning systems in cars, and systems for autonomous landing of aircraft. Several car manufacturers have demonstrated systems for autonomous driving of cars, but this technology has still not reached a level where it can be put on the market. There are ample examples of military autonomous vehicles ranging from advanced missiles to UAVs for recon missions or missile guidance. Space exploration is already being made with autonomous vehicles using computer vision, "e.g.", NASA's "Curiosity" and CNSA's "Yutu-2" rover.
Materials such as rubber and silicon are being used to create sensors that allow for applications such as detecting micro undulations and calibrating robotic hands. Rubber can be used in order to create a mold that can be placed over a finger, inside of this mold would be multiple strain gauges. The finger mold and sensors could then be placed on top of a small sheet of rubber containing an array of rubber pins. A user can then wear the finger mold and trace a surface. A computer can then read the data from the strain gauges and measure if one or more of the pins is being pushed upward. If a pin is being pushed upward then the computer can recognize this as an imperfection in the surface. This sort of technology is useful in order to receive accurate data of the imperfections on a very large surface. Another variation of this finger mold sensor are sensors that contain a camera suspended in silicon. The silicon forms a dome around the outside of the camera and embedded in the silicon are point markers that are equally spaced. These cameras can then be placed on devices such as robotic hands in order to allow the computer to receive highly accurate tactile data.
Other application areas include:
Each of the application areas described above employ a range of computer vision tasks; more or less well-defined measurement problems or processing problems, which can be solved using a variety of methods. Some examples of typical computer vision tasks are presented below.
Computer vision tasks include methods for acquiring, processing, analyzing and understanding digital images, and extraction of high-dimensional data from the real world in order to produce numerical or symbolic information, "e.g.", in the forms of decisions. Understanding in this context means the transformation of visual images (the input of the retina) into descriptions of the world that can interface with other thought processes and elicit appropriate action. This image understanding can be seen as the disentangling of symbolic information from image data using models constructed with the aid of geometry, physics, statistics, and learning theory.
The classical problem in computer vision, image processing, and machine vision is that of determining whether or not the image data contains some specific object, feature, or activity. Different varieties of the recognition problem are described in the literature:
Currently, the best algorithms for such tasks are based on convolutional neural networks. An illustration of their capabilities is given by the ImageNet Large Scale Visual Recognition Challenge; this is a benchmark in object classification and detection, with millions of images and hundreds of object classes. Performance of convolutional neural networks, on the ImageNet tests, is now close to that of humans. The best algorithms still struggle with objects that are small or thin, such as a small ant on a stem of a flower or a person holding a quill in their hand. They also have trouble with images that have been distorted with filters (an increasingly common phenomenon with modern digital cameras). By contrast, those kinds of images rarely trouble humans. Humans, however, tend to have trouble with other issues. For example, they are not good at classifying objects into fine-grained classes, such as the particular breed of dog or species of bird, whereas convolutional neural networks handle this with ease.
Several specialized tasks based on recognition exist, such as:
Several tasks relate to motion estimation where an image sequence is processed to produce an estimate of the velocity either at each points in the image or in the 3D scene, or even of the camera that produces the images . Examples of such tasks are:
Given one or (typically) more images of a scene, or a video, scene reconstruction aims at computing a 3D model of the scene. In the simplest case the model can be a set of 3D points. More sophisticated methods produce a complete 3D surface model. The advent of 3D imaging not requiring motion or scanning, and related processing algorithms is enabling rapid advances in this field. Grid-based 3D sensing can be used to acquire 3D images from multiple angles. Algorithms are now available to stitch multiple 3D images together into point clouds and 3D models.
The aim of image restoration is the removal of noise (sensor noise, motion blur, etc.) from images. The simplest possible approach for noise removal is various types of filters such as low-pass filters or median filters. More sophisticated methods assume a model of how the local image structures look, to distinguish them from noise. By first analysing the image data in terms of the local image structures, such as lines or edges, and then controlling the filtering based on local information from the analysis step, a better level of noise removal is usually obtained compared to the simpler approaches.
An example in this field is inpainting.
The organization of a computer vision system is highly application-dependent. Some systems are stand-alone applications that solve a specific measurement or detection problem, while others constitute a sub-system of a larger design which, for example, also contains sub-systems for control of mechanical actuators, planning, information databases, man-machine interfaces, etc. The specific implementation of a computer vision system also depends on whether its functionality is pre-specified or if some part of it can be learned or modified during operation. Many functions are unique to the application. There are, however, typical functions that are found in many computer vision systems.
Image-understanding systems (IUS) include three levels of abstraction as follows: low level includes image primitives such as edges, texture elements, or regions; intermediate level includes boundaries, surfaces and volumes; and high level includes objects, scenes, or events. Many of these requirements are entirely topics for further research.
The representational requirements in the designing of IUS for these levels are: representation of prototypical concepts, concept organization, spatial knowledge, temporal knowledge, scaling, and description by comparison and differentiation.
While inference refers to the process of deriving new, not explicitly represented facts from currently known facts, control refers to the process that selects which of the many inference, search, and matching techniques should be applied at a particular stage of processing. Inference and control requirements for IUS are: search and hypothesis activation, matching and hypothesis testing, generation and use of expectations, change and focus of attention, certainty and strength of belief, inference and goal satisfaction.
There are many kinds of computer vision systems; however, all of them contain these basic elements: a power source, at least one image acquisition device (camera, ccd, etc.), a processor, and control and communication cables or some kind of wireless interconnection mechanism. In addition, a practical vision system contains software, as well as a display in order to monitor the system. Vision systems for inner spaces, as most industrial ones, contain an illumination system and may be placed in a controlled environment. Furthermore, a completed system includes many accessories such as camera supports, cables and connectors.
Most computer vision systems use visible-light cameras passively viewing a scene at frame rates of at most 60 frames per second (usually far slower).
A few computer vision systems use image-acquisition hardware with active illumination or something other than visible light or both, such as structured-light 3D scanners, thermographic cameras, hyperspectral imagers, radar imaging, lidar scanners, magnetic resonance images, side-scan sonar, synthetic aperture sonar, etc. Such hardware captures "images" that are then processed often using the same computer vision algorithms used to process visible-light images.
While traditional broadcast and consumer video systems operate at a rate of 30 frames per second, advances in digital signal processing and consumer graphics hardware has made high-speed image acquisition, processing, and display possible for real-time systems on the order of hundreds to thousands of frames per second. For applications in robotics, fast, real-time video systems are critically important and often can simplify the processing needed for certain algorithms. When combined with a high-speed projector, fast image acquisition allows 3D measurement and feature tracking to be realised.
Egocentric vision systems are composed of a wearable camera that automatically take pictures from a first-person perspective.
As of 2016, vision processing units are emerging as a new class of processor, to complement CPUs and graphics processing units (GPUs) in this role.

</doc>
<doc id="6597" url="https://en.wikipedia.org/wiki?curid=6597" title="Curry">
Curry

Curry is a variety of dishes originating in the Indian subcontinent that use a complex combination of spices or herbs, usually including ground turmeric, cumin, coriander, ginger, and fresh or dried chilies. In southern India, where the word originated, curry leaves, from the curry tree, are also an integral ingredient. Curry is generally prepared in a sauce.
There are many varieties of dishes called 'curries'. For example, in original traditional cuisines, the precise selection of spices for each dish is a matter of national or regional cultural tradition, religious practice, and, to some extent, family preference. Such dishes are called by specific names that refer to their ingredients, spicing, and cooking methods. Spices are used both whole and ground, cooked or raw, and they may be added at different times during the cooking process to produce different results. The main spices found in most curry powders of the Indian subcontinent are coriander, cumin, and turmeric. A wide range of additional spices may be included depending on the geographic region and the foods being included (fish, lentils, red or white meat, rice, and vegetables). Curry powder, a commercially prepared mixture of spices, is largely a Western creation, dating to the 18th century. Such mixtures are commonly thought to have first been prepared by Indian merchants for sale to members of the British Colonial government and army returning to Britain.
Outside of the Indian subcontinent, "curry" may also be used to describe the various unrelated native dishes of Island Southeast Asia, Mainland Southeast Asia, and Oceania which use coconut milk or spice pastes and are commonly eaten over rice (like the Filipino "ginataan" and Thai "gaeng" class of dishes).
Dishes called 'curry' may contain fish, meat, poultry, or shellfish, either alone or in combination with vegetables. Additionally, many instead are entirely vegetarian, eaten especially among those who hold ethical or religious proscriptions against eating meat or seafood.
Curries may be either 'dry' or 'wet'. Dry curries are cooked with very little liquid which is allowed to evaporate, leaving the other ingredients coated with the spice mixture. Wet curries contain significant amounts of sauce or gravy based on broth, coconut cream or coconut milk, dairy cream or yogurt, or legume purée, sautéed crushed onion, or tomato purée.
"Curry" is an anglicised form of the Tamil word "" meaning 'sauce' or 'relish for rice' that uses the leaves of the curry tree ("Murraya koenigii"). The word "kari" is also used in other Dravidian languages, namely in Malayalam, Kannada and Kodava with the meaning of "vegetables (or meat) of any kind (raw or boiled), curry". "Kaṟi" is described in a mid-17th century Portuguese cookbook by members of the British East India Company, who were trading with Tamil merchants along the Coromandel Coast of southeast India, becoming known as a "spice blend ... called "kari podi" or curry powder". The first known appearance in its anglicised form (spelled "currey") appears in a 1747 book of recipes published by Hannah Glasse.
The word "cury" appears in the 1390s English cookbook, "The Forme of Cury", but is unrelated and comes from the Middle French word "cuire", meaning 'to cook'
Archaeological evidence dating to 2600 BCE from Mohenjo-daro suggests the use of mortar and pestle to pound spices including mustard, fennel, cumin, and tamarind pods with which they flavoured food. Black pepper is native to the Indian subcontinent and Southeast Asia and has been known to Indian cooking since at least 2000 BCE.
The establishment of the Mughal Empire, in the early 15th century, also influenced some curries, especially in the north. Another influence was the establishment of the Portuguese trading centre in Goa in 1510, resulting in the introduction of chili pepper, tomatoes and potatoes to India from the Americas, as a byproduct of the Columbian Exchange.
Curry was introduced to English cuisine starting with Anglo-Indian cooking in the 17th century as spicy sauces were added to plain boiled and cooked meats. The 1758 edition of Hannah Glasse's "The Art of Cookery" contains a recipe "To make a Currey the India Way". Curry was first served in coffee houses in Britain from 1809, and has been increasingly popular in Great Britain, with major jumps in the 1940s and the 1970s. During the 19th century, curry was also carried to the Caribbean by Indian indentured workers in the British sugar industry. Since the mid-20th century, curries of many national styles have become popular far from their origins, and increasingly become part of international fusion cuisine.
From the culinary point of view, it is useful to consider the Indian subcontinent to be the entire historical region encompassed prior to independence since August 1947; that is, the modern countries of India, Bangladesh, Pakistan and Sri Lanka. It is usual to distinguish broadly between northern and southern styles of Indian cuisine, recognising that within those categories are innumerable sub-styles and variations. The distinction is commonly made with reference to the staple starch: wheat in the form of unleavened breads in the north; rice in the east; rice and millet in the south.
Bengali cuisine, which refers to the cuisine of Bangladesh and the West Bengal state of India, includes curries, including seafood and fresh fish. Mustard seeds and mustard oil are added to many recipes, as are poppy seeds. Emigrants from the Sylhet district of Bangladesh founded the curry house industry in Britain and in Sylhet some restaurants run by expatriates specialise in British-style Indian food.
Curries are the most well-known part of Indian cuisine. Most Indian dishes are usually curry based, prepared by adding different types of vegetables, lentils or meats in the curry. The content of the curry and style of preparation varies per the region. Most curries are water based, with occasional use of dairy and coconut milk. Curry dishes are usually thick and spicy and are eaten along with steamed rice and variety of Indian breads.
Although wet curries play a smaller role in Gujarat than elsewhere, there are a number of vegetarian examples with gravies based on buttermilk or coconut milk. The main ingredient may variously be brinjal (eggplant/aubergine), potatoes, fresh corn kernels, okra, tomatoes, etc. In addition, there are several common kofta dishes which substitute vegetables for meat. Undhiyu, a Gujarati specialty, is a spicy 'wet' mixed-vegetable 'casserole' cooked in an earthenware pot, often eaten during the winter months.
The curries of Maharashtra vary from mildly spicy to very spicy and include vegetarian, mutton, chicken and fish. Coastal Maharashtrian – Konkani – curries use coconut extensively along with spices. In western Maharashtra, curries are very spicy, often with peanut powder. Vidharba's cuisine is usually spicier than that of the coastal and southern regions. The ingredients commonly used are besan (gram flour), or chickpea flour, and groundnut powder. As a result of the Mughal rule in the region, the cuisine of Aurangabad has been highly influenced by the North Indian method of cooking. Khandeshi food is very spicy and the most famous dish is shev bhaji. Others include Eggplant bharta (wangyache bhareet), (urid dal), stuffed eggplant (bharleli wangi), bhaakari with thecha etc. The majority of Maharashtrian people are farmers living in the rural areas and therefore their traditional food is very simple.
Most Punjabi dishes are prepared using "tadka", which is made with the frying of a "masala", which is a mix of ginger, garlic, onions and tomatoes with some dried spices. This is followed by the addition of other ingredients, water, and occasionally milk. Normally spicy, spice levels vary greatly depending on the household itself. Ghee and mustard oil are the most commonly used cooking fats. Many popular Punjabi dishes such as butter chicken and rajma are curry-based. These dishes are usually served with steamed rice and chapatis.
Rajasthani cuisine was influenced both by the war-like lifestyles of its inhabitants and the availability of ingredients in this arid region. Food that could last for several days and could be eaten without heating was preferred. Scarcity of water and fresh green vegetables have each had their effect on the cooking. Hence the curries in Rajasthan are usually made using dry spices and herbs and other dry items like gram flour. "Kadhi" is a popular gram flour curry, usually served with steamed rice and bread. To decrease the use of water in this desert state they use a lot of milk and milk-products to cook curries. Laal maans is a popular meat curry from Rajasthan.
The food in general from Andhra Pradesh and Telangana, both with Telugu-speaking natives, is considered the hottest in India. The state, being the leading producer of red chilli and green chilli, influences the liberal use of spices, making their curries, chutneys, savories and pickles the hottest and spiciest in taste.
Curries known as vindaloo have become well known in Great Britain, America, and elsewhere, where the name is usually used simply to indicate a fiery dish of lamb or chicken frequently including potatoes. Such dishes are far from the Goan originals.
The name "vindaloo" derives from the Portuguese "vinha d'alhos" or wine ("vinho") and garlic ("alho"), the two definitive flavour ingredients. The dish was originally made with pork, not taboo to the Christian Portuguese. The inclusion of potatoes was a later Indian addition, thought to be the result of confusion with the Hindi word for potato, "aloo". Throughout the years "vindaloo" has been altered to appeal to many people by adding spices and different wines.
The curries of Karnataka are typically vegetarian or with meat and fish around mostly coastal areas. They use a wide variety of vegetables, spices, coconut and jaggery. There are dry and sauce-based curries. Some typical sauce-based dishes include saaru, gojju, thovve, huli, majjige huli (which is similar to the "kadi" made in the north), sagu or kootu, which is eaten mixed with hot rice.
Malayali curries of Kerala typically contain shredded coconut paste or coconut milk, curry leaves, and various spices. Mustard seeds are used in almost every dish, along with onions, curry leaves, and sliced red chilies fried in hot oil. Most of the non-vegetarian dishes are heavily spiced. Kerala is known for its traditional sadya, a vegetarian meal served with boiled rice and a host of side dishes such as parippu (green gram), papadum, ghee, sambar, rasam, aviyal, kaalan, kichadi, pachadi, injipuli, Koottukari, pickles (mango, lime), thoran, one to four types of payasam, boli, olan, pulissery, moru (buttermilk), upperi, and banana chips. The sadya is customarily served on a banana leaf.
Tamil cuisine's distinctive flavour and aroma is achieved by a blend and combination of spices including curry leaves, tamarind, coriander, ginger, garlic, chili, pepper, poppy seeds, mustard seeds, cinnamon, cloves, cardamom, cumin, fennel or anise seeds, fenugreek seeds, nutmeg, coconut, turmeric root or powder, and rosewater. Lentils, vegetables and dairy products are essential accompaniments and are often served with rice. Traditionally vegetarian foods dominate the menu with a range of non-vegetarian dishes including freshwater fish and seafood cooked with spices and seasoning.
In the West, the best-known Kashmiri curry is "rogan josh", a wet curry of lamb with a brilliant red gravy whose colour is derived from a combination of Kashmiri chillies and an extract derived from the red flowers of the cockscomb plant ("mawal"). "Goshtaba" (large lamb meatballs cooked in yoghurt gravy) is another curry dish from the Wazwan tradition occasionally found in Western restaurants.
The most important curry in the cuisine of the Maldives is cooked with diced fresh tuna and is known as "mas riha". "Kukulhu riha", chicken curry, is cooked with a different mixture of spices.
Traditional vegetable curries in the Maldives include those that use "bashi" (eggplant/aubergine), "tora" ("Luffa aegyptiaca"), "barabō" (pumpkin), "chichanda" ("Trichosanthes cucumerina") and "muranga" ("Moringa oleifera"), as well as green unripe bananas and certain leaves as their main ingredients. Pieces of Maldive fish are normally added to give the vegetable curry a certain flavour.
The curries of Nepalese cuisine have been influenced by its neighbours, mainly India and Tibet. Well known Indian spices are used less. Goat is a popular meat in the Himalayan region of Nepal.
Daal bhaat (rice and lentil soup) is a staple dish of Nepal. Newa cuisine is a type of cuisine developed over centuries by the Newars of Nepal.
Pakistani curries, especially in the provinces of Punjab and Sindh, are basically similar to their counterparts in northern India. Mutton and beef are common ingredients. A typical Pakistani lunch or dinner often consists of some form of bread (such as naan or roti) or rice with a meat or vegetable-based curry. Barbecue style or roasted meats are also very popular in the form of kebabs.
It is worth noting that the term "curry" is virtually never used inside the country; instead, regional words such as "salan" or "shorba" are used to denote what is known outside the country as a "curry".
Several different types of curries exist, depending on the cooking style, such as bhuna, bharta, roghan josh, qorma, qeema, and shorba. A favourite Pakistani curry is karahi, which is either mutton or chicken cooked in a cooking utensil called karahi, which is similar in shape to a wok. Lahori karahi incorporates garlic, ginger, fresh chillies, tomatoes and select spices. Peshawari karahi is another very popular version made with just meat, salt, tomatoes, and coriander.
The cuisine from the Khyber Pakhtunkhwa province of Pakistan is somewhat similar to the cuisine of neighbouring Afghanistan. Extreme winters in some areas made the supply of fresh vegetables impossible, so a lot of dried fruits and vegetables are incorporated in the cuisine. The province still produces a large amount of nuts which are used abundantly in traditional cooking, along with cereals like wheat, maize, barley, and rice. Accompanying these staples are dairy products (yoghurt, whey), various nuts, native vegetables, and fresh and dried fruits. Peshawari karahi from the provincial capital of Peshawar is a popular curry all over the country.
Cuisine in Pakistani Punjab differs from Indian Punjab on account of contents and religious diet rules. A typical Punjabi meal consists of some form of bread or rice with a "salan" (curry). Most preparations start with the frying of a masala which is a concoction of ginger, garlic, onions, tomatoes, and dried spices. Various other ingredients are then added. Spice level varies greatly depending on the sub-region as well as the household itself. A popular cooking fat is desi ghee with some dishes enriched with liberal amounts of butter and cream. There are certain dishes that are exclusive to Punjab, such as maash di dal and saron da saag (sarson ka saag). In Punjab and Kashmir, the only dish known as kardhi (curry) is a dish made of dahi (yogurt) and flour dumplings.
In Pakistan, the provinces of Sindh and Balochistan border the Arabian Sea. Due to this, the Sindhi cuisine often has abundant use of fish in curries. Among Pakistani food, the Sindhi curries generally tend to be the hottest. The daily food in most Sindhi households consists of wheat-based flatbread (phulka) and rice accompanied by two dishes, one gravy and one dry.
In Sri Lankan cuisine, rice, which is usually consumed daily, can be found at any special occasion, while spicy curries are favourite dishes for lunch and dinner. "Rice and curry" refers to a range of Sri Lankan dishes.
Burmese cuisine is based on a very different understanding of curries. The principal ingredients of almost all Burmese curries are fresh onion (which provides the gravy and main body of the curry), Indian spices and red chilies. Usually, meat and fish are the main ingredients for popular curries.
Burmese curries can be generalised into two types – the hot spicy dishes which exhibit north Indian or Pakistani influence, and the milder "sweet" curries. Burmese curries almost overwhelmingly lack coconut milk, setting them apart from most southeast Asian curries.
Regular ingredients include fresh onion, garlic and chili paste. Common spices include garam masala, dried chili powder, cumin powder, turmeric and ngapi, a fermented paste made from either fish or prawns. Burmese curries are quite oily, as the extra oil helps the food to last longer. A spaghetti equivalent called Nan gyi thohk exists, in which wheat or rice noodles are eaten with thick chicken curry.
In Indonesia curry is called "kari" or "kare". The most common type of "kari" consumed in Indonesia is "kari ayam" (chicken curry) and "kari kambing" (goat meat curry). In Aceh and North Sumatra roti cane is often eaten with "kari kambing". Other dishes such as gulai and opor are dishes based on curry. They are often highly localised and reflect the meat and vegetables available. They can therefore employ a variety of meats (chicken, beef, water buffalo and goat as in the flavoursome "gulai kambing"), seafood (such as prawn, crab, mussel, clam, and squid), fish (tuna, mackerel, carp, pangasius, catfish), or vegetables (young jackfruit, common beans, cassava leaf) dishes in a spiced sauce. They use local ingredients such as chili peppers, kaffir lime leaves, lemongrass, galangal, Indonesian bay leaves (salam leaf), candlenuts, turmeric, turmeric leaves, asam gelugur and asam kandis (sour mangosteens similar to tamarind), shrimp paste (terasi), cumin, coriander seed and coconut milk. In Aceh, curries use "daun salam koja" or "daun kari" ("Murraya koenigii") translated as "curry leaves".
One popular dish, rendang from West Sumatran cuisine, is often described as caramelised beef dry curry. In Indonesia, rendang is usually not considered to be curry since it is richer and contains less liquid than is normal for Indonesian curries. Authentic rendang uses water buffalo meat slow-cooked in thick coconut milk for a number of hours to tenderise, caramelise, and flavour the meat. Opor Ayam is another variation of curry, which tastes very similar to gulai. Opor is usually whitish in colour and uses neither cinnamon nor turmeric, while gulai may contain either or both. Opor is also often part of a family meal around Lebaran, while gulai can be commonly found in Padang restaurants.
Being at the crossroads of ancient trade routes has left a mark on Malaysian cuisine. While curry may have initially found its way to Malaysian shores via the Indian population, it has since become a staple among the Malays and Chinese. Malaysian curries differ from state to state, even within similar ethnic groupings, as they are influenced by many factors, be they cultural, religious, agricultural or economical.
Malaysian curries typically use turmeric-rich curry powders, coconut milk, shallots, ginger, belacan (shrimp paste), chili peppers, and garlic. Tamarind is also often used. Rendang is another form of curry consumed in Malaysia, Singapore, Indonesia and the Philippines; it is drier and contains mostly meat and more coconut milk than a conventional Malaysian curry. Rendang was mentioned in Malay literature Hikayat Amir Hamzah (1550s) and is popular among Indonesians, Singaporeans and Malaysians. All sorts of things are curried in Malaysia, including mutton, chicken, tofu, shrimp, cuttlefish, fish, eggplants, eggs, and vegetables.
In the Philippines, two kinds of curry traditions are seen corresponding with the cultural divide between the Hispanicised north and Indianised/Islamised south. In the northern areas, a linear range of new curry recipes could be seen. The most common is a variant of the native "ginataang manok" (chicken is cooked in coconut milk) dish with the addition of curry powder, known as the "Filipino chicken curry". This is the usual curry dish that northern Filipinos are familiar with. Similarly, other northern Filipino dishes that can be considered "curries" are usually "ginataan" (cooked with coconut milk) variants of other native meat or seafood dishes such as "adobo", "kaldereta", and "mechado", that simply add curry powder or non-native Indian spices.
In southern areas of the Visayas, Mindanao, the Sulu Archipelago and southern Palawan, various older curry recipes are seen, and owe their origins to the limited influence of the Spanish in these regions that preserved older culinary traditions; as well as closer historical ties to Malay states like the Sultanate of Brunei. These Mindanaoan curries include "kulma", synonymous with the Indian "korma"; "tiyula itum" which is a beef curry blackened with burned coconut-meat powder; and "rendang", also eaten in Indonesia and Malaysia. Meats used in these curries include beef, goat, mutton, lamb, seafood and chicken. Pork is not used, in accordance with Islamic dietary laws.
In Thai cuisine, curries are called "kaeng", and usually consist of meat, fish or vegetables in a sauce based on a paste made from chilies, onions or shallots, garlic, and shrimp paste. Additional spices and herbs define the type of curry. Local ingredients, such as chili peppers, kaffir lime leaves, lemongrass, galangal are used and, in central and southern Thai cuisine, coconut milk. Northern and northeastern Thai curries generally do not contain coconut milk. Due to the use of sugar and coconut milk, Thai curries tend to be sweeter than Indian curries. In the West, some of the Thai curries are described by colour; red curries use red chilies while green curries use green chilies. Yellow curry—called "kaeng kari" (by various spellings) in Thai, of which a literal translation could be "curry soup"—is more similar to Indian curries, with the use of turmeric, cumin, and other dried spices. A few stir-fried Thai dishes also use an Indian style curry powder (Thai: "phong kari").
Thai curries:
In Vietnam where curry is called "cà ri", curry features include coconut milk, potato, sweet potato, taro roots, chicken garnished with coriander, and green onion. It is more soup-like than Indian curry. The curry is usually eaten with a baguette, rice vermicelli or steamed rice. Some dishes use a curry-based stew, such as snail dishes, phá lấu, stewed frogs or eels.
Although not an integral part of Chinese cuisine, curry powder is added to some dishes in southern part of China. The curry powder sold in Chinese grocery stores is similar to Madras curry powder but with addition of star anise and cinnamon.
Chinese curries (咖哩, gā lǐ) typically consist of chicken, beef, fish, lamb, or other meats, green peppers, onions, large chunks of potatoes, and a variety of other ingredients and spices in a mildly spicy yellow curry sauce, and topped over steamed rice. White pepper, soy sauce, hot sauce or hot chili oil may be applied to the sauce to enhance the flavour of the curry.
The most common Chinese variety of curry sauce is usually sold in powder form. The ethnic Cantonese being dominant in Kuala Lumpur, this yellow Chinese-Malaysian variety was naturally introduced to China by the Cantonese. It features typically in Hong Kong cuisine, where curry is often cooked with brisket or fish balls. Malay satay seems to have been introduced to China with wider success by the ethnic Teochew, who make up the second largest group of Chinese of Singapore and are the dominant group in Thailand.
In Hong Kong, curry fish balls are a street snack, and curried brisket is a typical main course in cha chaan teng and fast food restaurants.
 is usually eaten as "karē raisu" — curry, rice, and often pickled vegetables, served on the same plate and eaten with a spoon, a common lunchtime canteen dish. It is less spicy and seasoned than Indian and Southeast Asian curries, being more of a thick stew than a curry.
British people brought curry from the Indian colony back to Britain and introduced it to Japan during the Meiji period (1868 to 1912), after Japan ended its policy of national self-isolation ("sakoku"), and curry in Japan was categorised as a Western dish. Its spread across the country is commonly attributed to its use in the Japanese Army and Navy which adopted it extensively as convenient field and naval canteen cooking, allowing even conscripts from the remotest countryside to experience the dish. The Japan Maritime Self-Defense Force traditionally have curry every Friday for lunch and many ships have their own unique recipes.
The standard Japanese curry contains onions, carrots, potatoes, and sometimes celery, and a meat that is cooked in a large pot. Sometimes grated apples or honey are added for additional sweetness and other vegetables are sometimes used instead. For the meat, pork, beef, and chicken are the most popular, in order of decreasing popularity. In northern and eastern Japan including Tokyo, pork is the most popular meat for curry. Beef is more common in western Japan, including Osaka, and in Okinawa, chicken is favoured. Curry seasoning is commonly sold in the form of a condensed brick, similar to a bouillon cube, which dissolves in the mixture of meat and vegetables.
Sometimes the curry-rice is topped with breaded pork cutlet (tonkatsu); this is called "katsukarē". Korokke (potato croquettes) are also a common topping.
Apart from with rice, curry is also served over noodles, possibly even on top of broth in addition, in dishes such as curry udon and curry ramen. It is also used as the filling in a fried curry bread pastry.
Though curry was introduced to Korea in the 1940s, the Indian dish was only popularized decades later, when Ottogi entered the Korean food industry by launching its powder-type curry product in 1969. Korean curry, usually served with rice, is characterized by the golden yellow colour from turmeric.
Curry tteokbokki, along with curry rice, is one of the most popular curry dishes in Korea. It is made of tteok (rice cakes), eomuk (fish cakes), eggs, vegetables, and curry. Curry can be added to various Korean dishes such as bokkeumbap (fried rice), sundubujjigae (silken tofu stew), fried chicken, vegetable stir-fries, and salads. Curry is also used in Korean-style western food such as pasta and steak, as well as Korean-style Japanese food such as cream udon.
Curry is very popular in the United Kingdom, with a curry house in nearly every town. Such is the popularity of curry in the United Kingdom, it has frequently been called its "adopted national dish". It was estimated that in 2016 there were 12,000 curry houses, employing 100,000 people and with annual combined sales of approximately £4.2 billion.
In general the food offered is Indian food cooked to British taste; however, there is increasing demand for authentic Indian food. As of 2015 curry houses accounted for a fifth of the restaurant business in the U.K. but, being historically a low wage sector, they were plagued by a shortage of labour. Established Indian immigrants from South Asia were moving on to other occupations; there were difficulties in training Europeans to cook curry; and immigration restrictions, which require payment of a high wage to skilled immigrants, had crimped the supply of new cooks.
Historically, the word "curry" was first used in British cuisine to denote dishes of meat (often leftover lamb) in a Western-style sauce flavoured with curry powder.
The first curry recipe in Britain appeared in "The Art of Cookery made Plain and Easy" by Hannah Glasse in 1747. The first edition of her book used only black pepper and coriander seeds for seasoning of "currey". By the fourth edition of the book, other ingredients such as turmeric and ginger were called for. The use of hot spices was not mentioned, which reflected the limited use of chili in India — chili plants had only been introduced into India around the late 16th century and at that time were only popular in southern India.
Many curry recipes are contained in 19th century cookbooks such as those of Charles Elmé Francatelli and Mrs Beeton. In "Mrs Beeton's Book of Household Management", a recipe for curry powder is given that contains coriander, turmeric, cinnamon, cayenne, mustard, ginger, allspice and fenugreek; although she notes that it is more economical to purchase the powder at "any respectable shop".
According to legend, one 19th century attempt at curry resulted in the invention of Worcestershire sauce.
Throughout the 19th and early 20th centuries, curry grew increasingly popular in Britain owing to the large number of British civil servants and military personnel associated with the British Raj. Following World War II, curry became even more popular in Britain owing to the large number of immigrants from South Asia.
Curry has become an integral part of British cuisine, so much so that, since the late 1990s, chicken tikka masala has been referred to as "a true British national dish".
Other British curry derivatives include "Coronation chicken", a cold dish, often used as a sandwich filling, invented to commemorate the coronation of Queen Elizabeth II in 1953 – and curry sauce (or curry gravy), usually served warm with traditional British fast food dishes such as chips. Curry sauce occasionally includes sultanas or other dried fruits.
In 1810, the entrepreneur Sake Dean Mahomed, from the Bengal Presidency, opened the first Indian curry house in England: the Hindoostanee Coffee House in London. (Curry was served prior to this in some London coffee houses.)
The first modern "upscale" Indian restaurant in Britain is thought to have been The Shafi in 1915, followed by Veeraswamy in London's Regent Street, founded in 1926; the latter is still standing and is the oldest surviving Indian restaurant in Britain.
Bengalis in the UK settled in big cities with industrial employment. In London, they settled in the East End, which for centuries has been the first port of call for many immigrants working in the docks and shipping from east Bengal. Their regular stopover paved the way for food and curry outlets to be opened up catering for an all-male workforce as family migration and settlement took place some decades later. Brick Lane in the East London Borough of Tower Hamlets is famous for its many curry houses.
Until the early 1970s, more than three-quarters of Indian restaurants in Britain were identified as being owned and run by people of Bengali origin. Most were run by migrants from East Pakistan, which became Bangladesh in 1971. Bangladeshi restaurateurs overwhelmingly come from the northeastern division of Sylhet. Until 1998, as many as 85% of curry restaurants in the UK were British Bangladeshi restaurants, but in 2003 this figure declined to just over 65%. The dominance of Bangladeshi restaurants is generally declining in some parts of London and the further north one travels. In Glasgow, there are more restaurants of Punjabi origin than any other.
In the early 2010s the popularity of the curry house saw a decline. This has been attributed to the sale of this style of food in generic restaurants, increased home cooking of this style of food with easy supermarket availability of ingredients, and immigration restrictions brought in from 2008 making the availability of low-wage chefs and other staff difficult.
Regardless of the ethnic origin of a restaurant's ownership, the menu will often be influenced by the wider South Asia (sometimes including Nepalese dishes), and sometimes cuisines from further afield (such as Persian dishes). Some British variations on Indian food are now being exported from the U.K. to India. Curry restaurants of more-or-less the British style are also popular in Canada, Australia and New Zealand.
This cuisine is characterised by the use of a common base for all the sauces to which spices are added when individual dishes are prepared. The standard "feedstock" is usually a sautéed mixture of onion, garlic and fresh ginger, to which various spices are added, depending on the recipe, but which may include: cloves, cinnamon, cardamom, chilies, peppercorns, cumin and mustard seeds. Ground coriander seed is widely used as a thickening agent, and turmeric is added for colour and its digestive qualities. Fresh or canned tomatoes and bell peppers are a common addition.
Better quality restaurants will normally make up new sauces on a daily basis, using fresh ingredients wherever possible and grinding their own spices. More modest establishments are more likely to resort to frozen or dried ingredients and pre-packaged spice mixtures.
Restaurants in Great Britain have adopted a number of Indian terms to identify popular dishes. Although the names may derive from traditional dishes, often the recipes do not. Representative names include:
The tandoor was introduced into Britain in the 1960s, and tandoori and tikka chicken became popular dishes.
Other dishes may feature with varying strengths, with those of north Indian origin, such as butter chicken, tending to be mild, and recipes from the south of India tending to be hotter.
Baltis are a style of curry thought to have been developed in Birmingham, England which have spread to other western countries and are traditionally cooked and served in the same pot, typically made of cast iron, called karahi or "balty".
African curries, Cape Malay curries and Natal curries include the traditional Natal curry, the Durban curry, bunny chow, and roti rolls. South African curries appear to have been founded in two distinct regions – one in the east (KwaZulu-Natal) and the other in the west (Western Cape) – with a variety of other curries developing across the country over the late 20th century and early 21st century to include ekasi, coloured, and Afrikaner curries.
Durban has the largest single population of Indians outside of India, who have been developing traditional Natal curries since their arrival in the late 19th century. Natal curries are mostly based on South Indian dishes and mostly consist of simple spiced lamb and chicken dishes (with large amounts of ghee and oils), but also include very complex and elaborate seafood, chicken and lamb specialties (chicken and prawn curry is a Natal favourite). Continental and British recipes have also evolved alongside Indian South African curries. Continental and British versions use mainly traditional recipes with the addition of red wine, milk, cream, vanilla or butter instead of ghee.
Bunny chow or a "set", a South African standard, has spread in popularity throughout the country and into other southern African countries and countries with large South African immigrant populations. It consists of either lamb, chicken or bean curry poured into a tunnelled-out loaf of bread to be eaten with one's fingers. The roti roll is another classic takeaway curry that could either be a curry in a flat roti bread (similar to a kebab bread) or the classic "chip, cheese and curry" roll which basically consists of fried chips with melted cheese and curry gravy rolled into a roti roll.
In the West Indies, curry is a very popular dish. The Indian indentured servants that were brought over from India by different European powers brought this dish to the West Indies. In Jamaica and Trinidad, curried goat is prominently featured. Curry can be found at both inexpensive and upscale Caribbean restaurants, and ingredients can range from chicken or vegetables to shellfish such as shrimp and scallops. Examples of curries in the West Indies include:
In Fiji curries are made in many Indian homes and are eaten with rice or roti. Roti (circle or square) is mainly eaten for breakfast with vegetable curries. Lunch is often dal and rice with some side dishes. Many working people take roti and curry for their lunch. Dinner is usually curry, rice with some chutneys. Curries are normally cooked in vegetable oil. Ghee is mainly used to fry dal, to make puris or sweets. To make a curry, spices like cumin, fenugreek, mustard, and curry leaves are added to the hot oil. Onion is chopped or sliced and garlic crushed and added to the pot. Once the onion and garlic have turned slightly golden then turmeric and garam masala are added. For every 1 tsp turmeric normally 2 tsp masala is added. Salt and chillies are added according to taste. Curry is simmered on low heat until well cooked. Water is added so that it can be mixed with rice. If coriander leaves are available then they are added for extra flavour.
Sometimes potatoes or vegetables are also added to curries to increase volume and make them more nutritious. Often coconut cream is added to seafood curries, such as prawn, crab or fish curries. Dal is often cooked with only turmeric and then fried in cumin, onion, and garlic. Sometimes carrots and leafy vegetables like "chauraiya" or "saijan" are added for extra flavor and nutrients.
Curry powder is a spice mixture of widely varying composition developed by the British during the days of the Raj as a means of approximating the taste of Indian cuisine at home. Masala refers to spices, and this is the name given to the thick and pasty sauce based on a combination of spices with ghee (clarified butter), butter, palm oil or coconut milk. Most commercial curry powders available in Britain, the U.S. and Canada rely heavily on ground turmeric, in turn producing a very yellow sauce. Lesser ingredients in these Western yellow curry powders are often coriander, cumin, fenugreek, mustard, chili, black pepper and salt. By contrast, curry powders and curry pastes produced and consumed in India are extremely diverse; some red, some yellow, some brown; some with five spices and some with as many as 20 or more. Besides the previously mentioned spices, other commonly found spices in different curry powders in India are allspice, white pepper, ground mustard, ground ginger, cinnamon, roasted cumin, cloves, nutmeg, mace, green cardamom seeds or black cardamom pods, bay leaves and coriander seeds.
Curry powder is used as an incidental ingredient in other cuisines, including for example a "curry sauce" ("sauce au curry", sometimes even "au cari") variation of the classic French béchamel.

</doc>
<doc id="6598" url="https://en.wikipedia.org/wiki?curid=6598" title="Camel">
Camel

A camel is an even-toed ungulate in the genus "Camelus" that bears distinctive fatty deposits known as "humps" on its back. Camels have long been domesticated and, as livestock, they provide food (milk and meat) and textiles (fiber and felt from hair). Camels are working animals especially suited to their desert habitat and are a vital means of transport for passengers and cargo. There are three surviving species of camel. The one-humped dromedary makes up 94% of the world's camel population, and the two-humped Bactrian camel makes up 6%. The Wild Bactrian camel is a separate species and is now critically endangered.
The word "camel" is also used informally in a wider sense, where the more correct term is "camelid", to include all seven species of the family Camelidae: the true camels (the above three species), along with the "New World" camelids: the llama, the alpaca, the guanaco, and the vicuña. The word itself is derived via and ("kamēlos") from Hebrew, Arabic or Phoenician: "gāmāl".
3 species are extant:
An extinct species of camel in the separate genus "Camelops", known as "C. hesternus", lived in western North America until the end of the Pleistocene, roughly 11,000 years ago.
The average life expectancy of a camel is 40 to 50 years. A full-grown adult dromedary camel stands at the shoulder and at the hump. Bactrian camels can be a foot taller. Camels can run at up to in short bursts and sustain speeds of up to . Bactrian camels weigh and dromedaries . The widening toes on a camel's hoof provide supplemental grip for varying soil sediments.
The male dromedary camel has an organ called a dulla in its throat, a large, inflatable sac he extrudes from his mouth when in rut to assert dominance and attract females. It resembles a long, swollen, pink tongue hanging out of the side of its mouth. Camels mate by having both male and female sitting on the ground, with the male mounting from behind. The male usually ejaculates three or four times within a single mating session. Camelids are the only ungulates to mate in a sitting position.
Camels do not directly store water in their humps; they are reservoirs of fatty tissue. Concentrating body fat in their humps minimizes the insulating effect fat would have if distributed over the rest of their bodies, helping camels survive in hot climates. When this tissue is metabolized, it yields more than one gram of water for every gram of fat processed. This fat metabolization, while releasing energy, causes water to evaporate from the lungs during respiration (as oxygen is required for the metabolic process): overall, there is a net decrease in water.
Camels have a series of physiological adaptations that allow them to withstand long periods of time without any external source of water. The dromedary camel can drink as seldom as once every 10 days even under very hot conditions, and can lose up to 30% of its body mass due to dehydration. Unlike other mammals, camels' red blood cells are oval rather than circular in shape. This facilitates the flow of red blood cells during dehydration and makes them better at withstanding high osmotic variation without rupturing when drinking large amounts of water: a camel can drink of water in three minutes.
Camels are able to withstand changes in body temperature and water consumption that would kill most other mammals. Their temperature ranges from at dawn and steadily increases to by sunset, before they cool off at night again. In general, to compare between camels and the other livestock, camels lose only 1.3 liters of fluid intake every day while the other livestock lose 20 to 40 liters per day (Breulmann, et al., 2007). Maintaining the brain temperature within certain limits is critical for animals; to assist this, camels have a rete mirabile, a complex of arteries and veins lying very close to each other which utilizes countercurrent blood flow to cool blood flowing to the brain. Camels rarely sweat, even when ambient temperatures reach . Any sweat that does occur evaporates at the skin level rather than at the surface of their coat; the heat of vaporization therefore comes from body heat rather than ambient heat. Camels can withstand losing 25% of their body weight to sweating, whereas most other mammals can withstand only about 12–14% dehydration before cardiac failure results from circulatory disturbance.
When the camel exhales, water vapor becomes trapped in their nostrils and is reabsorbed into the body as a means to conserve water. Camels eating green herbage can ingest sufficient moisture in milder conditions to maintain their bodies' hydrated state without the need for drinking.
The camel's thick coat insulates it from the intense heat radiated from desert sand; a shorn camel must sweat 50% more to avoid overheating. During the summer the coat becomes lighter in color, reflecting light as well as helping avoid sunburn. The camel's long legs help by keeping its body farther from the ground, which can heat up to . Dromedaries have a pad of thick tissue over the sternum called the "pedestal". When the animal lies down in a sternal recumbent position, the pedestal raises the body from the hot surface and allows cooling air to pass under the body.
Camels' mouths have a thick leathery lining, allowing them to chew thorny desert plants. Long eyelashes and ear hairs, together with nostrils that can close, form a barrier against sand. If sand gets lodged in their eyes, they can dislodge it using their transparent third eyelid. The camels' gait and widened feet help them move without sinking into the sand.
The kidneys and intestines of a camel are very efficient at reabsorbing water. Camels' kidneys have a 1:4 cortex to medulla ratio. Thus, the medullary part of a camel's kidney occupies twice as much area as a cow's kidney. Secondly, renal corpuscles have a smaller diameter, which reduces surface area for filtration. These two major anatomical characteristics enable camels to conserve water and limit the volume of urine in extreme desert conditions. Camel urine comes out as a thick syrup, and camel faeces are so dry that they do not require drying when the Bedouins use them to fuel fires.
The camel immune system differs from those of other mammals. Normally, the Y-shaped antibody molecules consist of two heavy (or long) chains along the length of the Y, and two light (or short) chains at each tip of the Y. Camels, in addition to these, also have antibodies made of only two heavy chains, a trait that makes them smaller and more durable. These "heavy-chain-only" antibodies, discovered in 1993, are thought to have developed 50 million years ago, after camelids split from ruminants and pigs.
The karyotypes of different camelid species have been studied earlier by many groups, but no agreement on chromosome nomenclature of camelids has been reached. A 2007 study flow sorted camel chromosomes, building on the fact that camels have 37 pairs of chromosomes (2n=74), and found that the karyotype consisted of one metacentric, three submetacentric, and 32 acrocentric autosomes. The Y is a small metacentric chromosome, while the X is a large metacentric chromosome.
The hybrid camel, a hybrid between Bactrian and dromedary camels, has one hump, though it has an indentation deep that divides the front from the back. The hybrid is at the shoulder and tall at the hump. It weighs an average of and can carry around , which is more than either the dromedary or Bactrian can.
According to molecular data, the wild Bactrian camel ("C. ferus") separated from the domestic Bactrian camel ("C. bactrianus") about 1 million years ago. New World and Old World camelids diverged about 11 million years ago. In spite of this, these species can hybridize and produce viable offspring. The cama is a camel-llama hybrid bred by scientists to see how closely related the parent species are. Scientists collected semen from a camel via an artificial vagina and inseminated a llama after stimulating ovulation with gonadotrophin injections. The cama is halfway in size between a camel and a llama and lacks a hump. It has ears intermediate between those of camels and llamas, longer legs than the llama, and partially cloven hooves. Like the mule, camas are sterile, despite both parents having the same number of chromosomes.
The earliest known camel, called "Protylopus", lived in North America 40 to 50 million years ago (during the Eocene). It was about the size of a rabbit and lived in the open woodlands of what is now South Dakota. By 35 million years ago, the "Poebrotherium" was the size of a goat and had many more traits similar to camels and llamas. The hoofed "Stenomylus", which walked on the tips of its toes, also existed around this time, and the long-necked "Aepycamelus" evolved in the Miocene.
An early relative of extant Old World camels, "Paracamelus", existed in the upper Miocene to Middle Pleistocene. Around 3–5 million years ago, the North American Camelidae spread to South America as part of the Great American Interchange via the newly formed Isthmus of Panama, where they gave rise to guanacos and related animals, and to Asia via the Bering land bridge. Surprising finds of fossil "Paracamelus" on Ellesmere Island beginning in 2006 in the high Canadian Arctic suggest that the extant Old World camels may descend from a larger, boreal browser whose hump may have evolved as an adaptation in a cold climate. This creature is estimated to have stood around nine feet (2.7 metres) tall. The Bactrican camel diverged from the dromedary about 1 million years ago, according to the fossil record. 
The last camel native to North America was "Camelops hesternus", which vanished along with horses, short-faced bears, mammoths and mastodons, ground sloths, sabertooth cats, and many other megafauna, coinciding with the migration of humans from Asia.
Like horses before their extinction in their continent of origin, camels spread across Beringia, moving in the opposite direction from the Asian immigration to America. They survived in the Old World, and eventually humans domesticated them and spread them globally. Along with many other megafauna in North America, the original wild camels were wiped out during the spread of the first indigenous peoples of the Americas from Asia into North America, 12-10,000 years ago; although fossils have never been associated with definitive evidence of hunting.
Most camels surviving today are domesticated. Although feral populations exist in Australia, India and Kazakhstan, wild camels survive only in the wild Bactrian camel population of the Gobi Desert.
Humans may have first domesticated dromedaries in Somalia and southern Arabia around 3000 BCE, and Bactrian camels in central Asia around 2500 BCE, as at Shahr-e Sukhteh (also known as the Burnt City), Iran.
Martin Heide's 2010 work on the domestication of the camel tentatively concludes that humans had domesticated the Bactrian camel by at least the middle of the third millennium somewhere east of the Zagros Mountains, with the practice then moving into Mesopotamia. Heide suggests that mentions of camels "in the patriarchal narratives may refer, at least in some places, to the Bactrian camel", while noting that the camel is not mentioned in relationship to Canaan.
Recent excavations in the Timna Valley by Lidar Sapir-Hen and Erez Ben-Yosef discovered what may be the earliest domestic camel bones yet found in Israel or even outside the Arabian Peninsula, dating to around 930 BC. This garnered considerable media coverage, as it is strong evidence that the stories of Abraham, Jacob, Esau, and Joseph were written after this time.
The existence of camels in Mesopotamia—but not in the eastern Mediterranean lands—is not a new idea. The historian Richard Bulliet did not think that the occasional mention of camels in the Bible meant that the domestic camels were common in the Holy Land at that time. The archaeologist William F. Albright, writing even earlier, saw camels in the Bible as an anachronism.
The official report by Sapir-Hen and Ben-Joseph notes:
The introduction of the dromedary camel (Camelus dromedarius) as a pack animal to the southern Levant ... substantially facilitated trade across the vast deserts of Arabia, promoting both economic and social change (e.g., Kohler 1984; Borowski 1998: 112–116; Jasmin 2005). This ... has generated extensive discussion regarding the date of the earliest domestic camel in the southern Levant (and beyond) (e.g., Albright 1949: 207; Epstein 1971: 558–584; Bulliet 1975; Zarins 1989; Köhler-Rollefson 1993; Uerpmann and Uerpmann 2002; Jasmin 2005; 2006; Heide 2010; Rosen and Saidel 2010; Grigson 2012). Most scholars today agree that the dromedary was exploited as a pack animal sometime in the early Iron Age (not before the 12th century [BC])
and concludes:
Current data from copper smelting sites of the Aravah Valley enable us to pinpoint the introduction of domestic camels to the southern Levant more precisely based on stratigraphic contexts associated with an extensive suite of radiocarbon dates. The data indicate that this event occurred not earlier than the last third of the 10th century [BC] and most probably during this time. The coincidence of this event with a major reorganization of the copper industry of the region—attributed to the results of the campaign of Pharaoh Shoshenq I—raises the possibility that the two were connected, and that camels were introduced as part of the efforts to improve efficiency by facilitating trade.
Desert tribes and Mongolian nomads use camel hair for tents, yurts, clothing, bedding and accessories. Camels have outer guard hairs and soft inner down, and the fibers are sorted by color and age of the animal. The guard hairs can be felted for use as waterproof coats for the herdsmen, while the softer hair is used for premium goods. The fiber can be spun for use in weaving or made into yarns for hand knitting or crochet. Pure camel hair is recorded as being used for western garments from the 17th century onwards, and from the 19th century a mixture of wool and camel hair was used.
By at least 1200 BC the first camel saddles had appeared, and Bactrian camels could be ridden. The first saddle was positioned to the back of the camel, and control of the Bactrian camel was exercised by means of a stick. However, between 500 and 100 BC, Bactrian camels came into military use. New saddles, which were inflexible and bent, were put over the humps and divided the rider's weight over the animal. In the seventh century BC the military Arabian saddle evolved, which again improved the saddle design slightly.
Military forces have used camel cavalries in wars throughout Africa, the Middle East, and into the modern-day Border Security Force (BSF) of India (though as of July 2012, the BSF planned the replacement of camels with ATVs). The first documented use of camel cavalries occurred in the Battle of Qarqar in 853 BC. Armies have also used camels as freight animals instead of horses and mules.
The East Roman Empire used auxiliary forces known as "dromedarii", whom the Romans recruited in desert provinces. The camels were used mostly in combat because of their ability to scare off horses at close range (horses are afraid of the camels' scent), a quality famously employed by the Achaemenid Persians when fighting Lydia in the Battle of Thymbra (547 BC).
The United States Army established the U.S. Camel Corps, stationed in California, in the late 19th century. One may still see stables at the Benicia Arsenal in Benicia, California, where they nowadays serve as the Benicia Historical Museum. Though the experimental use of camels was seen as a success (John B. Floyd, Secretary of War in 1858, recommended that funds be allocated towards obtaining a thousand more camels), the outbreak of the American Civil War in 1861 saw the end of the Camel Corps: Texas became part of the Confederacy, and most of the camels were left to wander away into the desert.
France created a "méhariste" camel corps in 1912 as part of the Armée d'Afrique in the Sahara in order to exercise greater control over the camel-riding Tuareg and Arab insurgents, as previous efforts to defeat them on foot had failed. The Free French Camel Corps fought during World War II, and camel-mounted units remained in service until the end of French rule over Algeria in 1962.
In 1916, the British created the Imperial Camel Corps. It was originally used to fight the Senussi, but was later used in the Sinai and Palestine Campaign in World War I. The Imperial Camel Corps comprised infantrymen mounted on camels for movement across desert, though they dismounted at battle sites and fought on foot. After July 1918, the Corps began to become run down, receiving no new reinforcements, and was formally disbanded in 1919.
In World War I, the British Army also created the Egyptian Camel Transport Corps, which consisted of a group of Egyptian camel drivers and their camels. The Corps supported British war operations in Sinai, Palestine, and Syria by transporting supplies to the troops.
The Somaliland Camel Corps was created by colonial authorities in British Somaliland in 1912; it was disbanded in 1944.
Bactrian camels were used by Romanian forces during World War II in the Caucasian region. At the same period the Soviet units operating around Astrakhan in 1942 adopted local camels as draft animals due to shortage of trucks and horses, and kept them even after moving out of the area. Despite severe losses, some of these camels came as far West as to Berlin itself.
The Bikaner Camel Corps of British India fought alongside the British Indian Army in World Wars I and II.
The "Tropas Nómadas" (Nomad Troops) were an auxiliary regiment of Sahrawi tribesmen serving in the colonial army in Spanish Sahara (today Western Sahara). Operational from the 1930s until the end of the Spanish presence in the territory in 1975, the "Tropas Nómadas" were equipped with small arms and led by Spanish officers. The unit guarded outposts and sometimes conducted patrols on camelback.
Camel milk is a staple food of desert nomad tribes and is sometimes considered a meal itself; a nomad can live on only camel milk for almost a month.
Camel milk can readily be made into yogurt, but can only be made into butter if it is soured first, churned, and a clarifying agent is then added. Until recently, camel milk could not be made into camel cheese because rennet was unable to coagulate the milk proteins to allow the collection of curds. Developing less wasteful uses of the milk, the FAO commissioned Professor J.P. Ramet of the École Nationale Supérieure d'Agronomie et des Industries Alimentaires, who was able to produce curdling by the addition of calcium phosphate and vegetable rennet in the 1990s. The cheese produced from this process has low levels of cholesterol and is easy to digest, even for the lactose intolerant.
Camel milk can also be made into ice cream.
They provide food in the form of meat and milk (Tariq "et al.",2010). Approximately 3.3 million camels and camelids are slaughtered each year for meat worldwide. A camel carcass can provide a substantial amount of meat. The male dromedary carcass can weigh , while the carcass of a male Bactrian can weigh up to . The carcass of a female dromedary weighs less than the male, ranging between . The brisket, ribs and loin are among the preferred parts, and the hump is considered a delicacy. The hump contains "white and sickly fat", which can be used to make the "khli" (preserved meat) of mutton, beef, or camel. On the other hand, camel milk and meat are rich in protein, vitamins, glycogen, and other nutrients making them essential in the diet of many people. From chemical composition to meat quality, the dromedary camel is the preferred breed for meat production. It does well even in arid areas due to its unusual physiological behaviors and characteristics, which include tolerance to extreme temperatures, radiation from the sun, water paucity, rugged landscape and low vegetation. Camel meat is reported to taste like coarse beef, but older camels can prove to be very tough, although camel meat becomes tenderer the more it is cooked. The Abu Dhabi Officers' Club serves a camel burger mixed with beef or lamb fat in order to improve the texture and taste. In Karachi, Pakistan, some restaurants prepare nihari from camel meat. Specialist camel butchers provide expert cuts, with the hump considered the most popular.
Camel meat has been eaten for centuries. It has been recorded by ancient Greek writers as an available dish at banquets in ancient Persia, usually roasted whole. The Roman emperor Heliogabalus enjoyed camel's heel. Camel meat is mainly eaten in certain regions, including Eritrea, Somalia, Djibouti, Saudi Arabia, Egypt, Syria, Libya, Sudan, Ethiopia, Kazakhstan, and other arid regions where alternative forms of protein may be limited or where camel meat has had a long cultural history. Camel blood is also consumable, as is the case among pastoralists in northern Kenya, where camel blood is drunk with milk and acts as a key source of iron, vitamin D, salts and minerals.
A 2005 report issued jointly by the Saudi Ministry of Health and the United States Centers for Disease Control and Prevention details four cases of human bubonic plague resulting from the ingestion of raw camel liver.
Camel meat is also occasionally found in Australian cuisine: for example, a camel lasagna is available in Alice Springs. Australia has exported camel meat, primarily to the Middle East but also to Europe and the US, for many years. The meat is very popular among North African Australians, such as Somalis, and other Australians have also been buying it. The feral nature of the animals means they produce a different type of meat to farmed camels in other parts of the world, and it is sought after because it is disease-free, and a unique genetic group. Demand is outstripping supply, and governments are being urged not to cull the camels, but redirect the cost of the cull into developing the market. Australia has seven camel dairies, which produce milk, cheese and skincare products in addition to meat.
Camel meat is "halal" (, 'allowed') for Muslims. However, according to some Islamic schools of thought, a state of impurity is brought on by the consumption of it. Consequently, these schools hold that Muslims must perform "wudhu" (ablution) before the next time they pray after eating camel meat. Also, some Islamic schools of thought consider it "haram" (, 'forbidden') for a Muslim to perform "Salat" in places where camels lie, as it is said to be a dwelling place of the "Shaytan" (, 'Devil'). According to Abu Yusuf, the urine of camel may be used for medical treatment if necessary, but according to Abū Ḥanīfah, the drinking of camel urine is discouraged.
The Islamic texts contain several stories featuring camels. In the story of the people of Thamud, the Prophet Salih miraculously brings forth a "naqat" (, 'she-camel') out of a rock. After the Prophet Muhammad migrated from Mecca to Medina, he allowed his she-camel to roam there; the location where the camel stopped to rest determined the location where he would build his house in Medina.
According to Jewish tradition, camel meat and milk are not kosher. Camels possess only one of the two kosher criteria; although they chew their cud, they do not possess cloven hooves: "But these you shall not eat among those that bring up the cud and those that have a cloven hoof: the camel, because it brings up its cud, but does not have a [completely] cloven hoof; it is unclean for you."
There are around 14 million camels alive , with 90% being dromedaries. Dromedaries alive today are domesticated animals (mostly living in the Horn of Africa, the Sahel, Maghreb, Middle East and South Asia). The Horn region alone has the largest concentration of camels in the world, where the dromedaries constitute an important part of local nomadic life. They provide nomadic people in Somalia and Ethiopia with milk, food, and transportation.
Around 700,000 dromedary camels are now feral in Australia, descended from those introduced as a method of transport in the 19th and early 20th centuries. This population is growing about 8% per year. Representatives of the Australian government have culled more than 100,000 of the animals in part because the camels use too much of the limited resources needed by sheep farmers.
A small population of introduced camels, dromedaries and Bactrians, wandered through Southwestern United States after having been imported in the 19th century as part of the U.S. Camel Corps experiment. When the project ended, they were used as draft animals in mines and escaped or were released. Twenty-five U.S. camels were bought and exported to Canada during the Cariboo Gold Rush.
The Bactrian camel is, , reduced to an estimated 1.4 million animals, most of which are domesticated. The Wild Bactrian camel is a separate species and is the only truly wild (as opposed to feral) camel in the world. The wild camels are critically endangered and number approximately 1400, inhabiting the Gobi and Taklamakan Deserts in China and Mongolia.

</doc>
<doc id="6599" url="https://en.wikipedia.org/wiki?curid=6599" title="Chaldea">
Chaldea

Chaldea (, also spelled Chaldaea (Syriac ܟܠܕܝܐ)) was a country that existed between the late 10th or early 9th and mid-6th centuries BC, after which the country and its people were absorbed and assimilated into Babylonia. Semitic-speaking, it was located in the marshy land of the far southeastern corner of Mesopotamia and briefly came to rule Babylon. The Hebrew Bible uses the term ("Kaśdim") and this is translated as "Chaldaeans" in the Greek Old Testament, although there is some dispute as to whether "Kasdim" in fact means "Chaldean" or refers to the south Mesopotamian "Kaldu".
During a period of weakness in the East Semitic-speaking kingdom of Babylonia, new tribes of West Semitic-speaking migrants arrived in the region from the Levant between the 11th and 9th centuries BCE. The earliest waves consisted of Suteans and Arameans, followed a century or so later by the Kaldu, a group who became known later as the Chaldeans or the Chaldees. These migrations did not affect the powerful kingdom of Assyria in the northern half of Mesopotamia, which repelled these incursions.
The short-lived 11th dynasty of the Kings of Babylon (6th century BCE) is conventionally known to historians as the Chaldean Dynasty, although the last rulers, Nabonidus and his son Belshazzar, were from Assyria. (This is not found in Georges Roux - Ancient Iraq. Roux states that Nabonidus "was the son of a certain Nabu-Balatsu-Iqbi, who belonged to the Babylonian nobility but was not of royal blood and of a votaress... of the city of Harran.")
These nomadic Chaldeans settled in the far southeastern portion of Babylonia, chiefly on the left bank of the Euphrates. Though for a short time the name commonly referred to the whole of southern Mesopotamia in Hebraic literature, this was a geographical and historical misnomer as Chaldea proper was in fact only the plain in the far southeast formed by the deposits of the Euphrates and the Tigris, extending about four hundred miles along the course of these rivers and averaging about a hundred miles in width.
The name "Chaldaea" is a latinization of the Greek ' (), a hellenization of Akkadian ' or '. The name appears in Hebrew in the Bible as ' () and in Aramaic as "" ().
The Hebrew word possibly appears in the Bible (Genesis 22:22) in the name "Kesed"(כשד), the singular form of "Kasdim"(כַּשְׂדִּים), meaning Chaldeans. Kesed is identified as son of Abraham's brother Nahor (and brother of Kemuel the father of Aram), residing in Aram Naharaim. Jewish historian Flavius Josephus also links Arphaxad and Chaldaea, in his Antiquities of the Jews, stating, “Arphaxad named the Arphaxadites, who are now called Chaldeans.”
In the early period, between the early 9th century and late 7th century BCE, "mat Kaldi" was the name of a small sporadically independent migrant-founded territory under the domination of the Neo-Assyrian Empire (911-605 BCE) in southeastern Babylonia, extending to the western shores of the Persian Gulf.
The expression " mat Bit Yâkin" is also used, apparently synonymously. "Bit Yâkin" was the name of the largest and most powerful of the five tribes of the Chaldeans, or equivalently, their territory.
The original extension of "Bit Yâkin" is not known precisely, but it extended from the lower Tigris into Arabia. Sargon II mentions it as extending as far as Dilmun or "sea-land" (littoral Eastern Arabia).
"Chaldea" or "mat Kaldi" generally referred to the low, marshy, alluvial land around the estuaries of the Tigris and Euphrates, which at the time discharged their waters through separate mouths into the sea.
The tribal capital "Dur Yâkin" was the original seat of Marduk-Baladan.
The king of Chaldea was also called the king of Bit Yakin, just as the kings of Babylonia and Assyria were regularly styled simply king of Babylon or Assur, the capital city in each case. In the same way, what is now known as the Persian Gulf was sometimes called "the Sea of Bit Yakin", and sometimes "the Sea of the Land of Chaldea".
"Chaldea" came to be used in a wider sense, of Mesopotamia in general, following the ascendancy of the Chaldeans during 608–557 BCE. This is especially the case in the Hebrew Bible, which
was substantially composed during this period (roughly corresponding to the period of Babylonian captivity). The Book of Jeremiah makes frequent reference to the Chaldeans (KJV "Chaldees" following LXX ; in Biblical Hebrew as "Kasdîy(mâh)" "Kassites"). 
Habbakuk 1:6 calls them "that bitter and hasty nation" (). Isaiah 23:13 DRB states, “Behold the land of the Chaldeans, there was not such a people, the Assyrian founded it: they have led away the strong ones thereof into captivity, they have destroyed the houses thereof, they have brought it to ruin.”
Unlike the East Semitic Akkadian-speaking Akkadians, Assyrians and Babylonians, whose ancestors had been established in Mesopotamia since at least the 30th century BCE, the Chaldeans were not a native Mesopotamian people, but were late 10th or early 9th century BCE West Semitic Levantine migrants to the southeastern corner of the region, who had played no part in the previous 3,000 years or so of Sumero-Akkadian and Assyro-Babylonian Mesopotamian civilization and history.
The ancient Chaldeans seem to have migrated into Mesopotamia sometime between c. 940–860 BCE, a century or so after other new Semitic arrivals, the Arameans and the Suteans, appeared in Babylonia, c. 1100 BCE. They first appear in written record in the annals of the Assyrian king Shalmaneser III during the 850s BCE. This was a period of weakness in Babylonia, and its ineffectual native kings were unable to prevent new waves of semi-nomadic foreign peoples from invading and settling in the land.
Though belonging to the same West Semitic speaking ethnic group and migrating from the same Levantine regions like the earlier arriving Aramaeans, they are to be differentiated; the Assyrian king Sennacherib, for example, carefully distinguishes them in his inscriptions.
The Chaldeans were able to keep their identity despite the dominant Assyro-Babylonian culture although some were not able to, as was the case for the earlier Amorites, Kassites and Suteans before them by the time Babylon fell in 539 BCE. 
The Chaldeans originally spoke a West Semitic language similar to but distinct from Aramaic. During the Assyrian Empire, the Assyrian king Tiglath-Pileser III introduced an Eastern Aramaic dialect as the lingua franca of his empire in the mid-8th century BCE. As a result of this innovation, in late periods both the Babylonian and Assyrian dialects of Akkadian became marginalised, and Mesopotamian Aramaic took its place across Mesopotamia, including among the Chaldeans. This language in the form of Eastern Aramaic neo-Aramaic dialects still remains the mother-tongue of the now Christian Assyrian people of northern Iraq, north-east Syria, south-eastern Turkey and north-western Iran to this day.
One form of this once widespread language is used in Daniel and Ezra, but the use of the name "Chaldee" to describe it, first introduced by Jerome, is linguistically correct and accurate in the sense that the Chaldeans were using this language. 
In the Hebrew Bible, the prophet Abraham is stated to have originally come from "Ur of the Chaldees" (Ur Kaśdim).
The region that the Chaldeans eventually made their homeland was in relatively poor southeastern Mesopotamia, at the head of the Persian Gulf. They appear to have migrated into southern Babylonia from the Levant at some unknown point between the end of the reign of Ninurta-kudurri-usur II (a contemporary of Tiglath-Pileser II) circa 940 BCE, and the start of the reign of Marduk-zakir-shumi I in 855 BCE, although there is no historical proof of their existence prior to the late 850s BCE.
For perhaps a century or so after settling in the area, these semi-nomadic migrant Chaldean tribes had no impact on the pages of history, seemingly remaining subjugated by the native Akkadian speaking kings of Babylon or by perhaps regionally influential Aramean tribes. The main players in southern Mesopotamia during this period were Babylonia and Assyria, together with Elam to the east and the Aramaeans, who had already settled in the region a century or so prior to the arrival of the Chaldeans.
The very first "written historical attestation" of the existence of Chaldeans occurs in 852 BCE, in the annals of the Assyrian king Shalmaneser III, who mentions invading the southeastern extremes of Babylonia and subjugating one Mushallim-Marduk, the chief of the Amukani tribe and overall leader of the Kaldu tribes, together with capturing the town of Baqani, extracting tribute from Adini, chief of the Bet-Dakkuri, another Chaldean tribe.
Shalmaneser III had invaded Babylonia at the request of its own king, Marduk-zakir-shumi I, the Babylonian king being threatened by his own rebellious relations, together with powerful Aramean tribes pleaded with the more powerful Assyrian king for help. The subjugation of the Chaldean tribes by the Assyrian king appears to have been an aside, as they were not at that time a powerful force or a threat to the native Babylonian king.
Important Kaldu regions in southeastern Babylonia were Bit-Yâkin (the original area the Chaldeans settled in on the Persian Gulf), Bet-Dakuri, Bet-Adini, Bet-Amukkani, and Bet-Shilani.
Chaldean leaders had by this time already adopted Assyro-Babylonian names, religion, language, and customs, indicating that they had become Akkadianized to a great degree.
The Chaldeans remained quietly ruled by the native Babylonians (who were in turn subjugated by their Assyrian relations) for the next seventy-two years, only coming to historical prominence for the first time in Babylonia in 780 BCE, when a previously unknown Chaldean named Marduk-apla-usur usurped the throne from the native Babylonian king Marduk-bel-zeri (790–780 BCE). The latter was a vassal of the Assyrian king Shalmaneser IV (783–773 BCE), who was otherwise occupied quelling a civil war in Assyria at the time.
This was to set a precedent for all future Chaldean aspirations on Babylon during the Neo Assyrian Empire; always too weak to confront a strong Assyria alone and directly, the Chaldeans awaited periods when Assyrian kings were distracted elsewhere in their vast empire, or engaged in internal conflicts, then, in alliance with other powers stronger than themselves (usually Elam), they made a bid for control over Babylonia.
Shalmaneser IV attacked and defeated Marduk-apla-user, retaking northern Babylonia and forcing on him a border treaty in Assyria's favour. The Assyrians allowed him to remain on the throne, although subject to Assyria. Eriba-Marduk, another Chaldean, succeeded him in 769 BCE and his son, Nabu-shuma-ishkun in 761 BCE, with both being dominated by the new Assyrian king Ashur-Dan III (772–755 BCE). Babylonia appears to have been in a state of chaos during this time, with the north occupied by Assyria, its throne occupied by foreign Chaldeans, and continual civil unrest throughout the land.
The Chaldean rule proved short-lived. A native Babylonian king named Nabonassar (748–734 BCE) defeated and overthrew the Chaldean usurpers in 748 BCE, restored indigenous rule, and successfully stabilised Babylonia. The Chaldeans once more faded into obscurity for the next three decades. During this time both the Babylonians and the Chaldean and Aramean migrant groups who had settled in the land once more fell completely under the yoke of the powerful Assyrian king Tiglath-Pileser III (745–727 BCE), a ruler who introduced Imperial Aramaic as the lingua franca of his empire. The Assyrian king at first made Nabonassar and his successor native Babylonian kings Nabu-nadin-zeri, Nabu-suma-ukin II and Nabu-mukin-zeri his subjects, but decided to rule Babylonia directly from 729 BCE. He was followed by Shalmaneser V (727–722 BCE), who also ruled Babylon in person.
When Sargon II (722–705 BCE) ascended the throne of the Assyrian Empire in 722 BCE after the death of Shalmaneser V, he was forced to launch a major campaign in his subject states of Persia, Mannea and Media in Ancient Iran to defend his territories there. He defeated and drove out the Scythians and Cimmerians who had attacked Assyria's Persian and Medina vassal colonies in the region. At the same time, Egypt began encouraging and supporting the rebellion against Assyria in Israel and Canaan, forcing the Assyrians to send troops to deal with the Egyptians.
These events allowed the Chaldeans to once more attempt to assert themselves. While the Assyrian king was otherwise occupied defending his Iranian colonies from the Scythians and Cimmerians and driving the Egyptians from Canaan, Marduk-apla-iddina II (the Biblical Merodach-Baladan) of Bit-Yâkin, allied himself with the powerful Elamite kingdom and the native Babylonians, briefly seizing control of Babylon between 721 and 710 BCE. With the Scythians and Cimmerians vanquished, the Medes and Persians pledging loyalty, and the Egyptians defeated and ejected from southern Canaan, Sargon II was free at last to deal with the Chaldeans, Babylonians and Elamites. He attacked and deposed Marduk-apla-adding II in 710 BCE, also defeating his Elamite allies in the process. After defeat by the Assyrians, Merodach-Baladan fled to his protectors in Elam.
In 703, Merodach-Baladan very briefly regained the throne from a native Akkadian-Babylonian ruler Marduk-zakir-shumi II, who was a puppet of the new Assyrian king, Sennacherib (705–681 BCE). He was once more soundly defeated at Kish, and once again fled to Elam where he died in exile after one final failed attempt to raise a revolt against Assyria in 700 BCE, this time not in Babylon, but in the Chaldean tribal land of Bit-Yâkin. A native Babylonian king named Bel-ibni (703–701 BCE) was placed on the throne as a puppet of Assyria.
The next challenge to Assyrian domination came from the Elamites in 694 BCE, with Nergal-ushezib deposing and murdering Ashur-nadin-shumi (700–694 BCE), the Assyrian prince who was king of Babylon and son of Sennacherib. The Chaldeans and Babylonians again allied with their more powerful Elamite neighbors in this endeavour. This prompted the enraged Assyrian king Sennacherib to invade and subjugate Elam and Chaldea and to sack Babylon, laying waste to and largely destroying the city. Babylon was regarded as a sacred city by all Mesopotamians, including the Assyrians, and this act eventually resulted in Sennacherib's being murdered by his own sons while he was praying to the god Nisroch in Nineveh.
Esarhaddon (681–669 BCE) succeeded Sennacherib as ruler of the Assyrian Empire. He completely rebuilt Babylon and brought peace to the region. He conquered Egypt, Nubia and Libya and entrenched his mastery over the Persians, Medes, Parthians, Scythians, Cimmerians, Arameans, Israelites, Phoenicians, Canaanites, Urartians, Pontic Greeks, Cilicians, Phrygians, Lydians, Manneans and Arabs. For the next 60 or so years, Babylon and Chaldea remained peacefully under direct Assyrian control. The Chaldeans remained subjugated and quiet during this period, and the next major revolt in Babylon against the Assyrian empire was fermented not by a Chaldean, Babylonian or Elamite, but by Shamash-shum-ukin, who was an Assyrian king of Babylon, and elder brother of Ashurbanipal (668-627 BCE), the new ruler of the Neo-Assyrian Empire.
Shamash-shum-ukin (668–648 BCE) had become infused with Babylonian nationalism after sixteen years peacefully subject to his brother, and despite being Assyrian himself, declared that the city of Babylon and not Nineveh or Ashur should be the seat of the empire.
In 652 BCE, he raised a powerful coalition of peoples resentful of their subjugation to Assyria against his own brother Ashurbanipal. The alliance included the Babylonians, Persians, Chaldeans, Medes, Elamites, Sultans, Arameans, Israelites, Arabs and Canaanites, together with some disaffected elements among the Assyrians themselves. After a bitter struggle lasting five years, the Assyrian king triumphed over his rebellious brother in 648 BCE, Elam was utterly destroyed, and the Babylonians, Persians, Medes, Chaldeans, Arabs, and others were savagely punished. An Assyrian governor named Kandalanu was then placed on the throne of Babylon to rule on behalf of Ashurbanipal. The next 22 years were peaceful, and neither the Babylonians nor Chaldeans posed a threat to the dominance of Ashurbanipal.
However, after the death of the mighty Ashurbanipal (and Kandalanu) in 627 BCE, the Neo Assyrian Empire descended into a series of bitter internal dynastic civil wars that were to be the cause of its downfall.
Ashur-etil-ilani (626–623 BCE) ascended to the throne of the empire in 626 BCE but was immediately engulfed in a torrent of fierce rebellions instigated by rival claimants. He was deposed in 623 BCE by an Assyrian general ("turtanu") named Sin-shumu-lishir (623–622 BCE), who was also declared king of Babylon. Sin-shar-ishkun (622–612 BCE), the brother of Ashur-etil-ilani, took back the throne of empire from Sin-shumu-lishir in 622 BCE, but was then himself faced with unremitting rebellion against his rule by his own people. Continual conflict among the Assyrians led to a myriad of subject peoples, from Cyprus to Persia and The Caucasus to Egypt, quietly reasserting their independence and ceasing to pay tribute to Assyria.
Nabopolassar, a previously obscure and unknown Chaldean chieftain, followed the opportunistic tactics laid down by previous Chaldean leaders to take advantage of the chaos and anarchy gripping Assyria and Babylonia and seized the city of Babylon in 620 BCE with the help of its native Babylonian inhabitants.
Sin-shar-ishkun amassed a powerful army and marched into Babylon to regain control of the region. Nabopolassar was saved from likely destruction because yet another massive Assyrian rebellion broke out in Assyria proper, including the capital Nineveh, which forced the Assyrian king to turn back in order to quell the revolt. Nabopolassar took advantage of this situation, seizing the ancient city of Nippur in 619 BCE, a mainstay of pro-Assyrianism in Babylonia, and thus Babylonia as a whole.
However, his position was still far from secure, and bitter fighting continued in the Babylonian heartlands from 620 to 615 BCE, with Assyrian forces encamped in Babylonia in an attempt to eject Nabopolassar. Nabopolassar attempted a counterattack, marched his army into Assyria proper in 616 BCE, and tried to besiege Assur and Arrapha (modern Kirkuk), but was defeated by Sin-shar-ishkun and chased back into Babylonia after being driven from Idiqlat (modern Tikrit) at the southernmost end of Assyria. A stalemate seemed to have ensued, with Nabopolassar unable to make any inroads into Assyria despite its greatly weakened state, and Sin-shar-ishkun unable to eject Nabopolassar from Babylonia due to constant rebellions and civil war among his own people.
Nabopolassar's position, and the fate of the Assyrian empire, was sealed when he entered into an alliance with another of Assyria's former vassals, the Medes, the now dominant people of what was to become Persia. The Median Cyaxares had also recently taken advantage of the anarchy in the Assyrian Empire, while officially still a vassal of Assyria, he took the opportunity to meld the Iranian peoples; the Medes, Persians, Sagartians and Parthians, into a large and powerful Median-dominated force. The Medes, Persians, Parthians, Chaldeans and Babylonians formed an alliance that also included the Scythians and Cimmerians to the north.
While Sin-shar-ishkun was fighting both the rebels in Assyria and the Chaldeans and Babylonians in southern Mesopotamia, Cyaxares (hitherto a vassal of Assyria), in alliance with the Scythians and Cimmerians launched a surprise attack on civil-war-bleaguered Assyria in 615 BCE, sacking Kalhu (the Biblical Calah/Nimrud) and taking Arrapkha (modern Kirkuk). Nabopolassar, still pinned down in southern Mesopotamia, was not involved in this major breakthrough against Assyria. From this point however, the alliance of Medes, Persians, Chaldeans, Babylonians, Sagartians, Scythians and Cimmerians fought in unison against Assyria.
Despite the sorely depleted state of Assyria, bitter fighting ensued. Throughout 614 BCE the alliance of powers continued to make inroads into Assyria itself, although in 613 BCE the Assyrians somehow rallied to score a number of counterattacking victories over the Medes-Persians, Babylonians-Chaldeans and Scythians-Cimmerians. This led to a coalition of forces ranged against it to unite and launch a massive combined attack in 612 BCE, finally besieging and sacking Nineveh in late 612 BCE, killing Sin-shar-ishkun in the process.
A new Assyrian king, Ashur-uballit II (612–605 BCE), took the crown amidst the house-to-house fighting in Nineveh, and refused a request to bow in vassalage to the rulers of the alliance. He managed to fight his way out of Nineveh and reach the northern Assyrian city of Harran, where he founded a new capital. Assyria resisted for another seven years until 605 BCE, when the remnants of the Assyrian army and the army of the Egyptians (whose dynasty had also been installed as puppets of the Assyrians) were defeated at Karchemish. Nabopolassar and his Median, Scythian and Cimmerian allies were now in possession of much of the huge Neo Assyrian Empire. The Egyptians had belatedly come to the aid of Assyria, fearing that, without Assyrian protection, they would be the next to succumb to the new powers, having already been raided by the Scythians.
The Chaldean king of Babylon now ruled all of southern Mesopotamia (Assyria in the north was ruled by the Medes), and the former Assyrian possessions of Aram (Syria), Phoenicia, Israel, Cyprus, Edom, Philistia, and parts of Arabia, while the Medes took control of the former Assyrian colonies in Ancient Iran, Asia Minor and the Caucasus.
Nabopolassar was not able to enjoy his success for long, dying in 604 BCE, only one year after the victory at Karchemish. He was succeeded by his son, who took the name Nebuchadnezzar II, after the unrelated 12th century BCE native Akkadian-Babylonian king Nebuchadnezzar I, indicating the extent to which the migrant Chaldeans had become infused with native Mesopotamian culture.
Nebuchadnezzar II and his allies may well have been forced to deal with remnants of Assyrian resistance based in and around Dur-Katlimmu, as Assyrian imperial records continue to be dated in this region between 604 and 599 BCE. In addition, the Egyptians remained in the region, possibly in an attempt to aid their former Assyrian masters and to carve out an empire of their own.
Nebuchadnezzar II was to prove himself to be the greatest of the Chaldean rulers, rivaling another non-native ruler, the 18th century BCE Amorite king Hammurabi, as the greatest king of Babylon. He was a patron of the cities and a spectacular builder, rebuilding all of Babylonia's major cities on a lavish scale. His building activity at Babylon, expanding on the earlier major and impressive rebuilding of the Assyrian king Esarhaddon, helped to turn it into the immense and beautiful city of legend. Babylon covered more than three square miles, surrounded by moats and ringed by a double circuit of walls. The Euphrates flowed through the center of the city, spanned by a beautiful stone bridge. At the center of the city rose the giant ziggurat called Etemenanki, "House of the Frontier Between Heaven and Earth," which lay next to the Temple of Marduk. He is also believed by many historians to have built The Hanging Gardens of Babylon (although others believe these gardens were built much earlier by an Assyrian king in Nineveh) for his wife, a Median princess from the green mountains, so that she would feel at home.
A capable leader, Nebuchadnezzar II conducted successful military campaigns; cities like Tyre, Sidon and Damascus were subjugated. He also conducted numerous campaigns in Asia Minor against the Scythians, Cimmerians, and Lydians. Like their Assyrian relations, the Babylonians had to campaign yearly in order to control their colonies.
In 601 BCE, Nebuchadnezzar II was involved in a major but inconclusive battle against the Egyptians. In 599 BCE, he invaded Arabia and routed the Arabs at Qedar. In 597 BCE, he invaded Judah, captured Jerusalem, and deposed its king Jehoiachin. Egyptian and Babylonian armies fought each other for control of the Near East throughout much of Nebuchadnezzar's reign, and this encouraged king Zedekiah of Judah to revolt. After an eighteen-month siege, Jerusalem was captured in 587 BCE, thousands of Jews were deported to Babylon, and Solomon's Temple was razed to the ground.
Nebuchadnezzar successfully fought the Pharaohs Psammetichus II and Apries throughout his reign, and during the reign of Pharaoh Amasis in 568 BCE it is rumoured that he may have briefly invaded Egypt itself.
By 572, Nebuchadnezzar was in full control of Babylonia, Chaldea, Aramea (Syria), Phonecia, Israel, Judah, Philistia, Samarra, Jordan, northern Arabia, and parts of Asia Minor. Nebuchadnezzar died of illness in 562 BCE after a one-year co-reign with his son, Amel-Marduk, who was deposed in 560 BCE after a reign of only two years.
Neriglissar succeeded Amel-Marduk. It is unclear as to whether he was in fact an ethnic Chaldean or a native Babylonian nobleman, as he was not related by blood to Nabopolassar's descendants, having married into the ruling family. He conducted successful military campaigns against the Hellenic inhabitants of Cilicia, which had threatened Babylonian interests. Neriglissar reigned for only four years and was succeeded by the youthful Labashi-Marduk in 556 BCE. Again, it is unclear whether he was a Chaldean or a native Babylonian.
Labashi-Marduk reigned only for a matter of months, being deposed by Nabonidus in late 556 BCE. Nabonidus was certainly not a Chaldean, but an Assyrian from Harran, the last capital of Assyria, and proved to be the final native Mesopotamian king of Babylon. He and his son, the regent Belshazzar, were deposed by the Persians under Cyrus II in 539 BCE.
When the Babylonian Empire was absorbed into the Persian Achaemenid Empire, the name "Chaldean" lost its meaning in reference to a particular ethnicity or land, but lingered for a while as a term solely and explicitly used to describe a societal class of astrologers and astronomers in southern Mesopotamia. The original Chaldean tribe had long ago became Akkadianized, adopting Akkadian culture, religion, language and customs, blending into the majority native population, and eventually wholly disappearing as a distinct race of people, as had been the case with other preceding migrant peoples, such as the Amorites, Kassites, Suteans and Arameans of Babylonia.
The Persians considered this "Chaldean societal class" to be masters of reading and writing, and especially versed in all forms of incantation, sorcery, witchcraft, and the magical arts. They spoke of astrologists and astronomers as "Chaldeans", and it is used with this specific meaning in the Book of Daniel (Dan. i. 4, ii. 2 et seq.) and by classical writers, such as Strabo.
The disappearance of the Chaldeans as an ethnicity and Chaldea as a land is evidenced by the fact that the Persian rulers of the Achaemenid Empire (539–330 BCE) did not retain a province called "Chaldea", nor did they refer to "Chaldeans" as a race of people in their written annals. This is in contrast to Assyria, and for a time Babylonia also, where the Persians retained the names Assyria and Babylonia as designations for distinct geo-political entities within the Achaemenid Empire. In the case of the Assyrians in particular, Achaemenid records show Assyrians holding important positions within the empire, particularly with regards to military and civil administration.
The terms Chaldee and Chaldean were henceforth found in Hebraic and Biblical sources dating from the 6th and 5th centuries BCE, and referring specifically to the period of the Chaldean Dynasty of Babylon.
This absence of Chaldeans from the historical record continues throughout the Macedonian Empire, Seleucid Empire, Parthian Empire, Roman Empire, Sassanid Empire, Byzantine Empire and after the Arab Islamic conquest and Mongol Empire.
The fame of the Chaldeans was still solid at the time of Cicero (106–43 BC), who in one of his speeches mentions "Chaldean astrologers", and speaks of them more than once in his "De divinatione". Other classical Latin writers who speak of them as distinguished for their knowledge of astronomy and astrology are Pliny, Valerius Maximus, Aulus Gellius, Cato, Lucretius, Juvenal. Horace in his "Carpe diem" ode speaks of the "Babylonian calculations" ("Babylonii numeri"), the horoscopes of astrologers consulted regarding the future. 
The language that today is usually called Aramaic was called Chaldean by Jerome This usage continued down the centuries: it was still the normal terminology in the nineteenth century. Accordingly, in the earliest recorded Western mentions of the Christians of what is now Iraq and nearby countries the term is used with reference to their language. In 1220/1 Jacques de Vitry wrote that "they denied that Mary was the Mother of God and claimed that Christ existed in two persons. They consecrated leavened bread and used the 'Chaldean' (Syriac) language". In the fifteenth century the term "Chaldeans" was first applied specifically to East Syrians living in Cyprus who entered a short-lived union with Rome, and no longer merely with reference to their language.

</doc>
<doc id="6600" url="https://en.wikipedia.org/wiki?curid=6600" title="Currying">
Currying

In mathematics and computer science, currying is the technique of converting a function that takes multiple arguments into a sequence of functions that each take a single argument. For example, currying a function formula_1 that takes three arguments creates three functions:
formula_2
Or more abstractly, a function that takes two arguments, one from formula_3 and one from formula_4, and produces outputs in formula_5 by currying is translated into a function that takes a single argument from formula_3 and produces as outputs "functions" from formula_4 to formula_8 Currying is related to, but not the same as, partial application.
Currying is useful in both practical and theoretical settings. In functional programming languages, and many others, it provides a way of automatically managing how arguments are passed to functions and exceptions. In theoretical computer science, it provides a way to study functions with multiple arguments in simpler theoretical models which provide only one argument. The most general setting for the strict notion of currying and uncurrying is in the closed monoidal categories, which underpins a vast generalization of the Curry–Howard correspondence of proofs and programs to a correspondence with many other structures, including quantum mechanics, cobordisms and string theory. It was introduced by Gottlob Frege, developed by Moses Schönfinkel,
and further developed by Haskell Curry.
Uncurrying is the dual transformation to currying, and can be seen as a form of defunctionalization. It takes a function formula_1 whose return value is another function formula_10, and yields a new function formula_11 that takes as parameters the arguments for both formula_1 and formula_10, and returns, as a result, the application of formula_1 and subsequently, formula_10, to those arguments. The process can be iterated.
Currying provides a way for working with functions that take multiple arguments, and using them in frameworks where functions might take only one argument. For example, some analytical techniques can only be applied to functions with a single argument. Practical functions frequently take more arguments than this. Frege showed that it was sufficient to provide solutions for the single argument case, as it was possible to transform a function with multiple arguments into a chain of single-argument functions instead. This transformation is the process now known as currying. All "ordinary" functions that might typically be encountered in mathematical analysis or in computer programming can be curried. However, there are categories in which currying is not possible; the most general categories which allow currying are the closed monoidal categories.
Some programming languages almost always use curried functions to achieve multiple arguments; notable examples are ML and Haskell, where in both cases all functions have exactly one argument. This property is inherited from lambda calculus, where multi-argument functions are usually represented in curried form.
Currying is related to, but not the same as partial application. In practice, the programming technique of closures can be used to perform partial application and a kind of currying, by hiding arguments in an environment that travels with the curried function.
Suppose we have a function formula_16 which takes two real arguments and outputs real numbers, and it is defined by formula_17. Currying translates this into a function formula_18 which takes a single real argument and outputs functions from formula_19 to formula_19. In symbols, formula_21, where formula_22denotes the set of all functions that take a single real argument and produce real outputs. For every real number formula_23, define the function formula_24 by formula_25, and then define the function formula_21 by formula_27. So for instance, formula_28 is the function that sends its real argument formula_29 to the output formula_30, or formula_31. We see that in general 
so that the original function formula_1 and its currying formula_18 convey exactly the same information. In this situation, we also write 
This also works for functions with more than two arguments. If formula_1 were a function of three arguments formula_37, its currying formula_18 would have the property
The name "currying", coined by Christopher Strachey in 1967, is a reference to logician Haskell Curry. The alternative name "Schönfinkelisation" has been proposed as a reference to Moses Schönfinkel. In the mathematical context, the principle can be traced back to work in 1893 by Frege.
Currying is most easily understood by starting with an informal definition, which can then be molded to fit many different domains. First, there is some notation to be established. The notation formula_40 denotes all functions from formula_3 to formula_4. If formula_1 is such a function, we write formula_44. Let formula_45 denote the ordered pairs of the elements of formula_3 and formula_4 respectively, that is, the Cartesian product of formula_3 and formula_4. Here, formula_3 and formula_4 may be sets, or they may be types, or they may be other kinds of objects, as explored below. 
Given a function
currying constructs a new function
That is, formula_54 takes an argument from formula_3 and returns a function that maps formula_4 to formula_57. It is defined by
for formula_23 from formula_3 and formula_29 from formula_4. We then also write
Uncurrying is the reverse transformation, and is most easily understood in terms of its right adjoint, the function formula_64
In set theory, the notation formula_65 is used to denote the set of functions from the set formula_3 to the set formula_4. Currying is the natural bijection between the set formula_68 of functions from formula_69 to formula_70, and the set formula_71 of functions from formula_72 to the set of functions from formula_73 to formula_70. In symbols:
Indeed, it is this natural bijection that justifies the exponential notation for the set of functions. As is the case in all instances of currying, the formula above describes an adjoint pair of functors: for every fixed set formula_73, the functor formula_77 is left adjoint to the functor formula_78.
In the category of sets, the object formula_65 is called the exponential object.
In the theory of function spaces, such as in functional analysis or homotopy theory, one is commonly interested in continuous functions between topological spaces. One writes formula_80 (the Hom functor) for the set of "all" functions from formula_3 to formula_4, and uses the notation formula_65 to denote the subset of continuous functions. Here, formula_84 is the bijection
while uncurrying is the inverse map. If the set formula_65 of continuous functions from formula_3 to formula_4 is given the compact-open topology, and if the space formula_4 is locally compact Hausdorff, then
is a homeomorphism. This is also the case when formula_3, formula_4 and formula_65 are compactly generated, although there are more cases.
One useful corollary is that a function is continuous if and only if its curried form is continuous. Another important result is that the application map, usually called "evaluation" in this context, is continuous (note that eval is a strictly different concept in computer science.) That is,
formula_94
is continuous when formula_65 is compact-open and formula_4 locally compact Hausdorff. These two results are central for establishing the continuity of homotopy, i.e. when formula_3 is the unit interval formula_98, so that formula_99 can the thought of as either a homotopy of two functions from formula_4 to formula_57, or, equivalently, a single (continuous) path in formula_102.
In algebraic topology, currying serves as an example of Eckmann–Hilton duality, and, as such, plays an important role in a variety of different settings. For example, loop space is adjoint to reduced suspensions; this is commonly written as
where formula_104 is the set of homotopy classes of maps formula_105, and formula_106 is the suspension of "A", and formula_107 is the loop space of "A". In essence, the suspension formula_108 can be seen as the cartesian product of formula_3 with the unit interval, modulo an equivalence relation to turn the interval into a loop. The curried form then maps the space formula_3 to the space of functions from loops into formula_57, that is, from formula_3 into formula_113. Then formula_84 is the adjoint functor that maps suspensions to loop spaces, and uncurrying is the dual.
The duality between the mapping cone and the mapping fiber (cofibration and fibration) can be understood as a form of currying, which in turn leads to the duality of the long exact and coexact Puppe sequences.
In homological algebra, the relationship between currying and uncurrying is known as tensor-hom adjunction. Here, an interesting twist arises: the Hom functor and the tensor product functor might not lift to an exact sequence; this leads to the definition of the Ext functor and the Tor functor.
In order theory, that is, the theory of lattices of partially ordered sets, formula_84 is a continuous function when the lattice is given the Scott topology. Scott-continuous functions were first investigated in the attempt to provide a semantics for lambda calculus (as ordinary set theory is inadequate to do this). More generally, Scott-continuous functions are now studied in domain theory, which encompasses the study of denotational semantics of computer algorithms. Note that the Scott topology is quite different than many common topologies one might encounter in the category of topological spaces; the Scott topology is typically finer, and is not sober.
The notion of continuity makes its appearance in homotopy type theory, where, roughly speaking, two computer programs can be considered to be homotopic, i.e. compute the same results, if they can be "continuously" refactored from one to the other.
In theoretical computer science, currying provides a way to study functions with multiple arguments in very simple theoretical models, such as the lambda calculus, in which functions only take a single argument. Consider a function formula_116 taking two arguments, and having the type formula_117, which should be understood to mean that "x" must have the type formula_3, "y" must have the type formula_4, and the function itself returns the type formula_57. The curried form of "f" is defined as
where formula_122 is the abstractor of lambda calculus. Since curry takes, as input, functions with the type formula_123, one concludes that the type of curry itself is
The → operator is often considered right-associative, so the curried function type formula_125 is often written as formula_126. Conversely, function application is considered to be left-associative, so that formula_127 is equivalent to
That is, the parenthesis are not required to disambiguate the order of the application.
Curried functions may be used in any programming language that supports closures; however, uncurried functions are generally preferred for efficiency reasons, since the overhead of partial application and closure creation can then be avoided for most function calls.
In type theory, the general idea of a type system in computer science is formalized into a specific algebra of types. For example, when writing formula_44, the intent is that formula_3 and formula_4 are types, while the arrow formula_132 is a type constructor, specifically, the function type or arrow type. Similarly, the Cartesian product formula_45 of types is constructed by the product type constructor formula_134.
The type-theoretical approach is expressed in programming languages such as ML and the languages derived from and inspired by it: CaML, Haskell and F#.
The type-theoretical approach provides a natural complement to the language of category theory, as discussed below. This is because categories, and specifically, monoidal categories, have an internal language, with simply-typed lambda calculus being the most prominent example of such a language. It is important in this context, because it can be built from a single type constructor, the arrow type. Currying then endows the language with a natural product type. The correspondence between objects in categories and types then allows programming languages to be re-interpreted as logics (via Curry–Howard correspondence), and as other types of mathematical systems, as explored further, below.
Under the Curry–Howard correspondence, the existence of currying and uncurrying is equivalent to the logical theorem formula_135, as tuples (product type) corresponds to conjunction in logic, and function type corresponds to implication.
The exponential object formula_136 in the category of Heyting algebras is normally written as material implication formula_137. Distributive Heyting algebras are Boolean algebras, and the exponential object has the explicit form formula_138, thus making it clear that the exponential object really is material implication.
The above notions of currying and uncurrying find their most general, abstract statement in category theory. Currying is a universal property of an exponential object, and gives rise to an adjunction in cartesian closed categories. That is, there is a natural isomorphism between the morphisms from a binary product formula_52 and the morphisms to an exponential object formula_140. 
This generalizes to a broader result in closed monoidal categories: Currying is the statement that the tensor product and the internal Hom are adjoint functors; that is, for every object formula_72 there is a natural isomorphism: 
Here, "Hom" denotes the (external) Hom-functor of all morphisms in the category, while formula_143 denotes the internal hom functor in the closed monoidal category. For the category of sets, the two are the same. When the product is the cartesian product, then the internal hom formula_143 becomes the exponential object formula_145.
Currying can break down in one of two ways. One is if a category is not closed, and thus lacks an internal hom functor (possibly because there is more than one choice for such a functor). Another ways is if it is not monoidal, and thus lacks a product (that is, lacks a way of writing down pairs of objects). Categories that do have both products and internal homs are exactly the closed monoidal categories.
The setting of cartesian closed categories is sufficient for the discussion of classical logic; the more general setting of closed monoidal categories is suitable for quantum computation.
The difference between these two is that the product for cartesian categories (such as the category of sets, complete partial orders or Heyting algebras) is just the Cartesian product; it is interpreted as an ordered pair of items (or a list). Simply typed lambda calculus is the internal language of cartesian closed categories; and it is for this reason that pairs and lists are the primary types in the type theory of LISP, scheme and many functional programming languages.
By contrast, the product for monoidal categories (such as Hilbert space and the vector spaces of functional analysis) is the tensor product. The internal language of such categories is linear logic, a form of quantum logic; the corresponding type system is the linear type system. Such categories are suitable for describing entangled quantum states, and, more generally, allow a vast generalization of the Curry–Howard correspondence to quantum mechanics, to cobordisms in algebraic topology, and to string theory. The linear type system, and linear logic are useful for describing synchronization primitives, such as mutual exclusion locks, and the operation of vending machines.
Currying and partial function application are often conflated. One of the significant differences between the two is that a call to a partially applied function returns the result right away, not another function down the currying chain; this distinction can be illustrated clearly for functions whose arity is greater than two.
Given a function of type formula_146, currying produces formula_147. That is, while an evaluation of the first function might be represented as formula_148, evaluation of the curried function would be represented as formula_149, applying each argument in turn to a single-argument function returned by the previous invocation. Note that after calling formula_150, we are left with a function that takes a single argument and returns another function, not a function that takes two arguments.
In contrast, partial function application refers to the process of fixing a number of arguments to a function, producing another function of smaller arity. Given the definition of formula_1 above, we might fix (or 'bind') the first argument, producing a function of type formula_152. Evaluation of this function might be represented as formula_153. Note that the result of partial function application in this case is a function that takes two arguments.
Intuitively, partial function application says "if you fix the first argument of the function, you get a function of the remaining arguments". For example, if function "div" stands for the division operation "x"/"y", then "div" with the parameter "x" fixed at 1 (i.e., "div" 1) is another function: the same as the function "inv" that returns the multiplicative inverse of its argument, defined by "inv"("y") = 1/"y".
The practical motivation for partial application is that very often the functions obtained by supplying some but not all of the arguments to a function are useful; for example, many languages have a function or operator similar to codice_1. Partial application makes it easy to define these functions, for example by creating a function that represents the addition operator with 1 bound as its first argument.
Partial application can be seen as evaluating a curried function at a fixed point, e.g. given formula_146 and formula_155 then formula_156 or simply formula_157 where formula_158 curries f's first parameter. 
Thus, partial application is reduced to a curried function at a fixed point. Further, a curried function at a fixed point is (trivially), a partial application. For further evidence, note that, given any function formula_116, a function formula_160 may be defined such that formula_161. Thus, any partial application may be reduced to a single curry operation. As such, curry is more suitably defined as an operation which, in many theoretical cases, is often applied recursively, but which is theoretically indistinguishable (when considered as an operation) from a partial application.
So, a partial application can be defined as the objective result of a single application of the curry operator on some ordering of the inputs of some function.

</doc>
<doc id="6601" url="https://en.wikipedia.org/wiki?curid=6601" title="Cyrus">
Cyrus

Cyrus (Persian: کوروش) is a male given name. It is the given name of a number of Persian kings. Most notably it refers to Cyrus the Great. Cyrus is also the name of Cyrus I of Anshan (ca. 650 BC), King of Persia the grandfather of Cyrus the Great; and Cyrus the Younger (died 401 BC), brother to the Persian King Artaxerxes II of Persia.
Cyrus, as a word in English, is the Latinized form of the Greek Κῦρος, "Kȳros", from Old Persian "Kūruš". According to the inscriptions the name is reflected in Elamite "Kuraš", Babylonian "Ku(r)-raš/-ra-áš" and Imperial Aramaic "kwrš". The modern Persian form of the name is Kourosh.
The etymology of Cyrus has been and continues to be a topic of discussion amongst historians, linguists, and scholars of Iranology. The Old Persian name "kuruš" has been interpreted in various forms from "the Sun", "like Sun", "young", "hero" to "humiliator of the enemy in verbal contest" and the Elamite "kuraš" has been translated as one "who bestows care".
The name has appeared on many monuments and inscriptions in Old Persian. There is also the record of a small inscription in Morghab (southwestern Iran) on which there is the sentence ("adam kūruš xšāyaƟiya haxāmanišiya") in Old Persian meaning ("I am Cyrus the Achaemenian King"). After a questionable proposal by the German linguist F. H. Weissbach that Darius the Great was the first to inscribe in Persian, it had previously been concluded by some scholars that the inscription in Morghab refers to Cyrus the Younger. This proposal was the result of a false interpretation of a passage in paragraph 70 of Behistun inscription by Darius the Great. Based on many arguments, the accepted theory among modern scholars is that the inscription does belong to Cyrus the Great.
There are interpretations of name of Cyrus by classical authors identifying with or referring to the Persian word for “Sun”. The Historian Plutarch (46 - 120) states that "the sun, which, in the Persian language, is called Cyrus". Also the Physician Ctesias who served in the court of the Persian king Artaxerxes II of Persia writes in his book "Persica" as summarized by Photios that the name Cyrus is from Persian word "Khur" (the sun). These are, however, not accepted by modern scholars.
Regarding the etymology of Old Persian "kuruš", linguists have proposed various etymologies based on Iranian languages as well as non-Indo-European ones. According to Tavernier, the name "kuraš", attested in Elamite texts, is likely "the original form" as there is no Elamite or Babylonian spelling "ku-ru-uš" in the transcriptions of Old Persian "ku-u-r(u)-u-š". That is, according to Tavernier, "kuraš" is an Elamite name and means "to bestow care". Others, such as Schmitt, Hoffmann maintain that the Persian "Kuruš", which according to Skalmowsky, may be connected to (or a borrowing from) the IE "Kúru-" from Old Indic can give an etymology of the Elamite "kuraš". In this regard the Old Persian "kuruš" is considered with the following etymologies: One proposal is discussed by the linguist Janos Harmatta that refers to the common Iranian root "kur-" (be born) of many words in Old, middle, and new Iranian languages (e.g. Kurdish). Accordingly, the name Kūruš means "young, youth...". Other Iranian etymologies have been proposed. The Indian proposal of Skalmowsky goes down to "to do, accomplish". Another theory is the suggestion of Karl Hoffmann that "kuruš" goes down to a "-ru" derivation from the IE root "*(s)kau" meaning "to humiliate" and accordingly "kuruš" (hence "Cyrus") means ""humiliator" (of the enemy in verbal contest)".
People and fictional characters named Cyrus include:

</doc>
<doc id="6603" url="https://en.wikipedia.org/wiki?curid=6603" title="Case">
Case

Case or CASE may refer to:

</doc>
<doc id="6604" url="https://en.wikipedia.org/wiki?curid=6604" title="Rendering (computer graphics)">
Rendering (computer graphics)

Rendering or image synthesis is the process of generating a photorealistic or non-photorealistic image from a 2D or 3D model by means of a computer program. The resulting image is referred to as the render. Multiple models can be defined in a "scene file" containing objects in a strictly defined language or data structure. The scene file contains geometry, viewpoint, texture, lighting, and shading information describing the virtual scene. The data contained in the scene file is then passed to a rendering program to be processed and output to a digital image or raster graphics image file. The term "rendering" is analogous to the concept of an artist's impression of a scene. The term "rendering" is also used to describe the process of calculating effects in a video editing program to produce the final video output.
Rendering is one of the major sub-topics of 3D computer graphics, and in practice it is always connected to the others. It is the last major step in the graphics pipeline, giving models and animation their final appearance. With the increasing sophistication of computer graphics since the 1970s, it has become a more distinct subject.
Rendering has uses in architecture, video games, simulators, movie and TV visual effects, and design visualization, each employing a different balance of features and techniques. A wide variety of renderers are available for use. Some are integrated into larger modeling and animation packages, some are stand-alone, and some are free open-source projects. On the inside, a renderer is a carefully engineered program based on multiple disciplines, including light physics, visual perception, mathematics, and software development.
Though the technical details of rendering methods vary, the general challenges to overcome in producing a 2D image on a screen from a 3D representation stored in a scene file are handled by the graphics pipeline in a rendering device such as a GPU. A GPU is a purpose-built device that assists a CPU in performing complex rendering calculations. If a scene is to look relatively realistic and predictable under virtual lighting, the rendering software must solve the rendering equation. The rendering equation doesn't account for all lighting phenomena, but instead acts as a general lighting model for computer-generated imagery.
In the case of 3D graphics, scenes can be pre-rendered or generated in realtime. Pre-rendering is a slow, computationally intensive process that is typically used for movie creation, where scenes can be generated ahead of time, while real-time rendering is often done for 3D video games and other applications that must dynamically create scenes. 3D hardware accelerators can improve realtime rendering performance.
When the pre-image (a wireframe sketch usually) is complete, rendering is used, which adds in bitmap textures or procedural textures, lights, bump mapping and relative position to other objects. The result is a completed image the consumer or intended viewer sees.
For movie animations, several images (frames) must be rendered, and stitched together in a program capable of making an animation of this sort. Most 3D image editing programs can do this.
A rendered image can be understood in terms of a number of visible features. Rendering research and development has been largely motivated by finding ways to simulate these efficiently. Some relate directly to particular algorithms and techniques, while others are produced together.
Many rendering have been researched, and software used for rendering may employ a number of different techniques to obtain a final image.
Tracing every particle of light in a scene is nearly always completely impractical and would take a stupendous amount of time. Even tracing a portion large enough to produce an image takes an inordinate amount of time if the sampling is not intelligently restricted.
Therefore, a few loose families of more-efficient light transport modelling techniques have emerged:
The fourth type of light transport technique, radiosity is not usually implemented as a rendering technique, but instead calculates the passage of light as it leaves the light source and illuminates surfaces. These surfaces are usually rendered to the display using one of the other three techniques.
Most advanced software combines two or more of the techniques to obtain good-enough results at reasonable cost.
Another distinction is between image order algorithms, which iterate over pixels of the image plane, and object order algorithms, which iterate over objects in the scene. Generally object order is more efficient, as there are usually fewer objects in a scene than pixels.
A high-level representation of an image necessarily contains elements in a different domain from pixels. These elements are referred to as s. In a schematic drawing, for instance, line segments and curves might be primitives. In a graphical user interface, windows and buttons might be the primitives. In rendering of 3D models, triangles and polygons in space might be primitives.
If a pixel-by-pixel (image order) approach to rendering is impractical or too slow for some task, then a primitive-by-primitive (object order) approach to rendering may prove useful. Here, one loops through each of the primitives, determines which pixels in the image it affects, and modifies those pixels accordingly. This is called rasterization, and is the rendering method used by all current graphics cards.
Rasterization is frequently faster than pixel-by-pixel rendering. First, large areas of the image may be empty of primitives; rasterization will ignore these areas, but pixel-by-pixel rendering must pass through them. Second, rasterization can improve cache coherency and reduce redundant work by taking advantage of the fact that the pixels occupied by a single primitive tend to be contiguous in the image. For these reasons, rasterization is usually the approach of choice when interactive rendering is required; however, the pixel-by-pixel approach can often produce higher-quality images and is more versatile because it does not depend on as many assumptions about the image as rasterization.
The older form of rasterization is characterized by rendering an entire face (primitive) as a single color. Alternatively, rasterization can be done in a more complicated manner by first rendering the vertices of a face and then rendering the pixels of that face as a blending of the vertex colors. This version of rasterization has overtaken the old method as it allows the graphics to flow without complicated textures (a rasterized image when used face by face tends to have a very block-like effect if not covered in complex textures; the faces are not smooth because there is no gradual color change from one primitive to the next). This newer method of rasterization utilizes the graphics card's more taxing shading functions and still achieves better performance because the simpler textures stored in memory use less space. Sometimes designers will use one rasterization method on some faces and the other method on others based on the angle at which that face meets other joined faces, thus increasing speed and not hurting the overall effect.
In ray casting the geometry which has been modeled is parsed pixel by pixel, line by line, from the point of view outward, as if casting rays out from the point of view. Where an object is intersected, the color value at the point may be evaluated using several methods. In the simplest, the color value of the object at the point of intersection becomes the value of that pixel. The color may be determined from a texture-map. A more sophisticated method is to modify the colour value by an illumination factor, but without calculating the relationship to a simulated light source. To reduce artifacts, a number of rays in slightly different directions may be averaged.
Ray casting involves calculating the "view direction" (from camera position), and incrementally following along that "ray cast" through "solid 3d objects" in the scene, while accumulating the resulting value from each point in 3D space. This is related and similar to "ray tracing" except that the raycast is usually not "bounced" off surfaces (where the "ray tracing" indicates that it is tracing out the lights path including bounces). "Ray casting" implies that the light ray is following a straight path (which may include travelling through semi-transparent objects). The ray cast is a vector that can originate from the camera or from the scene endpoint ("back to front", or "front to back"). Sometimes the final light value is derived from a "transfer function" and sometimes it's used directly.
Rough simulations of optical properties may be additionally employed: a simple calculation of the ray from the object to the point of view is made. Another calculation is made of the angle of incidence of light rays from the light source(s), and from these as well as the specified intensities of the light sources, the value of the pixel is calculated. Another simulation uses illumination plotted from a radiosity algorithm, or a combination of these two.
Ray tracing aims to simulate the natural flow of light, interpreted as particles. Often, ray tracing methods are utilized to approximate the solution to the rendering equation by applying Monte Carlo methods to it. Some of the most used methods are path tracing, bidirectional path tracing, or Metropolis light transport, but also semi realistic methods are in use, like Whitted Style Ray Tracing, or hybrids. While most implementations let light propagate on straight lines, applications exist to simulate relativistic spacetime effects.
In a final, production quality rendering of a ray traced work, multiple rays are generally shot for each pixel, and traced not just to the first object of intersection, but rather, through a number of sequential 'bounces', using the known laws of optics such as "angle of incidence equals angle of reflection" and more advanced laws that deal with refraction and surface roughness.
Once the ray either encounters a light source, or more probably once a set limiting number of bounces has been evaluated, then the surface illumination at that final point is evaluated using techniques described above, and the changes along the way through the various bounces evaluated to estimate a value observed at the point of view. This is all repeated for each sample, for each pixel.
In distribution ray tracing, at each point of intersection, multiple rays may be spawned. In path tracing, however, only a single ray or none is fired at each intersection, utilizing the statistical nature of Monte Carlo experiments.
As a brute-force method, ray tracing has been too slow to consider for real-time, and until recently too slow even to consider for short films of any degree of quality, although it has been used for special effects sequences, and in advertising, where a short portion of high quality (perhaps even photorealistic) footage is required.
However, efforts at optimizing to reduce the number of calculations needed in portions of a work where detail is not high or does not depend on ray tracing features have led to a realistic possibility of wider use of ray tracing. There is now some hardware accelerated ray tracing equipment, at least in prototype phase, and some game demos which show use of real-time software or hardware ray tracing.
Radiosity is a method which attempts to simulate the way in which directly illuminated surfaces act as indirect light sources that illuminate other surfaces. This produces more realistic shading and seems to better capture the 'ambience' of an indoor scene. A classic example is the way that shadows 'hug' the corners of rooms.
The optical basis of the simulation is that some diffused light from a given point on a given surface is reflected in a large spectrum of directions and illuminates the area around it.
The simulation technique may vary in complexity. Many renderings have a very rough estimate of radiosity, simply illuminating an entire scene very slightly with a factor known as ambiance. However, when advanced radiosity estimation is coupled with a high quality ray tracing algorithm, images may exhibit convincing realism, particularly for indoor scenes.
In advanced radiosity simulation, recursive, finite-element algorithms 'bounce' light back and forth between surfaces in the model, until some recursion limit is reached. The colouring of one surface in this way influences the colouring of a neighbouring surface, and vice versa. The resulting values of illumination throughout the model (sometimes including for empty spaces) are stored and used as additional inputs when performing calculations in a ray-casting or ray-tracing model.
Due to the iterative/recursive nature of the technique, complex objects are particularly slow to emulate. Prior to the standardization of rapid radiosity calculation, some digital artists used a technique referred to loosely as false radiosity by darkening areas of texture maps corresponding to corners, joints and recesses, and applying them via self-illumination or diffuse mapping for scanline rendering. Even now, advanced radiosity calculations may be reserved for calculating the ambiance of the room, from the light reflecting off walls, floor and ceiling, without examining the contribution that complex objects make to the radiosity—or complex objects may be replaced in the radiosity calculation with simpler objects of similar size and texture.
Radiosity calculations are viewpoint independent which increases the computations involved, but makes them useful for all viewpoints. If there is little rearrangement of radiosity objects in the scene, the same radiosity data may be reused for a number of frames, making radiosity an effective way to improve on the flatness of ray casting, without seriously impacting the overall rendering time-per-frame.
Because of this, radiosity is a prime component of leading real-time rendering methods, and has been used from beginning-to-end to create a large number of well-known recent feature-length animated 3D-cartoon films.
One problem that any rendering system must deal with, no matter which approach it takes, is the sampling problem. Essentially, the rendering process tries to depict a continuous function from image space to colors by using a finite number of pixels. As a consequence of the Nyquist–Shannon sampling theorem (or Kotelnikov theorem), any spatial waveform that can be displayed must consist of at least two pixels, which is proportional to image resolution. In simpler terms, this expresses the idea that an image cannot display details, peaks or troughs in color or intensity, that are smaller than one pixel.
If a naive rendering algorithm is used without any filtering, high frequencies in the image function will cause ugly aliasing to be present in the final image. Aliasing typically manifests itself as jaggies, or jagged edges on objects where the pixel grid is visible. In order to remove aliasing, all rendering algorithms (if they are to produce good-looking images) must use some kind of low-pass filter on the image function to remove high frequencies, a process called antialiasing.
Due to the large number of calculations, a work in progress is usually only rendered in detail appropriate to the portion of the work being developed at a given time, so in the initial stages of modeling, wireframe and ray casting may be used, even where the target output is ray tracing with radiosity. It is also common to render only parts of the scene at high detail, and to remove objects that are not important to what is currently being developed.
For real-time, it is appropriate to simplify one or more common approximations, and tune to the exact parameters of the scenery in question, which is also tuned to the agreed parameters to get the most 'bang for the buck'.
The implementation of a realistic renderer always has some basic element of physical simulation or emulation — some computation which resembles or abstracts a real physical process.
The term "physically based" indicates the use of physical models and approximations that are more general and widely accepted outside rendering. A particular set of related techniques have gradually become established in the rendering community.
The basic concepts are moderately straightforward, but intractable to calculate; and a single elegant algorithm or approach has been elusive for more general purpose renderers. In order to meet demands of robustness, accuracy and practicality, an implementation will be a complex combination of different techniques.
Rendering research is concerned with both the adaptation of scientific models and their efficient application.
This is the key academic/theoretical concept in rendering. It serves as the most abstract formal expression of the non-perceptual aspect of rendering. All more complete algorithms can be seen as solutions to particular formulations of this equation.
Meaning: at a particular position and direction, the outgoing light (L) is the sum of the emitted light (L) and the reflected light. The reflected light being the sum of the incoming light (L) from all directions, multiplied by the surface reflection and incoming angle. By connecting outward light to inward light, via an interaction point, this equation stands for the whole 'light transport' — all the movement of light — in a scene.
The bidirectional reflectance distribution function (BRDF) expresses a simple model of light interaction with a surface as follows:
Light interaction is often approximated by the even simpler models: diffuse reflection and specular reflection, although both can ALSO be BRDFs.
Rendering is practically exclusively concerned with the particle aspect of light physics — known as geometrical optics. Treating light, at its basic level, as particles bouncing around is a simplification, but appropriate: the wave aspects of light are negligible in most scenes, and are significantly more difficult to simulate. Notable wave aspect phenomena include diffraction (as seen in the colours of CDs and DVDs) and polarisation (as seen in LCDs). Both types of effect, if needed, are made by appearance-oriented adjustment of the reflection model.
Though it receives less attention, an understanding of human visual perception is valuable to rendering. This is mainly because image displays and human perception have restricted ranges. A renderer can simulate an almost infinite range of light brightness and color, but current displays — movie screen, computer monitor, etc. — cannot handle so much, and something must be discarded or compressed. Human perception also has limits, and so does not need to be given large-range images to create realism. This can help solve the problem of fitting images into displays, and, furthermore, suggest what short-cuts could be used in the rendering simulation, since certain subtleties won't be noticeable. This related subject is tone mapping.
Mathematics used in rendering includes: linear algebra, calculus, numerical mathematics, signal processing, and Monte Carlo methods.
Rendering for movies often takes place on a network of tightly connected computers known as a render farm.
The current state of the art in 3-D image description for movie creation is the Mental Ray scene description language designed at Mental Images and RenderMan Shading Language designed at Pixar (compare with simpler 3D fileformats such as VRML or APIs such as OpenGL and DirectX tailored for 3D hardware accelerators).
Other renderers (including proprietary ones) can and are sometimes used, but most other renderers tend to miss one or more of the often needed features like good texture filtering, texture caching, programmable shaders, highend geometry types like hair, subdivision or nurbs surfaces with tesselation on demand, geometry caching, raytracing with geometry caching, high quality shadow mapping, speed or patent-free implementations. Other highly sought features these days may include interactive photorealistic rendering (IPR) and hardware rendering/shading.

</doc>
<doc id="6606" url="https://en.wikipedia.org/wiki?curid=6606" title="Cartridge">
Cartridge

Cartridge may refer to:

</doc>
<doc id="6607" url="https://en.wikipedia.org/wiki?curid=6607" title="Chaosium">
Chaosium

Chaosium Inc. is a publisher of tabletop role-playing games established by Greg Stafford in 1975. Its first product was "White Bear and Red Moon" (later renamed "Dragon Pass"), a board game set in Stafford's fantasy gaming world of Glorantha. Chaosium's major titles include "Call of Cthulhu" based on the horror fiction stories of H. P. Lovecraft", RuneQuest Glorantha", and "Pendragon", based on Thomas Mallory's "Le Morte d'Arthur".
Many of Chaosium’s product lines are based upon literary sources. While Stafford himself has been described as "one of the most decorated game designers of all time" and "the grand shaman of gaming", many other notable game designers have written material for Chaosium. These include David Conyers, Matthew Costello, Larry DiTillio, David A. Hargrave, Rob Heinsoo, Keith Herber, Jennell Jaquays, Katharine Kerr, Reiner Knizia, Charlie Krank, Robin Laws, Penelope Love, Mark Morrison, Steve Perrin, Sandy Petersen, Ken Rolston, Ken St. Andre, Jonathan Tweet, and Lynn Willis, among others.
Greg Stafford founded "The Chaosium" in 1975 to publish his board game "White Bear and Red Moon". He derived the name partly from his home, which was near the Oakland Coliseum, combining "coliseum" with "chaos."
In 1978 Chaosium published Steve Perrin's roleplaying game "RuneQuest", set in Stafford's mythic fantasy setting Glorantha, following up with a second edition in 1980 and various supplements over the next six years.
In 1980, the company officially incorporated as Chaosium Inc. That year, Stafford and Lynn Willis simplified the RuneQuest rules into the 16-page Basic Role-Playing (BRP). These simulationist, skill-based generic rules formed the basis of many of Chaosium's later "d100" RPGs, most notably "Call of Cthulhu", first published in 1982.
Chaosium entered into a licensing agreement with Avalon Hill in 1983 to produce a third edition of "RuneQuest". Avalon Hill manufactured and marketed the game, while Chaosium was responsible for acquisitions, design, development and layout. Ken Rolston managed the line as "Rune Czar".
One of the first RPGs by a female lead designer was published by Chaosium: Kerie Campbell-Robson's 1986 release Hawkmoon.
In 1996 it was prematurely reported that Chaosium had secured the rights to publish a collectible card game based on the video game Doom.
In 1998, following the financial failure of the collectible card game "Mythos", Greg Stafford resigned as Chaosium president and left the company, along with Sandy Petersen (although they both remained shareholders). Chaosium effectively split up into various successor companies, each maintaining its focus on a few of the company's products. Stafford took the rights to his game setting Glorantha, setting up the company Issaries, Inc. to continue publishing this line (later licensing it to Moon Design Publications, along with the game HeroQuest).
Long-time employees and part-owners Charlie Krank and Lynn Willis remained at Chaosium as President and Editor-in-Chief respectively, continuing on with "Call of Cthulhu" as the main product line. Lynn Willis retired in 2008 due to poor health and died in 2013.
Problems and delays fulfilling the Kickstarters for the 7th edition of "Call of Cthulhu" led Stafford and Petersen to return to an active role at Chaosium in June 2015. Charlie Krank subsequently left the company.
Later that year at Gen Con 2015, Stafford and Petersen announced Moon Design Publications were now part of the Chaosium ownership, and the four principals of Moon Design (Rick Meints, Jeff Richard, Michael O'Brien and Neil Robinson) had become the new Chaosium management team. Chaosium once again became the licensed publisher for "RuneQuest", "HeroQuest" and other products related to Gloranthan universe, and continue to publish the "Call of Cthulhu" line. Stafford and Petersen remained as board members (Stafford as chair), and creative consultants to the company.
As part of its financial reorganization, the new management closed the company office and warehouse in Hayward, California, ending Chaosium's long association with the San Francisco Bay Area. The company is now based in Ann Arbor, Michigan and uses a fulfillment house model for distribution of product.
Delivery of the core rewards of the Call of Cthulhu 7th Edition Kickstarter finally commenced in April 2016. The new edition went on to win nine of the ten awards it was nominated for at the Gen Con 2017 ENnie Awards.
On April 2, 2019, Chaosium Inc. announced they acquired the rights to the 7th Sea product line (both Second Edition and Khitai Kickstarters) from John Wick, including back stock of books published so far. 
Chaosium began publishing a line of non-game books (primarily fiction) in 1993. Many titles are themed around H. P. Lovecraft's Cthulhu Mythos and related topics, although the first work published was Greg Stafford's fantasy work "King of Sartar", set in his mythic world Glorantha.
"Cassilda's Song", a 2015 anthology based on Robert W. Chambers's King in Yellow and written entirely by women, was nominated for two 2016 World Fantasy Awards.
In May, 2017, Chaosium appointed award-winning author and editor James Lowder as executive editor of fiction. Lowder had previously served as a consultant for Chaosium, helping the company and freelancers resolve payment and contract problems with past fiction projects.
Although not published by Chaosium, the ongoing Wild Cards series of superhero science fiction originated from a long-running "Superworld" campaign gamemastered by Game of Thrones author George R. R. Martin and his circle of fellow writers who played in his game.
Three magazines have been published by Chaosium to promote its products:

</doc>
<doc id="6610" url="https://en.wikipedia.org/wiki?curid=6610" title="Carolina Panthers">
Carolina Panthers

The Carolina Panthers are a professional American football team based in Charlotte, North Carolina. The Panthers compete in the National Football League (NFL), as a member club of the league's National Football Conference (NFC) South division. The team is headquartered in Bank of America Stadium in uptown Charlotte; the stadium also serves as the team's home field. They are one of the few NFL teams to own the stadium they play in, which is legally registered as Panthers Stadium, LLC. The Panthers are supported throughout the Carolinas; although the team has played its home games in Charlotte since 1996, they played their home games at Memorial Stadium in Clemson, South Carolina during its first season. The team hosts its annual training camp at Wofford College in Spartanburg, South Carolina.
The Panthers were announced as the league's 29th franchise in 1993, and began play in 1995 under original owner and founder Jerry Richardson. The Panthers played well in their first two years, finishing in 1995 (an all-time best for an NFL expansion team's first season) and 12–4 the following year, winning the NFC West before ultimately losing to the eventual Super Bowl champion Green Bay Packers in the NFC Championship Game. They did not have another winning season until 2003, when they won the NFC Championship Game and reached Super Bowl XXXVIII, losing 32–29 to the New England Patriots. After recording playoff appearances in 2005 and 2008, the team failed to record another playoff appearance until 2013, the first of three consecutive NFC South titles. After losing in the divisional round to the San Francisco 49ers in 2013 and the Seattle Seahawks in 2014, the Panthers returned to the Super Bowl in 2015, but lost to the Denver Broncos. The Panthers have reached the playoffs eight times, advancing to four NFC Championship Games and two Super Bowls. They have won six division titles, one in the NFC West and five in the NFC South.
The Carolina Panthers are legally registered as Panther Football, LLC. and are controlled by David Tepper, whose purchase of the team from founder Jerry Richardson was unanimously approved by league owners on May 22, 2018. The club is worth approximately US$2.3 billion, according to "Forbes".
On December 15, 1987, entrepreneur Jerry Richardson announced his bid for an NFL expansion franchise in the Carolinas. A North Carolina native, Richardson was a former wide receiver on the Baltimore Colts who had used his 1959 league championship bonus to co-found the Hardee's restaurant chain, later becoming president and CEO of TW Services. Richardson drew his inspiration to pursue an NFL franchise from George Shinn, who had made a successful bid for an expansion National Basketball Association (NBA) team in Charlotte, the Charlotte Hornets. Richardson founded Richardson Sports, a partnership consisting of himself, his family, and a number of businessmen from North and South Carolina were also recruited to be limited partners. Richardson looked at four potential locations for a stadium, ultimately choosing uptown Charlotte.
To highlight the demand for professional football in the Carolinas, Richardson Sports held preseason games around the area from 1989 to 1991. The first two games were held at Carter–Finley Stadium in Raleigh, North Carolina, and Kenan Memorial Stadium in Chapel Hill, North Carolina, while the third and final game was held at Williams-Brice Stadium in Columbia, South Carolina. The matchups were between existing NFL teams. In 1991, the group formally filed an application for the open expansion spot, and on October 26, 1993, the 28 NFL owners unanimously named the Carolina Panthers as the 29th member of the NFL.
The Panthers first competed in the 1995 NFL season; they were one of two expansion teams to begin play that year, the other being the Jacksonville Jaguars. The Panthers were put in the NFC West to increase the size of that division to five teams; there were already two other southeastern teams in the division, the Atlanta Falcons and the New Orleans Saints. Former Pittsburgh Steelers defensive coordinator Dom Capers was named the first head coach. The team finished its inaugural season , the best performance ever from a first-year expansion team. They performed even better in their second season, finishing with a record and winning the NFC West division, as well as securing a first-round bye. The Panthers beat the defending Super Bowl champions Dallas Cowboys in the divisional round before losing the NFC Championship Game to the eventual Super Bowl champions, the Green Bay Packers. The team managed only a finish in 1997 and slipped to in 1998, leading to Capers' dismissal as head coach.
The Panthers hired former San Francisco 49ers head coach George Seifert to replace Capers, and he led the team to an record in 1999. The team finished in 2000 and fell to in 2001, winning their first game but losing their last 15. This performance tied the NFL record for most losses in a single season and it broke the record held by the winless 1976 Buccaneers for most consecutive losses in a single season (both records have since been broken by the 2008 Lions), leading the Panthers to fire Seifert.
After the NFL's expansion to 32 teams in 2002, the Panthers were relocated from the NFC West to the newly created NFC South division. The Panthers' rivalries with the Falcons and Saints were maintained, and they would be joined by the Tampa Bay Buccaneers. New York Giants defensive coordinator John Fox was hired to replace Seifert and led the team to a finish in 2002. Although the team's defense gave up very few yards, ranking the second-best in the NFL in yards conceded, they were hindered by an offense that ranked as the second-worst in the league in yards gained. The Panthers improved to in the 2003 regular season, winning the NFC South and making it to Super Bowl XXXVIII before losing to the New England Patriots, 32–29, in what was immediately hailed by sportswriter Peter King as the "Greatest Super Bowl of all time". King felt the game "was a wonderful championship battle, full of everything that makes football dramatic, draining, enervating, maddening, fantastic, exciting" and praised, among other things, the unpredictability, coaching, and conclusion. The game is still viewed as one of the best Super Bowls of all time, and in the opinion of Charlotte-based NPR reporter Scott Jagow, the Panthers' Super Bowl appearance represented the arrival of Charlotte onto the national scene.
Following a start in 2004, the Panthers rebounded to win six of their last seven games despite losing 14 players for the season due to injury. They lost their last game to New Orleans, finishing the 2004 season at . Had they won the game, the Panthers would have made the playoffs. The team improved to in 2005, finishing second in the division behind Tampa Bay and clinching a playoff berth as a wild-card. In the first round of the playoffs, the Panthers went on the road to face the New York Giants, beating them 23–0 for the NFL's first playoff shutout against a home team since 1980. The following week, they beat Chicago 29–21 on the road, but lost key players Julius Peppers, a defensive end, and DeShaun Foster, a running back, who were both injured during the game. The Panthers were then defeated 34–14 by the Seattle Seahawks in the NFC Championship Game, ending their season. Although the Panthers went into the 2006 season as favorites to win the NFC South, they finished with a disappointing record. The team finished the 2007 season with a record after losing quarterback Jake Delhomme early in the season due to an elbow injury. In 2008, the Panthers rebounded with a regular season record, winning the NFC South and securing a first-round bye. They were eliminated in the divisional round of the playoffs, losing 33–13 to the eventual NFC Champion Arizona Cardinals after Delhomme turned the ball over six times. Delhomme's struggles carried over into the 2009 season, where he threw 18 interceptions in the first 11 games before breaking a finger in his throwing hand. The Panthers were at a record before Delhomme's season-ending injury, and his backup, Matt Moore, led the team to a finish to the season for an overall record.
In 2010, after releasing Delhomme in the offseason, the Panthers finished with a league-worst () record; their offense was the worst in the league. John Fox's contract expired after the season ended, and the team did not retain him or his staff.
The team hired Ron Rivera to replace Fox as head coach and drafted Auburn's Heisman Trophy-winning quarterback Cam Newton with the first overall pick in the 2011 NFL Draft. The Panthers opened the 2011 season , but finished with a record, and Newton was awarded the AP Offensive Rookie of the Year award after setting the NFL record for most rushing touchdowns from a quarterback (14) in a single season and becoming the first rookie NFL quarterback to throw for over 4,000 yards in a single season. He also was the first rookie quarterback to rush for over 500 yards in a single season. After strengthening the defense with future all-pro Luke Kuechly in the 2012 draft, the Panthers again opened the 2012 season poorly, losing five out of their first six games, leading longtime general manager Marty Hurney to be fired in response. The team slid to a record before winning five of their last six games, resulting in a record. This strong finish helped save Rivera's job. The Panthers had a winning season the following year, finishing with a record and winning their third NFC South title and another playoff bye, but they were beaten by the 49ers in the Divisional Round. In 2014, the Panthers opened the season with two wins, but after 12 games sat at due in part to a seven-game winless streak. A four-game winning streak to end the season secured the team their second consecutive NFC South championship and playoff berth, despite a losing record of . The Panthers defeated the Arizona Cardinals, 27–16, in the wild card round to advance to the divisional playoffs, where they lost to eventual NFC champion Seattle, 31–17. The 2015 season saw the Panthers start the season and finish the season , which tied for the best regular-season record in NFC history. The Panthers also secured their third consecutive NFC South championship, as well as their first overall top-seeded playoff berth. In the 2015–16 playoffs, the Panthers defeated the Seattle Seahawks in the NFC Divisional playoffs, 31–24, after shutting them out in the first half, 31–0, and the Arizona Cardinals, 49–15, in the NFC Championship Game to advance to Super Bowl 50, their first Super Bowl appearance since the 2003 season. The Panthers lost a defensive struggle to the AFC champion Denver Broncos, 24–10.
In the 2016 season, the Panthers regressed on their 15–1 record from 2015, posting a 6–10 record and a last-place finish in the NFC South, missing the playoffs for the first time since 2012, and losing the division title to the second-seeded Falcons, who went on to represent the NFC in Super Bowl LI. In 2017, the Panthers finished with an 11–5 record and a #5 seed. However, they lost to the New Orleans Saints 31–26 in the Wild Card Round, their first loss in that round in franchise history.
On May 16, 2018, David Tepper, formerly a minority owner of the Pittsburgh Steelers, finalized an agreement to purchase the Panthers. The sale price was nearly $2.3 billion, a record. The agreement was approved by the league owners on May 22, 2018. The sale officially closed on July 9, 2018. After starting 6-2, the Panthers finished the 2018 season 7-9. They began the 2019 season 5-3, but lost the last eight games to finish 5-11; late in the season, Tepper fired Rivera as head coach. Perry Fewell finished out the season as interim coach, going 0-4. On January 7, 2020, the Panthers hired Baylor head coach Matt Rhule as head coach. On January 15, 2020, Luke Kuechly announced his retirement from the league. On March 17, 2020, The Panthers signed Teddy Bridgewater to a three-year $63 million dollar contract. On March 24, the Carolina Panthers released their 2011 1st overall pick and 2015 MVP quarterback Cam Newton.
The shape of the Panthers logo was designed to mimic the outline of both North Carolina and South Carolina. The Panthers changed their logo and logotype in 2012, the first such change in team history. According to the team, the changes were designed to give their logo an "aggressive, contemporary look" as well to give it a more three-dimensional feel. The primary tweaks were made in the eye and mouth, where the features, particularly the muscular brow and fangs, are more pronounced, creating a more menacing look. The revised logo has a darker shade of blue over the black logo, compared to the old design, which had a shade similar to teal on top of black.
By the time they had been announced as the 29th NFL team in October 1993, the Panthers' logo and helmet design had already been finalized, but the uniform design was still under creation. After discussion, the Panthers organization decided on jerseys colored white, black, and blue, and pants colored white and silver. The exact tone of blue, which they decided would be "process blue" (a shade lighter than Duke's and darker than North Carolina's), was the most difficult color to choose.
The team's uniform has remained largely the same since its creation, with only minor alterations such as changing the sock color of the team's black uniforms from blue to black and changing the team's shoes from white to black. Richardson, a self-described traditionalist, said that no major uniform changes would be made in his lifetime.
The Panthers have three main jersey colors: black, white, and blue. Their blue jerseys, designated their alternate uniforms, are the newest and were introduced in 2002. NFL regulations allow the team to use the blue jersey up to two times in any given season. In all other games, the team must wear either their white or black jerseys; in NFL games, the home team decides whether to wear a dark or white jersey, while the away team wears the opposite. Usually the Panthers opt for white or blue when the weather is expected to be hot and for black when the weather is expected to be cold.
The Panthers typically pair their white jerseys with white pants, while the black and blue jerseys are paired with silver pants; there have only been a few exceptions to these combinations.
The first such instance was in 1998, when the team paired their white jerseys with silver pants in a game against the Indianapolis Colts. The second instance was in 2012 during a game against the Denver Broncos, when they paired their black jerseys with new black pants; this created an all-black uniform, with the exception of blue socks and silver helmets. The decision to wear blue socks was made by team captain Steve Smith, who felt the blue socks gave the uniforms a more distinct appearance compared with other teams that have all-black uniforms. The all-black uniforms won the "Greatest Uniform in NFL History" contest, a fan-voted contest run by NFL.com in July 2013. In July 2013, the team's equipment manager, Jackie Miles, said the Panthers intended to use the all-black uniform more in the future. The Panthers wore the all-black uniform three times the following season, once each in the preseason and regular season, and the third time during the home divisional round playoff game vs the 49ers. During the Panthers' 2015 Thanksgiving Day game against the Dallas Cowboys, they debuted an all-blue uniform as part of Nike's "Color Rush" series.
In the 2018 exhibition season, the Panthers wore the black pants with the blue jerseys for a home game vs. the New England Patriots, then paired the black pants with the white jerseys in an away game vs. the Pittsburgh Steelers. During the 2018 season, the team did not wear silver pants. Instead they wore the all-black uniforms and blue jerseys with white pants. Away games saw the team wear black pants with white jerseys along with the traditional all-white.
The team's uniform did not change significantly after Nike became the NFL's jersey supplier in 2012, but the collar was altered to honor former Panthers player and coach Sam Mills by featuring the phrase "Keep Pounding". Nike had conceived the idea, and the team supported the concept as a way to expose newer fans to the legacy of Mills, who died of cancer in 2005. Mills had introduced the phrase, which has since become a team slogan, in a speech that he gave to the players and coaches prior to their 2003 playoff game against Dallas; in the speech, Mills compared his fight against cancer with the team's on-field battle, saying "When I found out I had cancer, there were two things I could do – quit or keep pounding. I'm a fighter. I kept pounding. You're fighters, too. Keep pounding!"
In 2019, the Panthers unveiled new uniforms. The new uniforms are Nike's "Vapor Untouchable" and have only minor differences: the tapered strips on the pants are replaced by stripes that extend down to the socks, the reflective shoulder cloth was replaced and the hip logos were also removed. The uniforms keep the same basic look, colors, numbers as the originals. As the 2019 season was the team's 25th, the Panthers sported a 25th anniversary patch on their uniforms.
The Panthers played their first season at Memorial Stadium in Clemson, South Carolina, as their facility in uptown Charlotte was still under construction. Ericsson Stadium, called Bank of America Stadium since 2004, opened in the summer of 1996.
Bank of America Stadium is owned entirely by the Panthers, making them one of the few teams in the NFL to own the facility they play in. The stadium was specially designed by HOK Sports Facilities Group for football and also serves as the headquarters and administrative offices of the Panthers. On some days the stadium offers public tours for a fee. Private tours for groups are offered for a fee seven days a week, though there are some exceptions, and such tours must be arranged in advance.
Two bronze panther statues flank each of the stadium's three main entrances; they are the largest sculptures ever commissioned in the United States. The names of the team's original PSL owners are engraved on the base of each statue. The first two people in the Panthers Hall of Honor, team executive Mike McCormack and linebacker Sam Mills, are honored with life-sized bronze statues outside the stadium. Mills, in addition to being the only player in the Hall of Honor for over 20 years, is the only player to have had his jersey number (#51) retired by the Panthers .
The Panthers have three open-air fields next to Bank of America Stadium where they currently hold their practices; during the 1995 season, when the team played their home games in South Carolina, the team held their practices at Winthrop University in Rock Hill, South Carolina. Because the practice fields, along with the stadium, are located in uptown Charlotte, the fields are directly visible from skyscrapers as well as from a four-story condominium located across the street. According to Mike Cranston, a running joke said that the Panthers' division rivals had pooled their resources to purchase a room on the building's top floor, and that a fire at the condominium was caused by the Panthers organization. In order to prevent people from seeing inside the field while the team is practicing, the team has added "strategically planted trees and a tarp over the ... fence surrounding the fields". Additionally, they employ a security team to watch for and chase away any people who stop alongside the fence surrounding the field. In the event of bad weather, the team moves their practices to an indoor sports facility about from the stadium. The team does not own this facility. The Panthers have hosted their annual training camp at Wofford College in Spartanburg, South Carolina, since 1995.
The Panthers are supported in both North Carolina and South Carolina; South Carolina Governor Nikki Haley declared July 30, 2012, "Carolina Panthers Day" in her state, saying that "when it comes to professional teams, the Carolina Panthers are the team that South Carolina calls their own". During the 2016 NFC Championship and Super Bowl, the hashtag #OneCarolina was used by college and professional sports teams from North Carolina and South Carolina to show unified support for the Panthers.
Pat Yasinskas of ESPN.com observed in 2012 that while there is "a bit of a wine-and-cheese atmosphere at Panthers games ... there is a strong core of die-hard fans who bring energy to Bank of America Stadium. Charlotte lives and dies with the Panthers because there aren't a lot of other options in the sports world". "Sports Illustrated" graded the Panthers as having the 10th highest "NFL Fan Value Experience" in 2007, attributing much of the fan atmosphere to the team's newness when compared to the established basketball fanbase. They also observed that the stadium has scattered parking lots, each of which has a different tailgating style. Some have fried chicken, pork, or Carolina-style barbecue, while others have live bands and televisions. Pickup football games in the parking lots are common.
The Carolina Panthers have sold out all home games since December 2002, and their home attendance has ranked in the NFL's top ten since 2006.
Sir Purr, an anthropomorphic black cat who wears a jersey numbered '00', has been the Panthers' mascot since their first season. During games, Sir Purr provides sideline entertainment through skits and "silly antics". The mascot participates in a number of community events year-round, including a monthly visit to the patients at Levine Children's Hospital. Sir Purr also hosts the annual Mascot Bowl, an event which pits pro and college mascots against each other during halftime at a selected Panthers home game.
The team's cheerleaders are the Carolina Topcats, a group of 24 women who lead cheers and entertain fans at home games. The TopCats participate in both corporate and charity events. The team's drumline is PurrCussion, an ensemble of snare, tenor, and bass drummers as well as cymbal players. PurrCussion performs for fans outside the stadium and introduces players prior to home games; it consists of drummers from across the Carolinas.
Starting with the 2012 season, the Panthers introduced the Keep Pounding Drum, inspired by the aforementioned motivational speech by Sam Mills before the team's 2004 playoff game against the Cowboys. Prior to each home game, an honorary drummer hits the six-foot tall drum four times to signify the four quarters of an American football game. According to the team, the drummers "come from a variety of backgrounds and occupations, but all have overcome a great trial or adversity that has not only made them strong but also pushes them to make others around them stronger". Drummers have included current and former Panthers players, military veterans, Make-A-Wish children, and athletes from other sports, including NBA MVP and Charlotte native Stephen Curry, US women's national soccer team players Whitney Engen and Heather O'Reilly, and 7 time NASCAR Cup Series champion Jimmie Johnson.
During the inaugural season of the Panthers, the team had an official fight song, which the team played before each home game. The song, "Stand and Cheer", remains the team's official fight song, but the team does not typically play it before home games. Due to negative fan reaction "Stand and Cheer" was pulled in 1999. Since 2006, the song has returned. The team plays Neil Diamond's "Sweet Caroline" after home victories.
A "keep pounding" chant was introduced during the 2015 season which starts before the opening kickoff of each home game. As prompted by the video boards, one side of the stadium shouts "keep" and the other side replies with "pounding". The chant is similar to ones that take place at college football games.
The Carolina Panthers support a variety of non-profits in North and South Carolina through the Carolina Panthers Charities. Four annual scholarships are awarded to student athletes through the Carolina Panthers Graduate Scholarship and the Carolina Panthers Players Sam Mills Memorial Scholarship programs. Carolina Panthers Charities also offers grants to non-profits that support education, athletics, and human services in the community. The Panthers and Fisher Athletic has provided six equipment grants to high school football teams in the Carolinas each year since 2010. Carolina Panthers Charities raises funds at three annual benefits: the Countdown to Kickoff Luncheon, the team's first public event each season; Football 101, an educational workshop for fans; and the Weekend Warrior Flag Football Tournament, a two-day non-contact flag football tournament. Another annual benefit is Taste of the Panthers, a gourmet food tasting which raises funds for Second Harvest Food Bank of Metrolina.
In 2003 the Panthers and Carolinas HealthCare Foundation established the Keep Pounding Fund, a fundraising initiative to support cancer research and patient support programs. The Panthers community has raised more than $1.4 million for the fund through direct donations, charity auctions, blood drives, and an annual 5k stadium run. The Panthers and Levine Children's Hospital coordinate monthly hospital visits and VIP game-day experiences for terminally ill or hospitalized children.
In addition to these team-specific efforts, the Panthers participate in a number of regular initiatives promoted by the NFL and USA Football, the league's youth football development partner. These include USA Football Month, held throughout August to encourage and promote youth football; A Crucial Catch, the league's Breast Cancer Awareness Month program; Salute to Service, held throughout November to support military families and personnel; and PLAY 60, which encourages young NFL fans to be active for at least 60 minutes each day.
Radio coverage is provided by flagship station WBT (1110 AM) and through the Carolina Panthers Radio Network, with affiliates throughout the Carolinas, Georgia, and Virginia. The Panthers' radio broadcasting team is led by play-by-play voice Mick Mixon, with Eugene Robinson as color analyst, and WBT sports director Jim Szoke as studio host. The radio network broadcasts pre-game coverage, games with commentary, and post-game wrap-ups. It also live-broadcasts "Panther Talk", a weekly event at Bank of America Stadium which offers fans a chance to meet a player and ask questions of the staff.
National broadcasting and cable television networks cover regular season games, as well as some preseason games. Locally, Fox affiliate WJZY airs most regular-season games, while any home games against an AFC team air on CBS affiliate WBTV. Any appearances on Monday Night Football are simulcast on ABC affiliate WSOC-TV, while any late-season appearances on Thursday Night Football are simulcast on WBTV. Sunday night and some Thursday night games are aired on NBC affiliate WCNC-TV.
All preseason games and team specials are televised by the Carolina Panthers Television Network on flagship station WSOC-TV in Charlotte and fourteen affiliate stations throughout the Carolinas, Georgia, Virginia, and Tennessee. WSOC took over as the Panthers' television partner for the 2019 season, replacing longtime television partner WCCB, which had retained this role after losing the Fox affiliation to WJZY in 2013. The television broadcasting team consists of play-by-play commentator Mike Morgan, color analyst and former Panthers player Mike Rucker, and sideline reporter Pete Yanity. The network also hosts "The Panthers Huddle", a weekly show focusing on the Panthers' upcoming opponent. "Panthers Gameday", the Panthers' postgame show, is hosted by sports anchor Russ Owens and former Panthers lineman Kevin Donnalley on WCNC-TV.
The Panthers also offer game broadcasts in Spanish on an eight-station network fronted by WGSP-FM in Pageland, South Carolina, as well as additional radio affiliates in Mexico. Jaime Moreno provides the play-by-play while his nephew, Luis Moreno Jr., is the color commentator. They have become popular even among English-speaking Panther fans for their high-energy, colorful announcing style.
The Panthers have developed heated rivalries with the three fellow members of the NFC South (the Atlanta Falcons, Tampa Bay Buccaneers, and New Orleans Saints). The team's fiercest rivals are the Falcons and Buccaneers.
The Falcons are a natural geographic rival for the Panthers, as Atlanta is only south on I-85. The two teams have played each other twice a year since the Panthers' inception, and games between the two teams feature large contingents of Panthers fans at Atlanta's Mercedes-Benz Stadium and large contingents of Falcons fans at Bank of America Stadium.
The Panthers' rivalry with Tampa Bay has been described as the most intense in the NFC South. The rivalry originated in 2002 with the formation of the NFC South, but became particularly heated before the 2003 season with verbal bouts between players on the two teams. It escalated further when the Panthers went to Tampa Bay and beat them in what ESPN.com writer Pat Yasinskas described as "one of the most physical contests in recent memory". The rivalry has resulted in a number of severe injuries for players on both teams, some of which were caused by foul play. One of these plays, an illegal hit on Tampa Bay punt returner Clifton Smith, sparked a brief melee between the teams in 2009.
During their time in the NFC West, the Panthers began developing a rivalry with the San Francisco 49ers. This rivalry faded after the NFL moved the Panthers out of the NFC West.
The Carolina Panthers Hall of Honor was established in 1997 to honor individuals for their contributions to the Carolina Panthers organization.
Nominees for the Pro Football Hall of Fame, which "honor[s] individuals who have made outstanding contributions to professional football", are determined by a 46-member selection committee. At least 80% of voters must approve the nominee for him to be inducted.
Jerry Richardson was the founder and first owner of the Carolina Panthers. Richardson and his family owned about 48% of the team, with the remaining 52% owned by a group of 14 limited partners. Richardson and the other investors paid $206 million for the rights to start the team in 1993.
Mike McCormack, a Hall of Fame lineman for the Cleveland Browns and former coach and executive for the Seattle Seahawks, was the Panthers' first team president, presiding in that role from 1994 until his retirement in 1997; McCormack was inducted as the first person in the Carolina Panthers Hall of Honor later that year. Jerry Richardson's son, Mark, was appointed as the team's second president in 1997 and served in that role until he stepped down in 2009. His brother Jon, who had been president of Bank of America Stadium, stepped down at the same time. The resignations of Mark and Jon Richardson were unexpected, as it was thought that the two would eventually take over the team from their father. Mark Richardson was replaced by Danny Morrison, who had previously served as the athletic director of both Texas Christian University and Wofford College, Richardson's alma mater. Morrison resigned in early 2017. The role was vacant until August 2018, when Tom Glick was hired as team president. He had previously served as the COO of Manchester City.
On May 16, 2018, David Tepper, formerly a minority owner of the Pittsburgh Steelers, finalized an agreement to purchase the Carolina Panthers, for nearly $2.3 billion, a record at the time. The agreement was approved by the league owners on May 22, 2018. According to "Forbes", the Panthers are worth approximately $2.3 billion . They ranked the Carolina Panthers as the 21st-most valuable NFL team and the 36th-most valuable sports team in the world.
The Carolina Panthers have had six head coaches. Dom Capers was the head coach from 1995 to 1998 and led the team to one playoff appearance. Counting playoff games, he finished with a record of 31–35 (.470). George Seifert coached the team from 1999 to 2001, recording 16 wins and 32 losses (.333). John Fox, the team's longest-tenured head coach, led the team from 2002 to 2010 and coached the team to three playoff appearances including Super Bowl XXXVIII which the Panthers lost. Including playoff games, Fox ended his tenure with a 78–74 (.513) record, making him the first Panthers coach to finish his tenure with the team with a winning record. Ron Rivera held the position from 2011 to 2019 and led the team to four playoff appearances including Super Bowl 50. Counting playoff games, he has a career record of 79–67–1 (.541). Statistically, Rivera holds the highest winning percentage of any Panthers head coach. On December 3, 2019, following a home loss against the Washington Redskins that sent the team's record to 5–7, Rivera was fired by David Tepper. Perry Fewell, then the defensive backs coach for the team, was named interim head coach the same day. On January 7, 2020, Matt Rhule was hired to be the Panthers head coach.
Since they began playing football in 1995, the Panthers have been to four NFC Championship Games; they lost two (1996 and 2005) and won two (2003 and 2015). The Panthers have won six division championships: the NFC West championship in 1996 and the NFC South championship in 2003, 2008, 2013, 2014, and 2015. They have won the NFC South more times than any other team in the division. They have finished as runners-up in their division six times, finishing second-place in the NFC West in 1997 and 1999 and finishing second-place in the NFC South in 2005, 2006, 2007, and 2012. They have qualified for the playoffs 8 times, most recently in 2017.
Kicker John Kasay is the team's career points leader. Kasay scored 1,482 points during his 16 seasons (1995–2010) with the Panthers. Quarterback Cam Newton, who has played for the Panthers since 2011, is the career passing leader, having thrown for 20,257 yards over his six seasons with the team. Running back Jonathan Stewart is the career rushing leader for the Carolina Panthers. Stewart, during his tenure with the team (2008–2018), rushed for 6,868 yards with the Panthers. Wide receiver Steve Smith, the team's leading receiver, recorded 12,197 receiving yards during his 13-year (2001–2013) tenure with the team.
Notes
Footnotes

</doc>
<doc id="6611" url="https://en.wikipedia.org/wiki?curid=6611" title="Chicago Bears">
Chicago Bears

The Chicago Bears are a professional American football team based in Chicago. The Bears compete in the National Football League (NFL) as a member club of the league's National Football Conference (NFC) North division. The Bears have won nine NFL Championships, including one Super Bowl, and hold the NFL record for the most enshrinees in the Pro Football Hall of Fame and the most retired jersey numbers. The Bears have also recorded more victories than any other NFL franchise.
The franchise was founded in Decatur, Illinois, on September 17, 1920, and moved to Chicago in 1921. It is one of only two remaining franchises from the NFL's founding in 1920, along with the Arizona Cardinals, which was originally also in Chicago. The team played home games at Wrigley Field on Chicago's North Side through the 1970 season; they now play at Soldier Field on the Near South Side, adjacent to Lake Michigan. The Bears have a long-standing rivalry with the Green Bay Packers.
The team headquarters, Halas Hall, is in the Chicago suburb of Lake Forest, Illinois. The Bears practice at adjoining facilities there during the season, and began hosting Training Camp at Halas Hall in 2020 after major renovations.
Originally named the Decatur Staleys, the club was established by the A. E. Staley food starch company of Decatur, Illinois as a company team. This was the typical start for several early professional football franchises. The company hired George Halas and Edward "Dutch" Sternaman in 1920 to run the team. The 1920 Decatur Staleys season was their inaugural regular season completed in the newly formed American Professional Football Association (later renamed the National Football League (NFL) in 1922).
Full control of the team was turned over to Halas and Sternaman in 1921. Official team and league records cite Halas as the founder as he took over the team in 1920 when it became a charter member of the NFL.
The team relocated to Chicago in 1921, where the club was renamed the Chicago Staleys. Under an agreement reached by Halas and Sternaman with Staley, Halas purchased the rights to the club from Staley for US$100.
In 1922, Halas changed the team name from the Staleys to the Bears. The team moved into Wrigley Field, which was home to the Chicago Cubs baseball franchise. As with several early NFL franchises, the Bears derived their nickname from their city's baseball team (some directly, some indirectly – like the Bears, whose young are called "cubs"). Halas liked the bright orange-and-blue colors of his alma mater, the University of Illinois, and the Bears adopted those colors as their own, albeit in a darker shade of each (the blue is Pantone 5395, navy blue, and the orange is Pantone 1665, similar to burnt orange).
The Staleys/Bears dominated the league in the early years. Their rivalry with the Chicago Cardinals, the oldest in the NFL (and a crosstown rival from 1920 to 1959), was key in four out of the first six league titles. During the league's first six years, the Bears lost twice to the Canton Bulldogs (who took two league titles over that span), and split with their crosstown rival Cardinals (going 4–4–2 against each other over that span), but no other team in the league defeated the Bears more than a single time. During that span, the Bears posted 34 shutouts.
The Bears' rivalry with the Green Bay Packers is one of the oldest and most storied in American professional sports, dating back to 1921 (the Green Bay Packers were an independent team until they joined the NFL in 1921). In one infamous incident that year, Halas got the Packers expelled from the league in order to prevent their signing a particular player, and then graciously got them re-admitted after the Bears had closed the deal with that player.
The franchise was an early success under Halas, capturing the NFL Championship in and remaining competitive throughout the decade. In 1924 the Bears claimed the Championship after defeating the Cleveland Bulldogs on December 7, even putting the title "World's Champions" on their 1924 team photo. But the NFL had ruled that games after November 30 did not count towards league standings, and the Bears had to settle for second place behind Cleveland. Their only losing season came in .
During the 1920s the club was responsible for triggering the NFL's long-standing rule that a player could not be signed until his college's senior class had graduated. The NFL took that action as a consequence of the Bears' aggressive signing of famous University of Illinois player Red Grange within a day of his final game as a collegian.
Despite much of the on-field success, the Bears were a team in trouble. They faced the problem of increased operating costs and flatlined attendance. The Bears would only draw roughly 5,000–6,000 fans a game, while a University of Chicago game would draw 40,000–50,000 fans a game. By adding top college football draw Red Grange to the roster, the Bears knew that they found something to draw more fans to their games. C.C. Pyle was able to secure a $2,000 per game contract for Grange, and in one of the first games, the Bears defeated the Green Bay Packers, 21–0. However, Grange remained on the sidelines while learning the team's plays from Bears quarterback Joey Sternaman. Later in 1925, The Bears would go on a barnstorming tour, showing off the best football player of the day. 75,000 people paid to see Grange lead the Bears to a 17–7 victory over the Los Angeles Tigers, who were a quickly put together team of West Coast college all-stars. After a loss to San Francisco, the Bears cruised to a 60–3 over a semi-pro team called the Portland All Stars.
Any hopes that Grange would lead the Bears to glory in 1926 were quickly dashed. A failed contract talk led to Grange bolting to the AFL's New York Yankees, owned by Pyle. The Bears also lost star quarterback Joey Sternaman, who joined the Chicago Bulls of the AFL. The Bears replaced Grange with Paddy Driscoll, a star football player in his own right. The Bears used the money made from the Grange barn-storming tour to sign the man that replaced him. Grange split his time between making movies and playing football. However, the time was not right to have two competing pro football leagues, and the AFL folded after only one season. Grange would return to the Bears.
After the financial losses of the Championship season, Halas' partner Dutch Sternaman left the organization. Halas maintained full control of the Bears until his death in 1983. He also coached the team off-and-on for forty seasons, an NFL record. In the 1932 "Unofficial" NFL Championship, the Bears defeated the Portsmouth Spartans in the first indoor American football game at Chicago Stadium.
The success of the playoff game led the NFL to institute a championship game. In the very first NFL Championship, the Bears played against the New York Giants, defeating them 23–21. The teams met again in the 1934 NFL Championship where the Giants, wearing sneakers defeated the Bears 30–13 on a cold, icy day at the Polo Grounds.
From 1940–1947, quarterback Sid Luckman led the Bears to victories in four out of the five NFL Championship Games in which they appeared. The team acquired the University of Chicago's discarded nickname "Monsters of the Midway" and their now-famous helmet wishbone "C", as well as a newly penned theme song that declared them "The Pride and Joy of Illinois". One famous victory during that period was their 73–0 victory over the favored Washington Redskins at Griffith Stadium in the 1940 NFL Championship Game; the score is still an NFL record for lopsided results. The secret behind the one-sided outcome was the introduction of a new offensive formation by Halas. The T-formation, as Halas named it, involved two running backs instead of the traditional one in the backfield. Luckman established himself as one of the franchise's most elite quarterbacks. Between 1939 and 1950, he set the Bears' passing records for most career touchdowns, yards, and completions. Many of Luckman's records stood for decades before they were eclipsed by Jay Cutler in .
Cutler then went on to break Luckman's franchise record for most career passing touchdowns a year later in .
After declining throughout the 1950s, the team rebounded in to capture its eighth NFL Championship, which would be its last until 1985. The late 1960s and early-1970s produced notable players like Dick Butkus, Gale Sayers, and Brian Piccolo, who died of embryonal carcinoma in 1970. The American television network ABC aired a movie about Piccolo in 1971 entitled "Brian's Song", starring James Caan and Billy Dee Williams in the roles of Piccolo and Sayers respectively; Jack Warden won an Emmy Award for his performance as Halas. The movie was later released for theater screenings after first being shown on television. Despite Hall of Fame careers, Butkus and Sayers would also have their careers cut short due to injuries, hamstringing the Bears of this era.
Halas retired as coach in 1967 and spent the rest of his days in the front office. He became the only person to be involved with the NFL throughout the first 60 years of its existence. He was also a member of the Pro Football Hall of Fame's first induction class in 1963. As the only living founder of the NFL at the February 1970 merger between the NFL and the American Football League, the owners honored Halas by electing him the first President of the National Football Conference, a position that he held until his death in 1983. In his honor, the NFL named the NFC Championship trophy as the George Halas Memorial Trophy.
After the merger, the Bears finished the 1970 season last place in their division, a repeat of their placing in the 1969 season. In 1975, the Bears drafted Walter Payton from Jackson State University with their first pick. He won the NFL Most Valuable Player Award in the 1977–78 season. Payton would go on to eclipse Jim Brown's NFL career rushing record in 1984 before retiring in 1987, and would hold the mark until , when Emmitt Smith of the Dallas Cowboys surpassed it. Payton's career and personality would capture the hearts of Bear fans, who called him "Sweetness". He died from a rare form of liver cancer in 1999 at the age of 45.
On November 1, 1983, a day after the death of George Halas, his oldest daughter, Virginia McCaskey, took over as the majority owner of the team. Her husband, Ed McCaskey, succeeded her father as the Chairman of the Board. Their son Michael became the third president in team history. Mrs. McCaskey holds the honorary title of "secretary of the board of directors", but the 90-year–old matriarch has been called the glue that holds the franchise together. Mrs. McCaskey's reign as the owner of the Bears was not planned, as her father originally earmarked her brother, George "Mugs" Halas Jr. as the heir apparent to the franchise. However, he died of a massive heart attack in 1979. Her impact on the team is well-noted as her own family has dubbed her "The First Lady of Sports", and the "Chicago Sun-Times" has listed her as one of Chicago's most powerful women.
Mike Ditka, a tight end for the Bears from 1961 to 1966, was hired to coach the team by George Halas in 1982. His gritty personality earned him the nickname "Iron Mike". The team reached the NFC Championship game in 1984. In the 1985 season the fire in the Bears–Packers rivalry was re-lit when Ditka used 315 pound defensive tackle "Refrigerator" Perry as a running back in a touchdown play at Lambeau Field, against the Packers. The Bears won their ninth NFL Championship, first since the AFL-NFL merger, in Super Bowl XX after the 1985 season in which they dominated the NFL with their then-revolutionary 46 defense and a cast of characters that recorded the novelty rap song "The Super Bowl Shuffle". The season was notable in that the Bears had only one loss, the "unlucky 13th" game of the season, a Monday night affair in which they were defeated by the Miami Dolphins. At the time, much was made of the fact that the Dolphins were the only franchise in history to have had an undefeated season and post-season. The Dolphins came close to setting up a rematch in the Super Bowl, but lost to the New England Patriots in the AFC title game. "The Super Bowl Shuffle" was videotaped the day after that Monday night loss in Miami.
After the 1985 Championship season, the Bears remained competitive throughout the 1980s but failed to return to the Super Bowl under Ditka. Between the firing of Ditka and the hiring of Lovie Smith, the Bears had two head coaches, Dave Wannstedt and Dick Jauron. While both head coaches led the team to the playoffs once (Wannstedt in 1994 and Jauron in 2001), neither was able to accumulate a winning record or bring the Bears back to the Super Bowl. Therefore, the 1990s was largely considered to be a disappointment.
Before the Bears hired Jauron in January 1999, Dave McGinnis (Arizona's defensive coordinator, and a former Bears assistant under Ditka and Wannstedt) backed out of taking the head coaching position. The Bears scheduled a press conference to announce the hiring before McGinnis agreed to contract terms. Soon after Jauron's hiring, Mrs. McCaskey fired her son Michael as president, replacing him with Ted Phillips and promoting Michael to chairman of the board. Phillips, the current Bears president, became the first man outside of the Halas-McCaskey family to run the team.
Lovie Smith, hired on January 15, 2004, is the third post-Ditka head coach. Joining the Bears as a rookie head coach, Smith brought the highly successful Tampa 2 defensive scheme with him to Chicago. Before his second season with the Bears, the team rehired their former offensive coordinator and then Illinois head coach Ron Turner to improve the Bears' struggling offense. In , the Bears won their division and reached the playoffs for the first time in four years. Their previous playoff berth was earned by winning the NFC Central in . The Bears improved upon their success the following season, by clinching their second consecutive NFC North title during Week 13 of the season, winning their first playoff game since 1995, and earning a trip to Super Bowl XLI. However, they fell short of the championship, losing 29–17 to the Indianapolis Colts. Following the 2006 season, the club decided to give Smith a contract extension through 2011, at roughly $5 million per year. This comes a season after being the lowest paid head coach in the National Football League.
The club has played in over a thousand games since becoming a charter member of the NFL in . Through the 2010 season, they led the NFL in overall franchise wins with 704 and had an overall record of 704–512–42 (going 687–494–42 during the regular season and 17–18 in the playoffs). On November 18, 2010 the Bears recorded franchise win number 700 in a win against the Miami Dolphins.
The Bears made one of the biggest trades in franchise history, acquiring Pro Bowl quarterback Jay Cutler from the Denver Broncos in exchange for Kyle Orton and draft picks on April 2, 2009. After a disappointing 2009 campaign with the team going 7–9, Mike Martz was hired as the team's offensive coordinator on February 1, 2010. On March 5, 2010, the Bears signed defensive end Julius Peppers, running back Chester Taylor, and tight end Brandon Manumaleuna, spending over $100 million on the first day of free agency. Also during the 2010 offseason, Michael McCaskey was replaced by brother George McCaskey as chairman of the Bears. With a 38–34 win against the New York Jets, the Bears clinched the No. 2 seed and a first-round bye for the 2010–11 NFL playoffs. In their first Playoff game since Super Bowl XLI, The Bears defeated the No. 4 seed Seattle Seahawks 35–24 in the Divisional Round. The Bears reached the NFC Championship Game, where they played Green Bay Packers at Soldier Field – only the second playoff meeting between the two storied rivals, the only other game played in 1941. The Bears lost the game, 21–14.
The team started the 2011 season strong with a 7–3 record, and running back Matt Forté led the NFL in total yards from scrimmage. Eventually, quarterback Jay Cutler fractured his thumb, and Forté also was lost for the season against the Kansas City Chiefs after spraining his MCL, and the Bears, with Caleb Hanie playing, lost five straight before winning against the Minnesota Vikings with Josh McCown starting over Hanie. At season's end, general manager Jerry Angelo was fired, and former Chiefs director of scouting and former Bears scout Phil Emery was brought in. Offensive coordinator Mike Martz resigned, and eventually retired, and was replaced by offensive line coach Mike Tice. The Bears made another notable move by trading for Miami Dolphins receiver and Pro Bowl MVP Brandon Marshall. The Bears became the first team in NFL history to return six interceptions for touchdowns in the first seven games of the season, with another pick-six by Brian Urlacher in Week 9 bringing Chicago two behind the record set by the 1961 San Diego Chargers. However, the Bears missed the playoffs with a record of 10–6 (after starting the season 7–1, the first team to start with the record and miss the playoffs since the 1996 Washington Redskins), and Smith was fired on December 31.
Then-CFL head coach and former NFL journeyman Marc Trestman was hired to succeed Smith after an exhaustive search that included at least 13 known candidates. On March 20, 2013, Brian Urlacher's 13-year tenure with the Bears ended when both sides failed to agree on a contract. The Trestman era began on September 8 with a 24–21 win over the Cincinnati Bengals, making Trestman the fourth head coach in Bears history to win in his coaching debut, after George Halas (1920), Neill Armstrong (1978) and Dick Jauron (1999). The Bears ended the 2013 season 8–8, barely missing the playoffs after losing in the final week of the season to the Packers. Despite having a second-ranked offense that set numerous franchise records, the defense greatly worsened as it set franchise worsts in categories like yards allowed (6,313).
The following season was a disaster for the Bears, with the offense regressing to finish outside the top 20 in scoring. The team also allowed 50-point games in two straight weeks against the Patriots and Packers, including a franchise-high 42 points and NFL-record six touchdowns allowed in the first half against the latter, to become the first team since the 1923 Rochester Jeffersons to allow at least 50 points in consecutive games. The Bears ended the year 5–11 and last in the NFC North. Trestman and Emery were fired after the season ended.
The Bears hired Ryan Pace of the New Orleans Saints to be their new general manager on January 8, 2015. On January 16, 2015, John Fox accepted a four-year deal to become head coach. In Fox's first season as head coach, the Bears saw improvements from 2014; after "USA Today" projected the Bears to win three games, they doubled that total and finished the season with a 6–10 record, including a Thanksgiving win over the Packers at Lambeau Field.
However, during the 2016 season, the Bears regressed heavily, compiling a 3–13 record (their worst since the NFL's change to 16-game seasons in 1978). The season included several injuries to starters and secondary players, including Jay Cutler, who only played five games as a result of two separate injuries. Backup quarterback Brian Hoyer started the next three games before a broken arm put him out for the season. He was replaced by Matt Barkley, who made his first career start with the Bears. None of the three quarterbacks returned for the 2017 season.
In the 2017 NFL Draft, the team selected quarterback Mitchell Trubisky with the second-overall pick, who sat behind newly-signed quarterback Mike Glennon for the first four games before taking over. The Bears ended the season 5–11 and again finished last in the NFC North. On January 1, 2018, Fox was fired, ending his tenure in Chicago with a 14–34 record.
The Bears hired Matt Nagy from the Kansas City Chiefs as their new head coach in January 2018. General manager Ryan Pace signed receivers Taylor Gabriel, Allen Robinson, and Trey Burton in the offseason to complement second-year quarterback Mitchell Trubisky. The Bears also acquired linebacker Khalil Mack in a block-blockbuster trade from the Oakland Raiders to further bolster their defense, sending a package of draft picks that includes 2019 and 2020 1st round draft picks in exchange. Nagy's Bears clinched the NFC North on December 16, 2018 for the first time since 2010 with a 24–17 victory over the Green Bay Packers. The Bears finished the 2018 season with a 12–4 record. They lost to the defending Super Bowl Champions Philadelphia Eagles in the Wild Card round of the Playoffs after Cody Parkey's game-winning field goal attempt was partially tipped and hit the uprights in the final seconds of the game, a play coined the "Double Doink". Despite the first-round exit, Nagy was named Coach of the Year by the Pro Football Writers Association and Associated Press. He was the first Bears coach to be given the AP award since Lovie Smith in 2005 and the fifth in team history.
In 2019, the team regressed to an 8–8 record, though Nagy's combined 20 wins in 2018 and 2019 were the most by a Bears head coach in his first two seasons. During the year, renovations to Halas Hall were completed, allowing the team to move Training Camp from Ward Field on the campus of Olivet Nazarene University in Bourbonnais, Illinois to Lake Forest for 2020.
Virginia Halas McCaskey, her children, and grandchildren control 80 percent of the team, and Mrs. McCaskey votes her children's stock as well as her own. Patrick Ryan, executive chairman of Aon Corp., and Aon director Andrew McKenna own 19.7% of the club. In a "Crain's Chicago Business" article, one businessman described his wishes for the team to maximize its potential. In 2009, "Yahoo! Sports" listed the McCaskeys as the third worst owner in the NFL, stating "[T]hey get less for what they've got than any team in our league." There have been rumors that the McCaskey family might split up over the team.
In 2012, "Forbes" magazine reported that the franchise is worth $1.19 billion, making it the eighth richest franchise in the NFL. Chicago is the third largest media market in the United States.
The team has major sponsorship deals with Dr Pepper Snapple Group, Miller Brewing Company, PNC Financial Services, United Airlines, Verizon, Xfinity, and Proven IT. The team was the first in the NFL to have a presenting sponsor, with the 2004 season advertised as "Bears Football presented by BankOne "(now Chase)"". Additionally, the Bears have an agreement with WFLD (the Fox owned-and-operated station in Chicago) to broadcast pre-season football games.
Before the 2003 season, the team had two unofficial mascots named "Rocky" and "Bearman". "Rocky" was a man who donned a #1 Bears jersey, carried a megaphone, and started chants all over Soldier Field during the 1970s, 1980s, and early 1990s, in a fashion similar to Fireman Ed. There is no known source of who "Rocky" was, and presumably currently lives in Northwestern Indiana. Don Wachter, also known as "Bearman", is a season ticket holder who decided in 1995 that he could also assist the team by cheerleading, similar to Rocky. The club allowed him to run across the field with a large Bears flag during player introductions and each team score (a role currently done by the Bears 4th Phase and Bears captains). In 1996, he donned his "costume" of face paint, bear head and arms, and a number 46 jersey. "Bearman" was forced to stop wearing his costume with the introduction of Staley Da Bear in 2003; however, in 2005, Wachter was allowed in costume again.
Staley Da Bear is an anthropomorphic bear with a customized No. 00 jersey, with blue and orange eyes, synonymous with the team's main colors. His name is eponymous to corn processing company A. E. Staley, who founded the Bears' franchise. Like Rocky and Bearman, he entertains Bears fans, but like other NFL mascots, and mascots in general, Staley also makes various visits to charity events, parties, Chicago Rush AFL games, and other Bears-related events, as well as taking part in various games with his "furballs" against youth football teams at halftime.
The team also formerly had their own cheerleading squad called the Chicago Honey Bears, who were formed in 1976. However, Bears owner Virginia Halas McCaskey terminated them after the 1985 season. The squad's uniforms have changed 3 times: from 1976–1979, the uniform was a white bodysuit with navy blue sleeves, then from 1980–1984 it became a white bodysuit, but with orange sleeves and the navy was moved to the trim, and in the squad's final season in 1985, the uniform was redesigned with an orange sequin vest.
Since 1998, the Bears have partnered with 'A Safe Place,' a domestic violence shelter in Waukegan, Illinois. In June 2017, current and former Bears employees helped with renovations at the shelter by ripping up carpet, painting walls, demolishing a kitchen and building a fence. The Bears have also provided financial support throughout the years.
The Green Bay Packers are the Bears' biggest rivals since their team's inception in 1920. The Green Bay Packers currently have the lead at 97–95–6, and the teams have met twice in the postseason. The Bears won the 1941 meeting, 33–14, and eventually defeated the New York Giants in the 1941 NFL Championship Game, and the Packers won the 2011 meeting, 21–14, en route to a Super Bowl XLV win over the Pittsburgh Steelers. The teams' first meeting was a victory for the Bears (known as the Staleys at the time) in 1921 in a shutout, 20–0. The Packers claimed their first win over the Bears in 1925, 14–10. The 1924 matchup (which ended in a 3–0 win for Chicago) was notable for featuring the first ever ejection of players in a game in NFL history, as Frank Hanny of the Bears and Walter Voss of the Packers were ejected for punching each other. The rivalry also featured one of the last successful fair catch kicks in 1968, when Bears kicker Mac Percival kicked the game-winning field goal.
Chicago and Minnesota took each other on in the Vikings' inaugural game, with the Vikings defeating the Bears in a 37–13 rout, and Minnesota currently holds the series lead 60–54–2.
The Detroit Lions and Bears have faced off since the Lions' inception in 1930, when they were known as the Portsmouth Spartans, with the Spartans winning, 7–6, and Chicago winning the second meeting, 14–6. Since then, the Bears have led the series, 99–74–5. The rivalry grew in 1932, when the Bears and Spartans met in the first ever postseason game in NFL history, with the Bears winning the game 9–0. The game also was known as the first "indoor football" game, as the game took place in indoor Chicago Stadium due to a blizzard at the time. The game also started the forward pass.
Soldier Field, located on Lake Shore Drive in Chicago, is the current home of the Bears. The Bears moved to Soldier Field in 1971 after outgrowing Wrigley Field, the team's home for 50 years. Northwestern University's residential neighbors objected to their playing at Dyche Stadium, now called Ryan Field. After the AFL-NFL Merger, the newly merged league wanted their teams to play in stadiums that could hold at least 50,000 fans. Even with the portable bleachers that the team brought into Wrigley, the stadium could still only hold 46,000. Soldier Field's playing turf was changed from natural grass to astroturf before the 1971 season, and then back to natural grass in time for the start of the 1988 season. The stadium was the site of the infamous Fog Bowl playoff game between the Bears and Philadelphia Eagles.
In 2002, the stadium was closed and rebuilt with only the exterior wall of the stadium being preserved. It was closed on Sunday, January 20, 2002, a day after the Bears lost in the playoffs. It reopened on September 27, 2003 after a complete rebuild (the second in the stadium's history). Many fans refer to the rebuilt stadium as "New Soldier Field". During the season, the Bears played their home games at the University of Illinois' Memorial Stadium in Champaign, where they went 3–5.
Many critics have negative views of the new stadium. They believe that its current structure has made it more of an eyesore than a landmark; some have dubbed it the "Mistake on the Lake". Soldier Field was stripped of its National Historic Landmark designation on February 17, 2006.
In the 2005 season, the Bears won the NFC North Division and the No. 2 Seed in the NFC Playoffs, entitling them to play at least one home game in the postseason. The team hosted (and lost) their divisional round match on January 15, 2006 against the Carolina Panthers. This was the first playoff game at Soldier Field since the stadium reopened.
The stadium's end zones and midfield were not painted until the 1982 season. The design sported on the field included the bolded word "Chicago" rendered in Highway Gothic in both end zones. In 1983, the end zone design returned, with the addition of a large wishbone "C" Bears logo painted at midfield. These field markings remained unchanged until the 1996 season. In 1996 the midfield wishbone "C" was changed to a large blue Bears head, and the end zone design were painted with "Bears" in cursive. This new design remained until the 1999 season, at which point the artwork was returned to the classic "Chicago" and the "C". In the new Soldier Field, the artwork was tweaked to where one end zone had the word "Chicago" bolded and the other had "Bears".
While the Super Bowl XX Champion Bears were a fixture of mainstream American pop culture in the 1980s, the Bears made a prior mark with the 1971 American TV movie "Brian's Song" starring Billy Dee Williams as Gale Sayers and James Caan as Brian Piccolo. The film told of how Piccolo helped Sayers recover from a devastating knee injury to return to his status as one of the league's best players, and how Sayers in turn helped the Piccolo family through Brian's fatal illness. A 2001 remake of the movie for ABC starred Sean Maher as Piccolo and Mekhi Phifer as Sayers.
The 1985 team is also remembered for recording the song "The Super Bowl Shuffle", which reached number forty-one on the "Billboard" Hot 100 and was nominated for a Grammy Award. The music video for the song depicts the team rapping that they are "not here to start no trouble" but instead "just here to do the Super Bowl Shuffle". The team took a risk by recording and releasing the song before the playoffs had even begun, but were able to avoid embarrassment by going on to win Super Bowl XX by a then-record margin of 46–10. That game was one of the most watched television events in history according to the Nielsen ratings system; the game had a rating of 48.3, ranking it 7th in all-time television history.
In addition to the "Super Bowl Shuffle" rap song, the Bears' success in the 1980s – and especially the personality of head coach Mike Ditka – inspired a recurring sketch on the American sketch comedy program "Saturday Night Live", called "Bill Swerski's Superfans". The sketch featured "Cheers" co-star George Wendt, a Chicago native, as host of a radio talk-show (similar in tone to WGN radio's "The Sportswriters"), with co-panelists Carl Wollarski (Robert Smigel), Pat Arnold (Mike Myers) and Todd O'Connor (Chris Farley). To hear them tell it, "Da Bears" and Coach Ditka could do no wrong. The sketch stopped after Ditka was fired in 1993. The sketch usually showed the panelists chugging beer and eating lots of Polish sausage, and often featured Todd getting so agitated about what was happening with the Bears that he suffered a heart attack, but quickly recovered (through self-administered CPR). The sketch also features the cast predicting unrealistic blowout victories for Bears games. Da Super Fan sketch has not been brought back by "SNL", with the exception of a single appearance by Horatio Sanz as a Super Fan for the Cubs on "Weekend Update" in 2003. Outside of "SNL", George Wendt reprised his role of Swerski in the opening promo of Super Bowl XL on ABC.
On TV shows based in Chicago such as "The Bob Newhart Show", "Married... with Children", "Family Matters", "Still Standing", "According to Jim", "Early Edition" and "The Bernie Mac Show", the main characters are all Bears fans, and have worn Bears' jerseys and T-shirts on some occasions. Some episodes even show them watching Bears games. "Roseanne" is another TV show based in Illinois (albeit not in Chicago itself) to feature the Bears as the consensus household favorite, as 'Dan Connor' John Goodman is seen wearing Bears hats in several episodes. "That '70s Show" featured several Bears references, as it was based in Wisconsin, home of the Packers. On one episode while the gang is at a Bears vs. Packers game, Eric comes to the seat in a Walter Payton jersey and is booed by the surrounding Packers fans. In an episode of the Disney Channel show "Shake It Up", based in Chicago, recurring character Dina Garcia (Ainsley Bailey) sold scalped Chicago Bears tickets. More recently, "Modern Family" character Cameron Tucker has been shown as a Bears fan. In an episode of the Disney Channel show "I Didn't Do It", based in Chicago, Lindy Watson (Olivia Holt) and Logan Watson (Austin North) try to get a football signed by NFL Hall of Famer Dick Butkus after destroying their fathers Butkus signed ball, Alshon Jeffery also makes a cameo appearance as well.
Ditka's success and popularity in Chicago has led him to land analyst roles on various American football pregame shows. Ditka worked for both the "NFL on NBC" and CBS's "The NFL Today", and he currently works on ESPN's "Sunday NFL Countdown" and provided Friday night analysis on the Bears on WBBM-TV's "2 on Football" with former WBBM-TV sports director Mark Malone. He is also the color analyst for all local broadcasts of Bears preseason games. Ditka also co-starred himself alongside actor Will Ferrell in the 2005 comedy film "Kicking & Screaming".
Also, Ditka, Dick Butkus, Walter Payton, Jim McMahon, William "Refrigerator" Perry and Brian Urlacher are among Bears figures known for their appearances in TV commercials. Urlacher, whose jersey was among the league's best-selling in 2002, was featured on Nike commercials with former Atlanta Falcons quarterback Michael Vick.
In the 1961 Hanna-Barbera animated short "Rah Rah Bear", Yogi Bear helps the Bears beat the New York Giants.
The Bears were later depicted in an episode of the 1985 cartoon version of the NBC sitcom "Punky Brewster", where the Bears are playing the Green Bay Packers.
Clark Griswold (Chevy Chase) from the "National Lampoon's Vacation series" appears in some scenes wearing a navy blue with burnt orange scripting Chicago Bears ball cap. He wears the same Chicago Bears cap throughout all four "Vacation" movies.
Currently, WBBM (780 AM) and its simulcasting partner, WCFS-FM (105.9 FM) broadcast Bears games with Jeff Joniak doing the play-by-play, along with color commentator Tom Thayer, who played for the Bears from 1985–1992, and sideline reporter Zach Zaidman. Over the years, many Bears play-by-play broadcasters have included play-by-play announcers Jack Brickhouse, Joe McConnell and Wayne Larrivee, and color commentators Hub Arkush, Dick Butkus, Jim Hart and Irv Kupcinet.
Spanish radio station WLEY-FM aired the Bears games from 2012 to 2014. Since 2015, WRTO and WVIV-FM air Bears games in Spanish.
Their current preseason TV announcers on WFLD (channel 32), which also carries the majority of the team's regular season games through the "NFL on Fox", are Sam Rosen (play-by-play), Erik Kramer (color commentary) and Lou Canellis (sideline reporter). When the games are played against an AFC team, it can be aired on the CBS O&O station, WBBM-TV. Sunday Night games are broadcast on WMAQ-TV, the NBC O&O station.
Patrick Mannelly holds the record for the most seasons in a Bears uniform with 16. On the other hand, Steve McMichael holds the record for most consecutive games played by a Bear with 191; he accomplished the feat from 1981 to 1993. In second place is Payton, who played 186 games from 1975 to 1987 at running back, a position considered to be conducive to injury, only missing one game in a span of 13 seasons.
Kicker Robbie Gould became the Bears' all-time scoring leader in Week 5 of 2015 season overtaking placekicker Kevin Butler who previously held the club record for scoring the most points in his ten-year Bear career. He scored 1,116 points as the Bears kicker from 1985 to 1995. He is followed by running back Walter Payton, with 750 points. Payton holds the team record for career rushing yards with 16,726. That was an NFL record until Emmitt Smith of the Dallas Cowboys broke it in . Former Bears running back Matt Forte, who started playing for the Bears in 2008, is the closest to Payton's record with 6,985 yards. Forte also holds the team's single season record for rookies in rushing attempts, rushing yards and receptions. Mark Bortz holds the record for most Bear playoff appearances, with 13 between 1983 and 1994, and is followed by Kevin Butler, Dennis Gentry, Dan Hampton, Jay Hilgenberg, Steve McMichael, Ron Rivera, Mike Singletary, and Keith Van Horne, who have each played in 12 playoff games.
The 1940 Chicago Bears team holds the record for the biggest margin of victory in an NFL game (playoff or regular season) with a 73–0 victory over the Washington Redskins in the 1940 NFL Championship Game. The largest home victory for the Bears came in a 61–7 result against the Green Bay Packers in 1980. The largest defeat in club history was a 52–0 loss against the Baltimore Colts in 1964. The club recorded undefeated regular seasons in 1934 and 1942, but (unlike the 1972 Dolphins) did not win the championship game in either season. In 1934, the club completed a 13–0 record but were defeated by the New York Giants, and in 1942 the club completed an 11–0 record but were defeated by the Redskins. Had the Bears won either championship, the club would have completed a championship three-peat – a feat completed only by the Packers (twice), although no team has done it since the AFL-NFL merger. Halas holds the team record for coaching the most seasons with 40 and for having the most career victories of 324. Halas' victories record stood until Don Shula surpassed Halas in . Ditka is the closest Bears coach to Halas, with 112 career victories. No other Bears coach has recorded over 100 victories with the team.
During the 2006 season, return specialist Devin Hester set several kick return records. He currently holds the franchise record for most return yards with 2,261. He had six touchdown returns, setting a record for most returns in a single season. In 2007, he recorded another six touchdown season from returns. One of the most notable of these returns came on November 12, 2006, when he returned a missed field goal for a 108-yard touchdown. The record tied former teammate Nathan Vasher's previous record, which was set almost a year earlier. Additionally, Hester set a Super Bowl record by becoming the first player to return an opening kick of a Super Bowl for a touchdown. On December 20, 2010, Hester set an NFL record for most touchdowns on a punt or kickoff return with his 14th career return coming against the Minnesota Vikings. In 2011, Hester broke the record for the most punt returns against the Carolina Panthers.
In 2012, Charles Tillman set the record for most forced fumbles in a single game with 4 against the Tennessee Titans. Also against the Titans, Chicago became the first team in league history to score a touchdown pass, a touchdown run, an interception return for a touchdown, and a blocked kick/punt for a score in the same quarter. Tillman and teammate Lance Briggs became the first pair in NFL history to return an interception for a touchdown in consecutive games against the Jacksonville Jaguars and Dallas Cowboys.
This is a partial list of the Bears' last five completed seasons. For the full season-by-season franchise results, see List of Chicago Bears seasons.
"Note: The Finish, Wins, Losses, and Ties columns list regular season results and exclude any postseason play."
In the Pro Football Hall of Fame, the Bears have the most enshrined primary members with 30; the club also has had seven Hall of Famers spend a minor portion of their career with the franchise. Founder, owner, head coach, and player George Halas, halfback Bronko Nagurski, and Red Grange were a part of the original class of inductees in 1963. The franchise saw 14 individuals inducted into the Hall of Fame from 1963 to 1967. Offensive tackle Jim Covert and defensive end Ed Sprinkle are the most recent Chicago Bear inductees, both being inducted as seniors as part of the Pro Football Hall of Fame's centennial class of 2020.
The Bears have retired 14 uniform numbers, which is the most in the NFL, and ranks fourth behind the basketball Boston Celtics (22), baseball New York Yankees (21), and hockey Montreal Canadiens (15) for the most in North American professional sports. The Bears retired Mike Ditka's number 89 jersey on December 9, 2013. It is the last number that the Bears retired.
In honor of the team centennial anniversary, on May 20, 2019, the Chicago Bears have unveiled the Top 100 players in franchise history, as voted on by Hall of Fame writers Don Pierson and Dan Pompei, two of the most famous journalists that have ever covered the club in their long history. At the time of the publish, the list included 27 Pro Football Hall of Famers, while two more inductees would join in the 2020 class (Jim Covert and Ed Sprinkle).
Among the 100 Greatest, four active players made the list, including safety Eddie Jackson (96), defensive lineman Akiem Hicks (75), offensive lineman Kyle Long (74) and highest-ranked active Bear was Khalil Mack (60), who played only one season with the team. Long would retire the following year.
On later date, Chicagobears.com released a list titled "Top 10: Best of the rest", that featured the top 10 snubs from the centennial list. The players include (in a following order): Alex Brown, Thomas Jones, Dave Whitsell, Curtis Conway, Tim Jennings, Leslie Frazier, Roberto Garza, Marty Booker, Nathan Vasher and William Perry.
During the week of June 3, 2019 the All-Time Team was announced in parts each day starting with the All-Time defensive players, followed by the All-Time specialists and then the All-Time offensive players.
Larry Mayer of the Chicagobears.com would later state, that according to the voters "if they had included a long-snapper on the team it would have been Patrick Mannelly".

</doc>
<doc id="6612" url="https://en.wikipedia.org/wiki?curid=6612" title="Cincinnati Bengals">
Cincinnati Bengals

The Cincinnati Bengals are a professional American football franchise based in Cincinnati. The Bengals compete in the National Football League (NFL) as a member club of the league's American Football Conference (AFC) North division. Their home stadium is Paul Brown Stadium, located in downtown Cincinnati. Their divisional opponents are the Baltimore Ravens, Cleveland Browns and Pittsburgh Steelers.
The Bengals were founded in as a member of the American Football League (AFL) by former Cleveland Browns head coach Paul Brown, and began play in the 1968 season. Brown was the Bengals' head coach from their inception to . After being dismissed as the Browns' head coach by Art Modell (who had purchased majority interest in the team in ) in January , Brown had shown interest in establishing another NFL franchise in Ohio and looked at both Cincinnati and Columbus. He ultimately chose the former when a deal between the city, Hamilton County, and Major League Baseball's Cincinnati Reds (who were seeking a replacement for the obsolete Crosley Field) was struck that resulted in an agreement to build a multipurpose stadium which could host both baseball and football games.
Due to the impending merger of the AFL and the NFL, which was scheduled to take full effect in the season, Brown agreed to join the AFL as its tenth and final franchise. The Bengals, like the other former AFL teams, were assigned to the AFC following the merger. Cincinnati was also selected because, like their neighbors the Reds, they could draw from several large neighboring cities (Louisville and Lexington, Kentucky; Columbus, Dayton, and Springfield, Ohio) that are all no more than away from downtown Cincinnati, along with Indianapolis, until the Baltimore Colts relocated there prior to the 1984 NFL season.
The Bengals won the AFC championship in and , but lost Super Bowls XVI and XXIII to the San Francisco 49ers. After Paul Brown's death in 1991, controlling interest in the team was inherited by his son, Mike Brown. In 2011, Brown purchased shares of the team owned by the estate of co-founder Austin Knowlton and is now the majority owner of the Bengals franchise.
The 1990s and the 2000s were a period of great struggle. Following the 1990 season, the team went 14 years without posting a winning record, nor qualifying to play in the NFL playoffs. The Bengals had several head coaches and several of their top draft picks did not pan out. Mike Brown, the team's "de facto" general manager, was rated as among the worst team owners in American professional sports. The team's fortunes improved in the mid-2000s, which saw them become more consistent postseason contenders, but they have continued to struggle past the regular season and have not won a playoff game since 1990, which is the longest active drought in the NFL.
The Bengals are one of 12 NFL teams to not have won a Super Bowl and one of five to have not won a championship, pre or post-Super Bowl era. They are also the only AFL franchise to have not won a championship in the AFL or NFL.
In 1967, an ownership group led by Paul Brown was granted a franchise in the American Football League. Brown named the team the Bengals in order "to give it a link with past professional football in Cincinnati". Another Cincinnati Bengals team had existed in the city and played in three previous American Football Leagues from 1937 to 1942. The city's world-renowned zoo was also home to a rare white Bengal tiger. However, possibly as an insult to Art Modell, or possibly as a homage to his own start as a head coach to the Massillon Tigers, Brown chose the exact shade of orange used by his former team. He added black as the secondary color. Brown chose a very simple logo: the word "BENGALS" in black lettering. One of the potential helmet designs Brown rejected was a striped motif that was similar to the helmets adopted by the team in 1981 and which is still in use; however, that design featured yellow stripes on a turquoise helmet which were more uniform in width. The Bengals would begin play in the 1968 season.
In 1966, the American Football League agreed to a merger with its older and more established rival, the National Football League. Among the terms of the merger was that the AFL was permitted to add one additional franchise. One of the reasons the NFL agreed to this was that they wanted an even number of clubs in the merged league, so a team needed to be added that brought the combined total number clubs in the merged league to twenty-six teams. The NFL was content for that team to be in the American Football League because it meant that the existing nine AFL clubs were the ones that had to provide players in the ensuing expansion draft and the NFL owners preferred for the ensuing dilution of talent to occur in what they had always considered to be an inferior league. For the AFL, a key motive behind their agreement to accept a new team was that the guarantee of an eventual place in the NFL meant the league could charge a steep expansion fee of $10 million–400 times the $25,000 the original eight owners paid when they founded the league in 1960. The cash from the new team provided the American Football League with the funds needed to pay the indemnities required to be paid by the AFL to the NFL, as stipulated by the merger agreement.
Prior to the merger being announced, Brown had not seriously considered joining the American Football League, and was not a supporter of what he openly regarded to be an inferior competition, once famously stating that "I didn't pay ten million dollars to be in the AFL." However, with the announcement of the merger, Brown realized that the AFL expansion franchise would likely be his only realistic path back into the NFL in the short to medium term. He ultimately acquiesced to joining the AFL when after learning that the team was guaranteed to become an NFL franchise after the merger was completed in 1970.
There was also a complication: Major League Baseball's Cincinnati Reds were in need of a facility to replace the antiquated, obsolete Crosley Field, which they had used since 1912. Parking nightmares had plagued the city as far back as the 1950s, the little park lacked modern amenities, and New York City, which in 1957 had lost both its National League teams (the Dodgers and the Giants) to Los Angeles and San Francisco, respectively, was actively courting Reds owner Powel Crosley. However, Crosley was adamant that the Reds remain in Cincinnati and tolerated worsening problems with the Crosley Field location, which were exacerbated by the Mill Creek Expressway (I-75) project that ran alongside the park.
With assistance from Ohio governor James A. Rhodes, Hamilton County and the Cincinnati city council agreed to build a single multi-purpose facility on the dilapidated riverfront section of the city. The new facility had to be ready by the opening of the 1970 NFL season and was officially named Riverfront Stadium. With the completion of the merger in 1970, the Cleveland Browns were one of three NFL teams that voluntarily moved to the AFL-based American Football Conference to give both conferences an equal number of teams and placed in the AFC Central, the same division as the Bengals. An instant rivalry was born, fueled initially by Paul Brown's rivalry with Art Modell.
For their first two seasons, the Bengals played at Nippert Stadium which is the current home of the University of Cincinnati Bearcats. The team held training camp at Wilmington College in Wilmington, through the 1968 preseason. The team finished its first season with a 3–11 record and running back Paul Robinson, who rushed for 1,023 yards, and was named the AFL Rookie of the Year.
Founder Paul Brown coached the team for its first eight seasons. One of Brown's college draft strategies was to draft players with above-average intelligence. Punter/wide receiver Pat McInally attended Harvard University and linebacker Reggie Williams attended Dartmouth College and served on Cincinnati city council while on the Bengals' roster. Because of this policy, many former players were highly articulate and went on to have successful careers in commentary and broadcasting as well as the arts. In addition, Brown had a knack for locating and recognizing pro football talent in unusual places.
In 1971, the Bengals moved to play at Riverfront Stadium, a home they shared with the Cincinnati Reds until the team moved to Paul Brown Stadium in 2000. The team reached the playoffs three times during that decade, but could not win any of those postseason games. In 1975, the team posted an 11–3 record, giving them what is to this day the highest winning percentage (.786) in franchise history. But it only earned them a wild card spot in the playoffs, behind the 12–2 Pittsburgh Steelers, who went on to win the Super Bowl. The Bengals lost to the Oakland Raiders 31–28 in the divisional playoffs.
The Bengals reached the Super Bowl twice during the 1980s, in Super Bowl XVI and Super Bowl XXIII, but lost both times to the San Francisco 49ers. The team appeared in the playoffs in 1990, making it to the second round before losing to the Los Angeles Raiders. Before the following season got underway, Paul Brown died at age 82. He had already transferred control to his son, Mike Brown, but was reported to still influence the daily operations of the team. The Bengals' fortunes changed for the worse as the team posted 14 consecutive non-winning seasons and were saddled with numerous draft busts. They began to emerge from that dismal period into a new era of increased consistency, however, after the team finished with its worst record in history, 2–14, which led to the hiring of Marvin Lewis as head coach in 2003. Carson Palmer, the future star quarterback, was drafted in 2003, but did not play a snap that whole season, as Jon Kitna had a comeback year (voted NFL Comeback Player of the Year). Despite Kitna's success, Palmer was promoted to starting quarterback the following season. Under Palmer, the team advanced to the playoffs for the first time since 1990 in the 2005 season, which also was the first time the team had a winning percentage above .500 since 1990.
The Bengals returned to the playoffs again in 2009 in a season that included the franchise's first ever division sweep. This was especially impressive since two of the teams swept by the Bengals (the Pittsburgh Steelers and the Baltimore Ravens) had both made it to the AFC Championship Game the previous season. Marvin Lewis was rewarded for the accomplishment with the NFL Coach of the Year Award. In the 2010 season, the Bengals posted a 4–12 record.
Following the disappointing 2010 season, quarterback Carson Palmer demanded to be traded. When the Bengals refused to do so, Palmer announced his retirement from the NFL. He later was moved at the NFL trade deadline to the Oakland Raiders. In the 2011 NFL draft, the Bengals selected wide receiver AJ Green in the first round, and quarterback Andy Dalton in the second round. The Bengals improved to 9–7 in the 2011 season, and clinched a playoff spot. Dalton and Green became the most prolific rookie WR-QB duo in history, connecting 65 times for 1,057 yards. However, they lost to the Houston Texans 31–10 in the Wild Card Round. In the 2012 season, the Bengals clinched a playoff spot once more with a win over the Pittsburgh Steelers, going to the playoffs in back-to-back years for the first time since 1982. However, the Bengals faced the Texans in the first round yet again and took another early exit, losing 19–13.
In the 2013 season, for the third straight year, the Bengals clinched a playoff berth and also won the AFC North, finishing with an 11–5 record. But once again, the Bengals were defeated in the wild card round, this time by the San Diego Chargers, 27–10. Most of the blame was put on Andy Dalton, who threw 2 interceptions and fumbled on a forward dive. This made the Bengals 0–5 in playoff games since Mike Brown took over as owner. The 2014 season started well with the Bengals winning their first three contests against the Baltimore Ravens, the Atlanta Falcons, and the Tennessee Titans. However, they lost their week 5 matchup at the New England Patriots, 43–17. An overtime tie to the Carolina Panthers and shutout loss to the Indianapolis Colts followed the primetime loss to the Patriots. Finishing the season 10–5–1 as the 5th seed, they lost to the Colts, 26–10, in the first round of the playoffs. This was the first time the franchise made the playoffs four straight seasons.
In 2015, the Bengals got out to a franchise-best 8–0 start with a 31–10 win over the Cleveland Browns, but they then lost multiple consequtive games yet clinched a playoff berth. However, they lost to the division rival Pittsburgh Steelers, 18–16, in the Wild Card round in the final minute, making them the first franchise in NFL history to lose five straight opening round playoff games. This frustration continued in 2016 for the Bengals. The Bengals finished the 2016 campaign with a 6–9–1 record, losing several key players to injury including AJ Green, Giovani Bernard, and Jeremy Hill. They missed the playoffs for the first time since 2010, marking the first time Andy Dalton missed the playoffs as the Bengals' starting quarterback. One notable game was a 27–27 tie against the Washington Redskins which was played in London in 2016.
Following a rough 2016 season, the Bengals looked forward into 2017. However, after starting 0–3, the Bengals never found their footing. At one point in the season, the Bengals were 5–9. There were rumors that Marvin Lewis would not return for the next season as the Bengals' head coach. However, after two come-from-behind victories over the Lions and Ravens, that eliminated both teams from the playoffs, the Bengals finished 7–9. The final two games were convincing enough for owner Mike Brown to give Lewis a new two-year contract.
The 2018 campaign began with promise for the Bengals under Lewis. Cincinnati began the season with a 4-1 record with impressive wins over the Colts, Ravens, Falcons, and the Dolphins. However, the Bengals suffered many setbacks after the hot start. Defensive Coordinator Teryl Austin was fired mid-season because of defensive woes, AJ Green was injured and officially out for the last 4 games, and Andy Dalton injured his thumb in the Bengals' first game against the Browns and replaced by Jeff Driskel for the rest of the season. The Bengals ended 2018 with a final record of 6-10 and last place in the AFC North. On December 31, 2018, with one year to go on his contract, Lewis and the Bengals mutually parted ways after three straight losing seasons under his watch.
With Zac Taylor assuming the head coaching mantle, the 2019 campaign started off with reasonable success, barely losing to Seattle 21-20 in CenturyLink Field, but what started with promise, ended in disaster. The Bengals then lost 10 more games and were 0-11 heading into December 2019. To open the month of December, they got their first win against the Jets 22-6 in Cincinnati. They eventually lost to the Patriots and lost to the Dolphins 38-35 in OT after Dalton led the team back from 23 points down in the fourth quarter. With the loss to the Dolphins, the Bengals officially clinched the #1 Overall Pick in the 2020 NFL Draft. They'd cap off the season with a win against the underperforming Cleveland Browns, finishing 2-14, equaling the 2002 season as the team's worst record in history.
When the team debuted in 1968, the Bengals' uniforms were modeled after the Cleveland Browns. When Paul Brown was fired by Art Modell, Brown still owned the equipment used by Cleveland so, after the firing, Paul Brown packed up all his equipment which he then used for his new team in Cincinnati. The Cleveland Browns' team colors were brown, orange, and white, and their helmets were solid orange with a white dorsal stripe over the crest.
The Bengals' team colors were orange, black, and white, and their helmets were a similar shade of orange, with the only variations being the word "Bengals" in black block letters (with a white outline) on either side of the helmet and no stripe on the helmet. The Cincinnati Bengals were unique in the NFL as they did not have secondary uniform numbers on the jerseys (called "TV numbers") until the 1980 season, when they appeared on the sleeves; they were the only NFL team that did not have them prior to that point. That same year, the team changed their helmet facemask color from gray to black. The team did not discard their Cleveland-like uniforms until 1981. During that year, a then-unique uniform design was introduced. Although the team kept black jerseys, white jerseys, and white pants, they were now trimmed with orange and black tiger stripes. The team also introduced the orange helmets with black tiger stripes that are still in use today.
In 1997, the Bengals designed a logo consisting of a leaping tiger, and it was added to the uniform sleeves (with this, the "TV numbers" moved to the shoulder). Another alternate logo consisted of a Bengal's head facing to the left. However, the orange helmet with black tiger stripes continued to be the trademark. In 2004, a new tiger stripe pattern and more accents were added to the uniforms. The black jerseys now featured orange tiger-striped sleeves and white side panels, while the white jerseys began to use black tiger-striped sleeves and orange shoulders. A new logo consisting of an orange "B" covered with black tiger stripes was introduced. The team also started rotating black pants and debuted an alternate orange jersey, with white side panels and black tiger-striped sleeves. The Bengals have worn their black uniforms at home throughout their history, with some exceptions such as the 1970 season when the Bengals wore white at home for the entire season, and most of the 1971 season. Since 2005, the Bengals wear white for September home games where the heat could become a factor.
In 2016, the Bengals unveiled their all-white Color Rush alternate uniform, featuring black tiger stripes along the sleeves and pants. Orange was only used on the Nike mark and on the team logo.
The team's official mascot is a Bengal tiger named Who Dey. Aside from Who Dey, the team also has the Cincinnati Ben–Gals, the team's cheerleading squad, which included Laura Vikmanis, the oldest cheerleader in league history.
A no-huddle offense was commonly used by all teams when time in the game was running low. However, Sam Wyche, the head coach of the Bengals in 1988, along with offensive coordinator Bruce Coslet, made the high-paced offense the standard modality for the ball club regardless of time remaining. By quickly substituting and setting up for the next play—often within 5–10 seconds after the last play despite being afforded 45 seconds—the Bengals hindered the other team's defense from substituting situational players, regrouping for tactical purpose, and resting. In response the NFL instituted rules allowing the defense ample time for substitutions when offensive substitutions were made.
The hurry-up tactic was used by the franchise during the late 1980s while Sam Wyche was the coach. A rival for AFC supremacy during this time was the Buffalo Bills, coached by Marv Levy, who also used a version of the no-huddle offense starting with the 1989 season. The Bengals had beaten the Bills three times in 1988 (pre-season, regular season, and the AFC Championship Game). Marv Levy threatened to fake injuries if the Bengals used the "no-huddle" in the AFC Championship. Wyche was notified that the commissioner had ordered the "no-huddle" illegal for the game. The official notified Wyche and the Bengals' team just two hours before the game kickoff. Wyche asked to talk directly to the commissioner and word immediately came back that the "no-huddle" would not be penalized. Levy did not have his players fake injuries in the game, but installed his version the next year, 1989. The Bengals first used the "no-huddle" in 1984. Most of the high-profile games (the various games for AFC titles and regular season games) between the two led to these changes in NFL rules. Wyche also first used the timeout periods as an opportunity to bring his entire team to the sideline to talk to all eleven players, plus substitutes, at one time. This allowed trainers time to treat a cut or bruise and equipment managers time to repair an equipment defect.
The West Coast offense is the popular name for the high-percentage passing scheme designed by former Bengals assistant Bill Walsh. Walsh formulated what has become popularly known as the West Coast offense during his tenure as assistant coach for the Cincinnati Bengals from 1968 to 1975, while working under the tutelage of Brown (and before embarking on his legendary coaching tenure with the San Francisco 49ers in the 1980s). Bengals quarterback Virgil Carter was the first player to successfully implement Walsh's system, leading the NFL in pass completion percentage in 1971. Ken Anderson replaced Carter as Cincinnati's starting quarterback in 1972 and was even more successful. In 1975 he would bring widespread recognition to the West Coast offense as well as to the Cincinnati team and its quarterback in a nationally televised Monday night contest between the Bengals and a Buffalo Bills team built around the running game of star player O.J. Simpson. Anderson's 447 passing yards were enough to overcome Simpson's 197 yards on the ground in a game that proved a milestone, providing a striking contrast between the "old" game of defense-minded football and the new game of higher scores and more action through a sophisticated aerial attack. The game, in effect, offered its viewers a glimpse of the future of professional football. Anderson, who was drafted by Paul Brown in 1971 and installed as starting quarterback in 1972, made four trips to the Pro Bowl, won four passing titles, was named NFL MVP in 1981, and set the record for completion percentage in a single season in 1982 with 70.66%. Defeated frequently during the 1970s by the Pittsburgh Steelers, a team that won four Super Bowls with 9 future Hall of Fame players, the Bengals under Anderson and head coach Forrest Gregg would finally break through the Steel Curtain, defeating the Steelers during both of their meetings in 1980 and again in 1981. Anderson, who had been named the "team franchise" by Bengal tight end Bob Trumpy, would ultimately prove his worth with a career record of 91 wins and 81 losses.
The defense created to combat the West Coast offense also came from Cincinnati. Then-Bengals defensive coordinator Dick LeBeau (who later served as the team's head coach from 2000–2002) created the zone blitz in the 1980s in response to the West Coast offense.
Three members of the Hall of Fame have spent some portion of their career with the Bengals, but only Anthony Muñoz spent his entire career with the Bengals. Bengals founder and former coach Paul Brown is also in the Hall of Fame, however he was inducted before founding the Bengals and therefore is not recognized as a Bengals Hall of Famer.
In 2007, in celebration of their 40th anniversary the Bengals named an all-time team voted on by the fans.
The Bengals contract with iHeartMedia as their radio partner, with their flagship radio stations being WCKY (1530) and WEBN (102.7 FM), along with WLW (700) if not in conflict with the Reds. Most preseason and regular season games, are telecast on CBS affiliate WKRC-TV (channel 12). The current TV announcers for preseason games are Dan Hoard on play-by-play, and Dave Lapham as analyst.
"Who Dey?!" is the name of a chant of support by fans of the Cincinnati Bengals, in use since the 1980s. The entire chant is: "Who dey, who dey, who dey think gonna beat dem Bengals?" The answer screamed in unison, "Nobody." Sometimes fans will instead shout "Who Dey?" to represent the entire cheer. "Who Dey" is also the name of the team's mascot, a Bengal tiger.
The Who Dey chant was first known to be used by fans of the 1980 Cincinnati Bengals. While the origins of the chant is disputed, one possible source for the chant is a 1980 commercial for (the now-defunct) Red Frazier Ford of Cincinnati, which used this tagline: "Who's going to give you a better deal than Red Frazier?...Nobody!" Cincinnati fans who had seen the commercial many times may have just copied it when cheering.
The Who Dey chant is also steeped in local beer lore. Hudy, a leading product of Hudepohl Brewing Company through the late 1980s, bears a phonetic similarity to the "Who Dey" chant. Beer vendors who carried full cases of bottled local beer up and down the steep upper stairs of what was then Riverfront Stadium would call out "If Hudy", "Berger" and other local beer names. Raucous fans would often chant back and forth with them as the vendors called out. During the 1980 season the banter with the Hudepohl vendors grew organically into the now famous (Hu-Dey) -Who They?- chant.
The chant bears some similarities to the phrase "Who Dat?", which was officially adopted by the New Orleans Saints in 1983 but had been used by Louisiana's high school team fans for some time. The saying "Who Dat?" originated in minstrel shows and vaudeville acts in the late 19th and early 20th centuries, then it was taken up by New Orleans Jazz and various Big band folks in the 1920s and 1930s. In the late 1960s, local Louisiana High Schools, St. Augustine High School and Patterson High School reportedly have been using the cheer and Gulf Coast fans of Alcorn State University and Louisiana State University picked up the cheer in the 1970s. Southern University in Baton Rouge, Louisiana claims to have originated the cheer in the late 1960s in their version: "Who dat talking 'bout beating dem Jags?"

</doc>
<doc id="6613" url="https://en.wikipedia.org/wiki?curid=6613" title="Yangtze">
Yangtze

The Yangtze or Yangzi ( or ) is the longest river in Asia, the third-longest in the world and the longest in the world to flow entirely within one country. It rises at Jari Hill in the Tanggula Mountains (Tibetan Plateau) and flows in a generally easterly direction to the East China Sea. It is the sixth-largest river by discharge volume in the world. Its drainage basin comprises one-fifth of the land area of China, and is home to nearly one-third of the country's population.
The Yangtze has played a major role in the history, culture and economy of China. For thousands of years, the river has been used for water, irrigation, sanitation, transportation, industry, boundary-marking and war. The prosperous Yangtze River Delta generates as much as 20% of China's GDP. The Three Gorges Dam on the Yangtze is the largest hydro-electric power station in the world. In mid-2014, the Chinese government announced it was building a multi-tier transport network, comprising railways, roads and airports, to create a new economic belt alongside the river.
The Yangtze flows through a wide array of ecosystems and is habitat to several endemic and threatened species including the Chinese alligator, the narrow-ridged finless porpoise and the Yangtze sturgeon, but also was the home of the extinct Yangtze river dolphin (or "baiji") and Chinese paddlefish. In recent years, the river has suffered from industrial pollution, plastic pollution, agricultural runoff, siltation, and loss of wetland and lakes, which exacerbates seasonal flooding. Some sections of the river are now protected as nature reserves. A stretch of the upstream Yangtze flowing through deep gorges in western Yunnan is part of the Three Parallel Rivers of Yunnan Protected Areas, a UNESCO World Heritage Site.
Because the source of the Yangtze was not ascertained until modern times, the Chinese have given different names to lower and upstream sections of the river.
 () is the modern Chinese name for the lower of the Yangtze from its confluence with the Min River at Yibin in Sichuan to the river mouth at Shanghai. "Chang Jiang" literally means the "Long River." In Old Chinese, this stretch of the Yangtze was simply called "Jiang/Kiang" , a character of phono-semantic compound origin, combining the water radical with the homophone (now pronounced , but "*kˤoŋ" in Old Chinese). "Krong" was probably a word in the Austroasiatic language of local peoples such as the Yue. Similar to "*krong" in Proto-Vietnamese and "krung" in Mon, all meaning "river", it is related to modern Vietnamese "sông" (river) and Khmer "kôngkea" (water).
By the Han dynasty, had come to mean "any" river in Chinese, and this river was distinguished as the "Great River" (). The epithet (simplified version ), means "long", was first formally applied to the river during the Six Dynasties period.
Various sections of the Yangtze have local names. From Yibin to Yichang, the river through Sichuan and Chongqing Municipality is also known as the () or "Sichuan River."
In Hubei, the river is also called the () or the "Jing River" after Jingzhou, one of the Nine Provinces of ancient China. In Anhui, the river takes on the local name after the shorthand name for Anhui, (皖). And () or the "Yangzi River", from which the English name Yangtze is derived, is the local name for the Lower Yangtze in the region of Yangzhou. The name likely comes from an ancient ferry crossing called or (). Europeans who arrived in the Yangtze River Delta region applied this local name to the whole river. The dividing site between upstream and midstream is considered to be at Yichang and that between midstream and downstream at Hukou (Jiujiang).
The Jinsha River () is the name for of the Yangtze from Yibin upstream to the confluence with the Batang River near Yushu in Qinghai. From antiquity until the Ming dynasty, this stretch of the river was believed to be a tributary of the Yangtze while the Min River was thought to be the main course of the river above Yibin. The name "Jinsha" originates in the Song dynasty when the river attracted large numbers of gold prospectors. Gold prospecting along the Jinsha continues to this day. Prior to the Song dynasty, other names were used including, for example () from the Three Kingdoms period.
The Tongtian River () describes the section from Yushu up to the confluence with the Dangqu River. The name comes from a fabled river in the "Journey to the West". In antiquity, it was called the Yak River. In Mongolian, this section is known as the Murui-ussu ( "Winding Stream"). and sometimes confused with the nearby Baishui.
The Tuotuo River () is the official headstream of the Yangtze, and flows from the glaciers of the Gar Kangri and the Geladandong Massifs in the Tanggula Mountains of southwestern Qinghai to the confluence with the Dangqu River to form the Tongtian River. In Mongolian, this section of the river known as the "Ulaan Mörön" or the "Red River."
The Tuotuo is one of three main headstreams of the Yangtze. The Dangqu River (,  "Dāngqū") is the actual geographic headwater of the Yangtze. The name is derived the Classical Tibetan for "Marsh River" (,  "'Dam Chu"). The Chumar River (楚玛尔河) is the Chinese name for the northern headwater of the Yangtze, which flows from the Hoh Xil Mountains in Qinghai into the Tongtian. Chumar is Tibetan for the "Red River."
The river was called Quian () and Quianshui () by Marco Polo and appeared on the earliest English maps as Kian or Kiam, all recording dialects which preserved forms of the Middle Chinese pronunciation of as "Kæwng". By the mid-19th century, these romanizations had standardized as Kiang; "Dajiang", e.g., was rendered as "Ta-Kiang." "Keeang-Koo," "Kyang Kew," "Kian-ku," and related names derived from mistaking the Chinese term for the mouth of the Yangtze (,  "Jiāngkǒu") as the name of the river itself.
The name Blue River began to be applied in the 18th century, apparently owing to a former name of the Dam Chu or Min and to analogy with the Yellow River, but it was frequently explained in early English references as a 'translation' of "Jiang", "Jiangkou", or "Yangzijiang". Very common in 18th- and 19th-century sources, the name fell out of favor due to growing awareness of its lack of "any" connection to the river's Chinese names and to the irony of its application to such a muddy waterway.
Matteo Ricci's 1615 Latin account included descriptions of the "Ianſu" and "Ianſuchian." The posthumous account's translation of the name as "Son of the Ocean" shows that Ricci, who by the end of his life was fluent in literary Chinese, was introduced to it as the homophonic rather than the 'proper' . Further, although railroads and the Shanghai concessions subsequently turned it into a backwater, Yangzhou was the lower river's principal port for much of the Qing dynasty, directing Liangjiang's important salt monopoly and connecting the Yangtze with the Grand Canal to Beijing. (That connection also made it one of the "Yellow" River's principal ports between the floods of 1344 and the 1850s, during which time the Yellow River ran well south of Shandong and discharged into the ocean a mere few hundred kilometers from the mouth of the Yangtze.) By 1800, English cartographers such as Aaron Arrowsmith had adopted the French style of the name as Yang-tse or Yang-tse Kiang. The British diplomat Thomas Wade emended this to Yang-tzu Chiang as part of his formerly popular romanization of Chinese, based on the Beijing dialect instead of Nanjing's and first published in 1867. The spellings Yangtze and Yangtze Kiang was a compromise between the two methods adopted at the 1906 Imperial Postal Conference in Shanghai, which established postal romanization. Hanyu Pinyin was adopted by the PRC's First Congress in 1958, but it was not widely employed in English outside mainland China prior to the normalization of diplomatic relations between the United States and the PRC in 1979; since that time, the spelling Yangzi has also been used.
The source and upper reaches of the Yangtze are located in ethnic Tibetan areas of Qinghai. In Tibetan, the Tuotuo headwaters are the "Machu" (,  "rMa-chu",  "Red River" or (perhaps "Wound-[like Red] River?")). The Tongtian is the "Drichu" (,  "'Bri Chu",  "River of the Female Yak"; transliterated into Chinese as ,  "Zhíqū").
The river originates from several tributaries in the eastern part of the Tibetan Plateau, two of which are commonly referred to as the "source." Traditionally, the Chinese government has recognized the source as the Tuotuo tributary at the base of a glacier lying on the west of Geladandong Mountain in the Tanggula Mountains. This source is found at and while not the furthest source of the Yangtze, it is the highest source at above sea level. The true source of the Yangtze, hydrologically the longest river distance from the sea, is at Jari Hill at the head of the Dam Qu tributary, approximately southeast of Geladandong. This source was only discovered in the late 20th century and lies in wetlands at and above sea level just southeast of Chadan Township in Zadoi County, Yushu Prefecture, Qinghai. As the historical spiritual source of the Yangtze, the Geladandong source is still commonly referred to as the source of the Yangtze since the discovery of the Jari Hill source.
These tributaries join and the river then runs eastward through Qinghai (Tsinghai), turning southward down a deep valley at the border of Sichuan (Szechwan) and Tibet to reach Yunnan. In the course of this valley, the river's elevation drops from above to less than . The headwaters of the Yangtze are situated at an elevation of about . In its descent to sea level, the river falls to an altitude of at Yibin, Sichuan, the head of navigation for riverboats, and to at Chongqing (Chungking). Between Chongqing and Yichang (I-ch'ang), at an altitude of and a distance of about , it passes through the spectacular Yangtze Gorges, which are noted for their natural beauty but are dangerous to shipping.
It enters the basin of Sichuan at Yibin. While in the Sichuan basin, it receives several mighty tributaries, increasing its water volume significantly. It then cuts through Mount Wushan bordering Chongqing and Hubei to create the famous Three Gorges. Eastward of the Three Gorges, Yichang is the first city on the Yangtze Plain.
After entering Hubei, the Yangtze receives water from a number of lakes. The largest of these lakes is Dongting Lake, which is located on the border of Hunan and Hubei provinces, and is the outlet for most of the rivers in Hunan. At Wuhan, it receives its biggest tributary, the Han River, bringing water from its northern basin as far as Shaanxi.
At the northern tip of Jiangxi, Lake Poyang, the biggest freshwater lake in China, merges into the river. The river then runs through Anhui and Jiangsu, receiving more water from innumerable smaller lakes and rivers, and finally reaches the East China Sea at Shanghai.
Four of China's five main freshwater lakes contribute their waters to the Yangtze River. Traditionally, the upstream part of the Yangtze River refers to the section from Yibin to Yichang; the middle part refers to the section from Yichang to Hukou County, where Lake Poyang meets the river; the downstream part is from Hukou to Shanghai.
The origin of the Yangtze River has been dated by some geologists to about 45 million years ago in the Eocene, but this dating has been disputed. 
The Yangtze flows into the East China Sea and was navigable by ocean-going vessels up from its mouth even before the Three Gorges Dam was built.
The Yangtze is flanked with metallurgical, power, chemical, auto, building materials and machinery industrial belts and high-tech development zones. It is playing an increasingly crucial role in the river valley's economic growth and has become a vital link for international shipping to the inland provinces. The river is a major transportation artery for China, connecting the interior with the coast.
The river is one of the world's busiest waterways. Traffic includes commercial traffic transporting bulk goods such as coal as well as manufactured goods and passengers. Cargo transportation reached 795 million tons in 2005. River cruises several days long, especially through the beautiful and scenic Three Gorges area, are becoming popular as the tourism industry grows in China.
Flooding along the river has been a major problem. The rainy season in China is May and June in areas south of Yangtze River, and July and August in areas north of it. The huge river system receives water from both southern and northern flanks, which causes its flood season to extend from May to August. Meanwhile, the relatively dense population and rich cities along the river make the floods more deadly and costly. The most recent major floods were the 1998 Yangtze River Floods, but more disastrous were the 1954 Yangtze River Floods, which killed around 30,000 people.
Although the mouth of the Yellow River has fluctuated widely north and south of the Shandong peninsula within the historical record, the Yangtze has remained largely static. Based on studies of sedimentation rates, however, it is unlikely that the present discharge site predates the late Miocene ( Ma). Prior to this, its headwaters drained south into the Gulf of Tonkin along or near the course of the present Red River.
The Yangtze River is important to the cultural origins of southern China and Japan. Human activity has been verified in the Three Gorges area as far back as 27,000 years ago, and by the 5th millennium BC, the lower Yangtze was a major population center occupied by the Hemudu and Majiabang cultures, both among the earliest cultivators of rice. By the 3rd millennium  BC, the successor Liangzhu culture showed evidence of influence from the Longshan peoples of the North China Plain. What is now thought of as Chinese culture developed along the more fertile Yellow River basin; the "Yue" people of the lower Yangtze possessed very different traditions blackening their teeth, cutting their hair short, tattooing their bodies, and living in small settlements among bamboo groves and were considered barbarous by the northerners.
The Central Yangtze valley was home to sophisticated Neolithic cultures. Later it became the earliest part of the Yangtze valley to be integrated into the North Chinese cultural sphere. (Northern Chinese were active there from the Bronze Age).
In the lower Yangtze, two Yue tribes, the "Gouwu" in southern Jiangsu and the "Yuyue" in northern Zhejiang, display increasing Zhou (i.e., North Chinese) influence from the 9th century BC. Traditional accounts credit these changes to northern refugees (Taibo and Zhongyong in Wu and Wuyi in Yue) who assumed power over the local tribes, though these are generally assumed to be myths invented to legitimate them to other Zhou rulers. As the kingdoms of Wu and Yue, they were famed as fishers, shipwrights, and sword-smiths. Adopting Chinese characters, political institutions, and military technology, they were among the most powerful states during the later Zhou. In the middle Yangtze, the state of Jing seems to have begun in the upper Han River valley a minor Zhou polity, but it adapted to native culture as it expanded south and east into the Yangtze valley. In the process, it changed its name to Chu.
Whether native or nativizing, the Yangtze states held their own against the northern Chinese homeland: some lists credit them with three of the Spring and Autumn period's Five Hegemons and one of the Warring States' Four Lords. They fell in against themselves, however. Chu's growing power led its rival Jin to support Wu as a counter. Wu successfully sacked Chu's capital Ying in 506 BC, but Chu subsequently supported Yue in its attacks against Wu's southern flank. In 473 BC, King Goujian of Yue fully annexed Wu and moved his court to its eponymous capital at modern Suzhou. In 333 BC, Chu finally united the lower Yangtze by annexing Yue, whose royal family was said to have fled south and established the Minyue kingdom in Fujian. Qin was able to unite China by first subduing Ba and Shu on the upper Yangtze in modern Sichuan, giving them a strong base to attack Chu's settlements along the river.
The state of Qin conquered the central Yangtze region, previous heartland of Chu, in 278 BC, and incorporated the region into its expanding empire. Qin then used its connections along the Yangtze River the Xiang River to expand China into Hunan, Jiangxi and Guangdong, setting up military commanderies along the main lines of communication. At the collapse of the Qin Dynasty, these southern commanderies became the independent Nanyue Empire under Zhao Tuo while Chu and Han vied with each other for control of the north.
From the Han dynasty, the region of the Yangtze River grew ever more important to China's economy. The establishment of irrigation systems (the most famous one is Dujiangyan, northwest of Chengdu, built during the Warring States period) made agriculture very stable and productive, eventually exceeding even the Yellow River region. The Qin and Han empires were actively engaged in the agricultural colonization of the Yangtze lowlands, maintaining a system of dikes to protect farmland from seasonal floods. By the Song dynasty, the area along the Yangtze had become among the wealthiest and most developed parts of the country, especially in the lower reaches of the river. Early in the Qing dynasty, the region called Jiangnan (that includes the southern part of Jiangsu, the northern part of Zhejiang, and the southeastern part of Anhui) provided – of the nation's revenues.
The Yangtze has long been the backbone of China's inland water transportation system, which remained particularly important for almost two thousand years, until the construction of the national railway network during the 20th century. The Grand Canal connects the lower Yangtze with the major cities of the Jiangnan region south of the river (Wuxi, Suzhou, Hangzhou) and with northern China (all the way from Yangzhou to Beijing). The less well known ancient Lingqu Canal, connecting the upper Xiang River with the headwaters of the Guijiang, allowed a direct water connection from the Yangtze Basin to the Pearl River Delta.
Historically, the Yangtze became the political boundary between north China and south China several times (see History of China) because of the difficulty of crossing the river. This occurred notably during the Southern and Northern Dynasties, and the Southern Song. Many battles took place along the river, the most famous being the Battle of Red Cliffs in 208 AD during the Three Kingdoms period.
The Yangtze was the site of naval battles between the Song dynasty and Jurchen Jin during the Jin–Song wars. In the Battle of Caishi of 1161, the ships of the Jin emperor Wanyan Liang clashed with the Song fleet on the Yangtze. Song soldiers fired bombs of lime and sulfur using trebuchets at the Jurchen warships. The battle was a Song victory that halted the invasion by the Jin. The Battle of Tangdao was another Yangtze naval battle from the same year.
Politically, Nanjing was the capital of China several times, although most of the time its territory only covered the southeastern part of China, such as the Wu kingdom in the Three Kingdoms period, the Eastern Jin Dynasty, and during the Southern and Northern Dynasties and Five Dynasties and Ten Kingdoms periods. Only the Ming occupied most parts of China from their capital at Nanjing, though it later moved the capital to Beijing. The ROC capital was located in Nanjing in the periods 1911–12, 1927–37, and 1945–49.
The first merchant steamer in China, the "Jardine", was built to order for the firm of Jardine Matheson in 1835. She was a small vessel intended for use as a mail and passenger carrier between Lintin Island, Macau and Whampoa. However, after several trips, the Chinese authorities, for reasons best known to themselves, prohibited her entrance into the river. Lord Palmerston, the British Foreign Secretary who personified gunboat diplomacy, decided to wage war on China mainly on the "suggestions" of Jardine Matheson. In mid-1840, a large fleet of warships appeared on the China coast, and with the first cannon fire aimed at a British ship, the "Royal Saxon", the British started the First Opium War. The Imperial Government, forced to surrender, gave in to the demands of the British. British military was vastly superior during the conflict. British warships, constructed using such innovations as steam power combined with sail and the use of iron in shipbuilding, wreaked havoc on coastal towns; such ships (like the "Nemesis") were not only virtually indestructible using contemporary available weapons, but also highly mobile and able to support a gun platform with very heavy guns. In addition, the British troops were armed with modern rifled muskets and cannons, unlike the Qing forces. After the British took Canton, they sailed up the Yangtze and took the tax barges, a devastating blow to the Empire as it slashed the revenue of the imperial court in Beijing to just a small fraction of what it had been.
In 1842, the Qing authorities sued for peace, which concluded with the Treaty of Nanking signed on a gunboat in the river, negotiated in August of that year and ratified in 1843. In the treaty, China was forced to pay an indemnity to Britain, open five ports to Britain, and cede Hong Kong to Queen Victoria. In the supplementary Treaty of the Bogue, the Qing empire also recognized Britain as an equal to China and gave British subjects extraterritorial privileges in treaty ports.
The US, at the same time, wanting to protect its interests and expand trade, ventured the six hundred miles up the river to Hankow sometime in the 1860s, while the , a sidewheeler, made her way up the river to Yichang in 1874. The first , a sidewheel gunboat, began charting the Yangtze River in 1871. The first , an armed tug, was on Asiatic Station into 1891, cruising the Chinese and Japanese coasts, visiting the open treaty ports and making occasional voyages up the Yangtze River. From June to September 1891, anti-foreign riots up the Yangtze forced the warship to make an extended voyage as far as Hankou, 600 miles upriver. Stopping at each open treaty port, the gunboat cooperated with naval vessels of other nations and repairing damage. She then operated along the north and central China coast and on the lower Yangtze until June 1892. The cessation of bloodshed with the Taiping Rebellion, Europeans put more steamers on the river. The French engaged the Chinese in war over the rule of Vietnam. The Sino-French Wars of the 1880s emerged with the Battle of Shipu having French cruisers in the lower Yangtze.
The China Navigation Company was an early shipping company founded in 1876 in London, initially to trade up the Yangtze River from their Shanghai base with passengers and cargo. Chinese coastal trade started shortly after and in 1883 a regular service to Australia was initiated. Most of the company's ships were seized by Japan in 1941 and services did not resume until 1946. Robert Dollar was a later shipping magnate, who became enormously influential moving Californian and Canadian lumber to the Chinese and Japanese market.
Yichang, or Ichang, from the sea, is the head of navigation for river steamers; oceangoing vessels may navigate the river to Hankow, a distance of almost from the sea. For about inland from its mouth, the river is virtually at sea level.
The Chinese Government, too, had steamers. It had its own naval fleet, the Nanyang Fleet, which fell prey to the French fleet. The Chinese would rebuild its fleet, only to be ravaged by another war with Japan (1895), Revolution (1911) and ongoing inefficiency and corruption. Chinese companies ran their own steamers, but were second tier to European operations at the time.
Steamers came late to the upper river, the section stretching from Yichang to Chongqing. Freshets from Himalayan snowmelt created treacherous seasonal currents. But summer was better navigationally and the three gorges, described as an "150-mile passage which is like the narrow throat of an hourglass," posed hazardous threats of crosscurrents, whirlpools and eddies, creating significant challenges to steamship efforts. Furthermore, Chongqing is 700 – 800 feet above sea level, requiring powerful engines to make the upriver climb. Junk travel accomplished the upriver feat by employing 70–80 trackers, men hitched to hawsers who physically pulled ships upriver through some of the most risky and deadly sections of the three gorges. Achibald John Little took an interest in Upper Yangtze navigation when in 1876, the Chefoo Convention opened Chongqing to consular residence but stipulated that foreign trade might only commence once steamships had succeeded in ascending the river to that point. Little formed the Upper Yangtze Steam Navigation Co., Ltd. and built "Kuling" but his attempts to take the vessel further upriver than Yichang were thwarted by the Chinese authorities who were concerned about the potential loss of transit duties, competition to their native junk trade and physical damage to their crafts caused by steamship wakes. "Kuling" was sold to China Merchants Steam Navigation Company for lower river service. In 1890, the Chinese government agreed to open Chongqing to foreign trade as long as it was restricted to native crafts. In 1895, the Treaty of Shimonoseki provided a provision which opened Chongqing fully to foreign trade. Little took up residence in Chongqing and built "Leechuan", to tackle the gorges in 1898. In March "Leechuan" completed the upriver journey to Chongqing but not without the assistance of trackers. "Leechuan" was not designed for cargo or passengers and if Little wanted to take his vision one step further, he required an expert pilot. In 1898, Little persuaded Captain Samuel Cornell Plant to come out to China to lend his expertise. Captain Plant had just completed navigation of Persia's Upper Karun River and took up Little's offer to assess the Upper Yangtze on "Leechuan" at the end of 1898. With Plant's design input, Little had SS "Pioneer" built with Plant in command. In June 1900, Plant was the first to successfully pilot a merchant steamer on the Upper Yangtze from Yichang to Chongqing. "Pioneer" was sold to British Royal Navy after its first run due to threat from the Boxer Rebellion and renamed HMS "Kinsha". Germany's steamship effort that same year on SS "Suixing" ended in catastrophe. On "Suixing's" maiden voyage, the vessel hit a rock and sunk, killing its captain and ending realistic hopes of regular commercial steam service on the Upper Yangtze. In 1908, local Sichuan merchants and their government partnered with Captain Plant to form Sichuan Steam Navigation Company becoming the first successful service between Yichang and Chongqing. Captain Plant designed and commanded its two ships, SS "Shutung" and SS "Shuhun". Other Chinese vessels came onto the run and by 1915, foreign ships expressed their interest too. Plant was appointed by Chinese Maritime Customs Service as First Senior River Inspector in 1915. In this role, Plant installed navigational marks and established signaling systems. He also wrote "Handbook for the Guidance of Shipmasters on the Ichang-Chungking Section of the Yangtze River", a detailed and illustrated account of the Upper Yangtze's currents, rocks, and other hazards with navigational instruction. Plant trained hundreds of Chinese and foreign pilots and issued licenses and worked with the Chinese government to make the river safer in 1917 by removing some of the most difficult obstacles and threats with explosives. In August 1917, British Asiatic Petroleum became the first foreign merchant steamship on the Upper Yangtze. Commercial firms, Robert Dollar Company, Jardine Matheson, Butterfield and Swire and Standard Oil added their own steamers on the river between 1917 and 1919. Between 1918 and 1919, Sichuan warlord violence and escalating civil war put Sichuan Steam Navigational Company out of business. "Shutung" was commandeered by warlords and "Shuhun" was brought down river to Shanghai for safekeeping. In 1921, when Captain Plant died tragically at sea while returning home to England, a Plant Memorial Fund was established to perpetuate Plant's name and contributions to Upper Yangtze navigation. The largest shipping companies in service, Butterfield & Swire, Jardine Matheson, Standard Oil, Mackenzie & Co., Asiatic Petroleum, Robert Dollar, China Merchants S.N. Co. and British-American Tobacco Co., contributed alongside international friends and Chinese pilots. In 1924, a 50-foot granite pyramidal obelisk was erected in Xintan, on the site of Captain Plant's home, in a Chinese community of pilots and junk owners. One face of the monument is inscribed in Chinese and another in English. Though recently relocated to higher ground ahead of the Three Gorges Dam, the monument still stands overlooking the Upper Yangtze River near Yichang, a rare collective tribute to a westerner in China.
Until 1881, the India and China coastal and river services were operated by several companies. In that year, however, these were merged into the Indo-China Steam Navigation Company Ltd, a public company under the management of Jardine's. The Jardine company pushed inland up the Yangtsze River on which a specially designed fleet was built to meet all requirements of the river trade. Jardine's established an enviable reputation for the efficient handling of shipping. As a result, the Royal Mail Steam Packet Company invited the firm to attend to the Agency of their Shire Line, which operated in the Far East. Standard Oil ran the tankers Mei Ping, Mei An and Mei Hsia, which were collectively destroyed on December 12, 1937, when Japanese warplanes bombed and sank the U.S.S. Panay. One of the Standard Oil captains who survived this attack had served on the Upper River for 14 years.
With the Treaty Ports, the European powers and Japan were allowed to sail navy ships into China's waters. The British, Americans, and French did this. A full international fleet featured on Chinese waters: Austro-Hungarian, Portuguese, Italian, Russian and German navy ships came to Shanghai and the treaty ports. The Japanese engaged in open warfare with the Chinese over conquest of the Chinese Qing Empire in the First Sino-Japanese War in 1894–1895, and with Russia over Qing Empire territory in the Russo-Japanese War of 1904–1905. Incidentally, both the French and Japanese navies were heavily involved in running opium and narcotics to Shanghai, where it was refined into morphine. It was then transhipped by liner back to Marseille and France (i.e. French Connection) for processing in Germany and eventual sale in the U.S. or Europe.
In 1909 the gunboat changed station to Shanghai, where she regularly patrolled the lower Yangtze River up to Nanking and Wuhu. Following an anti-foreign riots in Changsha in April 1910, which destroyed a number of missions and merchant warehouses, Samar sailed up the Yangtze River to Hankow and then Changsa to show the flag and help restore order. The gunboat was also administratively assigned to the Asiatic Fleet that year, which had been reestablished by the Navy to better protect, in the words of the Bureau of Navigation, "American interests in the Orient." After returning to Shanghai in August, she sailed up river again the following summer, passing Wuhu in June but then running aground off Kichau on July 1, 1911.
After staying stuck in the mud for two weeks, Samar broke free and sailed back down river to coal ship. Returning upriver, the gunboat reached Hankow in August and Ichang in September where she wintered over owing to both the dry season and the outbreak of rebellion at Wuchang in October 1911. Tensions eased and the gunboat turned downriver in July 1912, arriving at Shanghai in October. Samar patrolled the lower Yangtze after fighting broke out in the summer 1913, a precursor to a decade of conflict between provincial warlords in China. In 1919, she was placed on the disposal list at Shanghai following a collision with a Yangtze River steamer that damaged her bow.
The Spanish boats were replaced in the 1920s by and were the largest, and next in size, and and the smallest. China in the first fifty years of the 20th century, was in low-grade chaos. Warlords, revolutions, natural disasters, civil war and invasions contributed. Yangtze boats were involved in the Nanking incident of 1927 when the Communists and Nationalists broke into open war. The Chiang Kai-shek's massacre of the Communists in Shanghai in 1927 furthered the unrest, U.S. Marines with tanks were landed. River steamers were popular targets for both Nationalists and Communists, and peasants who would take periodic pot-shots at vessels. During the course of service the second protected American interests in China down the entire length of the Yangtze, at times convoying U.S. and foreign vessels on the river, evacuating American citizens during periods of disturbance and in general giving credible presence to U.S. consulates and residences in various Chinese cities. In the period of great unrest in central China in the 1920s, Palos was especially busy patrolling the upper Yangtze against bands of warlord soldiers and outlaws. The warship engaged in continuous patrol operations between Ichang and Chungking throughout 1923, supplying armed guards to merchant ships, and protecting Americans at Chungking while that city was under siege by a warlord army.
The British Royal Navy had a series of Insect-class gunboats which patrolled between Chungking and Shanghai. Cruisers and destroyers and Fly-class gunboats also patrolled. The most infamous incident was when "Panay" and in 1937, were divebombed by Japanese airplanes during the notorious Nanking massacre. Westerners were forced to leave areas neighboring the Yangtze River with the Japanese takeover in 1941. The former steamers were either sabotaged or pressed into Japanese or Chinese service. Probably the most curious incident involved in 1949 during the Chinese Civil War between Kuomintang and People's Liberation Army forces; and led to the award of the Dickin Medal to the ship's cat Simon.
In August 2019, Welsh adventurer Ash Dykes became the first person to complete the 4,000-mile (6,437 km) trek along the course of the river, walking for 352 days from its source to its mouth.
Tens of millions of people live in the floodplain of the Yangtze valley, an area that naturally floods every summer and is habitable only because it is protected by river dikes. The floods large enough to overflow the dikes have caused great distress to those who live and farm there. Floods of note include those of 1931, 1954, and 1998.
The 1931 Central China floods or the Central China floods of 1931 were a series of floods that occurred in the Republic of China. The floods are generally considered among the deadliest natural disasters ever recorded, and almost certainly the deadliest of the 20th century (when pandemics and famines are discounted). Estimates of the total death toll range from 145,000 to between 3.7 million and 4 million. The Yangtze again flooded in 1935, causing great loss of life.
From June to September 1954, the Yangtze River Floods were a series of catastrophic floodings that occurred mostly in Hubei Province. Due to unusually high volume of precipitation as well as an extraordinarily long rainy season in the middle stretch of the Yangtze River late in the spring of 1954, the river started to rise above its usual level in around late June. Despite efforts to open three important flood gates to alleviate the rising water by diverting it, the flood level continued to rise until it hit the historic high of 44.67 m in Jingzhou, Hubei and 29.73 m in Wuhan. The number of dead from this flood was estimated at around 33,000, including those who died of plague in the aftermath of the disaster.
The 1998 Yangtze River floods were a series of major floods that lasted from middle of June to the beginning of September 1998 along the Yangtze.
In the summer of 1998, China experienced massive flooding of parts of the Yangtze River, resulting in 3,704 dead, 15 million homeless and $26 billion in economic loss. Other sources report a total loss of 4150 people, and 180 million people were affected. A staggering were evacuated, 13.3 million houses were damaged or destroyed. The floods caused $26 billion in damages.
The 2016 China floods caused US$22 billion in damages.
Beginning in the 1950s, dams and dikes were built for flood control, land reclamation, irrigation, and control of diseases vectors such as blood flukes that caused Schistosomiasis. More than a hundred lakes were thusly cut off from the main river. There were gates between the lakes that could be opened during floods. However, farmers and settlements encroached on the land next to the lakes although it was forbidden to settle there. When floods came, it proved impossible to open the gates since it would have caused substantial destruction. Thus the lakes partially or completely dried up. For example, Baidang Lake shrunk from in the 1950s to in 2005. Zhangdu Lake dwindled to one quarter of its original size. Natural fisheries output in the two lakes declined sharply. Only a few large lakes, such as Poyang Lake and Dongting Lake, remained connected to the Yangtze. Cutting off the other lakes that had served as natural buffers for floods increased the damage done by floods further downstream. Furthermore, the natural flow of migratory fish was obstructed and biodiversity across the whole basin decreased dramatically. Intensive farming of fish in ponds spread using one type of carp who thrived in eutrophic water conditions and who feeds on algae, causing widespread pollution. The pollution was exacerbated by the discharge of waste from pig farms as well as of untreated industrial and municipal sewage. In September 2012, the Yangtze river near Chongqing turned red from pollution. The erection of the Three Gorges Dam has created an impassable "iron barrier" that has led to a great reduction in the biodiversity of the river. Yangtze sturgeon use seasonal changes in the flow of the river to signal when is it time to migrate. However, these seasonal changes will be greatly reduced by dams and diversions. Other animals facing immediate threat of extinction are the baiji dolphin, narrow-ridged finless porpoise and the Yangtze alligator. These animals numbers went into freefall from the combined effects of accidental catches during fishing, river traffic, habitat loss and pollution. In 2006 the baiji dolphin became extinct; the world lost an entire genus.
The Yangtze River produces more ocean plastic pollution than any other, according to The Ocean Cleanup, a Dutch environmental research foundation that focuses on ocean pollution. Together with 9 other rivers, the Yangtze transports 90% of all the plastic that reaches the oceans.
In 2002 a pilot program was initiated to reconnect lakes to the Yangtze with the objective to increase biodiversity and to alleviate flooding. The first lakes to be reconnected in 2004 were Zhangdu Lake, Honghu Lake, and Tian'e-Zhou in Hubei on the middle Yangtze. In 2005 Baidang Lake in Anhui was also reconnected.
Reconnecting the lakes improved water quality and fish were able to migrate from the river into the lake, replenishing their numbers and genetic stock. The trial also showed that reconnecting the lake reduced flooding. The new approach also benefitted the farmers economically. Pond farmers switched to natural fish feed, which helped them breed better-quality fish that can be sold for more, increasing their income by 30%. Based on the successful pilot project, other provincial governments emulated the experience and also reestablished connections to lakes that had previously been cut off from the river. In 2005 a Yangtze Forum has been established bringing together 13 riparian provincial governments to manage the river from source to sea. In 2006 China's Ministry of Agriculture made it a national policy to reconnect the Yangtze River with its lakes. As of 2010, provincial governments in five provinces and Shanghai set up a network of 40 effective protected areas, covering . As a result, populations of 47 threatened species increased, including the critically endangered Yangtze alligator. In the Shanghai area, reestablished wetlands now protect drinking water sources for the city. It is envisaged to extend the network throughout the entire Yangtze to eventually cover 102 areas and . The mayor of Wuhan announced that six huge, stagnating urban lakes including the East Lake (Wuhan) would be reconnected at the cost of US$2.3 billion creating China's largest urban wetland landscape.
Until 1957, there were no bridges across the Yangtze River from Yibin to Shanghai. For millennia, travelers crossed the river by ferry. On occasions, the crossing may have been dangerous, as evidenced by the "Zhong'anlun" disaster (October 15, 1945).
The river stood as a major geographic barrier dividing northern and southern China. In the first half of the 20th century, rail passengers from Beijing to Guangzhou and Shanghai had to disembark, respectively, at Hanyang and Pukou, and cross the river by steam ferry before resuming journeys by train from Wuchang or Nanjing West.
After the founding of the People's Republic in 1949, Soviet engineers assisted in the design and construction of the Wuhan Yangtze River Bridge, a dual-use road-rail bridge, built from 1955 to 1957. It was the first bridge across the Yangtze River. The second bridge across the river that was built was a single-track railway bridge built upstream in Chongqing in 1959. The Nanjing Yangtze River Bridge, also a road-rail bridge, was the first bridge to cross the lower reaches of the Yangtze, in Nanjing. It was built after the Sino-Soviet Split and did not receive foreign assistance. Road-rail bridges were then built in Zhicheng (1971) and Chongqing (1980).
Bridge-building slowed in the 1980s before resuming in the 1990s and accelerating in the first decade of the 21st century. The Jiujiang Yangtze River Bridge was built in 1992 as part of the Beijing-Jiujiang Railway. A second bridge in Wuhan was completed in 1995. By 2005, there were a total of 56 bridges and one tunnel across the Yangtze River between Yibin and Shanghai. These include some of the longest suspension and cable-stayed bridges in the world on the Yangtze Delta: Jiangyin Suspension Bridge (1,385 m, opened in 1999), Runyang Bridge (1,490 m, opened 2005), Sutong Bridge (1,088 m, opened 2008). The rapid pace of bridge construction has continued. The city of Wuhan now has six bridges and one tunnel across the Yangtze.
A number of power line crossings have also been built across the river.
As of 2007, there are two dams built on the Yangtze river: Three Gorges Dam and Gezhouba Dam.
The Three Gorges Dam is the largest power station in the world by installed capacity, at 22.5 GW.
Several dams are operating or are being constructed on the upper portion of the river, the Jinsha River.
Among them, the Xiluodu Dam is the third largest power stations in the world, and the Baihetan Dam, planned to be commissioned in 2021, will be the second largest after the Three Gorges Dam.
The Yangtze River has over 700 tributaries. The major tributaries (listed from upstream to downstream) with the locations of where they join the Yangtze are:
The Huai River flowed into the Yellow Sea until the 20th century, but now primarily discharges into the Yangtze.
The Yangtze River has a high species richness, including many endemics. A high percentage of these are seriously threatened by human activities.
, 416 fish species are known from the Yangtze basin, including 362 that strictly are freshwater species. The remaining are also known from salt or brackish waters, such as the river's estuary or the East China Sea. This makes it one of the most species-rich rivers in Asia and by far the most species-rich in China (in comparison, the Pearl River has almost 300 fish species and the Yellow River 160). 178 fish species are endemic to the Yangtze River Basin. Many are only found in some section of the river basin and especially the upper reach (above Yichang, but below the headwaters in the Qinghai-Tibet Plateau) is rich with 279 species, including 147 Yangtze endemics and 97 strict endemics (found only in this part of the basin). In contrast, the headwaters, where the average altitude is above , are only home to 14 highly specialized species, but 8 of these are endemic to the river. The largest orders in the Yangtze are Cypriniformes (280 species, including 150 endemics), Siluriformes (40 species, including 20 endemics), Perciformes (50 species, including 4 endemics), Tetraodontiformes (12 species, including 1 endemic) and Osmeriformes (8 species, including 1 endemic). No other order has more than four species in the river and one endemic.
Many Yangtze fish species have declined drastically and 65 were recognized as threatened in the 2009 Chinese red list. Among these are three that are considered entirely extinct (Chinese paddlefish, "Anabarilius liui liui" and "Atrilinea macrolepis"), two that are extinct in the wild ("Anabarilius polylepis", "Schizothorax parvus"), four that are critically endangered "Euchiloglanis kishinouyei", "Megalobrama elongata", "Schizothorax longibarbus" and "Leiocassis longibarbus"). Additionally, both the Yangtze sturgeon and Chinese sturgeon are considered critically endangered by the IUCN. The survival of these two sturgeon may rely on the continued release of captive bred specimens. Although still listed as critically endangered rather than extinct by both the Chinese red list and IUCN, recent reviews have found that the Chinese paddlefish is extinct. Surveys conducted between 2006 and 2008 by ichthyologists failed to catch any, but two probable specimens were recorded with hydroacoustic signals. The last definite record was an individual that was accidentally captured near Yibin in 2003 and released after having been radio tagged. The Chinese sturgeon is the largest fish in the river and among the largest freshwater fish in the world, reaching a length of ; the extinct Chinese paddlefish reputedly reached as much as , but its maximum size is labeled with considerable uncertainty.
The largest threats to the Yangtze native fish are overfishing and habitat loss (such as building of dams and land reclamation), but pollution, destructive fishing practices (such as fishing with dynamite or poison) and introduced species also cause problems. About of the total freshwater fisheries in China are in the Yangtze Basin, but a drastic decline in size of several important species has been recorded, as highlighted by data from lakes in the river basin. In 2015, some experts recommend a 10-year fishing moratorium to allow the remaining populations to recover, and in January 2020 China imposed a 10-year fishing moratorium on 332 sites along the Yangtze. Dams present another serious problem, as several species in the river perform breeding migrations and most of these are non-jumpers, meaning that normal fish ladders designed for salmon are ineffective. For example, the Gezhouba Dam blocked the migration of the paddlerfish and two sturgeon, while also effectively splitting the Chinese high fin banded shark population into two and causing the extirpation of the Yangtze population of the Japanese eel. In an attempt of minimizing the effect of the dams, the Three Gorges Dam has released water to mimic the (pre-dam) natural flooding and trigger the breeding of carp species downstream. In addition to dams already built in the Yangtze basin, several large dams are planned and these may present further problems for the native fauna.
While many fish species native to the Yangtze are seriously threatened, others have become important in fish farming and introduced widely outside their native range. A total of 26 native fish species of the Yangtze basin are farmed. Among the most important are four Asian carp: grass carp, black carp, silver carp and bighead carp. Other species that support important fisheries include northern snakehead, Chinese perch, "Takifugu" pufferfish (mainly in the lowermost sections) and predatory carp.
Due to commercial use of the river, tourism, and pollution, the Yangtze is home to several seriously threatened species of large animals (in addition to fish): the narrow-ridged finless porpoise, baiji (Yangtze river dolphin), Chinese alligator, Yangtze giant softshell turtle and Chinese giant salamander. This is the only other place besides the United States that is native to an alligator and paddlefish species. In 2010, the Yangtze population of finless porpoise was 1000 individuals. In December 2006, the Yangtze river dolphin was declared functionally extinct after an extensive search of the river revealed no signs of the dolphin's inhabitance. In 2007, a large, white animal was sighted and photographed in the lower Yangtze and was tentatively presumed to be a "baiji". However, as there have been no confirmed sightings since 2004, the "baiji" is presumed to be functionally extinct at this time. "Baijis were the last surviving species of a large lineage dating back seventy million years and one of only six species of freshwater dolphins." It has been argued that the extinction of the Yangtze river dolphin was a result of the completion of the Three Gorges Dam, a project that has affected many species of animals and plant life found only in the gorges area.
Numerous species of land mammals are found in the Yangtze valley, but most of these are not directly associated with the river. Three exceptions are the semi-aquatic Eurasian otter, water deer and Père David's deer.
In addition to the very large and exceptionally rare Yangtze giant softshell turtle, several smaller turtle species are found in the Yangtze basin, its delta and valleys. These include the Chinese box turtle, yellow-headed box turtle, Pan's box turtle, Yunnan box turtle, yellow pond turtle, Chinese pond turtle, Chinese stripe-necked turtle and Chinese softshell turtle, which all are considered threatened.
More than 160 amphibian species are known from the Yangtze basin, including the world's largest, the critically endangered Chinese giant salamander. It has declined drastically due to hunting (it is considered a delicacy), habitat loss and pollution. The polluted Dian Lake, which is part of the upper Yangtze watershed (via Pudu River), is home to several highly threatened fish, but was also home to the Yunnan lake newt. This newt has not been seen since 1979 and is considered extinct. In contrast, the Chinese fire belly newt from the lower Yangtze basin is one of the few Chinese salamander species to remain common and it is considered least concern by the IUCN.
The Yangtze basin contains a large number of freshwater crab species, including several endemics. A particularly rich genus in the river basin is the potamid "Sinopotamon". The Chinese mitten crab is catadromous (migrates between fresh and saltwater) and it has been recorded up to up the Yangtze, which is the largest river in its native range. It is a commercially important species in its native range where it is farmed, but the Chinese mitten crab has also been spread to Europe and North America where considered invasive.
The freshwater jellyfish "Craspedacusta sowerbii", now an invasive species in large parts of the world, originates from the Yangtze.

</doc>
<doc id="6614" url="https://en.wikipedia.org/wiki?curid=6614" title="Chrono Trigger">
Chrono Trigger

"Chrono Trigger" was a critical and commercial success upon release, and is frequently cited as one of the greatest video games of all time. "Nintendo Power" magazine described aspects of "Chrono Trigger" as revolutionary, including its multiple endings, plot-related side-quests focusing on character development, unique battle system, and detailed graphics. "Chrono Trigger" was the third best-selling game of 1995 in Japan, and shipped 2.65 million copies worldwide by March 2003.
Square released a ported version by Tose in Japan for the PlayStation in 1999, which was later repackaged with a "Final Fantasy IV" port as "Final Fantasy Chronicles" (2001) for the North American market. A slightly enhanced "Chrono Trigger", again ported by Tose, was released for the Nintendo DS in North America and Japan in 2008, and PAL regions in 2009. The Nintendo DS version sold 790,000 copies by March 2009, after about a year of sales. "Chrono Trigger" has also been ported to i-mode mobile phones, the Virtual Console, the PlayStation Network, iOS devices, Android devices, and Microsoft Windows.
"Chrono Trigger" features standard role-playing video game gameplay. The player controls the protagonist and his companions in the game's two-dimensional world, consisting of various forests, cities, and dungeons. Navigation occurs via an overworld map, depicting the landscape from a scaled-down overhead view. Areas such as forests, cities, and similar places are depicted as more realistic scaled-down maps, in which players can converse with locals to procure items and services, solve puzzles and challenges, or encounter enemies. "Chrono Trigger" gameplay deviates from that of traditional Japanese RPGs in that, rather than appearing in random encounters, many enemies are openly visible on field maps or lie in wait to ambush the party. Contact with enemies on a field map initiates a battle that occurs directly on the map rather than on a separate battle screen.
Players and enemies may use physical or magical attacks to wound targets during battle, and players may use items to heal or protect themselves. Each character and enemy has a certain number of hit points; successful attacks reduce that character's hit points, which can be restored with potions and spells. When a playable character loses all hit points, they faint; if all the player's characters fall in battle, the game ends and must be restored from a previously saved chapter, except in specific storyline-related battles that allow or force the player to lose. Between battles, a player can equip their characters with weapons, armor, helmets, and accessories that provide special effects (such as increased attack power or defense against magic), and various consumable items can be used both in and out of battles. Items and equipment can be purchased in shops or found on field maps, often in treasure chests. By exploring new areas and fighting enemies, players progress through "Chrono Trigger" story.
"Chrono Trigger" uses an "Active Time Battle" system—a recurring element of Square's "Final Fantasy" game series designed by Hiroyuki Ito for "Final Fantasy IV"—named "Active Time Battle 2.0." Each character can take action in battle once a personal timer dependent on the character's speed statistic counts to zero. Magic and special physical techniques are handled through a system called "Techs." Techs deplete a character's magic points (a numerical meter similar to hit points), and often have special areas of effect; some spells damage huddled monsters, while others can harm enemies spread in a line. Enemies often change positions during battle, creating opportunities for tactical Tech use. A unique feature of "Chrono Trigger"'s Tech system is that numerous cooperative techniques exist. Each character receives eight personal Techs which can be used in conjunction with others' to create Double and Triple Techs for greater effect. For instance, Crono's sword-spinning "Cyclone" Tech can be combined with Lucca's "Flame Toss" to create "Flame Whirl". When characters with compatible Techs have enough magic points available to perform their techniques, the game automatically displays the combo as an option.
"Chrono Trigger" features several other distinct gameplay traits, including time travel. Players have access to seven eras of the game world's history, and past actions affect future events. Throughout history, players find new allies, complete side quests, and search for keynote villains. Time travel is accomplished via portals and pillars of light called "time gates", as well as a time machine named "Epoch". The game contains thirteen unique endings; the ending the player receives depends on when and how they reach and complete the game's final battle. "Chrono Trigger DS" features a new ending that can be accessed from the End of Time upon completion of the final extra dungeon and optional final boss. "Chrono Trigger" also introduces a New Game Plus option; after completing the game, the player may begin a new game with the same character levels, techniques, and equipment, excluding money, with which they ended the previous playthrough. However, certain items central to the storyline are removed and must be found again, such as the sword Masamune. Square has employed the New Game Plus concept in later games including "Chrono Cross", "Parasite Eve", "Vagrant Story", "Final Fantasy X-2", and "".
"Chrono Trigger" takes place in a world similar to Earth, with eras such as the prehistoric age, in which primitive humans and dinosaurs share the earth; the Middle Ages, replete with knights, monsters, and magic; and the post-apocalyptic future, where destitute humans and sentient robots struggle to survive. The characters frequently travel through time to obtain allies, gather equipment, and learn information to help them in their quest. The party also gains access to the End of Time (represented as year ∞), which serves as a hub to travel back to other time periods. The party eventually acquires a time-machine vehicle known as the "Wings of Time," nicknamed the "Epoch" (this default name can be changed by the player when the vehicle is acquired)."." The vehicle is capable of time travel between any time period without first having to travel to the End of Time.
"Chrono Trigger"'s six playable characters (plus one optional character) come from different eras of history. "Chrono Trigger" begins in AD 1000 with Crono, Marle, and Lucca. Crono is the silent protagonist, characterized as a fearless young man who wields a katana in battle. Marle, revealed to be Princess Nadia, lives in Guardia Castle; though sheltered, at heart, she's a princess who seeks independence from her royal identity. Lucca is a childhood friend of Crono's and a mechanical genius; her home is filled with laboratory equipment and machinery. From the era of AD 2300 comes Robo, or Prometheus (designation R-66Y), a robot with a near-human personality created to assist humans. Lying dormant in the future, Robo is found and repaired by Lucca, and joins the group out of gratitude. The fiercely confident Ayla dwells in 65,000,000 BC. Unmatched in raw strength, Ayla is the chief of Ioka Village and leads her people in war against a species of humanoid reptiles known as Reptites.
The last two playable characters are Frog and Magus. Frog originated in AD 600. He is a former squire once known as Glenn, who was turned into an anthropomorphic frog by Magus, who also killed his friend Cyrus. Chivalrous but mired in regret, Frog dedicates his life to protecting Leene, the queen of Guardia, and avenging Cyrus. Meanwhile, Guardia in AD 600 is in a state of conflict against the Mystics (known as Fiends in the US/DS port), a race of demons and intelligent animals who wage war against humanity under the leadership of Magus, a powerful sorcerer. Magus's seclusion conceals a long-lost past; he was formerly known as Janus, the young prince of the Kingdom of Zeal, which was destroyed by Lavos in 12,000 BC. The incident sent him forward through time, and as he ages, he plots revenge against Lavos and broods over the fate of his sister, Schala. Lavos, the game's main antagonist who awakens and ravages the world in AD 1999, is an extraterrestrial, parasitic creature that harvests DNA and the Earth's energy for its own growth.
In AD 1000, Crono and Marle watch Lucca and her father demonstrate her new teleporter at the Millennial Fair in the Kingdom of Guardia. When Marle volunteers to be teleported, her pendant interferes with the device and creates a time portal into which she is drawn. After Crono and Lucca separately recreate the portal and find themselves in AD 600, they find Marle only to see her vanish before their eyes. Lucca realizes that this time period's kingdom has mistaken Marle— actually Princess Nadia of Guardia— for Queen Leene, an ancestor of hers who had been kidnapped, thus putting off the recovery effort for her ancestor and creating a grandfather paradox. Crono and Lucca, with the help of Frog, restore history to normal by rescuing Leene. After the three part ways with Frog and return to the present, Crono is arrested on charges of kidnapping Marle and sentenced to death by the current chancellor of Guardia. Lucca and Marle help Crono to flee, haphazardly using another time portal to escape their pursuers. This portal lands them in AD 2300, where they learn that an advanced civilization has been wiped out by a giant creature known as Lavos that appeared in 1999. The three vow to find a way to prevent the future destruction of their world. After meeting and repairing Robo, Crono and his friends find Gaspar, an old sage at the End of Time, who helps them acquire magical powers and travel through time by way of several pillars of light (from this point onwards, the party is able to challenge Lavos; doing so and emerging victorious will unlock one of twelve different endings, depending on the point in the story at which Lavos is fought, as well as whether or not certain actions are completed beforehand).
Research in AD 1000 tells the party about Magus summoning Lavos into the world in 600 AD, but Frog needs to reforge the legendary sword, Masamune, to open the way to Magus's castle. To get the ore to reforge it, they travel to prehistoric times and meet Ayla. After returning to AD 600, they challenge Magus, believing him to be the source of Lavos; the battle disrupts the spell Magus was using to summon Lavos and causes a time gate that throws Crono and his friends to the past. Back in prehistory, Ayla joins the group to battle the Reptites and witness the true origin of Lavos when the Reptites' ruler calls him down from the stars to crash into the planet. Entering a gate created by Lavos's impact, they go to BC 12,000, an ice age, where the party finds the Kingdom of Zeal, who recently discovered Lavos and seeks to drain its power to achieve immortality through the Mammon Machine. Zeal's leader, Queen Zeal, imprisons Crono and friends on orders of the Prophet, a mysterious figure who has recently begun advising the queen. Though Zeal's daughter Schala frees them, the Prophet forces her to banish them from the realm and seal the time gate they used to travel to the Dark Ages. They return next to AD 2300 to find a time machine called the Wings of Time (or "Epoch"), which can access any time period without using a time gate. They travel back to BC 12000 but fail to stop Zeal from activating the Mammon Machine in the Ocean Palace. Lavos awakens, disturbed by the Mammon Machine; the Prophet reveals himself to be Magus, and unsuccessfully tries to kill the creature. The party is beaten, and a broken Crono stands up to Lavos before being vaporized by a powerful blast. Schala transports the rest of the party back to the surface before Lavos destroys the Ocean palace and the Kingdom of Zeal, causing a devastating flood that submerges most of the world.
Crono's friends awaken in a village and find Magus, who confesses that he used to be Prince Janus of Zeal. In his memories, it is revealed that the disaster at the Ocean Palace scattered the Gurus of Zeal across time and sent him to the Middle Ages. Janus took the title of Magus and gained a cult of followers while plotting to summon and kill Lavos in revenge for the death of his sister, Schala. When Lavos appeared after his battle with Crono and his allies, he was cast back to the time of Zeal and presented himself to them as a prophet. At this point, Magus is either killed by the party, killed in a duel with Frog, or spared and convinced to join the party. As Crono's friends depart, the ruined Ocean Palace rises into the air as the Black Omen. The group turns to Gaspar for help, and he gives them a "Chrono Trigger," an egg-shaped device that allows the group to replace Crono just before the moment of death with a Dopple Doll (doing so is optional, and the game's ending will change depending on the player's decision in this matter). The party then gather power by helping people across time with Gaspar's instructions. Their journeys involve defeating the remnants of the Mystics, stopping Robo's maniacal AI creator, giving Frog closure for Cyrus' death, locating and charging up the mythical Sun Stone, retrieving the legendary Rainbow Shell, unmasking Guardia's Chancellor as a monster, helping restore a forest destroyed by a desert monster, and preventing an accident that crippled Lucca's mother. The group enters the Black Omen and defeats Queen Zeal, then battles Lavos; once faced with the creature's true form, they come to understand that it had been absorbing DNA and energy from every living creature before arising and razing the planet's surface in 1999 so that it could spawn a new generation to destroy other worlds. After slaying Lavos and saving the future, they celebrate at the final night of the Millennial Fair before returning to their own times.
If Magus joined the party, he departs to search for Schala. If Crono was resurrected before defeating Lavos, his sentence for kidnapping Marle is revoked by her father, King Guardia XXXIII, thanks to testimonies from Marle's ancestors and descendants, whom Crono had helped during his journey. Crono's mother accidentally enters the time gate at the Millennial Fair before it closes, prompting Crono, Marle, and Lucca to set out in the Epoch to find her while fireworks light up the night sky. If Crono was not resurrected, Frog, Robo, and Ayla (along with Magus if he was recruited) chase Gaspar to the Millennial Fair and back again, revealing that Gaspar knows how to resurrect Crono; Marle and Lucca then use the Epoch to travel through time and figure out how to achieve this. Alternatively, if the party used the Epoch to break Lavos's outer shell, Marle will help her father hang Nadia's bell at the festival and accidentally get carried away by several balloons. If resurrected, Crono jumps on to help her, but cannot bring them down to earth. Hanging on in each other's arms, the pair travel through the cloudy, moonlit sky.
"Chrono Trigger DS" added two new scenarios to the game In the first, Crono and his friends can help a "lost sanctum" of Reptites, who reward powerful items and armor. The second scenario adds ties to "Trigger"'s sequel, "Chrono Cross". In a New Game +, the group can explore several temporal distortions to combat shadow versions of Crono, Marle, and Lucca, and to fight Dalton, who promises in defeat to raise an army in the town of Porre to destroy the Kingdom of Guardia. The group can then fight the Dream Devourer, a prototypical form of the "Time Devourer"—a fusion of Schala and Lavos seen in "Chrono Cross". A version of Magus pleads with Schala to resist; though she recognizes him as her brother, she refuses to be helped and sends him away. Schala subsequently erases his memories and Magus awakens in a forest, determined to find what he had lost.
"Chrono Trigger" was conceived in 1992 by Hironobu Sakaguchi, producer and creator of the "Final Fantasy" series; Yuji Horii, writer, game designer and creator of the "Dragon Quest" series; and Akira Toriyama, character designer of "Dragon Quest" and creator of the "Dragon Ball" manga series. Traveling to the United States to research computer graphics, the three decided to create something that "no one had done before". After spending over a year considering the difficulties of developing a new game, they received a call from Kazuhiko Aoki, who offered to produce. The four met and spent four days brainstorming ideas for the game. Square convened 50–60 developers, including scenario writer Masato Kato, whom Square designated story planner. Development started in early 1993. An uncredited Square employee suggested that the team develop a time travel-themed game, which Kato initially opposed, fearing repetitive, dull gameplay. Kato and Horii then met several hours per day during the first year of development to write the game's plot. Square intended to license the work under the "Seiken Densetsu" franchise and gave it the working title "Maru Island"; Hiromichi Tanaka (the future producer of "Chrono Cross") monitored Toriyama's early designs. The team hoped to release it on Nintendo's planned Super Famicom Disk Drive; when Nintendo canceled the project, Square reoriented the game for release on a Super Famicom cartridge and rebranded it as "Chrono Trigger". Tanaka credited the ROM cartridge platform for enabling seamless transition to battles on the field map.
Aoki ultimately produced "Chrono Trigger", while director credits were attributed to Akihiko Matsui, Yoshinori Kitase and Takashi Tokita. Toriyama designed the game's aesthetic, including characters, monsters, vehicles, and the look of each era. Masato Kato also contributed character ideas and designs. Kato planned to feature Gaspar as a playable character and Toriyama sketched him, but he was cut early in development. The development staff studied the drawings of Toriyama to approximate his style. Sakaguchi and Horii supervised; Sakaguchi was responsible for the game's overall system and contributed several monster ideas. Other notable designers include Tetsuya Takahashi, the graphic director, and Yasuyuki Honne, Tetsuya Nomura, and Yusuke Naora, who worked as field graphic artists. Yasuhiko Kamata programmed graphics, and cited Ridley Scott's visual work in the film "Alien" as an inspiration for the game's lighting. Kamata made the game's luminosity and color choice lay between that of "Secret of Mana" and the "Final Fantasy" series. Features originally intended to be used in "Secret of Mana" or "Final Fantasy IV", also under development at the same time, were appropriated by the "Chrono Trigger" team. According to Tanaka, "Secret of Mana" (which itself was originally intended to be "Final Fantasy IV") was codenamed "Chrono Trigger" during development before being called "Seiken Densetsu 2" ("Secret of Mana"), and then the name "Chrono Trigger" was adopted for a new project.
Yuji Horii, a fan of time travel fiction (such as the TV series "The Time Tunnel"), fostered a theme of time travel in his general story outline of "Chrono Trigger" with input from Akira Toriyama. Horii liked the scenario of the grandfather paradox surrounding Marle. Concerning story planning, Horii commented, "If there's a fairground, I just write that there's a fairground; I don't write down any of the details. Then the staff brainstorm and come up with a variety of attractions to put in." Sakaguchi contributed some minor elements, including the character Gato; he liked Marle's drama and reconciliation with her father. Masato Kato subsequently edited and completed the outline by writing the majority of the game's story, including all the events of the 12,000 BC era. He took pains to avoid what he described as "a long string of errands ... [such as] 'do this', 'take this', 'defeat these monsters', or 'plant this flag'." Kato and other developers held a series of meetings to ensure continuity, usually attended by around 30 personnel. Kato and Horii initially proposed Crono's death, though they intended he stay dead; the party would have retrieved an earlier, living version of him to complete the quest. Square deemed the scenario too depressing and asked that Crono be brought back to life later in the story. Kato also devised the system of multiple endings because he could not branch the story out to different paths. Yoshinori Kitase and Takashi Tokita then wrote various subplots. They also devised an "Active Time Event Logic" system, "where you can move your character around during scenes, even when an NPC is talking to you", and with players "talking to different people and steering the conversation in different directions", allowing each scene to "have many permutations." Kato became friends with composer Yasunori Mitsuda during development, and they would collaborate on several future projects. Katsuhisa Higuchi programmed the battle system, which hosted combat on the map without transition to a special battleground as most previous Square games had done. Higuchi noted extreme difficulty in loading battles properly without slow-downs or a brief, black loading screen. The game's use of animated monster sprites consumed much more memory than previous "Final Fantasy" games, which used static enemy graphics.
Hironobu Sakaguchi likened the development of "Chrono Trigger" to "play[ing] around with Toriyama's universe," citing the inclusion of humorous sequences in the game that would have been "impossible with something like "Final Fantasy"." When Square Co. suggested a non-human player character, developers created Frog by adapting one of Toriyama's sketches. The team created the End of Time to help players with hints, worrying that they might become stuck and need to consult a walkthrough. The game's testers had previously complained that "Chrono Trigger" was too difficult; as Horii explained, "It's because we know too much. The developers think the game's just right; that they're being too soft. They're thinking from their own experience. The puzzles were the same. Lots of players didn't figure out things we thought they'd get easily." Sakaguchi later cited the unusual desire of beta testers to play the game a second time or "travel through time again" as an affirmation of the New Game + feature: "Wherever we could, we tried to make it so that a slight change in your behavior caused subtle differences in people's reactions, even down to the smallest details ... I think the second playthrough will hold a whole new interest." The game's reuse of locations due to time traveling made bug-fixing difficult, as corrections would cause unintended consequences in other eras.
"Chrono Trigger" was scored primarily by Yasunori Mitsuda, with contributions from veteran "Final Fantasy" composer Nobuo Uematsu, and one track composed by Noriko Matsueda. A sound programmer at the time, Mitsuda was unhappy with his pay and threatened to leave Square if he could not compose music. Hironobu Sakaguchi suggested he score "Chrono Trigger", remarking, "maybe your salary will go up." Mitsuda composed new music and drew on a personal collection of pieces composed over the previous two years. He reflected, "I wanted to create music that wouldn't fit into any established genre ... music of an imaginary world. The game's director, Masato Kato, was my close friend, and so I'd always talk with him about the setting and the scene before going into writing." Mitsuda slept in his studio several nights, and attributed certain pieces—such as the game's ending theme, "To Far Away Times"—to inspiring dreams. He later attributed this song to an idea he was developing before "Chrono Trigger", reflecting that the tune was made in dedication to "a certain person with whom [he] wanted to share a generation". He also tried to use leitmotifs of the "Chrono Trigger" main theme to create a sense of consistency in the soundtrack. Mitsuda wrote each tune to be around two minutes long before repeating, unusual for Square's games at the time. Mitsuda suffered a hard drive crash that lost around forty in-progress tracks. After Mitsuda contracted stomach ulcers, Uematsu joined the project to compose ten pieces and finish the score. Mitsuda returned to watch the ending with the staff before the game's release, crying upon seeing the finished scene.
At the time of the game's release, the number of tracks and sound effects was unprecedented—the soundtrack spanned three discs in its 1995 commercial pressing. Square also released a one-disc acid jazz arrangement called "The Brink of Time" by Guido that year. "The Brink of Time" came about because Mitsuda wanted to do something that no one else was doing, and he noted that acid jazz and its related genres were uncommon in the Japanese market. Mitsuda considers "Chrono Trigger" a landmark game which helped mature his talent. While Mitsuda later held that the title piece was "rough around the edges", he maintains that it had "significant influence on [his] life as a composer". In 1999, Square produced another one-disc soundtrack to complement the PlayStation release of "Trigger", featuring orchestral tracks used in cut scenes. Tsuyoshi Sekito composed four new pieces for the game's bonus features which weren't included on the soundtrack. Some fans were displeased by Mitsuda's absence in creating the port, whose instruments sometimes aurally differed from the original game's. Mitsuda arranged versions of music from the "Chrono" series for Play! video game music concerts, presenting the main theme, "Frog's Theme", and "To Far Away Times". He worked with Square Enix to ensure that the music for the Nintendo DS would sound closer to the Super NES version. Mitsuda encouraged feedback about the game's soundtrack from contemporary children (who he thought would expect "full symphonic scores blaring out of the speakers"). Fans who preordered "Chrono Trigger DS" received a special music disc containing two orchestral arrangements of "Chrono Trigger" music directed by Natsumi Kameoka; Square Enix also held a random prize drawing for two signed copies of "Chrono Trigger" sheet music. Mitsuda expressed difficulty in selecting the tune for the orchestral medley, eventually picking a tune from each era and certain character themes. Mitsuda later wrote:
Music from the game was performed live by the Tokyo Symphony Orchestra in 1996 at the Orchestral Game Concert in Tokyo, Japan. A suite of music including "Chrono Trigger" is a part of the symphonic world-tour with video game music Play! A Video Game Symphony, where Mitsuda was in attendance for the concert's world-premiere in Chicago on May 27, 2006. His suite of "Chrono" music, comprising "Reminiscence", "Chrono Trigger", "Chrono Cross~Time's Scar", "Frog's Theme", and "To Far Away Times" was performed. Mitsuda has also appeared with the Eminence Symphony Orchestra as a special guest. Video Games Live has also featured medleys from "Chrono Trigger" and "Chrono Cross". A medley of Music from "Chrono Trigger" made of one of the four suites of the "Symphonic Fantasies" concerts in September 2009 which was produced by the creators of the Symphonic Game Music Concert series, conducted by Arnie Roth. Square Enix re-released the game's soundtrack, along with a video interview with Mitsuda in July 2009.
The team planned to release "Chrono Trigger" in late 1994, but release was pushed back to the following year. Early alpha versions of "Chrono Trigger" were demonstrated at the 1994 and 1995 V-Jump festivals in Japan. A few months prior to the game's release, Square shipped a beta version to magazine reviewers and game stores for review. An unfinished build of the game dated November 17, 1994, it contains unused music tracks, locations, and other features changed or removed from the final release—such as a dungeon named "Singing Mountain" and its eponymous tune. Some names also differed; the character Soysaw (Slash in the US version) was known as Wiener, while Mayonnay (Flea in the US version) was named Ketchappa. The ROM image for this early version was eventually uploaded to the internet, prompting fans to explore and document the game's differences, including two unused world map NPC character sprites and presumed additional sprites for certain non-player characters. Around the game's release, Yuji Horii commented that "Chrono Trigger" "went beyond [the development team's] expectations", and Hironobu Sakaguchi congratulated the game's graphic artists and field designers. Sakaguchi intended to perfect the "sense of dancing you get from exploring Toriyama's worlds" in the event that they would make a sequel.
"Chrono Trigger" used a 32-megabit ROM cartridge with battery-backed RAM for saved games, lacking special on-cartridge coprocessors. The Japanese release of "Chrono Trigger" included art for the game's ending and running counts of items in the player's status menu. Developers created the North American version before adding these features to the original build, inadvertently leaving in vestiges of "Chrono Trigger"'s early development (such as the piece "Singing Mountain"). Hironobu Sakaguchi asked translator Ted Woolsey to localize "Chrono Trigger" for English audiences and gave him roughly thirty days to work. Lacking the help of a modern translation team, he memorized scenarios and looked at drafts of commercial player's guides to put dialogue in context. Woolsey later reflected that he would have preferred two-and-a-half months, and blames his rushed schedule on the prevailing attitude in Japan that games were children's toys rather than serious works. Some of his work was cut due to space constraints, though he still considered "Trigger" "one of the most satisfying games [he] ever worked on or played". Nintendo of America censored certain dialogue, including references to breastfeeding, consumption of alcohol, and religion.
The original SNES edition of "Chrono Trigger" was released on the Wii download service Virtual Console in Japan on April 26, 2011, in the US on May 16, 2011, and in Europe on May 20, 2011. Previously in April 2008, a "Nintendo Power" reader poll had identified "Chrono Trigger" as the third-most wanted game for the Virtual Console. It went on to receive a perfect score of 10 out 10 on IGN.
Square released an enhanced port of "Chrono Trigger" developed by Tose in Japan for the Sony PlayStation in 1999. Square timed its release before that of "Chrono Cross", the 1999 sequel to "Chrono Trigger", to familiarize new players with story leading up to it. This version included anime cutscenes created by original character designer Akira Toriyama's Bird Studio and animated at Toei Animation, as well as several bonus features, accessible after achieving various endings in the game. Scenarist Masato Kato attended planning meetings at Bird Studio to discuss how the ending cutscenes would illustrate subtle ties to "Chrono Cross". The port was released in North America in 2001—along with a newly translated version of "Final Fantasy IV"—as "Final Fantasy Chronicles". Reviewers criticized "Chronicles" for its lengthy load times and an absence of new in-game features. This same iteration was also re-released as a downloadable game on the PlayStation Network on October 4, 2011, for the PlayStation 3, PlayStation Vita, and PlayStation Portable.
On July 2, 2008, Square Enix announced that they were planning to bring "Chrono Trigger" to the Nintendo DS handheld platform. Composer Yasunori Mitsuda was pleased with the project, exclaiming "finally!" after receiving the news from Square Enix and maintaining, "it's still a very deep, very high-quality game even when you play it today. I'm very interested in seeing what kids today think about it when they play it." Square retained Masato Kato to oversee the port, and Tose to program it. Kato explained, "I wanted it to be based on the original Super NES release rather than the PlayStation version. I thought we should look at the additional elements from the Playstation version, re-examine and re-work them to make it a complete edition. That's how it struck me and I told the staff so later on." Square Enix touted the game by displaying Akira Toriyama's original art at the 2008 Tokyo Game Show.
The DS re-release contains all of the bonus material from the PlayStation port, as well as other enhancements. The added features include a more accurate and revised translation by Tom Slattery, a dual-screen mode which clears the top screen of all menus, a self-completing map screen, and a default "run" option. It also featured the option to choose between two control schemes: one mirroring the original SNES controls, and the other making use of the DS's touch screen. Masato Kato participated in development, overseeing the addition of the monster-battling Arena, two new areas, the Lost Sanctum and the Dimensional Vortex, and a new ending that further foreshadows the events of "Chrono Cross". One of the areas within the Vortex uses the "Singing Mountain" song that was featured on the original "Chrono Trigger" soundtrack. These new dungeons met with mixed reviews; GameSpot called them "frustrating" and "repetitive", while IGN noted that "the extra quests in the game connect extremely well." It was a nominee for "Best RPG for the Nintendo DS" in IGN's 2008 video game awards. The Nintendo DS version of "Chrono Trigger" was the 22nd best-selling game of 2008 in Japan.
A cellphone version was released in Japan on i-mode distribution service on August 25, 2011. An iOS version was released on December 8, 2011. This version is based on the Nintendo DS version, with graphics optimized for iOS. The game was later released for Android on October 29, 2012. An update incorporating most of the features of the Windows version—including the reintroduction of the animated cutscenes, which had been absent from the initial mobile release—was released on February 27, 2018.
Square Enix released "Chrono Trigger" without an announcement for Microsoft Windows via Steam on February 27, 2018. This version includes all content from the Nintendo DS port, the higher resolution graphics from the mobile device releases, support for mouse and keyboard controls, and autosave features, along with additional content such as wallpapers and music. The PC port received negative reception due to its inferior graphical quality, additional glitches, UI adapted for touchscreens, and failure to properly adapt the control scheme for keyboards and controllers. In response, Square Enix provided various UI updates and other improvements over the next few months to address the complaints.
The game was a bestseller in Japan. The game's SNES and PS1 iterations have shipped more than 2.36 million copies in Japan and 290,000 abroad. The first two million copies sold in Japan were delivered in only two months, and the game ended 1995 as the third best-selling game of the year behind ' and '. The game was met with substantial success upon release in North America, and its rerelease on the PlayStation as part of the "Final Fantasy Chronicles" package topped the NPD TRSTS PlayStation sales charts for over six weeks. This version was later re-released again in 2003 as part of Sony's Greatest Hits line. "Chrono Trigger DS" has sold 490,000 copies in Japan, 240,000 in North America and 60,000 in Europe as of March 2009.
"Chrono Trigger" garnered much critical praise in addition to its brisk sales. "Famicom Tsūshin" gave "Chrono Trigger" first an 8 out of 10 and later a 9 out of 10 in their Reader Cross Review. "Nintendo Power" compared it favorably with "Secret of Mana", "Final Fantasy", and "", citing improved graphics, sound, story and gameplay. "GamePro" praised the varied gameplay, the humor, the ability to replay the game with previously built-up characters, and the graphics, which they said far exceed even those of "Final Fantasy VI". They commented that combat is easier and more simplistic than in most RPGs, but argued that "Most players would choose an easier RPG of this caliber over a hundred more complicated, but less developed, fantasy role-playing adventures." They gave the game a perfect 5 out of 5 in all four categories: graphics, sound, control, and funfactor. "Electronic Gaming Monthly" gave it their "Game of the Month" award, with their four reviewers praising the graphics, story, and music. "Chrono Trigger" won multiple awards from "Electronic Gaming Monthly" 1995 video game awards, including Best Role-Playing Game, Best Music in a Cartridge-Based Game, and Best Super NES Game. "Official U.S. PlayStation Magazine" described "Trigger" as "original and extremely captivating", singling out its graphics, sound and story as particularly impressive. IGN commented that "it may be filled with every imaginable console RPG cliché, but "Chrono Trigger" manages to stand out among the pack" with "a [captivating] story that doesn't take itself too serious " and "one of the best videogame soundtracks ever produced". Other reviewers (such as the staff of RPGFan and RPGamer) have criticized the game's short length and relative ease compared to its peers. Victoria Earl of Gamasutra praised the game design for balancing "developer control with player freedom using designed mechanics and a modular approach to narrative."
Overall, critics lauded "Chrono Trigger" for its "fantastic yet not overly complex" story, simple but innovative gameplay, and high replay value afforded by multiple endings. Online score aggregator GameRankings lists the original Super NES version as the 2nd highest scoring RPG and 24th highest scoring game ever reviewed. In 2009, Guinness World Records listed it as the 32nd most influential video game in history. "Nintendo Power" listed the ending to "Chrono Trigger" as one of the greatest endings in Nintendo history, due to over a dozen endings that players can experience. Tom Hall drew inspiration from "Chrono Trigger" and other console games in creating "Anachronox", and used the campfire scene to illustrate the dramatic depth of Japanese RPGs. "Next Generation" reviewed the Super NES version of the game, rating it four stars out of five, and stated that "it [...] easily qualifies as one of the best RPGs ever made".
"Chrono Trigger" is frequently listed among the greatest video games of all time. In 1997 "Electronic Gaming Monthly" ranked it the 29th best console video game of all time; while noting that it was not as good as "Final Fantasy VI" (which ranked 9th), they gave superlative praise to its handling of time travel and its combat engine. It has placed highly on all six of multimedia website IGN's "top 100 games of all time" lists—4th in 2002, 6th in early 2005, 13th in late 2005, 2nd in 2006, 18th in 2007, and 2nd in 2008. "Game Informer" called it its 15th favourite game in 2001. Its staff thought that it was the best non-"Final Fantasy" game Square had produced at the time. GameSpot included "Chrono Trigger" in "The Greatest Games of All Time" list released in April 2006, and it also appeared as 28th on an "All Time Top 100" list in a poll conducted by Japanese magazine "Famitsu" the same year. In 2004, "Chrono Trigger" finished runner up to "Final Fantasy VII" in the inaugural GameFAQs video game battle. In 2008, readers of Dengeki Online voted it the eighth best game ever made. "Nintendo Power"'s twentieth anniversary issue named it the fifth best Super NES game. In 2012, it came 32nd place on GamesRadar's "100 best games of all time" list, and 1st place on its "Best JRPGs" list. GamesRadar named "Chrono Trigger" the 2nd best Super NES game of all time, behind "Super Metroid".
In contrast to the critical acclaim of "Chrono Trigger"'s original SNES release, the 2018 Microsoft Windows port of "Chrono Trigger" was critically panned. Grievances noted by reviewers included tiling errors on textures, the addition of aesthetically-intrusive sprite filters, an unattractive GUI carried over from the 2011 mobile release, a lack of graphic customization options, and the inability to remap controls. In describing the port, "Forbes" commented: "From pretty awful graphical issues, such as tiling textures and quite a painful menu system, this port really doesn’t do this classic game justice." "USGamer" characterized the Windows release as carrying "all the markings of a project farmed out to the lowest bidder. It's a shrug in Square-Enix's mind, seemingly not worth the money or effort necessary for a half-decent port." In a Twitter post detailing his experiences with the Windows version, indie developer Fred Wood derisively compared the port to "someone's first attempt at an RPG Maker game", a comment which was republished across numerous articles addressing the poor quality of the rerelease.
"Chrono Trigger" inspired several related releases; the first were three games released for the Satellaview on July 31, 1995. They included "Chrono Trigger: Jet Bike Special", a racing video game based on a minigame from the original; "Chrono Trigger: Character Library", featuring profiles on characters and monsters from the game; and "Chrono Trigger: Music Library", a collection of music from the game's soundtrack. The contents of "Character Library" and "Music Library" were later included as extras in the PlayStation rerelease of "Chrono Trigger". Production I.G created a 16-minute OVA, "", which was shown at the Japanese V-Jump Festival of July 31, 1996.
There have been two notable attempts by "Chrono Trigger" fans to unofficially remake parts of the game for PC with a 3D graphics engine. "Chrono Resurrection", an attempt at remaking ten small interactive cut scenes from "Chrono Trigger", and "Chrono Trigger Remake Project", which sought to remake the entire game, were forcibly terminated by Square Enix by way of a cease and desist order. Another group of fans created a sequel via a ROM hack of "Chrono Trigger" called ""; developed from 2004 to 2009; although feature-length and virtually finished, it also was terminated through a cease & desist letter days before its May 2009 release. The letter also banned the dissemination of existing "Chrono Trigger" ROM hacks and documentation. After the cease and desist was issued, an incomplete version of the game was leaked in May 2009, though due to the early state of the game, playability was limited.
This was followed by a more complete ROM leak in January 2011, which allowed the game to be played from beginning to end.
Square released a fourth Satellaview game in 1996, named "". Having thought that "Trigger" ended with "unfinished business", scenarist Masato Kato wrote and directed the game. "Dreamers" functioned as a side story to "Chrono Trigger", resolving a loose subplot from its predecessor. A short, text-based game relying on minimal graphics and atmospheric music, the game never received an official release outside Japan—though it was translated by fans to English in April 2003. Square planned to release "Radical Dreamers" as an easter egg in the PlayStation edition of "Chrono Trigger", but Kato was unhappy with his work and halted its inclusion.
Square released "Chrono Cross" for the Sony PlayStation in 1999. "Cross" is a sequel to "Chrono Trigger" featuring a new setting and cast of characters. Presenting a theme of parallel worlds, the story followed the protagonist Serge—a teenage boy thrust into an alternate reality in which he died years earlier. With the help of a thief named Kid, Serge endeavors to discover the truth behind his apparent death and obtain the Frozen Flame, a mythical artifact. Regarded by writer and director Masato Kato as an effort to "redo "Radical Dreamers" properly", "Chrono Cross" borrowed certain themes, scenarios, characters, and settings from "Dreamers". Yasunori Mitsuda also adapted certain songs from "Radical Dreamers" while scoring "Cross". "Radical Dreamers" was consequently removed from the series' main continuity, considered an alternate dimension. "Chrono Cross" shipped 1.5 million copies and was almost universally praised by critics.
There are no plans as of for a new title, despite a statement from Hironobu Sakaguchi in 2001 that the developers of "Chrono Cross" wanted to make a new "Chrono" game. The same year, Square applied for a trademark for the names "Chrono Break" in the United States and "Chrono Brake" in Japan. However, the United States trademark was dropped in 2003. Director Takashi Tokita mentioned "Chrono Trigger 2" in a 2003 interview which has not been translated to English. Yuji Horii expressed no interest in returning to the Chrono franchise in 2005, while Hironobu Sakaguchi remarked in April 2007 that his creation "Blue Dragon" was an "extension of [Chrono Trigger]." During a Cubed³ interview on February 1, 2007, Square Enix's Senior Vice President Hiromichi Tanaka said that although no sequel is currently planned, some sort of sequel is still possible if the "Chrono Cross" developers can be reunited. Yasunori Mitsuda has expressed interest in scoring a new game, but warned that "there are a lot of politics involved" with the series. He stressed that Masato Kato should participate in development. The February 2008 issue of "Game Informer" ranked the "Chrono" series eighth among the "Top Ten Sequels in Demand", naming the games "steadfast legacies in the Square Enix catalogue" and asking, "what's the damn holdup?!" In Electronic Gaming Monthly's June 2008 "Retro Issue", writer Jeremy Parish cited "Chrono" as the franchise video game fans would be most thrilled to see a sequel to. In the first May "Famitsu" of 2009, "Chrono Trigger" placed 14th out of 50 in a vote of most-wanted sequels by the magazine's readers. At E3 2009, SE Senior Vice President Shinji Hashimoto remarked, "If people want a sequel, they should buy more!"
In July 2010, Obsidian Entertainment designer Feargus Urquhart, replying to an interview question about what franchises he would like to work on, said that "if [he] could come across everything that [he] played", he would choose a "Chrono Trigger" game. At the time, Obsidian was making "Dungeon Siege III" for Square Enix. Urquhart said: "You make RPGs, we make RPGs, it would be great to see what we could do together. And they really wanted to start getting into Western RPGs. And, so it kind of all ended up fitting together." Yoshinori Kitase stated that he used the time travel mechanics of "Chrono Trigger" as a starting point for that of "Final Fantasy XIII-2".

</doc>
<doc id="6615" url="https://en.wikipedia.org/wiki?curid=6615" title="Cornwall Wildlife Trust">
Cornwall Wildlife Trust

The Cornwall Wildlife Trust is a charitable organisation founded in 1962 that is concerned solely with Cornwall, England.
It deals with the conservation and preservation of Cornwall's wildlife and habitats managing over 50 nature reserves covering approximately , amongst them Looe Island.
Cornwall Wildlife Trust is part of The Wildlife Trusts partnership of 46 wildlife trusts in the United Kingdom. It works in conjunction with the Isles of Scilly Wildlife Trust, and jointly produces a thrice yearly magazine called "Wild Cornwall & Wild Scilly"
The direction and work that the Trust currently does is guided by the Cornwall Biodiversity action plan. Living Seas and Living Landscapes are two such projects. The Trust runs ERCCIS (Environmental Records Centre for Cornwall and the Isles of Scilly), a county wide database of sightings of animals and plants. It also gives planning advice (CEC - Cornwall Environmental Consultants) to land developers.
The Trust is based at Allet near Truro in Cornwall. The headquarters and offices are adjacent to the Trust's Five Acres nature reserve. This reserve includes two ponds, as well as mixed broadleaved woodland.
1. Armstrong Wood
2. Baker's Pit
3. Beales Meadows
4. Bissoe Valley
5. Bosvenning Common
6. Cabilla and Redrice Woods
7. Caer Brân
8. Carn Moor
9. Chûn Downs
10. Churchtown Farm, near Saltash
11. Chyverton
12. Devichoys Wood, near Penryn
13. Downhill Meadow
14. River Fal—River Ruan Estuary
15. Five Acres, at the Cornwall Wildlife Trust Headquarters, Allet, near Truro
16. Fox Corner, south of Truro
17. Greena Moor
18. Halbullock Moor, south of Truro 
19. Hawkes Wood
20. Helman Tor (including Breney Common and Red Moor, near Lostwithiel 
21. Kemyel Crease
22. Kennall Vale, at Ponsanooth, between Falmouth & Redruth
23. Lanvean Bottoms
24. Loggan's Moor, near Hayle
25. Loveny/Colliford Reservoir
26. Lower Lewdon
27. Luckett/Greenscombe Wood
28. Maer Lake
29. Nansmellyn Marsh
30. North Predannack Downs
31. Park Hoskyn - The Hayman Reserve
32. Pendarves Wood, near Camborne
33. Penlee Battery, near Kingsand
34. Phillips's Point
35. Priddacombe Downs
36. Prideaux Wood
37. Quoit Heathland
38. Redlake Cottage Meadows
39. Ropehaven Cliffs
40. Rosenannon Downs
41. St Erth Pits, at St. Erth
42. St George's Island (or Looe Island), near Looe
43. Swanvale, Falmouth
44. Sylvia's Meadow, near Callington
45. Tamar Estuary, near Saltash
46. Tincombe, near Saltash
47. Trebarwith, near Tintagel
48. Tregonetha Downs, near Goss Moor
49. Tresayes, near Roche
50. Tywardreath Marsh, near Par
51. Upton Meadow, near Bude
52. Upton Towans, near Hayle
53. Ventongimps Moor, near Zelah, Cornwall
54. Marsland Valley, north of Bude
55. Windmill Farm, on The Lizard

</doc>
<doc id="6616" url="https://en.wikipedia.org/wiki?curid=6616" title="Conservatory">
Conservatory

Conservatory may refer to:

</doc>
<doc id="6617" url="https://en.wikipedia.org/wiki?curid=6617" title="Compactification (mathematics)">
Compactification (mathematics)

In mathematics, in general topology, compactification is the process or result of making a topological space into a compact space. A compact space is a space in which every open cover of the space contains a finite subcover. The methods of compactification are various, but each is a way of controlling points from "going off to infinity" by in some way adding "points at infinity" or preventing such an "escape".
Consider the real line with its ordinary topology. This space is not compact; in a sense, points can go off to infinity to the left or to the right. It is possible to turn the real line into a compact space by adding a single "point at infinity" which we will denote by ∞. The resulting compactification can be thought of as a circle (which is compact as a closed and bounded subset of the Euclidean plane). Every sequence that ran off to infinity in the real line will then converge to ∞ in this compactification.
Intuitively, the process can be pictured as follows: first shrink the real line to the open interval (-π,π) on the "x"-axis; then bend the ends of this interval upwards (in positive "y"-direction) and move them towards each other, until you get a circle with one point (the topmost one) missing. This point is our new point ∞ "at infinity"; adding it in completes the compact circle.
A bit more formally: we represent a point on the unit circle by its angle, in radians, going from -π to π for simplicity. Identify each such point θ on the circle with the corresponding point on the real line tan(θ/2). This function is undefined at the point π, since tan(π/2) is undefined; we will identify this point with our point ∞.
Since tangents and inverse tangents are both continuous, our identification function is a homeomorphism between the real line and the unit circle without ∞. What we have constructed is called the "Alexandroff one-point compactification" of the real line, discussed in more generality below. It is also possible to compactify the real line by adding "two" points, +∞ and -∞; this results in the extended real line.
An embedding of a topological space "X" as a dense subset of a compact space is called a compactification of "X". It is often useful to embed topological spaces in compact spaces, because of the special properties compact spaces have.
Embeddings into compact Hausdorff spaces may be of particular interest. Since every compact Hausdorff space is a Tychonoff space, and every subspace of a Tychonoff space is Tychonoff, we conclude that any space possessing a Hausdorff compactification must be a Tychonoff space. In fact, the converse is also true; being a Tychonoff space is both necessary and sufficient for possessing a Hausdorff compactification.
The fact that large and interesting classes of non-compact spaces do in fact have compactifications of particular sorts makes compactification a common technique in topology.
For any noncompact topological space "X" the (Alexandroff) one-point compactification α"X" of "X" is obtained by adding one extra point ∞ (often called a "point at infinity") and defining the open sets of the new space to be the open sets of "X" together with the sets of the form "G" ∪ {∞}, where "G" is an open subset of "X" such that "X" \ "G" is closed and compact. The one-point compactification of "X" is Hausdorff if and only if "X" is Hausdorff, noncompact and locally compact.
Of particular interest are Hausdorff compactifications, i.e., compactifications in which the compact space is Hausdorff. A topological space has a Hausdorff compactification if and only if it is Tychonoff. In this case, there is a unique (up to homeomorphism) "most general" Hausdorff compactification, the Stone–Čech compactification of "X", denoted by β"X"; formally, this exhibits the category of Compact Hausdorff spaces and continuous maps as a reflective subcategory of the category of Tychonoff spaces and continuous maps.
"Most general" or formally "reflective" means that the space β"X" is characterized by the universal property that any continuous function from "X" to a compact Hausdorff space "K" can be extended to a continuous function from β"X" to "K" in a unique way. More explicitly, β"X" is a compact Hausdorff space containing "X" such that the induced topology on "X" by β"X" is the same as the given topology on "X", and for any continuous map "f":"X" → "K", where "K" is a compact Hausdorff space, there is a unique continuous map "g":β"X" → "K" for which "g" restricted to "X" is identically "f".
The Stone–Čech compactification can be constructed explicitly as follows: let "C" be the set of continuous functions from "X" to the closed interval [0,1]. Then each point in "X" can be identified with an evaluation function on "C". Thus "X" can be identified with a subset of [0,1], the space of "all" functions from "C" to [0,1]. Since the latter is compact by Tychonoff's theorem, the closure of "X" as a subset of that space will also be compact. This is the Stone–Čech compactification.
Walter Benz and Isaak Yaglom have shown how stereographic projection onto a single-sheet hyperboloid can be used to provide a compactification for split complex numbers. In fact, the hyperboloid is part of a quadric in real projective four-space. The method is similar to that used to provide a base manifold for group action of the conformal group of spacetime.
Real projective space RP is a compactification of Euclidean space R. For each possible "direction" in which points in R can "escape", one new point at infinity is added (but each direction is identified with its opposite). The Alexandroff one-point compactification of R we constructed in the example above is in fact homeomorphic to RP. Note however that the projective plane RP is "not" the one-point compactification of the plane R since more than one point is added.
Complex projective space CP is also a compactification of C; the Alexandroff one-point compactification of the plane C is (homeomorphic to) the complex projective line CP, which in turn can be identified with a sphere, the Riemann sphere.
Passing to projective space is a common tool in algebraic geometry because the added points at infinity lead to simpler formulations of many theorems. For example, any two different lines in RP intersect in precisely one point, a statement that is not true in R. More generally, Bézout's theorem, which is fundamental in intersection theory, holds in projective space but not affine space. This distinct behavior of intersections in affine space and projective space is reflected in algebraic topology in the cohomology rings – the cohomology of affine space is trivial, while the cohomology of projective space is non-trivial and reflects the key features of intersection theory (dimension and degree of a subvariety, with intersection being Poincaré dual to the cup product).
Compactification of moduli spaces generally require allowing certain degeneracies – for example, allowing certain singularities or reducible varieties. This is notably used in the Deligne–Mumford compactification of the moduli space of algebraic curves.
In the study of discrete subgroups of Lie groups, the quotient space of cosets is often a candidate for more subtle compactification to preserve structure at a richer level than just topological.
For example, modular curves are compactified by the addition of single points for each cusp, making them Riemann surfaces (and so, since they are compact, algebraic curves). Here the cusps are there for a good reason: the curves parametrize a space of lattices, and those lattices can degenerate ('go off to infinity'), often in a number of ways (taking into account some auxiliary structure of "level"). The cusps stand in for those different 'directions to infinity'.
That is all for lattices in the plane. In "n"-dimensional Euclidean space the same questions can be posed, for example about SO(n)\SL(R)/SL(Z). This is harder to compactify. There are a variety of compactifications, such as the Borel–Serre compactification, the reductive Borel-Serre compactification, and the Satake compactifications, that can be formed.

</doc>
<doc id="6620" url="https://en.wikipedia.org/wiki?curid=6620" title="Cotangent space">
Cotangent space

In differential geometry, one can attach to every point formula_1 of a smooth (or differentiable) manifold, formula_2, a vector space called the cotangent space at "formula_1". Typically, the cotangent space, formula_4 is defined as the dual space of the tangent space at "formula_1", formula_6, although there are more direct definitions (see below). The elements of the cotangent space are called cotangent vectors or tangent covectors.
All cotangent spaces at points on a connected manifold have the same dimension, equal to the dimension of the manifold. All the cotangent spaces of a manifold can be "glued together" (i.e. unioned and endowed with a topology) to form a new differentiable manifold of twice the dimension, the cotangent bundle of the manifold.
The tangent space and the cotangent space at a point are both real vector spaces of the same dimension and therefore isomorphic to each other via many possible isomorphisms. The introduction of a Riemannian metric or a symplectic form gives rise to a natural isomorphism between the tangent space and the cotangent space at a point, associating to any tangent covector a canonical tangent vector.
Let "formula_2" be a smooth manifold and let "formula_1" be a point in "formula_2". Let "formula_6" be the tangent space at "formula_1". Then the cotangent space at "x" is defined as the dual space of "formula_6":
Concretely, elements of the cotangent space are linear functionals on "formula_6". That is, every element formula_15 is a linear map
where formula_17 is the underlying field of the vector space being considered, for example, the field of real numbers. The elements of formula_4 are called cotangent vectors.
In some cases, one might like to have a direct definition of the cotangent space without reference to the tangent space. Such a definition can be formulated in terms of equivalence classes of smooth functions on "formula_2". Informally, we will say that two smooth functions "f" and "g" are equivalent at a point "formula_1" if they have the same first-order behavior near "formula_1", analogous to their linear Taylor polynomials; two functions "f" and "g" have the same first order behavior near "formula_1" if and only if the derivative of the function "f"-"g" vanishes at "formula_1". The cotangent space will then consist of all the possible first-order behaviors of a function near "formula_1".
Let "M" be a smooth manifold and let "x" be a point in "formula_2". Let formula_26be the ideal of all functions in formula_27 vanishing at "formula_1", and let formula_29 be the set of functions of the form formula_30, where formula_31. Then "formula_26" and formula_29 are real vector spaces and the cotangent space is defined as the quotient space formula_34.
This formulation is analogous to the construction of the cotangent space to define the Zariski tangent space in algebraic geometry. The construction also generalizes to locally ringed spaces.
Let "M" be a smooth manifold and let "f" ∈ C("M") be a smooth function. The differential of "f" at a point "x" is the map
where "X" is a tangent vector at "x", thought of as a derivation. That is formula_35 is the Lie derivative of "f" in the direction "X", and one has d"f"("X")="X"("f"). Equivalently, we can think of tangent vectors as tangents to curves, and write
In either case, d"f" is a linear map on "T""M" and hence it is a tangent covector at "x".
We can then define the differential map d : C("M") → "T""M" at a point "x" as the map which sends "f" to d"f". Properties of the differential map include:
The differential map provides the link between the two alternate definitions of the cotangent space given above. Given a function "f" ∈ "I" (a smooth function vanishing at "x") we can form the linear functional d"f" as above. Since the map d restricts to 0 on "I" (the reader should verify this), d descends to a map from "I" / "I" to the dual of the tangent space, ("T""M"). One can show that this map is an isomorphism, establishing the equivalence of the two definitions.
Just as every differentiable map "f" : "M" → "N" between manifolds induces a linear map (called the "pushforward" or "derivative") between the tangent spaces
every such map induces a linear map (called the "pullback") between the cotangent spaces, only this time in the reverse direction:
The pullback is naturally defined as the dual (or transpose) of the pushforward. Unraveling the definition, this means the following:
where θ ∈ "T""N" and "X" ∈ "T""M". Note carefully where everything lives.
If we define tangent covectors in terms of equivalence classes of smooth maps vanishing at a point then the definition of the pullback is even more straightforward. Let "g" be a smooth function on "N" vanishing at "f"("x"). Then the pullback of the covector determined by "g" (denoted d"g") is given by
That is, it is the equivalence class of functions on "M" vanishing at "x" determined by "g" o "f".
The "k"-th exterior power of the cotangent space, denoted Λ("T""M"), is another important object in differential geometry. Vectors in the "k"th exterior power, or more precisely sections of the "k"-th exterior power of the cotangent bundle, are called differential "k"-forms. They can be thought of as alternating, multilinear maps on "k" tangent vectors. 
For this reason, tangent covectors are frequently called "one-forms".

</doc>
<doc id="6621" url="https://en.wikipedia.org/wiki?curid=6621" title="Cnidaria">
Cnidaria

Cnidaria () is a phylum under kingdom Animalia containing over 11,000 species of aquatic animals found both in freshwater and marine environments, predominantly the latter.
Their distinguishing feature is cnidocytes, specialized cells that they use mainly for capturing prey. Their bodies consist of mesoglea, a non-living jelly-like substance, sandwiched between two layers of epithelium that are mostly one cell thick. 
They mostly have two basic body forms: swimming medusae and sessile polyps, both of which are radially symmetrical with mouths surrounded by tentacles that bear cnidocytes. Both forms have a single orifice and body cavity that are used for digestion and respiration. Many cnidarian species produce colonies that are single organisms composed of medusa-like or polyp-like zooids, or both (hence they are trimorphic). Cnidarians' activities are coordinated by a decentralized nerve net and simple receptors. Several free-swimming species of Cubozoa and Scyphozoa possess balance-sensing statocysts, and some have simple eyes. Not all cnidarians reproduce sexually, with many species having complex life cycles of asexual polyp stages and sexual medusae. Some, however, omit either the polyp or the medusa stage.
Cnidarians were formerly grouped with ctenophores in the phylum Coelenterata, but increasing awareness of their differences caused them to be placed in separate phyla. Cnidarians are classified into four main groups: the almost wholly sessile Anthozoa (sea anemones, corals, sea pens); swimming Scyphozoa (jellyfish); Cubozoa (box jellies); and Hydrozoa (a diverse group that includes all the freshwater cnidarians as well as many marine forms, and has both sessile members, such as "Hydra", and colonial swimmers, such as the Portuguese Man o' War). Staurozoa have recently been recognised as a class in their own right rather than a sub-group of Scyphozoa, and the highly derived parasitic Myxozoa and Polypodiozoa were firmly recognized as cnidarians in 2007.
Most cnidarians prey on organisms ranging in size from plankton to animals several times larger than themselves, but many obtain much of their nutrition from dinoflagellates, and a few are parasites. Many are preyed on by other animals including starfish, sea slugs, fish, turtles, and even other cnidarians. Many scleractinian corals—which form the structural foundation for coral reefs—possess polyps that are filled with symbiotic photo-synthetic zooxanthellae. While reef-forming corals are almost entirely restricted to warm and shallow marine waters, other cnidarians can be found at great depths, in polar regions, and in freshwater.
Recent phylogenetic analyses support monophyly of cnidarians, as well as the position of cnidarians as the sister group of bilaterians. Fossil cnidarians have been found in rocks formed about , and other fossils show that corals may have been present shortly before and diversified a few million years later. However, molecular clock analysis of mitochondrial genes suggests a much older age for the crown group of cnidarians, estimated around , almost 200 million years before the Cambrian period as well as any fossils.
Cnidarians form a phylum of animal that are more complex than sponges, about as complex as ctenophores (comb jellies), and less complex than bilaterians, which include almost all other animals. Both cnidarians and ctenophores are more complex than sponges as they have: cells bound by inter-cell connections and carpet-like basement membranes; muscles; nervous systems; and some have sensory organs. Cnidarians are distinguished from all other animals by having cnidocytes that fire harpoon like structures and are usually used mainly to capture prey. In some species, cnidocytes can also be used as anchors. Cnidarians are also distinguished by the fact that they have only one opening in their body for ingestion and excretion i.e. they don't have a separate mouth and anus.
Like sponges and ctenophores, cnidarians have two main layers of cells that sandwich a middle layer of jelly-like material, which is called the mesoglea in cnidarians; more complex animals have three main cell layers and no intermediate jelly-like layer. Hence, cnidarians and ctenophores have traditionally been labelled diploblastic, along with sponges. However, both cnidarians and ctenophores have a type of muscle that, in more complex animals, arises from the middle cell layer. As a result, some recent text books classify ctenophores as triploblastic, and it has been suggested that cnidarians evolved from triploblastic ancestors.
Most adult cnidarians appear as either free-swimming medusae or sessile polyps, and many hydrozoans species are known to alternate between the two forms. 
Both are radially symmetrical, like a wheel and a tube respectively. Since these animals have no heads, their ends are described as "oral" (nearest the mouth) and "aboral" (furthest from the mouth). 
Most have fringes of tentacles equipped with cnidocytes around their edges, and medusae generally have an inner ring of tentacles around the mouth. Some hydroids may consist of colonies of zooids that serve different purposes, such as defense, reproduction and catching prey. The mesoglea of polyps is usually thin and often soft, but that of medusae is usually thick and springy, so that it returns to its original shape after muscles around the edge have contracted to squeeze water out, enabling medusae to swim by a sort of jet propulsion.
In medusae the only supporting structure is the mesoglea. "Hydra" and most sea anemones close their mouths when they are not feeding, and the water in the digestive cavity then acts as a hydrostatic skeleton, rather like a water-filled balloon. Other polyps such as "Tubularia" use columns of water-filled cells for support. Sea pens stiffen the mesoglea with calcium carbonate spicules and tough fibrous proteins, rather like sponges.
In some colonial polyps, a chitinous periderm gives support and some protection to the connecting sections and to the lower parts of individual polyps. Stony corals secrete massive calcium carbonate exoskeletons. A few polyps collect materials such as sand grains and shell fragments, which they attach to their outsides. Some colonial sea anemones stiffen the mesoglea with sediment particles.
Cnidaria are diploblastic animals; in other words, they have two main cell layers, while more complex animals are triploblasts having three main layers. The two main cell layers of cnidarians form epithelia that are mostly one cell thick, and are attached to a fibrous basement membrane, which they secrete. They also secrete the jelly-like mesoglea that separates the layers. The layer that faces outwards, known as the ectoderm ("outside skin"), generally contains the following types of cells:
In addition to epitheliomuscular, nerve and interstitial cells, the inward-facing gastroderm ("stomach skin") contains gland cells that secrete digestive enzymes. In some species it also contains low concentrations of cnidocytes, which are used to subdue prey that is still struggling.
The mesoglea contains small numbers of amoeba-like cells, and muscle cells in some species. However, the number of middle-layer cells and types are much lower than in sponges.
Polymorphism refers to the occurrence of structurally and functionally more than two different types of individuals within the same organism. It is a characteristic feature of Cnidarians, particularly the polyp and medusa forms, or of zooids within colonial organisms like those in Hydrozoa. In Hydrozoans, colonial individuals arising from individuals zooids will take on separate tasks.
For example, in "Obelia" there are feeding individuals, the gastrozooids; the individuals capable of asexual reproduction only, the gonozooids, blastostyles and free-living or sexually reproducing individuals, the medusae.
These "nettle cells" function as harpoons, since their s remain connected to the bodies of the cells by threads. Three types of cnidocytes are known:
The main components of a cnidocyte are:
It is difficult to study the firing mechanisms of cnidocytes as these structures are small but very complex. At least four hypotheses have been proposed:
Cnidocytes can only fire once, and about 25% of a hydra's nematocysts are lost from its tentacles when capturing a brine shrimp. Used cnidocytes have to be replaced, which takes about 48 hours. To minimise wasteful firing, two types of stimulus are generally required to trigger cnidocytes: nearby sensory cells detect chemicals in the water, and their cilia respond to contact. This combination prevents them from firing at distant or non-living objects. Groups of cnidocytes are usually connected by nerves and, if one fires, the rest of the group requires a weaker minimum stimulus than the cells that fire first.
Medusae swim by a form of jet propulsion: muscles, especially inside the rim of the bell, squeeze water out of the cavity inside the bell, and the springiness of the mesoglea powers the recovery stroke. Since the tissue layers are very thin, they provide too little power to swim against currents and just enough to control movement within currents.
Hydras and some sea anemones can move slowly over rocks and sea or stream beds by various means: creeping like snails, crawling like inchworms, or by somersaulting. A few can swim clumsily by waggling their bases.
Cnidarians are generally thought to have no brains or even central nervous systems. However, they do have integrative areas of neural tissue that could be considered some form of centralization. Most of their bodies are innervated by decentralized nerve nets that control their swimming musculature and connect with sensory structures, though each clade has slightly different structures. These sensory structures, usually called rhopalia, can generate signals in response to various types of stimuli such as light, pressure, and much more. Medusa usually have several of them around the margin of the bell that work together to control the motor nerve net, that directly innervates the swimming muscles. Most Cnidarians also have a parallel system. In scyphozoans, this takes the form of a diffuse nerve net, which has modulatory effects on the nervous system. As well as forming the "signal cables" between sensory neurons and motoneurons, intermediate neurons in the nerve net can also form ganglia that act as local coordination centers. Communication between nerve cells can occur by chemical synapses or gap junctions in hydrozoans, though gap junctions are not present in all groups. Cnidarians have many of the same neurotransmitters as many animals, including chemicals such as glutamate, GABA, and acetylcholine.
This structure ensures that the musculature is excited rapidly and simultaneously, and can be directly stimulated from any point on the body, and it also is better able to recover after injury.
Medusae and complex swimming colonies such as siphonophores and chondrophores sense tilt and acceleration by means of statocysts, chambers lined with hairs which detect the movements of internal mineral grains called statoliths. If the body tilts in the wrong direction, the animal rights itself by increasing the strength of the swimming movements on the side that is too low. Most species have ocelli ("simple eyes"), which can detect sources of light. However, the agile box jellyfish are unique among Medusae because they possess four kinds of true eyes that have retinas, corneas and lenses. Although the eyes probably do not form images, Cubozoa can clearly distinguish the direction from which light is coming as well as negotiate around solid-colored objects.
Cnidarians feed in several ways: predation, absorbing dissolved organic chemicals, filtering food particles out of the water, obtaining nutrients from symbiotic algae within their cells, and parasitism. Most obtain the majority of their food from predation but some, including the corals "Hetroxenia" and "Leptogorgia", depend almost completely on their endosymbionts and on absorbing dissolved nutrients. Cnidaria give their symbiotic algae carbon dioxide, some nutrients, a place in the sun and protection against predators.
Predatory species use their cnidocytes to poison or entangle prey, and those with venomous nematocysts may start digestion by injecting digestive enzymes. The "smell" of fluids from wounded prey makes the tentacles fold inwards and wipe the prey off into the mouth. In medusae the tentacles round the edge of the bell are often short and most of the prey capture is done by "oral arms", which are extensions of the edge of the mouth and are often frilled and sometimes branched to increase their surface area. Medusae often trap prey or suspended food particles by swimming upwards, spreading their tentacles and oral arms and then sinking. In species for which suspended food particles are important, the tentacles and oral arms often have rows of cilia whose beating creates currents that flow towards the mouth, and some produce nets of mucus to trap particles. Their digestion is both intra and extracellular.
Once the food is in the digestive cavity, gland cells in the gastroderm release enzymes that reduce the prey to slurry, usually within a few hours. This circulates through the digestive cavity and, in colonial cnidarians, through the connecting tunnels, so that gastroderm cells can absorb the nutrients. Absorption may take a few hours, and digestion within the cells may take a few days. The circulation of nutrients is driven by water currents produced by cilia in the gastroderm or by muscular movements or both, so that nutrients reach all parts of the digestive cavity. Nutrients reach the outer cell layer by diffusion or, for animals or zooids such as medusae which have thick mesogleas, are transported by mobile cells in the mesoglea.
Indigestible remains of prey are expelled through the mouth. The main waste product of cells' internal processes is ammonia, which is removed by the external and internal water currents.
There are no respiratory organs, and both cell layers absorb oxygen from and expel carbon dioxide into the surrounding water. When the water in the digestive cavity becomes stale it must be replaced, and nutrients that have not been absorbed will be expelled with it. Some Anthozoa have ciliated grooves on their tentacles, allowing them to pump water out of and into the digestive cavity without opening the mouth. This improves respiration after feeding and allows these animals, which use the cavity as a hydrostatic skeleton, to control the water pressure in the cavity without expelling undigested food.
Cnidaria that carry photosynthetic symbionts may have the opposite problem, an excess of oxygen, which may prove toxic. The animals produce large quantities of antioxidants to neutralize the excess oxygen.
All cnidarians can regenerate, allowing them to recover from injury and to reproduce asexually. Medusae have limited ability to regenerate, but polyps can do so from small pieces or even collections of separated cells. This enables corals to recover even after apparently being destroyed by predators.
Cnidarian sexual reproduction often involves a complex life cycle with both polyp and medusa stages. For example, in Scyphozoa (jellyfish) and Cubozoa (box jellies) a larva swims until it finds a good site, and then becomes a polyp. This grows normally but then absorbs its tentacles and splits horizontally into a series of disks that become juvenile medusae, a process called strobilation. The juveniles swim off and slowly grow to maturity, while the polyp re-grows and may continue strobilating periodically. The adults have gonads in the gastroderm, and these release ova and sperm into the water in the breeding season.
This phenomenon of succession of differently organized generations (one asexually reproducing, sessile polyp, followed by a free-swimming medusa or a sessile polyp that reproduces sexually) is sometimes called "alternation of asexual and sexual phases" or "metagenesis", but should not be confused with the alternation of generations as found in plants.
Shortened forms of this life cycle are common, for example some oceanic scyphozoans omit the polyp stage completely, and cubozoan polyps produce only one medusa. Hydrozoa have a variety of life cycles. Some have no polyp stages and some (e.g. "hydra") have no medusae. In some species, the medusae remain attached to the polyp and are responsible for sexual reproduction; in extreme cases these reproductive zooids may not look much like medusae. Meanwhile, life cycle reversal, in which polyps are formed directly from medusae without the involvement of sexual reproduction process, was observed in both Hydrozoa ("Turritopsis dohrnii" and "Laodicea undulata") and Scyphozoa ("Aurelia" sp.1). Anthozoa have no medusa stage at all and the polyps are responsible for sexual reproduction.
Spawning is generally driven by environmental factors such as changes in the water temperature, and their release is triggered by lighting conditions such as sunrise, sunset or the phase of the moon. Many species of Cnidaria may spawn simultaneously in the same location, so that there are too many ova and sperm for predators to eat more than a tiny percentage — one famous example is the Great Barrier Reef, where at least 110 corals and a few non-cnidarian invertebrates produce enough gametes to turn the water cloudy. These mass spawnings may produce hybrids, some of which can settle and form polyps, but it is not known how long these can survive. In some species the ova release chemicals that attract sperm of the same species.
The fertilized eggs develop into larvae by dividing until there are enough cells to form a hollow sphere (blastula) and then a depression forms at one end (gastrulation) and eventually becomes the digestive cavity. However, in cnidarians the depression forms at the end further from the yolk (at the animal pole), while in bilaterians it forms at the other end (vegetal pole). The larvae, called planulae, swim or crawl by means of cilia. They are cigar-shaped but slightly broader at the "front" end, which is the aboral, vegetal-pole end and eventually attaches to a substrate if the species has a polyp stage.
Anthozoan larvae either have large yolks or are capable of feeding on plankton, and some already have endosymbiotic algae that help to feed them. Since the parents are immobile, these feeding capabilities extend the larvae's range and avoid overcrowding of sites. Scyphozoan and hydrozoan larvae have little yolk and most lack endosymbiotic algae, and therefore have to settle quickly and metamorphose into polyps. Instead, these species rely on their medusae to extend their ranges.
All known cnidaria can reproduce asexually by various means, in addition to regenerating after being fragmented. Hydrozoan polyps only bud, while the medusae of some hydrozoans can divide down the middle. Scyphozoan polyps can both bud and split down the middle. In addition to both of these methods, Anthozoa can split horizontally just above the base. Asexual reproduction makes the daughter cnidarian a clone of the adult.
Cnidarians were for a long time grouped with Ctenophores in the phylum Coelenterata, but increasing awareness of their differences caused them to be placed in separate phyla. Modern cnidarians are generally classified into four main classes: sessile Anthozoa (sea anemones, corals, sea pens); swimming Scyphozoa (jellyfish) and Cubozoa (box jellies); and Hydrozoa, a diverse group that includes all the freshwater cnidarians as well as many marine forms, and has both sessile members such as "Hydra" and colonial swimmers such as the Portuguese Man o' War. Staurozoa have recently been recognised as a class in their own right rather than a sub-group of Scyphozoa, and the parasitic Myxozoa and Polypodiozoa are now recognized as highly derived cnidarians rather than more closely related to the bilaterians.
Stauromedusae, small sessile cnidarians with stalks and no medusa stage, have traditionally been classified as members of the Scyphozoa, but recent research suggests they should be regarded as a separate class, Staurozoa.
The Myxozoa, microscopic parasites, were first classified as protozoans. Research then found that "Polypodium hydriforme", a non-Myxozoan parasite "within" the egg cells of sturgeon, is closely related to the Myxozoa and suggested that both "Polypodium" and the Myxozoa were intermediate between cnidarians and bilaterian animals. More recent research demonstrates that the previous identification of bilaterian genes
reflected contamination of the Myxozoan samples by material from their host organism, and they are now firmly identified as heavily derived cnidarians, and more closely related to Hydrozoa and Scyphozoa than to Anthozoa.
Some researchers classify the extinct conulariids as cnidarians, while others propose that they form a completely separate phylum.
Current classification according to the World Register of Marine Species: 
Many cnidarians are limited to shallow waters because they depend on endosymbiotic algae for much of their nutrients. The life cycles of most have polyp stages, which are limited to locations that offer stable substrates. Nevertheless, major cnidarian groups contain species that have escaped these limitations. Hydrozoans have a worldwide range: some, such as "Hydra", live in freshwater; "Obelia" appears in the coastal waters of all the oceans; and "Liriope" can form large shoals near the surface in mid-ocean. Among anthozoans, a few scleractinian corals, sea pens and sea fans live in deep, cold waters, and some sea anemones inhabit polar seabeds while others live near hydrothermal vents over below sea-level. Reef-building corals are limited to tropical seas between 30°N and 30°S with a maximum depth of , temperatures between , high salinity, and low carbon dioxide levels. Stauromedusae, although usually classified as jellyfish, are stalked, sessile animals that live in cool to Arctic waters. 
Cnidarians range in size from a mere handful of cells for the parasitic myxozoans 
through "Hydra"'s length of , to the Lion's mane jellyfish, which may exceed in diameter and in length.
Prey of cnidarians ranges from plankton to animals several times larger than themselves. Some cnidarians are parasites, mainly on jellyfish but a few are major pests of fish. Others obtain most of their nourishment from endosymbiotic algae or dissolved nutrients. Predators of cnidarians include: sea slugs, which can incorporate nematocysts into their own bodies for self-defense; starfish, notably the crown of thorns starfish, which can devastate corals; butterfly fish and parrot fish, which eat corals; and marine turtles, which eat jellyfish. Some sea anemones and jellyfish have a symbiotic relationship with some fish; for example clown fish live among the tentacles of sea anemones, and each partner protects the other against predators.
Coral reefs form some of the world's most productive ecosystems. Common coral reef cnidarians include both Anthozoans (hard corals, octocorals, anemones) and Hydrozoans (fire corals, lace corals). The endosymbiotic algae of many cnidarian species are very effective primary producers, in other words converters of inorganic chemicals into organic ones that other organisms can use, and their coral hosts use these organic chemicals very efficiently. In addition, reefs provide complex and varied habitats that support a wide range of other organisms. Fringing reefs just below low-tide level also have a mutually beneficial relationship with mangrove forests at high-tide level and seagrass meadows in between: the reefs protect the mangroves and seagrass from strong currents and waves that would damage them or erode the sediments in which they are rooted, while the mangroves and seagrass protect the coral from large influxes of silt, fresh water and pollutants. This additional level of variety in the environment is beneficial to many types of coral reef animals, which for example may feed in the sea grass and use the reefs for protection or breeding.
The earliest widely accepted animal fossils are rather modern-looking cnidarians, possibly from around , although fossils from the Doushantuo Formation can only be dated approximately. The identification of some of these as embryos of animals has been contested, but other fossils from these rocks strongly resemble tubes and other mineralized structures made by corals. Their presence implies that the cnidarian and bilaterian lineages had already diverged. Although the Ediacaran fossil "Charnia" used to be classified as a jellyfish or sea pen, more recent study of growth patterns in "Charnia" and modern cnidarians has cast doubt on this hypothesis, leaving only the Canadian polyp, "Haootia", as the only bona-fide cnidarian body fossil from the Ediacaran. Few fossils of cnidarians without mineralized skeletons are known from more recent rocks, except in lagerstätten that preserved soft-bodied animals.
A few mineralized fossils that resemble corals have been found in rocks from the Cambrian period, and corals diversified in the Early Ordovician. These corals, which were wiped out in the Permian-Triassic extinction about , did not dominate reef construction since sponges and algae also played a major part. During the Mesozoic era rudist bivalves were the main reef-builders, but they were wiped out in the Cretaceous–Paleogene extinction event , and since then the main reef-builders have been scleractinian corals.
It is difficult to reconstruct the early stages in the evolutionary "family tree" of animals using only morphology (their shapes and structures), because the large differences between Porifera (sponges), Cnidaria plus Ctenophora (comb jellies), Placozoa and Bilateria (all the more complex animals) make comparisons difficult. Hence reconstructions now rely largely or entirely on molecular phylogenetics, which groups organisms according to similarities and differences in their biochemistry, usually in their DNA or RNA.
It is now generally thought that the Calcarea (sponges with calcium carbonate spicules) are more closely related to Cnidaria, Ctenophora (comb jellies) and Bilateria (all the more complex animals) than they are to the other groups of sponges. In 1866 it was proposed that Cnidaria and Ctenophora were more closely related to each other than to Bilateria and formed a group called Coelenterata ("hollow guts"), because Cnidaria and Ctenophora both rely on the flow of water in and out of a single cavity for feeding, excretion and respiration. In 1881, it was proposed that Ctenophora and Bilateria were more closely related to each other, since they shared features that Cnidaria lack, for example muscles in the middle layer (mesoglea in Ctenophora, mesoderm in Bilateria). However more recent analyses indicate that these similarities are rather vague, and the current view, based on molecular phylogenetics, is that Cnidaria and Bilateria are more closely related to each other than either is to Ctenophora. This grouping of Cnidaria and Bilateria has been labelled "Planulozoa" because it suggests that the earliest Bilateria were similar to the planula larvae of Cnidaria.
Within the Cnidaria, the Anthozoa (sea anemones and corals) are regarded as the sister-group of the rest, which suggests that the earliest cnidarians were sessile polyps with no medusa stage. However, it is unclear how the other groups acquired the medusa stage, since Hydrozoa form medusae by budding from the side of the polyp while the other Medusozoa do so by splitting them off from the tip of the polyp. The traditional grouping of Scyphozoa included the Staurozoa, but morphology and molecular phylogenetics indicate that Staurozoa are more closely related to Cubozoa (box jellies) than to other "Scyphozoa". Similarities in the double body walls of Staurozoa and the extinct Conulariida suggest that they are closely related. The position of Anthozoa nearest the beginning of the cnidarian family tree also implies that Anthozoa are the cnidarians most closely related to Bilateria, and this is supported by the fact that Anthozoa and Bilateria share some genes that determine the main axes of the body.
However, in 2005 Katja Seipel and Volker Schmid suggested that cnidarians and ctenophores are simplified descendants of triploblastic animals, since ctenophores and the medusa stage of some cnidarians have striated muscle, which in bilaterians arises from the mesoderm. They did not commit themselves on whether bilaterians evolved from early cnidarians or from the hypothesized triploblastic ancestors of cnidarians.
In molecular phylogenetics analyses from 2005 onwards, important groups of developmental genes show the same variety in cnidarians as in chordates. In fact cnidarians, and especially anthozoans (sea anemones and corals), retain some genes that are present in bacteria, protists, plants and fungi but not in bilaterians.
The mitochondrial genome in the medusozoan cnidarians, unlike those in other animals, is linear with fragmented genes. The reason for this difference is unknown.
Jellyfish stings killed about 1,500 people in the 20th century, and cubozoans are particularly dangerous. On the other hand, some large jellyfish are considered a delicacy in East and Southeast Asia. Coral reefs have long been economically important as providers of fishing grounds, protectors of shore buildings against currents and tides, and more recently as centers of tourism. However, they are vulnerable to over-fishing, mining for construction materials, pollution, and damage caused by tourism.
Beaches protected from tides and storms by coral reefs are often the best places for housing in tropical countries. Reefs are an important food source for low-technology fishing, both on the reefs themselves and in the adjacent seas. However, despite their great productivity, reefs are vulnerable to over-fishing, because much of the organic carbon they produce is exhaled as carbon dioxide by organisms at the middle levels of the food chain and never reaches the larger species that are of interest to fishermen. Tourism centered on reefs provides much of the income of some tropical islands, attracting photographers, divers and sports fishermen. However, human activities damage reefs in several ways: mining for construction materials; pollution, including large influxes of fresh water from storm drains; commercial fishing, including the use of dynamite to stun fish and the capture of young fish for aquariums; and tourist damage caused by boat anchors and the cumulative effect of walking on the reefs. Coral, mainly from the Pacific Ocean has long been used in jewellery, and demand rose sharply in the 1980s.
Some large jellyfish species of the Rhizostomae order are commonly consumed in Japan, Korea and Southeast Asia. In parts of the range, fishing industry is restricted to daylight hours and calm conditions in two short seasons, from March to May and August to November. The commercial value of jellyfish food products depends on the skill with which they are prepared, and "Jellyfish Masters" guard their trade secrets carefully. Jellyfish is very low in cholesterol and sugars, but cheap preparation can introduce undesirable amounts of heavy metals.
The "sea wasp" "Chironex fleckeri" has been described as the world's most venomous jellyfish and is held responsible for 67 deaths, although it is difficult to identify the animal as it is almost transparent. Most stingings by "C. fleckeri" cause only mild symptoms. Seven other box jellies can cause a set of symptoms called Irukandji syndrome, which takes about 30 minutes to develop, and from a few hours to two weeks to disappear. Hospital treatment is usually required, and there have been a few deaths.
A number of the parasitic Myxozoans are commercially important pathogens in salmonid aquaculture.

</doc>
<doc id="6623" url="https://en.wikipedia.org/wiki?curid=6623" title="Conservative Judaism">
Conservative Judaism

Conservative Judaism (known as Masorti Judaism outside North America) is a Jewish religious movement that regards the authority of Jewish law and tradition as emanating primarily from the assent of the people and the community through the generations, more than from divine revelation. It therefore views Jewish law, or "halakha", as both binding and subject to historical development. The Conservative rabbinate employs modern historical-critical research, rather than only traditional methods and sources, and lends great weight to its constituency when determining its stance on matters of practice. The movement considers its approach as the authentic and most appropriate continuation of "halakhic" discourse, maintaining both fealty to received forms and flexibility in their interpretation. It also eschews strict theological definitions, lacking a consensus in matters of faith and allowing great pluralism.
While regarding itself as the heir of Rabbi Zecharias Frankel's 19th-century Positive-Historical School in Europe, Conservative Judaism fully institutionalized only in the United States during the mid-20th century. Its largest center today is in North America, where its main congregational arm is the United Synagogue of Conservative Judaism and the New York–based Jewish Theological Seminary of America operates as its largest rabbinic seminary. Globally, affiliated communities are united within the umbrella organization Masorti Olami. Conservative Judaism is the third-largest Jewish religious movement worldwide, estimated to represent close to 1.1 million people, both over 600,000 registered adult congregants and many non-member identifiers.
Conservative Judaism, from its earliest stages, was marked by ambivalence and ambiguity in all matters theological. Rabbi Zecharias Frankel, considered its intellectual progenitor, believed the very notion of theology was alien to traditional Judaism. He was often accused of obscurity on the subject by his opponents, both Reform and Orthodox. The American movement largely espoused a similar approach, and its leaders mostly avoided the field. Only in 1985 did a course about Conservative theology open in the Jewish Theological Seminary of America (JTS). The hitherto sole major attempt to define a clear credo was made in 1988, with the Statement of Principles "Emet ve-Emunah" (Truth and Belief), formulated and issued by the Leadership Council of Conservative Judaism. The introduction stated that "lack of definition was useful" in the past but a need to articulate one now arose. The platform provided many statements citing key concepts such as God, revelation and Election, but also acknowledged that a variety of positions and convictions existed within its ranks, eschewing strict delineation of principles and often expressing conflicting views. In a 1999 special edition of "Conservative Judaism" dedicated to the matter, leading rabbis Elliot N. Dorff and Gordon Tucker clarified that "the great diversity" within the movement "makes the creation of a theological vision shared by all neither possible nor desirable".
Conservative Judaism largely upholds the theistic notion of a personal God. "Emet ve-Emunah" stated that "we affirm our faith in God as the Creator and Governor of the universe. His power called the world into being; His wisdom and goodness guide its destiny." 
Concurrently, the platform also noted that His nature was "elusive" and subject to many options of belief. A naturalistic conception of divinity, regarding it as inseparable from the mundane world, once had an important place within the movement, especially represented by Mordecai Kaplan. After Kaplan's Reconstructionism fully coalesced into an independent movement, these views were marginalized.
A similarly inconclusive position is expressed toward other precepts. Most theologians adhere to the Immortality of the Soul, but while references to the Resurrection of the Dead are maintained, English translations of the prayers obscure the issue. In "Emet", it was stated that death is not tantamount to the end of one's personality. Relating to the Messianic ideal, the movement rephrased most petitions for the restoration of the Sacrifices into past tense, rejecting a renewal of animal offerings, though not opposing a Return to Zion and even a new Temple. The 1988 platform announced that "some" believe in classic eschatology, but dogmatism in this matter was "philosophically unjustified". The notions of Election of Israel and God's covenant with it were basically retained as well.
Conservative conception of Revelation encompasses an extensive spectrum. Zecharias Frankel himself applied critical-scientific methods to analyze the stages in the development of the Oral Torah, pioneering modern study of the Mishnah. He regarded the Beatified Sages as innovators who added their own, original contribution to the canon, not merely as expounders and interpreters of a legal system given in its entirety to Moses on Mount Sinai. Yet he also vehemently rejected utilizing these disciplines on the Pentateuch, maintaining it was beyond human reach and wholly celestial in origin. Frankel never elucidated his beliefs, and the exact correlation between human and divine in his thought is still subject to scholarly debate. A similar negative approach toward Higher Criticism, while accepting an evolutionary understanding of Oral Law, defined Rabbi Alexander Kohut, Solomon Schechter and the early generation of American Conservative Judaism. When JTS faculty began to embrace Biblical criticism in the 1920s, they adapted a theological view consistent with it: an original, verbal revelation did occur at Sinai, but the text itself was composed by later authors. The latter, classified by Dorff as a relatively moderate metamorphosis of the old one, is still espoused by few traditionalist right-wing Conservative rabbis, though it is marginalized among senior leadership.
A small but influential segment within the JTS and the movement adhered, from the 1930s, to Mordecai Kaplan's philosophy that denied any form of revelation but viewed all scripture as a purely human product. Along with other Reconstructionist tenets, it dwindled as the latter consolidated into a separate group. Kaplan's views and the permeation of Higher Criticism gradually swayed most Conservative thinkers towards a non-verbal understanding of theophany, which has become dominant in the 1970s. This was en sync with the wider trend of lowering rates of Americans who accepted the Bible as the Word of God. Dorff categorized the proponents of this into two schools. One maintains that God projected some form of message which inspired the human authors of the Pentateuch to record what they perceived. The other is often strongly influenced by Franz Rosenzweig and other existentialists, but also attracted many Objectivists who consider human reason paramount. The second school states that God conferred merely his presence on those he influenced, without any communication, and the experience drove them to spiritual creativity. While they differ in the theoretical level surrounding revelation, both practically regard all scripture and religious tradition as a human product with certain divine inspiration—providing an understanding that recognizes Biblical Criticism and also justifies major innovation in religious conduct. The first doctrine, advocated by such leaders as rabbis Ben-Zion Bokser and Robert Gordis, largely imparted that some elements within Judaism are fully divine but determining which would be impractical, and therefore received forms of interpretation should be basically upheld. Exponents of the latter view, among them rabbis Louis Jacobs and Neil Gillman, also emphasized the encounter of God with the Jews as a collective and the role of religious authorities through the generations in determining what it implied. The stress on the supremacy of community and tradition, rather than individual consciousness, defines the entire spectrum of Conservative thought.
The Conservative mainstay was the adoption of the historical-critical method in understanding Judaism and setting its future course. In accepting an evolutionary approach to the religion, as something that developed over time and absorbed considerable external influences, the movement distinguished between the original meaning implied in traditional sources and the manner they were grasped by successive generations, rejecting belief in an unbroken chain of interpretation from God's original Revelation, immune to any major extraneous effects. This evolutionary perception of religion, while relatively moderate in comparison with more radical modernizers—the scholarship of the Positive-Historical school, for example, sought to demonstrate the continuity and cohesiveness of Judaism along the years—still challenged Conservative leaders.
They regarded tradition and received mores with reverence, especially the continued adherence to the mechanism of Religious Law ("Halakha"), opposing indiscriminate modification, and emphasized they should be changed only with care and caution, and remain observed by the people. Rabbi Louis Ginzberg, summarizing his movement's position, wrote:
This discrepancy between scientific criticism and insistence on heritage had to be compensated by a conviction that would forestall either deviation from accepted norms or laxity and apathy.
A key doctrine which was to fulfill this capacity was the collective will of the Jewish people. Conservatives lent it great weight in determining religious practice, both in historical precedent and as a means to shape present conduct. Zecharias Frankel pioneered this approach; as Michael A. Meyer commented, "the extraordinary status which he ascribed to the ingrained beliefs and practices of the community is probably the most original element of his thought." He turned it into a source of legitimacy for both change and preservation, but mostly the latter. The basic moderation and traditionalism of the majority among the people were to guarantee a sense of continuity and unity, restraining the guiding rabbis and scholars who at his age were intent on reform, but also allowing them maneuverability in adopting or discarding certain elements. Solomon Schechter espoused a similar position. He turned the old rabbinic concept of "K'lal Yisrael", which he translated as "Catholic Israel", into a comprehensive worldview. For him, the details of divine Revelation were of secondary significance, as historical change dictated its interpretation through the ages notwithstanding: "the center of authority is actually removed from the Bible", he surmised, "and placed in some living body... in touch with the ideal aspirations and the religious needs of the age, best able to determine... This living body, however, is not represented by... priesthood, or Rabbihood, but by the collective conscience of Catholic Israel."
The scope, limits and role of this corpus were a matter for contention in Conservative ranks. Schechter himself used it to oppose any major break with either traditionalist or progressive elements within American Jewry of his day, while some of his successors argued that the idea became obsolete due to the great alienation of many from received forms, that had to be countered by innovative measures to draw them back. The Conservative rabbinate often vacillated on to which degree may the non-practicing, religiously apathetic strata be included as a factor within Catholic Israel, providing impulse for them in determining religious questions; even avant-garde leaders acquiesced that the majority could not serve that function. Right-wing critics often charged that the movement allowed its uncommitted laity an exaggerated role, conceding to its demands and successively stretching "halakhic" boundaries beyond any limit.
The Conservative leadership had limited success in imparting their worldview to the general public. While the rabbinate perceived itself as bearing a unique, original conception of Judaism, the masses lacked much interest, regarding it mainly as a compromise offering a channel for religious identification that was more traditional than Reform Judaism yet less strict than Orthodoxy. Only a low percentage of Conservative congregants actively pursue an observant lifestyle: in the mid-1980s, Charles Liebman and Daniel J. Elazar calculated that barely 3 to 4 per cent held to one quite thoroughly. This gap between principle and the public, more pronounced than in any other Jewish movement, is often credited at explaining the decline of the Conservative movement. While some 41 per cent of American Jews identified with it in the 1970s, it had shrunk to an estimated 18 per cent (and 11 per cent among those under 30) in 2013.
Fidelity and commitment to "Halakha", while subject to criticism as disingenuous both from within and without, were and remain a cornerstone doctrine of Conservative Judaism: The movement views the legalistic system as normative and binding, and believes Jews must practically observe its precepts, like Sabbath, dietary ordinances, ritual purity, daily prayer with phylacteries and the like. Concurrently, examining Jewish history and rabbinic literature through the lens of academic criticism, it maintained that these laws were always subject to considerable evolution, and must continue to do so. "Emet ve-Emunah" titled its chapter on the subject with "The Indispensability of Halakha", stating that ""Halakha" in its developing form is an indispensable element of a traditional Judaism which is vital and modern." Conservative Judaism regards itself as the authentic inheritor of a flexible legalistic tradition, charging the Orthodox with petrifying the process and Reform with abandoning it.
The tension between "tradition and change"—which were also the motto adopted by the movement since the 1950s—and the need to balance them were always a topic of intense debate within Conservative Judaism. In its early stages, the leadership opposed pronounced innovation, mostly adopting a relatively rigid position. Mordecai Kaplan's Reconstructionism raised the demand for thoroughgoing modification without much regard for the past or "halakhic" considerations, but senior rabbis opposed him vigorously. Even in the 1940s and 1950s, when Kaplan's influence grew, his superiors rabbis Ginzberg, Louis Finkelstein and Saul Lieberman espoused a very conservative line. Since the 1970s, with the strengthening of the liberal wing within the movement, the majority in the Rabbinic Assembly opted for quite radical reformulations in religious conduct, but rejected the Reconstructionist non-"halakhic" approach, insisting that the legalistic method be maintained. The "halakhic" commitment of Conservative Judaism has been subject to much criticism, from within and without. Right-wing discontents, including the Union for Traditional Judaism which seceded in protest of the 1983 resolution to ordain women rabbis—adopted at an open vote, where all JTS faculty regardless of qualification were counted—contested the validity of this description, as well as progressives like Rabbi Neil Gillman, who exhorted the movement to cease describing itself as "halakhic" in 2005, stating that after repeated concessions, "our original claim has died a death by a thousand qualifications... It has lost all factual meaning."
The main body entrusted with formulating rulings, responsa and statues is the Committee on Jewish Law and Standards (CJLS), a panel with 25 voting legalistic specialists and further 11 observers. There is also the smaller "Va'ad ha-Halakha" (Law Committee) of Israel's Masorti Movement. Every responsa must receive a minimum of six voters to be considered an official position of the CJLS. Conservative Judaism explicitly acknowledges the principle of "halakhic" pluralism, enabling the panel to adopt more than one resolution in any given subject. The final authority in each Conservative community is the local rabbi, the "mara d'atra" (Lord of the Locality, in traditional terms), enfranchised to adopt either minority or majority opinions from the CJLS or maintain local practice. Thus, on the issue of admitting openly Homosexual rabbinic candidates, the Committee approved two resolutions, one in favour and one against; the JTS took the lenient position, while the Seminario Rabinico Latinoamericano still adheres to the latter. Likewise, while most Conservative synagogues approved of egalitarianism for women in religious life, some still maintain traditional gender roles and do not count females for prayer quorums.
The Conservative treatment of "Halakha" is defined by several features, though the entire range of its "Halakhic" discourse cannot be sharply distinguished from either the traditional or Orthodox one. Rabbi David Golinkin, who attempted to classify its parameters, stressed that quite often rulings merely reiterate conclusions reached in older sources or even Orthodox ones. for example, in the details of preparing Sabbath ritual enclosures, it draws directly on the opinions of the "Shulchan Aruch" and Rabbi Hayim David HaLevi. Another tendency prevalent among the movement's rabbis, yet again not particular to it, is the adoption of the more lenient positions on the matters at question—though this is not universal, and responsa also took stringent ones not infrequently.
A more distinctive characterization is a greater proclivity to base rulings on earlier sources, in the "Rishonim" or before them, as far back as the Talmud. Conservative decisors frequently resort to less canonical sources, isolated responsa or minority opinions. They demonstrate more fluidity in regards to established precedent and continuum in rabbinic literature, mainly those by the later authorities, and lay little stress on the perceived hierarchy between major and minor legalists of the past. They are far more inclined to contend ("machloket") with old rulings, to be flexible towards custom or to wholly disregard it. This is especially expressed in less hesitancy to rule against or notwithstanding the major codifications of Jewish Law, like "Mishne Torah", "Arba'ah Turim" and especially the "Shulchan Aruch" with its Isserles Gloss and later commentaries. Conservative authorities, while often relying on the "Shulchan Aruch" themselves, criticize the Orthodox for relatively rarely venturing beyond it and overly canonizing Rabbi Joseph Karo's work. In several occasions, Conservative rabbis discerned that the "Shulchan Aruch" ruled without firm precedent, sometimes deriving his conclusions from the "Kabbalah". An important example is the ruling of Rabbi Golinkin—contrary to the majority consensus among the "Acharonim" and the more prominent "Rishonim", but based on many opinions of the lesser "Rishonim" which is derived from a minority view in the Talmud—that the Sabbatical Year is not obligatory in present times at all (neither "de'Oraita" nor "de'Rabanan") but rather an act of piety.
Ethical considerations and the weight due to them in determining "halakhic" issues, mainly to what degree may modern sensibilities shape the outcome, are subject to much discourse. Right-wing decisors, like Rabbi Joel Roth, maintained that such elements are naturally a factor in formulating conclusions, but may not alone serve as a justification for adopting a position. The majority, however, basically subscribed to the opinion evinced already by Rabbi Seymour Siegel in the 1960s, that the cultural and ethical norms of the community, the contemporary equivalents of Talmudic "Aggadah", should supersede the legalistic forms when the two came into conflict and there was a pivotal ethical concern. Rabbi Elliot Dorff concluded that in contrast to the Orthodox, Conservative Judaism maintains that the juridical details and processes mainly serve higher moral purposes and could be modified if they no longer do so: "in other words, the "Aggadah" should control the "Halakha"." The liberal Rabbi Gordon Tucker, along with Gillman and other progressives, supported a far-reaching implementation of this approach, making Conservative Judaism much more "Aggadic" and allowing moral priorities an overriding authority at all occasions. This idea became very popular among the young generation, but it was not fully embraced either. In the 2006 resolution on homosexuals, the CJLS chose a middle path: they agreed that the ethical consideration of human dignity was of supreme importance, but not sufficient to uproot the express Biblical prohibition on not to lie with mankind as with womankind (traditionally understood as banning full anal intercourse). All other limitations, including on other forms of sexual relations, were lifted. A similar approach is manifest in the great weight ascribed to sociological changes in deciding religious policy. The CJLS and the Rabbinical Assembly members frequently state that circumstances were profoundly transformed in modern times, fulfilling the criteria mandating new rulings in various fields (based on general talmudic principles like "Shinui ha-I'ttim", "Change of Times"). This, along with the ethical aspect, was a main argument for revolutionizing the role of women in religious life and embracing egalitarianism.
The most distinctive feature of Conservative legalistic discourse, in which it is conspicuously and sharply different from Orthodoxy, is the incorporation of critical-scientific methods into the process. Deliberations almost always delineate the historical development of the specific issue at hand, from the earliest known mentions until modern times. This approach enables a thorough analysis of the manner in which it was practiced, accepted, rejected or modified in various periods, not necessarily en sync with the received rabbinic understanding. Archaeology, philology and Judaic Studies are employed; rabbis use comparative compendiums of religious manuscripts, sometimes discerning that sentences were only added later or include spelling, grammar and transcription errors, changing the entire understanding of certain passages. This critical approach is central to the movement, for its historicist underpinning stresses that all religious literature has an original meaning relevant in the context of its formulation. This meaning may be analyzed and discerned, and is distinct from the later interpretations ascribed by traditional commentators. Decisors are also far more prone to include references to external scientific sources in relevant fields, like veterinarian publications in "halakhic" matters concerning livestock.
Conservative authorities, as part of their promulgation of a dynamic "Halakha", often cite the manner in which the sages of old used rabbinic statues ("Takkanah") that enabled to bypass prohibitions in the Pentateuch, like the "Prozbul" or "Heter I'ska". In 1948, when employing those was first debated, Rabbi Isaac Klein argued that since there was no consensus on leadership within Catholic Israel, formulation of significant "takkanot" should be avoided. Another proposal, to ratify them only with a two-thirds majority in the RA, was rejected. New statues require a simple majority, 13 supporters among the 25 members of the CJLS. In the 1950s and 1960s, such drastic measures—as Rabbi Arnold M. Goodman cited in a 1996 writ allowing members of the priestly caste to marry divorcees, "Later authorities were reluctant to assume such unilateral authority... fear that invoking this principle would create the proverbial slippery slope, thereby weakening the entire "halakhic" structure... thus imposed severe limitations on the conditions and situations where it would be appropriate"—were carefully drafted as temporal, emergency ordinances ("Horaat Sha'ah"), grounded on the need the avoid a total rift of many nonobservant Jews. Later on, these ordinances became accepted and permanent on the practical level. The Conservative movement issued a wide range of new, thoroughgoing statues, from the famous 1950 responsum that allowed driving to the synagogue on the Sabbath and up to the 2000 decision to ban rabbis from inquiring about whether someone was a Bastard, de facto abolishing this legal category.
The RA and CJLS reached many decisions through the years, shaping a distinctive profile for Conservative practice and worship. In the 1940s, when the public demanded mixed seating of both sexes in synagogue, some rabbis argued there was no precedent but obliged on the ground of dire need (Eth la'asot); others noted that archaeological research showed no partitions in ancient synagogues. Mixed seating became commonplace in almost all congregations. In 1950, it was ruled that using electricity (that is, closure of an electrical circuit) did not constitute kindling a fire unto itself, not even in incandescent bulbs, and therefore was not a forbidden labour and could be done on the Sabbath. On that basis, while performing banned labours is of course forbidden—for example, video recording is still constituted as writing—switching lights and other functions are allowed, though the RA strongly urges adherents to keep the sanctity of the Sabbath (refraining from doing anything that may imitate the atmosphere of weekdays, like loud noise reminiscent of work).
The need to encourage arrival at synagogue also motivated the CJLS, during the same year, to issue a temporal statue allowing driving on that day, for that purpose alone; it was supported by decreeing that the combustion of fuel did not serve any of the acts prohibited during the construction of the Tabernacle, and could therefore be classified, according to their interpretation of the Tosafists' opinion, as "redundant labour" ("Sh’eina Tzricha L’gufa") and be permitted. The validity of this argument was heavily disputed within the movement. In 1952, members of the priestly caste were allowed to marry divorcees, conditioned on forfeiture of their privileges, as termination of marriage became widespread and women who underwent it could not be suspected of unsavory acts. In 1967, the ban on priests marrying converts was also lifted.
In 1954, the issue of "agunot" (women refused divorce by their husbands) was largely settled by adding a clause to the prenuptial contract under which men had to pay alimony as long as they did not concede. In 1968, this mechanism was replaced by a retroactive expropriation of the bride price, rendering the marriage void. In 1955, more girls were celebrating Bat Mitzvah and demanded to be allowed ascents to the Torah, the CJLS agreed that the ordinance under which women were banned from this due to respect for the congregation ("Kvod ha'Tzibur") was no longer relevant. In 1972 it was decreed that rennet, even if derived from unclean animals, was so transformed that it constituted a wholly new item ("Panim Chadashot ba'u l'Khan") and therefore all hard cheese could be considered kosher.
The 1970s and 1980s saw the emergence of women's rights on the main agenda. Growing pressure led the CJLS to adopt a motion that females may be counted as part of a quorum, based on the argument that only the "Shulchan Aruch" explicitly stated that it consist of men. While accepted, this was very controversial in the Committee and heavily disputed. A more complete solution was offered in 1983 by Rabbi Joel Roth, and was also enacted to allow women rabbinic ordination. Roth noted that some decisors of old acknowledged that women may bless when performing positive time-bound commandments (from which they are exempted, and therefore unable to fulfill the obligation for others), especially citing the manner in which they assumed upon themselves the Counting of the Omer. He suggested that women voluntarily commit to pray thrice a day et cetera, and his responsa was adopted. Since then, female rabbis were ordained at JTS and other seminaries. In 1994, the movement accepted Judith Hauptman's principally egalitarian argument, according to which equal prayer obligations for women were never banned explicitly and it was only their inferior status that hindered participation. In 2006, openly gay rabbinic candidates were also to be admitted into the JTS. In 2012, a commitment ceremony for same-sex couples was devised, though not defined as "kiddushin". In 2016, the rabbis passed a resolution supporting transgender rights.
Conservative Judaism in the United States held a relatively strict policy regarding intermarriage. Propositions for acknowledging Jews by patrilineal descent, as in the Reform movement, were overwhelmingly dismissed. Unconverted spouses were largely barred from community membership and participation in rituals; clergy are banned from any involvement in interfaith marriage on pain of dismissal. However, as the rate of such unions rose dramatically, Conservative congregations began describing gentile family members as "K'rov Yisrael" (Kin of Israel) and be more open toward them. The Leadership Council of Conservative Judaism stated in 1995: "we want to encourage the Jewish partner to maintain his/her Jewish identity, and raise their children as Jews."
Despite the centralization of legal deliberation on matters of Jewish law in the CJLS individual synagogues and communities must, in the end, depend on their local decision-makers. The rabbi in his or her or their community is regarded as the Mara D'atra, or the local halakhic decisor. Rabbis trained in the reading practices of Conservative Jewish approaches, historical evaluation of Jewish law and interpretation of Biblical and Rabbinic texts may align directly with the CJLS decisions or themselves opine on matters based on precedents or readings of text that shine light on congregants' questions. So, for instance, a rabbi may or may not choose to permit video streaming on Shabbat despite a majority ruling that allows for use of electronics. A local mara d'atra may rely on the reasoning found in the majority or minority opinions of the CJLS or have other textual and halakhic grounds, i.e., prioritizing Jewish values or legal concepts, to rule one way or another on matters of ritual, family life or sacred pursuits. This balance between a centralization of halakhic authority and maintaining the authority of local rabbis reflects the commitment to pluralism at the heart of the Movement.
The term "Conservative Judaism" was used, still generically and not yet as a specific label, already in the 1887 dedication speech of the Jewish Theological Seminary of America by Rabbi Alexander Kohut. By 1901, the JTS alumni formed the Rabbinical Assembly, of which all ordained Conservative clergy in the world are members. As of 2010, there were 1,648 rabbis in the RA. In 1913, the United Synagogue of America, renamed the United Synagogue of Conservative Judaism in 1991, was founded as a congregational arm of the RA. The movement established the World Council of Conservative Synagogues in 1957. Offshoots outside North America mostly adopted the Hebrew name "Masorti", traditional', as did the Israeli Masorti Movement, founded in 1979, and the British Assembly of Masorti Synagogues, formed in 1985. The World Council eventually changed its name to "Masorti Olami", Masorti International. Besides the RA, the international Cantors Assembly supplies prayer leaders for congregations worldwide.
The United Synagogue of Conservative Judaism, covering the United States, Canada and Mexico, is by far the largest constituent of Masorti Olami. While most congregations defining themselves as "Conservative" are affiliated with the USCJ, some are independent. While accurate information of Canada is scant, it is estimated that some third of religiously affiliated Canadian Jews are Conservative. In 2008, the more traditional Canadian Council of Conservative Synagogues seceded from the parent organization. It numbered seven communities as of 2014. According to the Pew Research Center survey in 2013, 18 per cent of Jews in the United States identified with the movement, making it the second largest in the country. Steven M. Cohen calculated that as of 2013, 962,000 U.S. Jewish adults considered themselves Conservative: 570,000 were registered congregants and further 392,000 were not members in a synagogue but identified. In addition, Cohen assumed in 2006 that 57,000 unconverted non-Jewish spouses were also registered (12 per cent of member households had one at the time): 40 per cent of members intermarry. Conservatives are also the most aged group: among those aged under 30 only 11 per cent identified as such, and there are three people over 55 for every single one aged between 35 and 44. As of November 2015, the USCJ had 580 member congregations (a sharp decline from 630 two years prior), 19 in Canada and the remainder in the United States. In 2011 the USCJ initiated a plan to reinvigorate the movement.
Beyond North America, the movement has little presence—in 2011, Rela Mintz Geffen appraised there were only 100,000 members outside the U.S. (and the former figure including Canada). "Masorti AmLat", the MO branch in Latin America, is the largest with 35 communities in Argentina, 7 in Brazil, 6 in Chile and further 11 in the other countries. The British Assembly of Masorti Synagogues has 13 communities and estimates its membership at over 4,000. More than 20 communities are spread across Europe, and there are 3 in Australia and 2 in Africa. The Masorti Movement in Israel incorporates some 70 communities and prayer groups with several thousand full members. In addition, while Hungarian Neolog Judaism, with a few thousands of adherents and forty partially active synagogues, is not officially affiliated with Masorti Olami, Conservative Judaism regards it as a fraternal, "non-Orthodox but halakhic" movement.
In New York, the JTS serves as the movement's original seminary and legacy institution, along with the Ziegler School of Rabbinic Studies at the American Jewish University in Los Angeles; the Marshall T. Meyer Latin American Rabbinical Seminary (Spanish: "Seminario Rabínico Latinoamericano Marshall T. Meyer"), in Buenos Aires, Argentina; and the Schechter Institute of Jewish Studies in Jerusalem. A Conservative institution that does not grant rabbinic ordination but which runs along the lines of a traditional yeshiva is the Conservative Yeshiva, located in Jerusalem. The Neolog Budapest University of Jewish Studies also maintains connections with Conservative Judaism.
The current chancellor of the JTS is Rabbi Arnold Eisen, in office since 2008. The current dean of the Ziegler School of Rabbinic Studies is Bradley Shavit Artson. The Committee on Jewish Law and Standards is chaired by Rabbi Elliot N. Dorff, serving since 2007. The Rabbinical Assembly is headed by President Rabbi Debra Newman Kamin, as of 2019, and managed by executive vice-president Rabbi Julie Schonfeld. The USCJ is directed by President Ned Gladstein. In South America, Rabbi Ariel Stofenmacher serves as chancellor in the Seminary and Rabbi Marcelo Rittner as president of Masorti AmLat. In Britain, the Masorti Assembly is chaired by Senior Rabbi Jonathan Wittenberg. In Israel, the Masorti movement's executive director is Yizhar Hess and chair Sophie Fellman Rafalovitz.
The global youth movement is known as NOAM, an acronym for No'ar Masorti; its North American chapter is called the United Synagogue Youth. Marom Israel is the Masorti movement's organization for students and young adults, providing activities based on religious pluralism and Jewish content. The Women's League for Conservative Judaism is also active in North America.
The USCJ maintains the Solomon Schechter Day Schools, comprising 76 day schools in 17 American states and 2 Canadian provinces serving Jewish children. Many other "community day schools" that are not affiliated with Schechter take a generally Conservative approach, but unlike these, generally have "no barriers to enrollment based on the faith of the parents or on religious practices in the home". During the first decade of the 21st century, a number of schools that were part of the Schechter network transformed themselves into non-affiliated community day schools. The USCJ also maintains the Camp Ramah system, where children and adolescents spend summers in an observant environment.
The rise of modern, centralized states in Europe by the early 19th century hearkened the end of Jewish judicial autonomy and social seclusion. Their communal corporate rights were abolished, and the process of emancipation and acculturation that followed quickly transformed the values and norms of the public. Estrangement and apathy toward Judaism were rampant. The process of communal, educational and civil reform could not be restricted from affecting the core tenets of the faith. The new academic, critical study of Judaism ("Wissenschaft des Judentums") soon became a source of controversy. Rabbis and scholars argued to what degree, if at all, its findings could be used to determine present conduct. The modernized Orthodox in Germany, like rabbis Isaac Bernays and Azriel Hildesheimer, were content to cautiously study it while stringently adhering to the sanctity of holy texts and refusing to grant "Wissenschaft" any say in religious matters. On the other extreme were Rabbi Abraham Geiger, who would emerge as the founding father of Reform Judaism, and his supporters. They opposed any limit on critical research or its practical application, laying more weight on the need for change than on continuity.
The Prague-born Rabbi Zecharias Frankel, appointed chief rabbi of the Kingdom of Saxony in 1836, gradually rose to become the leader of those who stood at the middle. Besides working for the civic betterment of local Jews and educational reform, he displayed keen interest in "Wissenschaft". But Frankel was always cautious and deeply reverent towards tradition, privately writing in 1836 that "the means must be applied with such care and discretion... that forward progress will be reached unnoticed, and seem inconsequential to the average spectator." He soon found himself embroiled in the great disputes of the 1840s. In 1842, during the second Hamburg Temple controversy, he opposed the new Reform prayerbook, arguing the elimination of petitions for a future Return to Zion led by the Messiah was a violation of an ancient tenet. But he also opposed the ban placed on the tome by Rabbi Bernays, stating this was a primitive behaviour. In the same year, he and the moderate conservative S.L. Rapoport were the only ones of nineteen respondents who negatively answered the Breslau community's enquiry on whether the deeply unorthodox Geiger could serve there. In 1843, Frankel clashed with the radical Reform rabbi Samuel Holdheim, who argued that the act of marriage in Judaism was a civic ("memonot") rather than sanctified () matter and could be subject to the Law of the Land. In December 1843 Frankel launched the magazine "Zeitschrift für die Religiösen Interessen des Judenthums". In the preamble, he attempted to present his approach to the present plight: "the further development of Judaism cannot be done through Reform that would lead to total dissipation... But must be involved in its study... pursued via scientific research, on a "positive, historical" basis." The term Positive-Historical became associated with him and his middle way. The "Zeitschrift" was, along the convictions of its publisher, neither dogmatically orthodox nor overly polemic, wholly opposing Biblical criticism and arguing for the antiquity of custom and practice.
In 1844, Geiger and like-minded allies arranged a conference in Braunschweig that was to have enough authority (since 1826, Rabbi Aaron Chorin called for the convocation of a new "Sanhedrin") to debate and enact thoroughgoing revisions. Frankel was willing to agree only to a meeting without any practical results, and refused the invitation. When the protocols, which contained many radical statements, were published, he denounced the assembly for "applying the scalpel of criticism" and favouring the spirit of the age over tradition. However, he later agreed to attend the second conference, held in Frankfurt am Main on 15 July 1845—in spite of warnings from Rapoport, who cautioned that compromise with Geiger was impossible and he would only damage his reputation among the traditionalists. On the 16th, the issue of Hebrew in the liturgy arose. Most present were inclined to retain it, but with more German segments. A small majority adopted a resolution stating there were subjective, but no objective, imperatives to keep it as the language of service. Frankel then astounded his peers by vehemently protesting, stating it was a breach with the past and that Hebrew was of dire importance and great sentimental value. The others immediately began quoting all passages in rabbinic literature allowing prayer in the vernacular. Frankel could not contend with the "halakhic" validity of their decision, but he perceived it as a sign of profound differences between them. On the 17th he formally withdrew, publishing a lambasting critique of the procedures. "Opponents of the conference, who feared he went to the other side," noted historian Michael A. Meyer, "now felt reassured of his loyalty".
The rabbi of Saxony had many sympathizers, who supported a similarly moderate approach and change only on the basis of the authority of the Talmud. When Geiger began preparing a third conference in Breslau, Hirsch Bär Fassel convinced Frankel to organize one of his own in protest. Frankel invited colleagues to an assembly in Dresden, which was to be held on 21 October 1846. He announced that one measure he was willing to countenance was the possible abolition of the second day of festivals, though only if a broad consensus will be reached and not before thorough deliberation. Attendants were to include Rapoport, Fassel, Adolf Jellinek, Leopold Löw, Michael Sachs, Abraham Kohn and others. However, the Dresden assembly soon drew heated Orthodox resistance, especially from Rabbi Jacob Ettlinger, and was postponed indefinitely.
In 1854, Frankel was appointed chancellor in the new Jewish Theological Seminary of Breslau, the first modern rabbinical seminary in Germany. His opponents on both flanks were incensed. Geiger and the Reform camp long accused him of theological ambiguity, hypocrisy and attachment to stagnant remnants, and now protested the "medieval" atmosphere in the seminary, which was mainly concerned with teaching Jewish Law. The hardline Orthodox Samson Raphael Hirsch, who fiercely opposed "Wissenschaft" and emphasized the divine origin of the entire "halakhic" system in the Theophany at Sinai, was deeply suspicious of Frankel's beliefs, use of science and constant assertions that Jewish Law was flexible and evolving.
The final schism between Frankel and the Orthodox occurred after the 1859 publication of his "Darke ha-Mishna" (Ways of the Mishna). He heaved praise on the Beatified Sages, presenting them as bold innovators, but not once affirmed the divinity of the Oral Torah. On the ordinances classified as Law given to Moses at Sinai, he quoted Asher ben Jehiel that stated several of those were only apocryphally dubbed as such; he applied the latter's conclusion to all, noting they were "so evident "as if" given at Sinai". Hirsch branded Frankel a heretic, demanding he announce whether he believed that both the Oral and Written Torah were of celestial origin. Rabbis Benjamin Hirsch Auerbach, Solomon Klein and others published more complaisant tracts, but also requested an explanation. Rapoport marshaled to Frankel's aid, assuring that his words were merely reiterating ben Jehiel's and that he would soon release a statement that will belie Hirsch's accusations. But then the Chancellor of Breslau issued an ambiguous defence, writing that his book was not concerned with theology and avoiding giving any clear answer. Now even Rapoport joined his critics.
Hirsch succeeded, severely tarnishing his Frankel's reputation among most concerned. Along with fellow Orthodox Rabbi Azriel Hildesheimer, Hirsch launched a protracted public campaign through the 1860s. They ceaselessly stressed the chasm between an Orthodox understanding of "Halakha" as derived and revealed, applied differently to different circumstances and subject to human judgement and possibly error, yet unchanging and divine in principle—as opposed to an evolutionary, historicist and non-dogmatic approach in which past authorities were not just elaborating but consciously innovating, as taught by Frankel. Hildesheimer often repeated that this issue utterly overshadowed any specific technical argument with the Breslau School (the students of which were often more lenient on matters of headcovering for women, Chalav Yisrael and other issues). Hildesheimer was concerned that Jewish public opinion perceived no practical difference between them; though he cared to distinguish the observant acolytes of Frankel from the Reform camp, he noted in his diary: "how meager is the principal difference between the Breslau School, who don silk gloves at their work, and Geiger who wields a sledgehammer." In 1863, when Breslau faculty member Heinrich Graetz published an article where he appeared to doubt the Messianic belief, Hildesheimer immediately seized upon the occasion to prove once more the dogmatic, rather than practical, divide. He denounced Graetz as a heretic.
The Positive-Historical School was influential, but never institutionalized itself as thoroughly as its opponents. Apart from the many graduates of Breslau, Isaac Noah Mannheimer, Adolf Jellinek and Rabbi Moritz Güdemann led the central congregation in Vienna along a similar path. In Jellinek's local seminary, Meir Friedmann and Isaac Hirsch Weiss followed Frankel's moderate approach to critical research. The rabbinate of the liberal Neolog public in Hungary, which formally separated from the Orthodox, was also permeated with the "Breslau spirit". Many of its members studied there, and its Jewish Theological Seminary of Budapest was modeled after it, though the assimilationist congregants cared little for rabbinic opinion. In Germany itself, Breslau alumni founded in 1868 a short-lived society, the Jüdisch-Theologische Verein. It was dissolved within a year, boycotted by both Reform and Orthodox. Michael Sachs led the Berlin congregation in a very conservative style, eventually resigning when an organ was introduced in services. Manuel Joël, another of the Frankelist party, succeeded Geiger in Breslau. He maintained his predecessor's truncated German translation of the liturgy for the sake of compromise, but restored the full Hebrew text.
The Breslau Seminary and the Reform Hochschule für die Wissenschaft des Judentums maintained very different approaches; but on the communal level, the former's alumni failure to organize or articulate a coherent agenda, coupled with the declining prestige of Breslau and the conservatism of the Hochschule's alumni—a necessity in heterogeneous communities which remained unified, especially after the Orthodox gained the right to secede in 1876—imposed a rather uniform and mild character on what was known in Germany as "Liberal Judaism". In 1909, 63 rabbis associated with the Breslau approach founded the Freie jüdische Vereinigung, another brief attempt at institutionalization, but it too failed soon. Only in 1925 did the Religiöse Mittelpartei für Frieden und Einheit succeed in driving the same agenda. It won several seats in communal elections, but was small and of little influence.
Jewish immigration to the United States bred an amalgam of loose communities, lacking strong tradition or stable structures. In this free-spirited environment, a multitude of forces was at work. As early as 1866, Rabbi Jonas Bondi of New York wrote that a Judaism of the "golden middleway, which was termed Orthodox by the left and heterodox or reformer by the right" developed in the new country. The rapid ascendancy of Reform Judaism by the 1880s left few who opposed it: merely a handful of congregations and ministers remained outside the Union of American Hebrew Congregations. These included Sabato Morais and Rabbi Henry Pereira Mendes of the elitist Sephardi congregations, along with rabbis Bernard Drachman (ordained at Breslau, though he regarded himself as Orthodox) and Henry Schneeberger.
While spearheaded by radical and principled Reformers like Rabbi Kaufmann Kohler, the UAHC was also home to more conservative elements. President Isaac Meyer Wise, a pragmatist intent on compromise, hoped to forge a broad consensus that would turn a moderate version of Reform to dominant in America. He kept the dietary laws at home and attempted to assuage traditionalists. On 11 July 1883, apparently due to negligence by the Jewish caterer, non-kosher dishes were served to UAHC rabbis in Wise's presence. Known to posterity as the "trefa banquet", it purportedly made some guests abandon the hall in disgust, but little is factually known about the incident. In 1885, the traditionalist forces were bolstered upon the arrival of Rabbi Alexander Kohut, an adherent of Frankel. He publicly excoriated Reform for disdaining ritual and received forms, triggering a heated polemic with Kohler. The debate was one of the main factors which motivated the latter to compose the Pittsburgh Platform, which unambiguously declared the principles of Reform Judaism: "to-day we accept as binding only the moral laws, and maintain only such ceremonies as elevate and sanctify our lives."
The explicit wording alienated a handful of conservative UAHC ministers: Henry Hochheimer, Frederick de Sola Mendes, Aaron Wise, Marcus Jastrow, and Benjamin Szold. They joined Kohut, Morais and the others in seeking to establish a traditional rabbinic seminary that would serve as a counterweight to Hebrew Union College. In 1886, they founded the Jewish Theological Seminary of America in New York City. Kohut, professor of Talmud who held to the Positive-Historical ideal, was the main educational influence in the early years, prominent among the founders who encompassed the entire spectrum from progressive Orthodox to the brink of Reform; to describe what the seminary intended to espouse, he used the term "Conservative Judaism", which had no independent meaning at the time and was only in relation to Reform. In 1898, Pereira Mendes, Schneeberger and Drachman also founded the Orthodox Union, which maintained close ties with the seminary.
The JTS was a small, fledgling institution with financial difficulties, and was ordaining merely a rabbi per year. But soon after Chancellor Morais' death in 1897, its fortunes turned. Since 1881, a wave of Jewish immigration from Eastern Europe was inundating the country—by 1920, 2.5 million of them had arrived, increasing American Jewry tenfold. They came from regions where civil equality or emancipation were never granted, while acculturation and modernization made little headway. Whether devout or irreligious, they mostly retained strong traditional sentiments in matters of faith, accustomed to old-style rabbinate; the hardline Agudas HaRabbanim, founded by emigrant clergy, opposed secular education or vernacular sermons, and its members spoke almost only Yiddish. The Eastern Europeans were alienated by the local Jews, who were all assimilated in comparison, and especially aghast by the mores of Reform. The need to find a religious framework that would both accommodate and Americanize them motivated Jacob Schiff and other rich philanthropists, all Reform and of German descent, to donate $500,000 to the JTS. The contribution was solicited by Professor Cyrus Adler. It was conditioned on the appointment of Solomon Schechter as Chancellor. In 1901, the Rabbinical Assembly was established as the fraternity of JTS alumni.
Schechter arrived in 1902, and at once reorganized the faculty, dismissing both Pereira Mendes and Drachman for lack of academic merit. Under his aegis, the institute began to draw famous scholars, becoming a center of learning on par with HUC. Schechter was both traditional in sentiment and quite unorthodox in conviction. He maintained that theology was of little importance and it was practice that must be preserved. He aspired to solicit unity in American Judaism, denouncing sectarianism and not perceiving himself as leading a new denomination: "not to create a new party, but to consolidate an old one". The need to raise funds convinced him that a congregational arm for the Rabbinical Assembly and the JTS was required. On 23 February 1913, he founded the United Synagogue of America (since 1991: United Synagogue of Conservative Judaism), which then consisted of 22 communities. He and Mendes first came to major disagreement; Schechter insisted that any alumnus could be appointed to the USoA's managerial board, and not just to serve as communal rabbi, including several the latter did not consider sufficiently devout, or who tolerated mixed seating in their synagogues (though some of those he still regarded as Orthodox). Mendes, president of the Orthodox Union, therefore refused to join. He began to distinguish between the "Modern Orthodoxy" of himself and his peers in the OU, and "Conservatives" who tolerated what was beyond the pale for him. However, this first sign of institutionalization and separation was far from conclusive. Mendes himself could not clearly differentiate between the two groups, and many he viewed as Orthodox were members of the USoA. The epithets "Conservative" and "Orthodox" remained interchangeable for decades to come. JTS graduates served in OU congregations; many students of the Orthodox Rabbi Isaac Elchanan Theological Seminary and members of the OU's Rabbinical Council of America, or RCA, attended it. In 1926, RIETS and the JTS even negotiated a possible merger, though it was never materialized. Upon Schechter's death in 1915, the first generation of his disciples kept his non-sectarian legacy of striving for a united, traditional American Judaism. He was replaced by Cyrus Adler. The USoA grew rapidly as the Eastern European immigrant population slowly integrated. In 1923 it already had 150 affiliated communities, and 229 before 1930. Synagogues offered a more modernized ritual: English sermons, choir singing, late Friday evening services which tacitly acknowledging that most had to work until after the Sabbath began, and often mixed-gender seating. Men and women sat separately with no partition, and some houses of prayer already introduced family pews. Motivated by popular pressure and frowned upon by both RA and seminary faculty—in its own synagogue, the institute maintained a partition until 1983—this was becoming common among the OU as well. As both social conditions and apathy turned American Jews away from tradition (barely 20 per cent were attending prayers weekly), a young professor named Mordecai Kaplan promoted the idea of transforming the synagogue into a community center, a "Shul with a Pool", a policy which indeed stymied the tide somewhat.
In 1927, the RA also established its own Committee of Jewish Law, entrusted with determining "halakhic" issues. Consisting of seven members, it was chaired by the traditionalist Rabbi Louis Ginzberg, who already distinguished himself in 1922, drafting a responsa that allowed to use grape juice rather than fermented wine for "Kiddush" on the background of Prohibition. Kaplan himself, who rose to become an influential and popular figure within the JTS, concluded that his fellow rabbis' ambiguity in matters of belief and the contradiction between full observance and critical study were untenable and hypocritical. He formulated his own approach of Judaism as a Civilization, rejecting the concept of Revelation and any supernatural belief in favour of a cultural-ethnic perception. While valuing received mores, he eventually suggested giving the past "a vote, not a veto". Though popular among students, Kaplan's nascent Reconstructionism was opposed by the new traditionalist Chancellor Louis Finkelstein, appointed in 1940, and a large majority among the faculty.
Tensions within the JTS and RA grew. The Committee of Jewish Law consisted mainly of scholars who had little field experience, almost solely from the seminary's Talmudic department. They were greatly concerned with "halakhic" licitness and indifferent to the pressures exerted on the pulpit rabbis, who had to contend with an Americanized public which cared little for such considerations or for tradition in general. In 1935, the RA almost adopted a groundbreaking motion: Rabbi Louis Epstein offered a solution to the agunah predicament, a clause that would have had husbands appoint wives as their proxies to issue divorce. It was repealed under pressure from the Orthodox Union. As late as 1947, CJL Chair Rabbi Boaz Cohen, himself a historicist who argued that the Law evolved much through time, rebuked pulpit clergy who requested lenient or radical rulings, stating he and his peers were content to "progress in inches... Free setting up of new premises and the introduction of novel categories of ritual upon the basis of pure reason and thinking would be perilous, if not fatal, to the principles and continuity of Jewish Law."
The boundaries between Orthodox and Conservative Judaism in America were institutionalized only in the aftermath of World War II. The 1940s saw the younger generation of JTS graduates less patient with the prudence of the CJL and Talmud faculty in face of popular demand. Kaplan's Reconstructionism, while its fully committed partisans were few, had much influence. The majority among recent alumni eschewed the epithet "Orthodox" and tended to employ "Conservative" exclusively. Succeeding Schechter's direct disciples who headed the RA, JTS and United Synagogue in the interwar period, a new strata of activist leaders was rising. Rabbi Robert Gordis, RA president in 1944–1946, represented the junior members in advocating more flexibility; Rabbi Jacob Agus, a RIETS graduate who joined the body only in 1945, clamored that "we need a law making body, not a law interpreting committee." Agus argued that the breach between the Jewish public and tradition was too wide to be bridged conventionally, and that the RA would always remain inferior to the Orthodox as long as it retained its policy of merely adopting lenient precedents in rabbinic literature. He offered to extensively apply the tool of "takkanah", rabbinic ordinance.
In 1946, a committee chaired by Gordis issued the "Sabbath and Festival Prayerbook", the first clearly Conservative liturgy: references to the sacrificial cult were in the past tense instead of a petition for restoration, and it rephrased blessings such as "who hast made me according to thy will" for women to "who hast made me a woman". During the movement's national conference in Chicago, held 13–17 May 1948, the pulpit rabbis in the RA gained the upper hand. Spurned by Gordis, Agus and fellow leaders, They voted to reorganize the CJL into a Committee of Jewish Law and Standards, enfranchised to issue "takkanot" by a majority. Membership was conditioned on having experience as a congregational rabbi, and unseasoned JTS faculty were thus denied entrance. While the RA was asserting a Conservative distinctive identity, the seminary remained more cautious. Finkelstein opposed sectarianism and preferred the neutral epithet "traditional", later commenting that "Conservative Judaism is a gimmick to get Jews back to real Judaism". He and the very right-wing Talmud professor Saul Lieberman, who maintained ties with the Orthodox while also viewing them as obstructionist and ossified, dominated the JTS, providing a counterweight to the liberals in the Assembly. Kaplan, meanwhile, spent more time on consolidating his Society for Advancement of Judaism. Abraham Joshua Heschel, who espoused a mysticist understanding of Jewish religion, also became an important figure among the faculty.
The CJLS now proceeded to demonstrate its independence. Sabbath was widely desecrated by a large majority of Jews, and the board believed arrival at synagogues should be encouraged. They therefore enacted an ordinance that allowed driving on the Sabbath (for worship alone) and the use of electricity. The driving responsum was later severely criticized by Conservative rabbis, and was charged with imparting the movement was overly keen to condone the laxity of congregants. It also signified the final break with the Orthodox, who were themselves being bolstered by more strictly observant immigrants from Europe. In 1954, the RCA reverted its 1948 ruling that allowed the use of microphones on Sabbath and festivals and declared that praying without a partition between sexes was banned. Though enforced slowly—in 1997, there were still seven OU congregations with no physical barrier, and so-called "Conservadox" remain extant—these two attributes became a demarcation line between Orthodox and Conservative synagogues. RA converts were denied ablution in Orthodox ritual baths, and rabbis from one movement would gradually cease serving in the other's communities.
Rather than a force within American Judaism, the JTS-centered movement emerged as a third movement. The historicist and critical approach to "halakha", as well as other features, were emphasized by leaders eager to demonstrate their uniqueness. In their efforts to solidify a coherent identity, Conservative thinkers like Mordecai Waxman in his 1957 "Tradition and Change", ventured beyond Schechter's deem conceptions to Rabbi Zecharias Frankel and Breslau, presenting themselves as its direct inheritors via Alexander Kohut and others. The CJLS continued to issue groundbreaking ordinances and rulings.
The postwar decades were a time of immense growth for the Conservative movement. Most of the 500,000 decommissioned Jewish GIs left the densely populated immigrant neighbourhoods of the East Coast, moving to suburbia. They were Americanized but still retained traditional sentiments, and Reform Judaism was too radical for most. The United Synagogue of America offered Jewish education for children and a familiar religious environment which was also comfortable and not strict. It expanded from 350 communities by 1945 to 832 by 1971, becoming the largest denomination, with some 350,000 dues-paying member households (1.5 million people) at synagogues and over 40 per cent of American Jewry identifying with it in polls, adding an estimated million more non-registered supporters.
Already in a 1955 study, Marshall Sklare defined Conservative Judaism as the quintessential American Jewish movement, but stressed the gap between laity and clergy, noting "rabbis now recognize that they are not making decisions or writing responsa, but merely taking a poll of their membership." Most congregants, commented Edward S. Shapiro, were "Conservative Jews because their rabbi kept kosher and the Sabbath... Not because of their religious behavior." The movement established its presence outside the U.S. and Canada: In 1962, the young Rabbi Marshall Meyer founded the Seminario Rabinico Latinoamericano in Buenos Aires, which would serve as the basis for Conservative expansion in South America. In 1979, four communities formed the Israel Masorti Movement. Rabbi Louis Jacobs, dismissed in 1964 from the British Orthodox rabbinate on the charge of heresy after espousing a non-literal understanding of the Torah, joined with the Conservatives and founded his country's first Masorti community. The new branches were all united within the World Council of Synagogues, later to be named Masorti Olami.
The movement peaked in numbers in the 1970s. During that decade, the tensions between the various elements within it intensified. The right wing, conservative in "halakhic" matters and often adhering to a verbal understanding of revelation, was dismayed by the failure to bolster observance among the laity and the resurgence of Orthodoxy. The left was influenced by the Reconstructionists, who formed their own seminary in 1968 and were slowly coalescing, as well as the growing appeal of Reform, which turned more traditional and threatened to sway congregants. While the rightists opposed further modifications, their left-wing peers demanded them. The Chavurah movement, consisting of nonaligned prayer quorums of young (and frequently, Conservative-raised) worshipers who sought a more intense religious experience, also weakened congregations. In 1972, the liberal wing gained an influential position with the appointment of Gerson D. Cohen as JTS Chancellor. During the same year, after Reform began to ordain female rabbis, a strong lobby rose to advocate the same. The CJLS rapidly enacted an ordinance which allowed women to be tallied for a "minyan", and by 1976 the percentage of synagogues allowing them to bless during the reading of the Torah grew from 7 per cent to 50 per cent. In 1979, ignoring the denominational leadership, Beth Israel Congregation of Chester County accepted the RRC-ordained Rabbi Linda Joy Holtzman. Pressures to allow women to assume rabbinical positions was mounting from the congregational level, though the RA agreed to delay any action until the JTS scholars would concur.
Female ordination was a matter of great friction until 1983, when Rabbi Joel Roth devised a solution that entailed women voluntarily accepting the obligation to pray regularly. The leadership passed it not by scholarly consensus but via a popular vote of all JTS faculty, including non-specialists. Two years later, the first JTS-ordained female rabbi, Amy Eilberg, was admitted into the RA. David Weiss Halivni, professor of the Talmud faculty, claimed that Roth's method must have required waiting until a considerable number of women did prove sufficient commitment. He and his sympathizers regarded the vote as belying any claim to "halakhic" integrity. They formed the Union for Traditional Conservative Judaism in 1985, a right-wing lobby which numbered some 10,000 supporters from the Conservative observant elite. The UTJC withdrew from the movement and erased the word "Conservative" in 1990, attempting to merge with moderate Orthodox organizations.
In the very same year, the Reconstructionist also seceded fully, joining the World Union for Progressive Judaism under observer status. The double defection narrowed the movement's spectrum of opinions, at a time when large swaths of congregants were abandoning in favour of Reform, which was more tolerant of intermarriage. RA leaders were engaged in introspection through the later 1980s, resulting in the 1988 "Emet ve-Emunah" platform, while Reform slowly bypassed them and became the largest American Jewish movement.
After the issue of egalitarianism for women subsided, LGBT acceptance replaced it as the main source of contention between the declining right wing and the liberal majority. A first attempt was rebuffed in 1992 by a harsh responsum written by Roth. The retirement of Chancellor Ismar Schorsch, a staunch opponent, allowed the CJLS to endorse a motion which still banned anal intercourse but not any other physical contact, and allowed the ordination of openly LGBT rabbis, in 2006. Roth and three other supporters resigned from the panel in protest, claiming the responsum was not valid; Masorti affiliates in South America, Israel and Hungary objected severely. The Seminario is yet to accept the resolution, while several Canadian congregations seceded from the United Synagogue in 2008 to form an independent union in protest of the slide to the left. Since the 2013 Pew survey, which assessed that only 18 per cent of American Jews identify with it, Conservative leadership is engaged in attempting to solve Conservative Judaism's demographic crisis.

</doc>
<doc id="6626" url="https://en.wikipedia.org/wiki?curid=6626" title="CDE">
CDE

CDE may refer to:

</doc>
<doc id="6627" url="https://en.wikipedia.org/wiki?curid=6627" title="Common Desktop Environment">
Common Desktop Environment

The Common Desktop Environment (CDE) is a desktop environment for Unix and OpenVMS, based on the Motif widget toolkit. It was part of the UNIX 98 Workstation Product Standard, and was for a long time the "classic" Unix desktop associated with commercial Unix workstations.
After a long history as proprietary software, CDE was released as free software on August 6, 2012, under the GNU Lesser General Public License, version 2 or later. Since its release as free software, CDE has been ported to Linux and BSD derivatives.
Hewlett-Packard, IBM, SunSoft, and USL announced CDE in June 1993 as a joint development within the Common Open Software Environment (COSE) initiative. Each development group contributed its own technology to CDE:
After its release, HP endorsed CDE as the new standard desktop for Unix, and provided documentation and software for migrating HP VUE customizations to CDE.
In March 1994 CDE became the responsibility of the "new OSF", a merger of the Open Software Foundation and Unix International;
in September 1995, the merger of Motif and CDE into a single project, CDE/Motif, was announced. OSF became part of the newly formed Open Group in 1996.
In February 1997, the Open Group released their last major version of CDE, version 2.1.
Red Hat Linux was the only Linux distribution that proprietary CDE was ported to. In 1997, Red Hat began offering a version of CDE licensed from TriTeal Corporation. In 1998, Xi Graphics, a company specializing in the X Windowing System, offered a version of CDE bundled with Red Hat Linux, called "Xi Graphics maXimum cde/OS". These were phased out, and Red Hat moved to the GNOME desktop.
Until about 2000, users of Unix desktops regarded CDE as the "de facto" standard, but at that time, other desktop environments such as GNOME and K Desktop Environment 2 were quickly becoming mature, and became widespread on Linux systems.
In 2001, Sun Microsystems announced that they would phase out CDE as the standard desktop environment in Solaris in favor of GNOME. Solaris 10, released in early 2005, includes both CDE and the GNOME-based Java Desktop System. The OpenSolaris project, begun around the same time, did not include CDE, and had no intent to make Solaris CDE available as open-source. The original release of Solaris 11 in November 2011 only contained GNOME as standard desktop, though some CDE libraries, such as Motif and ToolTalk, remained for binary compatibility but Oracle Solaris 11.4, released in August 2018, removed support for the CDE runtime environment and background services.
From its launch until 2012, CDE was proprietary software.
Motif, the toolkit on which CDE is built, was released by The Open Group in 2000 as "Open Motif," under a "revenue sharing" license. That license did not meet either the open source or free software definitions. The Open Group had wished to make Motif open source, but did not succeed doing so at that time.
In 2006, a petition was created asking The Open Group to release the source code for CDE and Motif under a free license. On August 6, 2012, CDE was open-sourced under the LGPL free software license. The CDE source code was then released to SourceForge.
The free software project OpenCDE had been started in 2010 to reproduce the look and feel, organization, and feature set of CDE. In August 2012, when CDE was released as free software, OpenCDE was officially deprecated in favor of CDE.
On October 23, 2012, the Motif widget toolkit was also released under the LGPL v2.1. This allowed CDE to become a completely free and open source desktop environment.
Shortly after CDE was released as free software, a Linux live CD was created based on Debian 6 with CDE 2.2.0c pre-installed, called CDEbian. The live CD has since been discontinued.
The Debian-based Linux distribution SparkyLinux offers binary packages of CDE that can be installed with APT. 
In March 2014, the first stable release of CDE, version 2.2.1, was made since its release as free software.
Beginning with version 2.2.2, released in July 2014, CDE is able to compile under FreeBSD 10 with the default Clang compiler.
Since version 2.3.0, released in July 2018, CDE uses TIRPC on Linux, so that the portmapper rpcbind does not need to be run in insecure mode. It does not use Xprint anymore, and can be compiled on the BSDs without installing first a custom version of Motif. Multihead display support with Xinerama has been improved. 
Since its release as free software, CDE has been ported to:
Future project goals of the CDE project include:

</doc>
<doc id="6628" url="https://en.wikipedia.org/wiki?curid=6628" title="Children of Dune">
Children of Dune

Children of Dune is a 1976 science fiction novel by Frank Herbert, the third in his "Dune" series of six novels. It was originally serialized in "Analog Science Fiction and Fact" in 1976, and was the last "Dune" novel to be serialized before book publication.
At the end of "Dune Messiah", Paul Atreides walks into the desert, a blind man, leaving his twin children Leto and Ghanima in the care of the Fremen, while his sister Alia rules the universe as regent. Awakened in the womb by the spice, the children are the heirs to Paul's prescient vision of the fate of the universe, a role that Alia desperately craves. House Corrino schemes to return to the throne, while the Bene Gesserit make common cause with the Tleilaxu and Spacing Guild to gain control of the spice and the children of Paul Atreides.
Initially selling over 75,000 copies, it became the first hardcover best-seller ever in the science fiction field. The novel was critically well-received for its gripping plot, action, and atmosphere, and was nominated for the Hugo Award for Best Novel in 1977. "Dune Messiah" (1969) and "Children of Dune" were collectively adapted by the Sci-Fi Channel in 2003 into a miniseries entitled "Frank Herbert's Children of Dune".
Nine years after Emperor Paul Muad'Dib walked into the desert, blind, the ecological transformation of Dune has reached the point where some Fremen are living without stillsuits in the less arid climate and have started to move out of the sietches and into the villages and cities. As the old ways erode, more and more pilgrims arrive to experience the planet of Muad'Dib. The Imperial high council has lost its political might and is powerless to control the Jihad.
Paul's young twin children, Leto II and Ghanima, have concluded that their guardian Alia has succumbed to Abomination—possession by her grandfather Baron Vladimir Harkonnen—and fear that a similar fate awaits them. They (and Alia) also realize that the terraforming of Dune will kill all the sandworms, thus destroying the source of the spice, but Harkonnen desires this outcome. Leto also fears that, like his father, he will become trapped by his prescience.
Meanwhile, a new religious figure called "The Preacher" has risen in the desert, railing against the religious government's injustices and the changes among the Fremen. Some Fremen believe he is Paul Atreides. Princess Wensicia of the fallen House Corrino on Salusa Secundus plots to assassinate the twins and regain power for her House.
Lady Jessica, Alia and Paul's mother, returns to Arrakis and recognizes that her daughter is possessed, but finds no signs of Abomination in the twins. Leto arranges for Fremen leader Stilgar to protect his sister if there is an attempt on their lives. The Preacher journeys to Salusa Secundus to meet Wensicia's son Farad'n, and in return pledges Duncan Idaho as an agent of House Corrino. Alia attempts to assassinate Jessica, who escapes into the desert with Duncan's help, precipitating a rebellion among the Fremen. The twins anticipate and survive the Corrino assassination plot. Leto leaves to seek out the Preacher, while Ghanima, changing her memory with self-hypnosis, reports (and believes) that her brother has been murdered. Duncan and Jessica flee to Salusa Secundus, where Jessica begins to mentor Farad'n. He seizes power from his regent mother Wensicia and allies with the Bene Gesserit, who promise to marry him to Ghanima and support his bid to become Emperor.
A band of Fremen outlaws capture Leto and force him to undergo the spice trance at the suggestion of Gurney Halleck, who has infiltrated the group on Jessica's orders. Leto's spice-induced visions show him a myriad of possible futures where humanity becomes extinct and only one where it survives. He names this future "The Golden Path" and resolves to bring it to fruition—something that his father, who had already glimpsed this future, refused to do. He escapes his captors and sacrifices his humanity in pursuit of the Golden Path by physically fusing with a school of sandtrout, gaining superhuman strength and near-invulnerability. He travels across the desert and confronts the Preacher, who is indeed Paul.
Duncan returns to Arrakis and provokes Stilgar into killing him so that Stilgar is forced to take Ghanima and go into hiding. Alia recaptures Ghanima and arranges her marriage to Farad'n, planning to exploit the expected chaos when Ghanima kills him to avenge her brother's murder. The Preacher and Leto return to the capital to confront Alia. Upon arriving, Paul is murdered, to Alia's horror. Leto reveals himself in a display of superhuman strength and triggers the return of Ghanima's genuine memories. He confronts Alia and offers to help her overcome her possession, but Harkonnen resists. Alia manages to commit suicide by throwing herself off a high balcony.
Leto declares himself Emperor and asserts control over the Fremen. Farad'n enlists in his service and delivers control of the Corrino armies. Leto marries his sister Ghanima to further his goals, but Farad'n is her true consort so the Atreides line can continue.
Parts of "Dune Messiah" and "Children of Dune" were written before "Dune" was completed. "Children of Dune" was originally serialized in "Analog Science Fiction and Fact" in 1976, and was the last "Dune" novel to be serialized before book publication. "Dune Messiah" and "Children of Dune" were published in one volume by the Science Fiction Book Club in 2002.
Herbert likened the initial trilogy of novels ("Dune", "Dune Messiah", and "Children of Dune") to a fugue, and while "Dune" was a heroic melody, "Dune Messiah" was its inversion. Paul rises to power in "Dune" by seizing control of the single critical resource in the universe, melange. His enemies are dead or overthrown, and he is set to take the reins of power and bring a hard but enlightened peace to the universe. Herbert chose in the books that followed to undermine Paul's triumph with a string of failures and philosophical paradoxes.
Initially selling over 75,000 copies, "Children of Dune" became the first hardcover best-seller ever in the science fiction field. The novel was critically well-received for its gripping plot, action, and atmosphere, and was nominated for the Hugo Award for Best Novel in 1977.
The "Los Angeles Times" called "Children of Dune" "a major event", and "Challenging Destiny" noted that "Herbert adds enough new twists and turns to the ongoing saga that familiarity with the recurring elements brings pleasure." "Publishers Weekly" wrote, "Ranging from palace intrigue and desert chases to religious speculation and confrontations with the supreme intelligence of the universe, there is something here for all science fiction fans." In a 1976 review, Spider Robinson found "Children of Dune" unsatisfying, faulting the ending as unconvincing and thematically overfamiliar. The novel is referenced in "A Thousand Plateaus" (1980) by Gilles Deleuze and Félix Guattari. David Pringle gave the novel a rating of two stars out of four and described the novel as "dark and convoluted stuff."
"Dune Messiah" (1969) and "Children of Dune" were collectively adapted by the Sci-Fi Channel in 2003 into a miniseries entitled "Frank Herbert's Children of Dune". The three-part, six-hour miniseries covers the bulk of the plot of "Dune Messiah" in the first installment, and adapts "Children of Dune" in the second and third parts.

</doc>
<doc id="6629" url="https://en.wikipedia.org/wiki?curid=6629" title="Candide">
Candide

' ( , ) is a French satire first published in 1759 by Voltaire, a philosopher of the Age of Enlightenment. The novella has been widely translated, with English versions titled Candide: or, All for the Best (1759); Candide: or, The Optimist (1762); and Candide: Optimism""' (1947). It begins with a young man, Candide, who is living a sheltered life in an Edenic paradise and being indoctrinated with Leibnizian optimism by his mentor, Professor Pangloss. The work describes the abrupt cessation of this lifestyle, followed by Candide's slow and painful disillusionment as he witnesses and experiences great hardships in the world. Voltaire concludes Candide with, if not rejecting Leibnizian optimism outright, advocating a deeply practical precept, "we must cultivate our garden", in lieu of the Leibnizian mantra of Pangloss, "all is for the best" in the "best of all possible worlds".
"Candide" is characterized by its tone as well as by its erratic, fantastical, and fast-moving plot. A picaresque novel with a story similar to that of a more serious coming-of-age narrative ("Bildungsroman"), it parodies many adventure and romance clichés, the struggles of which are caricatured in a tone that is bitter and matter-of-fact. Still, the events discussed are often based on historical happenings, such as the Seven Years' War and the 1755 Lisbon earthquake. As philosophers of Voltaire's day contended with the problem of evil, so does Candide in this short theological novel, albeit more directly and humorously. Voltaire ridicules religion, theologians, governments, armies, philosophies, and philosophers. Through "Candide", he assaults Leibniz and his optimism.
"Candide" has enjoyed both great success and great scandal. Immediately after its secretive publication, the book was widely banned to the public because it contained religious blasphemy, political sedition, and intellectual hostility hidden under a thin veil of naïveté. However, with its sharp wit and insightful portrayal of the human condition, the novel has since inspired many later authors and artists to mimic and adapt it. Today, "Candide" is recognized as Voltaire's "magnum opus" and is often listed as part of the Western canon. It is among the most frequently taught works of French literature. The British poet and literary critic Martin Seymour-Smith listed "Candide" as one of the 100 most influential books ever written.
A number of historical events inspired Voltaire to write "Candide", most notably the publication of Leibniz's "Monadology", a short metaphysical treatise, the Seven Years' War, and the 1755 Lisbon earthquake. Both of the latter catastrophes are frequently referred to in "Candide" and are cited by scholars as reasons for its composition. The 1755 Lisbon earthquake, tsunami, and resulting fires of All Saints' Day, had a strong influence on theologians of the day and on Voltaire, who was himself disillusioned by them. The earthquake had an especially large effect on the contemporary doctrine of optimism, a philosophical system which implies that such events should not occur. Optimism is founded on the theodicy of Gottfried Wilhelm Leibniz and says all is for the best because God is a benevolent deity. This concept is often put into the form, "all is for the best in the best of all possible worlds" (). Philosophers had trouble fitting the horrors of this earthquake into their optimistic world view.
Voltaire actively rejected Leibnizian optimism after the natural disaster, convinced that if this were the best possible world, it should surely be better than it is. In both "Candide" and ("Poem on the Lisbon Disaster"), Voltaire attacks this optimist belief. He makes use of the Lisbon earthquake in both "Candide" and his to argue this point, sarcastically describing the catastrophe as one of the most horrible disasters "in the best of all possible worlds". Immediately after the earthquake, unreliable rumours circulated around Europe, sometimes overestimating the severity of the event. Ira Wade, a noted expert on Voltaire and "Candide", has analyzed which sources Voltaire might have referenced in learning of the event. Wade speculates that Voltaire's primary source for information on the Lisbon earthquake was the 1755 work by Ange Goudar.
Apart from such events, contemporaneous stereotypes of the German personality may have been a source of inspiration for the text, as they were for , a 1669 satirical picaresque novel written by Hans Jakob Christoffel von Grimmelshausen and inspired by the Thirty Years' War. The protagonist of this novel, who was supposed to embody stereotypically German characteristics, is quite similar to the protagonist of "Candide". These stereotypes, according to Voltaire biographer Alfred Owen Aldridge, include "extreme credulousness or sentimental simplicity", two of Candide's and Simplicius's defining qualities. Aldridge writes, "Since Voltaire admitted familiarity with fifteenth-century German authors who used a bold and buffoonish style, it is quite possible that he knew as well."
A satirical and parodic precursor of "Candide", Jonathan Swift's "Gulliver's Travels" (1726) is one of "Candide"s closest literary relatives. This satire tells the story of "a gullible ingenue", Gulliver, who (like Candide) travels to several "remote nations" and is hardened by the many misfortunes which befall him. As evidenced by similarities between the two books, Voltaire probably drew upon "Gulliver's Travels" for inspiration while writing "Candide". Other probable sources of inspiration for "Candide" are (1699) by François Fénelon and (1753) by Louis-Charles Fougeret de Monbron. "Candide"s parody of the is probably based on , which includes the prototypical parody of the tutor on whom Pangloss may have been partly based. Likewise, Monbron's protagonist undergoes a disillusioning series of travels similar to those of Candide.
Born François-Marie Arouet, Voltaire (1694–1778), by the time of the Lisbon earthquake, was already a well-established author, known for his satirical wit. He had been made a member of the Académie Française in 1746. He was a deist, a strong proponent of religious freedom, and a critic of tyrannical governments. "Candide" became part of his large, diverse body of philosophical, political and artistic works expressing these views. More specifically, it was a model for the eighteenth- and early nineteenth-century novels called the "contes philosophiques". This genre, of which Voltaire was one of the founders, included previous works of his such as "Zadig" and "Micromegas".
It is unknown exactly when Voltaire wrote "Candide", but scholars estimate that it was primarily composed in late 1758 and begun as early as 1757. Voltaire is believed to have written a portion of it while living at Les Délices near Geneva and also while visiting Charles Théodore, the Elector-Palatinate at Schwetzingen, for three weeks in the summer of 1758. Despite solid evidence for these claims, a popular legend persists that Voltaire wrote "Candide" in three days. This idea is probably based on a misreading of the 1885 work by Lucien Perey (real name: Clara Adèle Luce Herpin) and Gaston Maugras. The evidence indicates strongly that Voltaire did not rush or improvise "Candide", but worked on it over a significant period of time, possibly even a whole year. "Candide" is mature and carefully developed, not impromptu, as the intentionally choppy plot and the aforementioned myth might suggest.
There is only one extant manuscript of "Candide" that was written before the work's 1759 publication; it was discovered in 1956 by Wade and since named the "La Vallière Manuscript". It is believed to have been sent, chapter by chapter, by Voltaire to the Duke and Duchess La Vallière in the autumn of 1758. The manuscript was sold to the Bibliothèque de l'Arsenal in the late eighteenth century, where it remained undiscovered for almost two hundred years. The "La Vallière Manuscript", the most original and authentic of all surviving copies of "Candide", was probably dictated by Voltaire to his secretary, Jean-Louis Wagnière, then edited directly. In addition to this manuscript, there is believed to have been another, one copied by Wagnière for the Elector Charles-Théodore, who hosted Voltaire during the summer of 1758. The existence of this copy was first postulated by Norman L. Torrey in 1929. If it exists, it remains undiscovered.
Voltaire published "Candide" simultaneously in five countries no later than 15 January 1759, although the exact date is uncertain. Seventeen versions of "Candide" from 1759, in the original French, are known today, and there has been great controversy over which is the earliest. More versions were published in other languages: "Candide" was translated once into Italian and thrice into English that same year. The complicated science of calculating the relative publication dates of all of the versions of "Candide" is described at length in Wade's article "The First Edition of "Candide": A Problem of Identification". The publication process was extremely secretive, probably the "most clandestine work of the century", because of the book's obviously illicit and irreverent content. The greatest number of copies of "Candide" were published concurrently in Geneva by Cramer, in Amsterdam by Marc-Michel Rey, in London by Jean Nourse, and in Paris by Lambert.
"Candide" underwent one major revision after its initial publication, in addition to some minor ones. In 1761, a version of "Candide" was published that included, along with several minor changes, a major addition by Voltaire to the twenty-second chapter, a section that had been thought weak by the Duke of Vallière. The English title of this edition was "Candide, or Optimism, Translated from the German of Dr. Ralph. With the additions found in the Doctor's pocket when he died at Minden, in the Year of Grace 1759." The last edition of "Candide" authorised by Voltaire was the one included in Cramer's 1775 edition of his complete works, known as , in reference to the border or frame around each page.
Voltaire strongly opposed the inclusion of illustrations in his works, as he stated in a 1778 letter to the writer and publisher Charles Joseph Panckoucke:
Despite this protest, two sets of illustrations for "Candide" were produced by the French artist Jean-Michel Moreau le Jeune. The first version was done, at Moreau's own expense, in 1787 and included in Kehl's publication of that year, "Oeuvres Complètes de Voltaire". Four images were drawn by Moreau for this edition and were engraved by Pierre-Charles Baquoy. The second version, in 1803, consisted of seven drawings by Moreau which were transposed by multiple engravers. The twentieth-century modern artist Paul Klee stated that it was while reading "Candide" that he discovered his own artistic style. Klee illustrated the work, and his drawings were published in a 1920 version edited by Kurt Wolff.
"Candide" contains thirty episodic chapters, which may be grouped into two main schemes: one consists of two divisions, separated by the protagonist's hiatus in El Dorado; the other consists of three parts, each defined by its geographical setting. By the former scheme, the first half of "Candide" constitutes the rising action and the last part the resolution. This view is supported by the strong theme of travel and quest, reminiscent of adventure and picaresque novels, which tend to employ such a dramatic structure. By the latter scheme, the thirty chapters may be grouped into three parts each comprising ten chapters and defined by locale: I–X are set in Europe, XI–XX are set in the Americas, and XXI–XXX are set in Europe and the Ottoman Empire. The plot summary that follows uses this second format and includes Voltaire's additions of 1761.
The tale of "Candide" begins in the castle of the Baron Thunder-ten-Tronckh in Westphalia, home to the Baron's daughter, Lady Cunégonde; his bastard nephew, Candide; a tutor, Pangloss; a chambermaid, Paquette; and the rest of the Baron's family. The protagonist, Candide, is romantically attracted to Cunégonde. He is a young man of "the most unaffected simplicity" (), whose face is "the true index of his mind" (). Dr. Pangloss, professor of "" (English: "metaphysico-theologo-cosmolonigology") and self-proclaimed optimist, teaches his pupils that they live in the "best of all possible worlds" and that "all is for the best".
All is well in the castle until Cunégonde sees Pangloss sexually engaged with Paquette in some bushes. Encouraged by this show of affection, Cunégonde drops her handkerchief next to Candide, enticing him to kiss her. For this infraction, Candide is evicted from the castle, at which point he is captured by Bulgar (Prussian) recruiters and coerced into military service, where he is flogged, nearly executed, and forced to participate in a major battle between the Bulgars and the Avars (an allegory representing the Prussians and the French). Candide eventually escapes the army and makes his way to Holland where he is given aid by Jacques, an Anabaptist, who strengthens Candide's optimism. Soon after, Candide finds his master Pangloss, now a beggar with syphilis. Pangloss reveals he was infected with this disease by Paquette and shocks Candide by relating how Castle Thunder-ten-Tronckh was destroyed by Bulgars, that Cunégonde and her whole family were killed, and that Cunégonde was raped before her death. Pangloss is cured of his illness by Jacques, losing one eye and one ear in the process, and the three set sail to Lisbon.
In Lisbon's harbor, they are overtaken by a vicious storm which destroys the boat. Jacques attempts to save a sailor, and in the process is thrown overboard. The sailor makes no move to help the drowning Jacques, and Candide is in a state of despair until Pangloss explains to him that Lisbon harbor was created in order for Jacques to drown. Only Pangloss, Candide, and the "brutish sailor" who let Jacques drown survive the wreck and reach Lisbon, which is promptly hit by an earthquake, tsunami and fire that kill tens of thousands. The sailor leaves in order to loot the rubble while Candide, injured and begging for help, is lectured on the optimistic view of the situation by Pangloss.
The next day, Pangloss discusses his optimistic philosophy with a member of the Portuguese Inquisition, and he and Candide are arrested for heresy, set to be tortured and killed in an " set up to appease God and prevent another disaster. Candide is flogged and sees Pangloss hanged, but another earthquake intervenes and he escapes. He is approached by an old woman, who leads him to a house where Lady Cunégonde waits, alive. Candide is surprised: Pangloss had told him that Cunégonde had been raped and disemboweled. She had been, but Cunégonde points out that people survive such things. However, her rescuer sold her to a Jewish merchant, Don Issachar, who was then threatened by a corrupt Grand Inquisitor into sharing her (Don Issachar gets Cunégonde on Mondays, Wednesdays, and the sabbath day). Her owners arrive, find her with another man, and Candide kills them both. Candide and the two women flee the city, heading to the Americas. Along the way, Cunégonde falls into self-pity, complaining of all the misfortunes that have befallen her.
The old woman reciprocates by revealing her own tragic life: born the daughter of Pope Urban X and the Princess of Palestrina, she was raped and enslaved by African pirates, witnessed violent civil wars in Morocco under the bloodthirsty King Moulay Ismaïl (during which her mother was drawn and quartered), suffered further slavery and famine, nearly died from a plague in Algiers, and had a buttock cut off to feed starving Janissaries during the Russian siege of Azov. After traversing all the Russian Empire, she eventually became a servant of Don Issachar and met Cunégonde.
The trio arrives in Buenos Aires, where Governor Don Fernando d'Ibarra y Figueroa y Mascarenes y Lampourdos y Souza asks to marry Cunégonde. Just then, an alcalde (a Spanish fortress commander) arrives, pursuing Candide for killing the Grand Inquisitor. Leaving the women behind, Candide flees to Paraguay with his practical and heretofore unmentioned manservant, Cacambo.
At a border post on the way to Paraguay, Cacambo and Candide speak to the commandant, who turns out to be Cunégonde's unnamed brother. He explains that after his family was slaughtered, the Jesuits' preparation for his burial revived him, and he has since joined the order. When Candide proclaims he intends to marry Cunégonde, her brother attacks him, and Candide runs him through with his rapier. After lamenting all the people (mainly priests) he has killed, he and Cacambo flee. In their flight, Candide and Cacambo come across two naked women being chased and bitten by a pair of monkeys. Candide, seeking to protect the women, shoots and kills the monkeys, but is informed by Cacambo that the monkeys and women were probably lovers.
Cacambo and Candide are captured by Oreillons, or Orejones; members of the Inca nobility who widened the lobes of their ears, and are depicted here as the fictional inhabitants of the area. Mistaking Candide for a Jesuit by his robes, the Oreillons prepare to cook Candide and Cacambo; however, Cacambo convinces the Oreillons that Candide killed a Jesuit to procure the robe. Cacambo and Candide are released and travel for a month on foot and then down a river by canoe, living on fruits and berries.
After a few more adventures, Candide and Cacambo wander into El Dorado, a geographically isolated utopia where the streets are covered with precious stones, there exist no priests, and all of the king's jokes are funny. Candide and Cacambo stay a month in El Dorado, but Candide is still in pain without Cunégonde, and expresses to the king his wish to leave. The king points out that this is a foolish idea, but generously helps them do so. The pair continue their journey, now accompanied by one hundred red pack sheep carrying provisions and incredible sums of money, which they slowly lose or have stolen over the next few adventures.
Candide and Cacambo eventually reach Suriname, where they split up: Cacambo travels to Buenos Aires to retrieve Lady Cunégonde, while Candide prepares to travel to Europe to await the two. Candide's remaining sheep are stolen, and Candide is fined heavily by a Dutch magistrate for petulance over the theft. Before leaving Suriname, Candide feels in need of companionship, so he interviews a number of local men who have been through various ill-fortunes and settles on a man named Martin.
This companion, Martin, is a Manichaean scholar based on the real-life pessimist Pierre Bayle, who was a chief opponent of Leibniz. For the remainder of the voyage, Martin and Candide argue about philosophy, Martin painting the entire world as occupied by fools. Candide, however, remains an optimist at heart, since it is all he knows. After a detour to Bordeaux and Paris, they arrive in England and see an admiral (based on Admiral Byng) being shot for not killing enough of the enemy. Martin explains that Britain finds it necessary to shoot an admiral from time to time "pour l'encouragement des autres" (to encourage the others). Candide, horrified, arranges for them to leave Britain immediately. Upon their arrival in Venice, Candide and Martin meet Paquette, the chambermaid who infected Pangloss with his syphilis. She is now a prostitute, and is spending her time with a Theatine monk, Brother Giroflée. Although both appear happy on the surface, they reveal their despair: Paquette has led a miserable existence as a sexual object, and the monk detests the religious order in which he was indoctrinated. Candide gives two thousand piastres to Paquette and one thousand to Brother Giroflée.
Candide and Martin visit the Lord Pococurante, a noble Venetian. That evening, Cacambo—now a slave—arrives and informs Candide that Cunégonde is in Constantinople. Prior to their departure, Candide and Martin dine with six strangers who had come for the Carnival of Venice. These strangers are revealed to be dethroned kings: the Ottoman Sultan Ahmed III, Emperor Ivan VI of Russia, Charles Edward Stuart (an unsuccessful pretender to the English throne), Augustus III of Poland, Stanisław Leszczyński, and Theodore of Corsica.
On the way to Constantinople, Cacambo reveals that Cunégonde—now horribly ugly—currently washes dishes on the banks of the Propontis as a slave for a Transylvanian prince by the name of Rákóczi. After arriving at the Bosphorus, they board a galley where, to Candide's surprise, he finds Pangloss and Cunégonde's brother among the rowers. Candide buys their freedom and further passage at steep prices. The baron and Pangloss relate how they survived, but despite the horrors he has been through, Pangloss's optimism remains unshaken: "I still hold to my original opinions, because, after all, I'm a philosopher, and it wouldn't be proper for me to recant, since Leibniz cannot be wrong, and since pre-established harmony is the most beautiful thing in the world, along with the plenum and subtle matter."
Candide, the baron, Pangloss, Martin, and Cacambo arrive at the banks of the Propontis, where they rejoin Cunégonde and the old woman. Cunégonde has indeed become hideously ugly, but Candide nevertheless buys their freedom and marries Cunégonde to spite her brother, who forbids Cunégonde from marrying anyone but a baron of the Empire (he is secretly sold back into slavery). Paquette and Brother Giroflée—having squandered their three thousand piastres—are reconciled with Candide on a small farm () which he just bought with the last of his finances.
One day, the protagonists seek out a dervish known as a great philosopher of the land. Candide asks him why Man is made to suffer so, and what they all ought to do. The dervish responds by asking rhetorically why Candide is concerned about the existence of evil and good. The dervish describes human beings as mice on a ship sent by a king to Egypt; their comfort does not matter to the king. The dervish then slams his door on the group. Returning to their farm, Candide, Pangloss, and Martin meet a Turk whose philosophy is to devote his life only to simple work and not concern himself with external affairs. He and his four children cultivate a small area of land, and the work keeps them "free of three great evils: boredom, vice, and poverty." Candide, Pangloss, Martin, Cunégonde, Paquette, Cacambo, the old woman, and Brother Giroflée all set to work on this "commendable plan" () on their farm, each exercising his or her own talents. Candide ignores Pangloss's insistence that all turned out for the best by necessity, instead telling him "we must cultivate our garden" ().
As Voltaire himself described it, the purpose of "Candide" was to "bring amusement to a small number of men of wit". The author achieves this goal by combining his sharp wit with a fun parody of the classic adventure-romance plot. Candide is confronted with horrible events described in painstaking detail so often that it becomes humorous. Literary theorist Frances K. Barasch described Voltaire's matter-of-fact narrative as treating topics such as mass death "as coolly as a weather report". The fast-paced and improbable plot—in which characters narrowly escape death repeatedly, for instance—allows for compounding tragedies to befall the same characters over and over again. In the end, "Candide" is primarily, as described by Voltaire's biographer Ian Davidson, "short, light, rapid and humorous".
Behind the playful façade of "Candide" which has amused so many, there lies very harsh criticism of contemporary European civilization which angered many others. European governments such as France, Prussia, Portugal and England are each attacked ruthlessly by the author: the French and Prussians for the Seven Years' War, the Portuguese for their Inquisition, and the British for the execution of John Byng. Organised religion, too, is harshly treated in "Candide". For example, Voltaire mocks the Jesuit order of the Roman Catholic Church. Aldridge provides a characteristic example of such anti-clerical passages for which the work was banned: while in Paraguay, Cacambo remarks, "[The Jesuits] are masters of everything, and the people have no money at all …". Here, Voltaire suggests the Christian mission in Paraguay is taking advantage of the local population. Voltaire depicts the Jesuits holding the indigenous peoples as slaves while they claim to be helping them.
The main method of "Candide"s satire is to contrast ironically great tragedy and comedy. The story does not invent or exaggerate evils of the world—it displays real ones starkly, allowing Voltaire to simplify subtle philosophies and cultural traditions, highlighting their flaws. Thus "Candide" derides optimism, for instance, with a deluge of horrible, historical (or at least plausible) events with no apparent redeeming qualities.
A simple example of the satire of "Candide" is seen in the treatment of the historic event witnessed by Candide and Martin in Portsmouth harbour. There, the duo spy an anonymous admiral, supposed to represent John Byng, being executed for failing to properly engage a French fleet. The admiral is blindfolded and shot on the deck of his own ship, merely "to encourage the others" (, an expression Voltaire is credited with originating). This depiction of military punishment trivializes Byng's death. The dry, pithy explanation "to encourage the others" thus satirises a serious historical event in characteristically Voltairian fashion. For its classic wit, this phrase has become one of the more often quoted from "Candide".
Voltaire depicts the worst of the world and his pathetic hero's desperate effort to fit it into an optimistic outlook. Almost all of "Candide" is a discussion of various forms of evil: its characters rarely find even temporary respite. There is at least one notable exception: the episode of El Dorado, a fantastic village in which the inhabitants are simply rational, and their society is just and reasonable. The positivity of El Dorado may be contrasted with the pessimistic attitude of most of the book. Even in this case, the bliss of El Dorado is fleeting: Candide soon leaves the village to seek Cunégonde, whom he eventually marries only out of a sense of obligation.
Another element of the satire focuses on what William F. Bottiglia, author of many published works on "Candide", calls the "sentimental foibles of the age" and Voltaire's attack on them. Flaws in European culture are highlighted as "Candide" parodies adventure and romance clichés, mimicking the style of a picaresque novel. A number of archetypal characters thus have recognisable manifestations in Voltaire's work: Candide is supposed to be the drifting rogue of low social class, Cunégonde the sex interest, Pangloss the knowledgeable mentor and Cacambo the skilful valet. As the plot unfolds, readers find that Candide is no rogue, Cunégonde becomes ugly and Pangloss is a stubborn fool. The characters of "Candide" are unrealistic, two-dimensional, mechanical, and even marionette-like; they are simplistic and stereotypical. As the initially naïve protagonist eventually comes to a mature conclusion—however noncommittal—the novella is a "bildungsroman", if not a very serious one.
Gardens are thought by many critics to play a critical symbolic role in "Candide". The first location commonly identified as a garden is the castle of the Baron, from which Candide and Cunégonde are evicted much in the same fashion as Adam and Eve are evicted from the Garden of Eden in the Book of Genesis. Cyclically, the main characters of "Candide" conclude the novel in a garden of their own making, one which might represent celestial paradise. The third most prominent "garden" is El Dorado, which may be a false Eden. Other possibly symbolic gardens include the Jesuit pavilion, the garden of Pococurante, Cacambo's garden, and the Turk's garden.
These gardens are probably references to the Garden of Eden, but it has also been proposed, by Bottiglia, for example, that the gardens refer also to the "Encyclopédie", and that Candide's conclusion to cultivate "his garden" symbolises Voltaire's great support for this endeavour. Candide and his companions, as they find themselves at the end of the novella, are in a very similar position to Voltaire's tightly knit philosophical circle which supported the : the main characters of "Candide" live in seclusion to "cultivate [their] garden", just as Voltaire suggested his colleagues leave society to write. In addition, there is evidence in the epistolary correspondence of Voltaire that he had elsewhere used the metaphor of gardening to describe writing the . Another interpretative possibility is that Candide cultivating "his garden" suggests his engaging in only necessary occupations, such as feeding oneself and fighting boredom. This is analogous to Voltaire's own view on gardening: he was himself a gardener at his estates in Les Délices and Ferney, and he often wrote in his correspondence that gardening was an important pastime of his own, it being an extraordinarily effective way to keep busy.
"Candide" satirises various philosophical and religious theories that Voltaire had previously criticised. Primary among these is Leibnizian optimism (sometimes called "Panglossianism" after its fictional proponent), which Voltaire ridicules with descriptions of seemingly endless calamity. Voltaire demonstrates a variety of irredeemable evils in the world, leading many critics to contend that Voltaire's treatment of evil—specifically the theological problem of
its existence—is the focus of the work. Heavily referenced in the text are the Lisbon earthquake, disease, and the sinking of ships in storms. Also, war, thievery, and murder—evils of human design—are explored as extensively in "Candide" as are environmental ills. Bottiglia notes Voltaire is "comprehensive" in his enumeration of the world's evils. He is unrelenting in attacking Leibnizian optimism.
Fundamental to Voltaire's attack is Candide's tutor Pangloss, a self-proclaimed follower of Leibniz and a teacher of his doctrine. Ridicule of Pangloss's theories thus ridicules Leibniz himself, and Pangloss's reasoning is silly at best. For example, Pangloss's first teachings of the narrative absurdly mix up cause and effect:
Following such flawed reasoning even more doggedly than Candide, Pangloss defends optimism. Whatever their horrendous fortune, Pangloss reiterates "all is for the best" ("") and proceeds to "justify" the evil event's occurrence. A characteristic example of such theodicy is found in Pangloss's explanation of why it is good that syphilis exists:
Candide, the impressionable and incompetent student of Pangloss, often tries to justify evil, fails, invokes his mentor and eventually despairs. It is by these failures that Candide is painfully cured (as Voltaire would see it) of his optimism.
This critique of Voltaire's seems to be directed almost exclusively at Leibnizian optimism. "Candide" does not ridicule Voltaire's contemporary Alexander Pope, a later optimist of slightly different convictions. "Candide" does not discuss Pope's optimistic principle that "all is right", but Leibniz's that states, "this is the best of all possible worlds". However subtle the difference between the two, "Candide" is unambiguous as to which is its subject. Some critics conjecture that Voltaire meant to spare Pope this ridicule out of respect, although Voltaire's "Poème" may have been written as a more direct response to Pope's theories. This work is similar to "Candide" in subject matter, but very different from it in style: the "Poème" embodies a more serious philosophical argument than "Candide".
The conclusion of the novel, in which Candide finally dismisses his tutor's optimism, leaves unresolved what philosophy the protagonist is to accept in its stead. This element of "Candide" has been written about voluminously, perhaps above all others. The conclusion is enigmatic and its analysis is contentious.
Voltaire develops no formal, systematic philosophy for the characters to adopt. The conclusion of the novel may be thought of not as a philosophical alternative to optimism, but as a prescribed practical outlook (though it prescribes is in dispute). Many critics have concluded that one minor character or another is portrayed as having the right philosophy. For instance, a number believe that Martin is treated sympathetically, and that his character holds Voltaire's ideal philosophy—pessimism. Others disagree, citing Voltaire's negative descriptions of Martin's principles and the conclusion of the work in which Martin plays little part.
Within debates attempting to decipher the conclusion of "Candide" lies another primary "Candide" debate. This one concerns the degree to which Voltaire was advocating a pessimistic philosophy, by which Candide and his companions give up hope for a better world. Critics argue that the group's reclusion on the farm signifies Candide and his companions' loss of hope for the rest of the human race. This view is to be compared to a reading that presents Voltaire as advocating a melioristic philosophy and a precept committing the travellers to improving the world through metaphorical gardening. This debate, and others, focuses on the question of whether or not Voltaire was prescribing passive retreat from society, or active industrious contribution to it.
Separate from the debate about the text's conclusion is the "inside/outside" controversy. This argument centers on the matter of whether or not Voltaire was actually prescribing anything. Roy Wolper, professor emeritus of English, argues in a revolutionary 1969 paper that "Candide" does not necessarily speak for its author; that the work should be viewed as a narrative independent of Voltaire's history; and that its message is entirely (or mostly) it. This point of view, the "inside", specifically rejects attempts to find Voltaire's "voice" in the many characters of "Candide" and his other works. Indeed, writers have seen Voltaire as speaking through at least Candide, Martin, and the Turk. Wolper argues that "Candide" should be read with a minimum of speculation as to its meaning in Voltaire's personal life. His article ushered in a new era of Voltaire studies, causing many scholars to look at the novel differently. 
Critics such as Lester Crocker, Henry Stavan, and Vivienne Mylne find too many similarities between "Candide"s point of view and that of Voltaire to accept the "inside" view; they support the "outside" interpretation. They believe that Candide's final decision is the same as Voltaire's, and see a strong connection between the development of the protagonist and his author. Some scholars who support the "outside" view also believe that the isolationist philosophy of the Old Turk closely mirrors that of Voltaire. Others see a strong parallel between Candide's gardening at the conclusion and the gardening of the author. Martine Darmon Meyer argues that the "inside" view fails to see the satirical work in context, and that denying that "Candide" is primarily a mockery of optimism (a matter of historical context) is a "very basic betrayal of the text".
Though Voltaire did not openly admit to having written the controversial "Candide" until 1768 (until then he signed with a pseudonym: "Monsieur le docteur Ralph", or "Doctor Ralph"), his authorship of the work was hardly disputed.
Immediately after publication, the work and its author were denounced by both secular and religious authorities, because the book openly derides government and church alike. It was because of such polemics that Omer-Louis-François Joly de Fleury, who was Advocate General to the Parisian parliament when "Candide" was published, found parts of "Candide" to be "contrary to religion and morals".
Despite much official indictment, soon after its publication, "Candide"s irreverent prose was being quoted. "Let us eat a Jesuit", for instance, became a popular phrase for its reference to a humorous passage in "Candide". By the end of February 1759, the Grand Council of Geneva and the administrators of Paris had banned "Candide". "Candide" nevertheless succeeded in selling twenty thousand to thirty thousand copies by the end of the year in over twenty editions, making it a best seller. The Duke de La Vallière speculated near the end of January 1759 that "Candide" might have been the fastest-selling book ever. In 1762, "Candide" was listed in the "Index Librorum Prohibitorum", the Roman Catholic Church's list of prohibited books.
Bannings of "Candide" lasted into the twentieth century in the United States, where it has long been considered a seminal work of Western literature. At least once, "Candide" was temporarily barred from entering America: in February 1929, a US customs official in Boston prevented a number of copies of the book, deemed "obscene", from reaching a Harvard University French class. "Candide" was admitted in August of the same year; however by that time the class was over. In an interview soon after "Candide"s detention, the official who confiscated the book explained the office's decision to ban it, "But about 'Candide,' I'll tell you. For years we've been letting that book get by. There were so many different editions, all sizes and kinds, some illustrated and some plain, that we figured the book must be all right. Then one of us happened to read it. It's a filthy book".
"Candide" is the most widely read of Voltaire's many works, and it is considered one of the great achievements of Western literature. However, "Candide" is not necessarily considered a true "classic". According to Bottiglia, "The physical size of "Candide", as well as Voltaire's attitude toward his fiction, precludes the achievement of artistic dimension through plenitude, autonomous '3D' vitality, emotional resonance, or poetic exaltation. "Candide", then, cannot in quantity or quality, measure up to the supreme classics." Bottiglia instead calls it a miniature classic, though others are more forgiving of its size. As the only work of Voltaire which has remained popular up to the present day, "Candide" is listed in Harold Bloom's "". It is included in the Encyclopædia Britannica collection "Great Books of the Western World". "Candide" has influenced modern writers of black humour such as Céline, Joseph Heller, John Barth, Thomas Pynchon, Kurt Vonnegut, and Terry Southern. Its parody and picaresque methods have become favourites of black humorists.
Charles Brockden Brown, an early American novelist, may have been directly affected by Voltaire, whose work he knew well. Mark Kamrath, professor of English, describes the strength of the connection between "Candide" and "Edgar Huntly; or, Memoirs of a Sleep-Walker" (1799): "An unusually large number of parallels...crop up in the two novels, particularly in terms of characters and plot." For instance, the protagonists of both novels are romantically involved with a recently orphaned young woman. Furthermore, in both works the brothers of the female lovers are Jesuits, and each is murdered (although under different circumstances). Some twentieth-century novels that may have been influenced by "Candide" are dystopian science-fiction works. Armand Mattelart, a French critic, sees "Candide" in Aldous Huxley's "Brave New World", George Orwell's "Nineteen Eighty-Four" and Yevgeny Zamyatin's "We", three canonical works of the genre. Specifically, Mattelart writes that in each of these works, there exist references to "Candide"s popularisation of the phrase "the best of all possible worlds". He cites as evidence, for example, that the French version of "Brave New World" was entitled ().
Readers of "Candide" often compare it with certain works of the modern genre the Theatre of the Absurd. Haydn Mason, a Voltaire scholar, sees in "Candide" a few similarities to this brand of literature. For instance, he notes commonalities of "Candide" and "Waiting for Godot" (1952). In both of these works, and in a similar manner, friendship provides emotional support for characters when they are confronted with harshness of their existences. However, Mason qualifies, "the must not be seen as a forerunner of the 'absurd' in modern fiction. Candide's world has many ridiculous and meaningless elements, but human beings are not totally deprived of the ability to make sense out of it." John Pilling, biographer of Beckett, does state that "Candide" was an early and powerful influence on Beckett's thinking. Rosa Luxemburg, in the aftermath of the First World War, remarked upon re-reading "Candide": "Before the war, I would have thought this wicked compilation of all human misery a caricature. Now it strikes me as altogether realistic."
The American alternative rock band Bloodhound Gang refer to "Candide" in their song "Take the Long Way Home", from the American edition of their 1999 album "Hooray for Boobies".
In 1760, one year after Voltaire published "Candide", a sequel was published with the name . This work is attributed both to Thorel de Campigneulles, a writer unknown today, and Henri Joseph Du Laurens, who is suspected of having habitually plagiarised Voltaire. The story continues in this sequel with Candide having new adventures in the Ottoman Empire, Persia, and Denmark. "Part II" has potential use in studies of the popular and literary receptions of "Candide", but is almost certainly apocryphal. In total, by the year 1803, at least ten imitations of "Candide" or continuations of its story were published by authors other than Voltaire.
"Candide" was adapted for the radio anthology program "On Stage" in 1953. Richard Chandlee wrote the script; Elliott Lewis, Cathy Lewis, Edgar Barrier, Byron Kane, Jack Kruschen, Howard McNear, Larry Thor, Martha Wentworth, and Ben Wright performed.
The operetta "Candide" was originally conceived by playwright Lillian Hellman, as a play with incidental music. Leonard Bernstein, the American composer and conductor who wrote the music, was so excited about the project that he convinced Hellman to do it as a "comic operetta". Many lyricists worked on the show, including James Agee, Dorothy Parker, John Latouche, Richard Wilbur, Leonard and Felicia Bernstein, and Hellman. Hershy Kay orchestrated all the pieces except for the overture, which Bernstein did himself. "Candide" first opened on Broadway as a musical on 1 December 1956. The premier production was directed by Tyrone Guthrie and conducted by Samuel Krachmalnick. While this production was a box office flop, the music was highly praised, and an original cast album was made. The album gradually became a cult hit, but Hellman's libretto was criticised as being too serious an adaptation of Voltaire's novel. "Candide" has been revised and reworked several times. The first New York revival, directed by Hal Prince, featured an entirely new libretto by Hugh Wheeler and additional lyrics by Stephen Sondheim. Bernstein revised the work again in 1987 with the collaboration of John Mauceri and John Wells. After Bernstein's death, further revised productions of the musical were performed in versions prepared by Trevor Nunn and John Caird in 1999, and Mary Zimmerman in 2010.
"" (1977) or simply is a book by Leonardo Sciascia. It was at least partly based on Voltaire's "Candide", although the actual influence of "Candide" on is a hotly debated topic. A number of theories on the matter have been proposed. Proponents of one say that is very similar to "Candide", only with a happy ending; supporters of another claim that Voltaire provided Sciascia with only a starting point from which to work, that the two books are quite distinct.
The BBC produced a television adaptation in 1973, with Ian Ogilvy as Candide, Emrys James as Dr. Pangloss, and Frank Finlay as Voltaire himself, acting as the narrator.
Nedim Gürsel wrote his 2001 novel "Le voyage de Candide à Istanbul" about a minor passage in "Candide" during which its protagonist meets Ahmed III, the deposed Turkish sultan. This chance meeting on a ship from Venice to Istanbul is the setting of Gürsel's book. Terry Southern, in writing his popular novel "Candy" with Mason Hoffenberg adapted "Candide" for a modern audience and changed the protagonist from male to female. "Candy" deals with the rejection of a sort of optimism which the author sees in women's magazines of the modern era; "Candy" also parodies pornography and popular psychology. This adaptation of "Candide" was adapted for the cinema by director Christian Marquand in 1968.
In addition to the above, "Candide" was made into a number of minor films and theatrical adaptations throughout the twentieth century. For a list of these, see (1989) with preface and commentaries by Pierre Malandain.
In May 2009, a play titled "Optimism", based on "Candide" opened at the CUB Malthouse Theatre in Melbourne. It followed the basic story of "Candide", incorporating anachronisms, music and stand up comedy from comedian Frank Woodley. It toured Australia and played at the Edinburgh International Festival. In 2010, the Icelandic writer Óttar M. Norðfjörð published a rewriting and modernisation of "Candide", titled .
 (plain text and HTML)

</doc>
<doc id="6630" url="https://en.wikipedia.org/wiki?curid=6630" title="Chapterhouse: Dune">
Chapterhouse: Dune

Chapterhouse: Dune is a 1985 science fiction novel by Frank Herbert, the last in his "Dune" series of six novels. It rose to No. 2 on "The New York Times" Best Seller list.
A direct follow-up to "Heretics of Dune", the novel chronicles the continued struggles of the Bene Gesserit Sisterhood against the violent Honored Matres, who are succeeding in their bid to seize control of the universe and destroy the factions and planets that oppose them.
"Chapterhouse: Dune" ends with a cliffhanger, and Herbert's subsequent death in 1986 left some overarching plotlines of the series unresolved. Two decades later, Herbert's son Brian Herbert, along with Kevin J. Anderson, published two sequels – "Hunters of Dune" (2006) and "Sandworms of Dune" (2007) – based in part on notes left behind by Frank Herbert for what he referred to as "Dune 7", his own planned seventh novel in the "Dune" series.
The Bene Gesserit find themselves the target of the Honored Matres, whose conquest of the Old Empire is almost complete. The Matres are seeking to assimilate the technology and superhuman skills of the Bene Gesserit, and exterminate the Sisterhood itself. Now in command of the Bene Gesserit, Mother Superior Darwi Odrade continues to develop her drastic, secret plan to overcome the Honored Matres. The Bene Gesserit are also terraforming the planet Chapterhouse to accommodate the all-important sandworms, whose native planet Dune had been destroyed by the Matres. Sheeana, in charge of the project, expects sandworms to appear soon. The Honored Matres have also destroyed the entire Bene Tleilax civilization, with Tleilaxu Master Scytale the only one of his kind left alive. In Bene Gesserit captivity, Scytale possesses the Tleilaxu secret of ghola production, which he has reluctantly traded for the Sisterhood's protection. The first ghola produced is that of their recently deceased military genius, Miles Teg. The Bene Gesserit have two other prisoners on Chapterhouse: the latest Duncan Idaho ghola, and former Honored Matre Murbella, whom they have accepted as a novice despite their suspicion that she intends to escape back to the Honored Matres.
Lampadas, a center for Bene Gesserit education, has been destroyed by the Honored Matres. The planet's Chancellor, Reverend Mother Lucilla, manages to escape carrying the shared-minds of millions of Reverend Mothers. Lucilla is forced to land on Gammu where she seeks refuge with an underground group of Jews. The Rabbi gives Lucilla sanctuary, but to save his people from the Matres he must deliver her to the them. Before doing so, he reveals Rebecca, a "wild" Reverend Mother who has gained her Other Memory without Bene Gesserit training. Lucilla shares minds with Rebecca, who promises to take the memories of Lampadas safely back to the Sisterhood. Lucilla is then "betrayed", and taken before the Great Honored Matre Dama, who tries to persuade her to join the Honored Matres, preserving her life in exchange for Bene Gesserit secrets. The Honored Matres are particularly interested in learning to voluntarily modify their body chemistry, a skill that atrophied among the Bene Gesserit who went out into the Scattering and evolved into the Honored Matres. From this, Lucilla deduces that the greater enemy that the Matres are fleeing from is making extensive use of biological warfare. Lucilla refuses to share this knowledge with the Matres, and Dama ultimately kills her. 
Back on Chapterhouse, Odrade confronts Duncan and forces him to admit that he is a Mentat, proving that he retains the memories of his many ghola lives. Meanwhile, Murbella collapses under the pressure of Bene Gesserit training, and realizes that she wants to be Bene Gesserit. Odrade believes that the Sisterhood made a mistake in fearing emotion, and that in order to evolve, they must learn to accept emotions. Murbella survives the spice agony and becomes a Reverend Mother. Odrade confronts Sheeana, discovering that Duncan and Sheeana have been allies for some time. Sheeana does not reveal that they have been considering the option of reawakening Teg's memory through imprinting, nor does Odrade discover that Sheeana has the keys to Duncan's no-ship prison. Teg is awakened by Sheeana using imprinting techniques. Odrade appoints him again as Bashar of the military forces of the Sisterhood for the assault on the Honored Matres. Odrade announces to the Bene Gesserit that Teg will lead an attack against the Honored Matres. She also makes clear her intention to share her memories with Murbella and Sheeana, making them candidates to succeed her as Mother Superior if she dies. Odrade meets with the Great Honored Matre while the Bene Gesserit forces under Teg attack Gammu with tremendous force. Teg uses his secret ability to see no-ships to secure control of the system, and victory for the Bene Gesserit seems inevitable. In the midst of this battle, the Rebecca and the Jews take refuge with the Bene Gesserit fleet.
Dama's chief advisor Logno assassinates Dama with poison and assumes control of the Honored Matres. Too late, Odrade and Teg realize they have fallen into a trap, and the Honored Matres use a mysterious weapon to turn defeat into victory, and capture Odrade. Murbella saves as much of the Bene Gesserit force as she can and they withdraw to Chapterhouse. Odrade, however, had planned for the possible failure of the Bene Gesserit attack and left Murbella instructions for a last desperate gamble. Murbella pilots a small craft down to the surface, announcing herself as an Honored Matre who, in the confusion, has managed to escape the Bene Gesserit with all their secrets. She arrives on the planet and is taken to the Great Honored Matre. Unable to control her anger, Logno attacks but is killed by Murbella. Awed by her physical prowess, the remaining Honored Matres are forced to accept her as their new leader. Odrade is also killed in the melee and Murbella shares with Odrade to absorb her newest memories, as they had already shared prior to the battle. Murbella's ascension to leadership is not accepted as victory by all the Bene Gesserit. Some flee Chapterhouse, notably Sheeana, who has a vision of her own, and arranges to have some of the new worms that have emerged in the Chapterhouse desert brought aboard the no-ship. Sheeana is joined by Duncan. The two escape in the giant no-ship, with Scytale, Teg and the Jews. Murbella recognizes their plan at the last minute, but is powerless to stop them.
"Chapterhouse: Dune" debuted at No. 5 and rose to No. 2 on "The New York Times" Best Seller list. Gerald Jonas of "The New York Times" noted that "Against all odds, the universe of "Dune" keeps getting richer in texture, more challenging in its moral dilemmas."
Dave Langford reviewed "Chapter House Dune" for "White Dwarf" #65, and stated that "The hyper-acute characters are impressive, the resolution thoughtful and humane. Though initially I gave up after "Children", "Heretics" and "Chapter House" have partially Restored My Faith."
Two decades after Frank Herbert's death, his son Brian Herbert, along with Kevin J. Anderson, published two sequels – "Hunters of Dune" (2006) and "Sandworms of Dune" (2007) – based on notes left behind by Frank Herbert for what he referred to as "Dune 7", his own planned seventh novel in the "Dune" series.

</doc>
<doc id="6631" url="https://en.wikipedia.org/wiki?curid=6631" title="Bus (computing)">
Bus (computing)

In computer architecture, a bus (a contraction of the Latin "omnibus", and historically also called "data highway") is a communication system that transfers data between components inside a computer, or between computers. This expression covers all related hardware components (wire, optical fiber, etc.) and software, including communication protocols.
Early computer buses were parallel electrical wires with multiple hardware connections, but the term is now used for any physical arrangement that provides the same logical function as a parallel electrical bus. Modern computer buses can use both parallel and bit serial connections, and can be wired in either a multidrop (electrical parallel) or daisy chain topology, or connected by switched hubs, as in the case of USB.
Computer systems generally consist of three main parts: 
An early computer might contain a hand-wired CPU of vacuum tubes, a magnetic drum for main memory, and a punch tape and printer for reading and writing data respectively. A modern system might have a multi-core CPU, DDR4 SDRAM for memory, a solid-state drive for secondary storage, a graphics card and LCD as a display system, a mouse and keyboard for interaction, and a Wi-Fi connection for networking. In both examples, computer buses of one form or another move data between all of these devices.
In most traditional computer architectures, the CPU and main memory tend to be tightly coupled. A microprocessor conventionally is a single chip which has a number of electrical connections on its pins that can be used to select an "address" in the main memory and another set of pins to read and write the data stored at that location. In most cases, the CPU and memory share signalling characteristics and operate in synchrony. The bus connecting the CPU and memory is one of the defining characteristics of the system, and often referred to simply as the system bus.
It is possible to allow peripherals to communicate with memory in the same fashion, attaching adaptors in the form of expansion cards directly to the system bus. This is commonly accomplished through some sort of standardized electrical connector, several of these forming the expansion bus or local bus. However, as the performance differences between the CPU and peripherals varies widely, some solution is generally needed to ensure that peripherals do not slow overall system performance. Many CPUs feature a second set of pins similar to those for communicating with memory, but able to operate at very different speeds and using different protocols. Others use smart controllers to place the data directly in memory, a concept known as direct memory access. Most modern systems combine both solutions, where appropriate.
As the number of potential peripherals grew, using an expansion card for every peripheral became increasingly untenable. This has led to the introduction of bus systems designed specifically to support multiple peripherals. Common examples are the SATA ports in modern computers, which allow a number of hard drives to be connected without the need for a card. However, these high-performance systems are generally too expensive to implement in low-end devices, like a mouse. This has led to the parallel development of a number of low-performance bus systems for these solutions, the most common example being the standardized Universal Serial Bus (USB). All such examples may be referred to as peripheral buses, although this terminology is not universal.
In modern systems the performance difference between the CPU and main memory has grown so great that increasing amounts of high-speed memory is built directly into the CPU, known as a cache. In such systems, CPUs communicate using high-performance buses that operate at speeds much greater than memory, and communicate with memory using protocols similar to those used solely for peripherals in the past. These system buses are also used to communicate with most (or all) other peripherals, through adaptors, which in turn talk to other peripherals and controllers. Such systems are architecturally more similar to multicomputers, communicating over a bus rather than a network. In these cases, expansion buses are entirely separate and no longer share any architecture with their host CPU (and may in fact support many different CPUs, as is the case with PCI). What would have formerly been a system bus is now often known as a front-side bus.
Given these changes, the classical terms "system", "expansion" and "peripheral" no longer have the same connotations. Other common categorization systems are based on the bus's primary role, connecting devices internally or externally, PCI vs. SCSI for instance. However, many common modern bus systems can be used for both; SATA and the associated eSATA are one example of a system that would formerly be described as internal, while certain automotive applications use the primarily external IEEE 1394 in a fashion more similar to a system bus. Other examples, like InfiniBand and I²C were designed from the start to be used both internally and externally.
The internal bus, also known as internal data bus, memory bus, system bus or front-side bus, connects all the internal components of a computer, such as CPU and memory, to the motherboard. Internal data buses are also referred to as local buses, because they are intended to connect to local devices. This bus is typically rather quick and is independent of the rest of the computer operations.
The external bus, or expansion bus, is made up of the electronic pathways that connect the different external devices, such as printer etc., to the computer.
An address bus is a bus that is used to specify a physical address. When a processor or DMA-enabled device needs to read or write to a memory location, it specifies that memory location on the address bus (the value to be read or written is sent on the data bus). The width of the address bus determines the amount of memory a system can address. For example, a system with a 32-bit address bus can 
address 2 (4,294,967,296) memory locations. If each memory location holds one byte, the addressable memory space is 4 GiB.
Early processors used a wire for each bit of the address width. For example, a 16-bit address bus had 16 physical wires making up the bus. As the buses became wider and lengthier, this approach became expensive in terms of the number of chip pins and board traces. Beginning with the Mostek 4096 DRAM, address multiplexing implemented with multiplexers became common. In a multiplexed address scheme, the address is sent in two equal parts on alternate bus cycles. This halves the number of address bus signals required to connect to the memory. For example, a 32-bit address bus can be implemented by using 16 lines and sending the first half of the memory address, immediately followed by the second half memory address
Typically 2 additional pins in the control bus -- a row-address strobe (RAS) and the column-address strobe (CAS) -- are used to tell the DRAM whether the address bus is currently sending the first half of the memory address or the second half.
Accessing an individual byte frequently requires reading or writing the full bus width (a word) at once. In these instances the least significant bits of the address bus may not even be implemented - it is instead the responsibility of the controlling device to isolate the individual byte required from the complete word transmitted. This is the case, for instance, with the VESA Local Bus which lacks the two least significant bits, limiting this bus to aligned 32-bit transfers.
Historically, there were also some examples of computers which were only able to address words -- word machines.
Buses can be parallel buses, which carry data words in parallel on multiple wires, or serial buses, which carry data in bit-serial form. The addition of extra power and control connections, differential drivers, and data connections in each direction usually means that most serial buses have more conductors than the minimum of one used in 1-Wire and UNI/O. As data rates increase, the problems of timing skew, power consumption, electromagnetic interference and crosstalk across parallel buses become more and more difficult to circumvent. One partial solution to this problem has been to double pump the bus. Often, a serial bus can be operated at higher overall data rates than a parallel bus, despite having fewer electrical connections, because a serial bus inherently has no timing skew or crosstalk. USB, FireWire, and Serial ATA are examples of this. Multidrop connections do not work well for fast serial buses, so most modern serial buses use daisy-chain or hub designs.
Network connections such as Ethernet are not generally regarded as buses, although the difference is largely conceptual rather than practical. An attribute generally used to characterize a bus is that power is provided by the bus for the connected hardware. This emphasizes the busbar origins of bus architecture as supplying switched or distributed power. This excludes, as buses, schemes such as serial RS-232, parallel Centronics, IEEE 1284 interfaces and Ethernet, since these devices also needed separate power supplies. Universal Serial Bus devices may use the bus supplied power, but often use a separate power source. This distinction is exemplified by a telephone system with a connected modem, where the RJ11 connection and associated modulated signalling scheme is not considered a bus, and is analogous to an Ethernet connection. A phone line connection scheme is not considered to be a bus with respect to signals, but the Central Office uses buses with cross-bar switches for connections between phones.
However, this distinctionthat power is provided by the busis not the case in many avionic systems, where data connections such as ARINC 429, ARINC 629, MIL-STD-1553B (STANAG 3838), and EFABus (STANAG 3910) are commonly referred to as “data buses” or, sometimes, "databuses". Such avionic data buses are usually characterized by having several equipments or Line Replaceable Items/Units (LRI/LRUs) connected to a common, shared media. They may, as with ARINC 429, be simplex, i.e. have a single source LRI/LRU or, as with ARINC 629, MIL-STD-1553B, and STANAG 3910, be duplex, allow all the connected LRI/LRUs to act, at different times (half duplex), as transmitters and receivers of data.
Some processors use a dedicated wire for each bit of the address bus, data bus, and the control bus.
For example, the 64-pin STEbus is composed of 8 physical wires dedicated to the 8-bit data bus, 20 physical wires dedicated to the 20-bit address bus, 21 physical wires dedicated to the control bus, and 15 physical wires dedicated to various power buses.
Bus multiplexing requires fewer wires, which reduces costs in many early microprocessors and DRAM chips.
One common multiplexing scheme, address multiplexing, has already been mentioned.
Another multiplexing scheme re-uses the address bus pins as the data bus pins, an approach used by conventional PCI.
The various "serial buses" can be seen as the ultimate limit of multiplexing, sending each of the address bits and each of the data bits, one at a time, through a single pin (or a single differential pair).
Over time, several groups of people worked on various computer bus standards, including the IEEE Bus Architecture Standards Committee (BASC), the IEEE "Superbus" study group, the open microprocessor initiative (OMI), the open microsystems initiative (OMI), the "Gang of Nine" that developed EISA, etc.
Early computer buses were bundles of wire that attached computer memory and peripherals. Anecdotally termed the "digit trunk", they were named after electrical power buses, or busbars. Almost always, there was one bus for memory, and one or more separate buses for peripherals. These were accessed by separate instructions, with completely different timings and protocols.
One of the first complications was the use of interrupts. Early computer programs performed I/O by waiting in a loop for the peripheral to become ready. This was a waste of time for programs that had other tasks to do. Also, if the program attempted to perform those other tasks, it might take too long for the program to check again, resulting in loss of data. Engineers thus arranged for the peripherals to interrupt the CPU. The interrupts had to be prioritized, because the CPU can only execute code for one peripheral at a time, and some devices are more time-critical than others.
High-end systems introduced the idea of channel controllers, which were essentially small computers dedicated to handling the input and output of a given bus. IBM introduced these on the IBM 709 in 1958, and they became a common feature of their platforms. Other high-performance vendors like Control Data Corporation implemented similar designs. Generally, the channel controllers would do their best to run all of the bus operations internally, moving data when the CPU was known to be busy elsewhere if possible, and only using interrupts when necessary. This greatly reduced CPU load, and provided better overall system performance.
To provide modularity, memory and I/O buses can be combined into a unified system bus. In this case, a single mechanical and electrical system can be used to connect together many of the system components, or in some cases, all of them.
Later computer programs began to share memory common to several CPUs. Access to this memory bus had to be prioritized, as well. The simple way to prioritize interrupts or bus access was with a daisy chain. In this case signals will naturally flow through the bus in physical or logical order, eliminating the need for complex scheduling.
Digital Equipment Corporation (DEC) further reduced cost for mass-produced minicomputers, and mapped peripherals into the memory bus, so that the input and output devices appeared to be memory locations. This was implemented in the Unibus of the PDP-11 around 1969.
Early microcomputer bus systems were essentially a passive backplane connected directly or through buffer amplifiers to the pins of the CPU. Memory and other devices would be added to the bus using the same address and data pins as the CPU itself used, connected in parallel. Communication was controlled by the CPU, which read and wrote data from the devices as if they are blocks of memory, using the same instructions, all timed by a central clock controlling the speed of the CPU. Still, devices interrupted the CPU by signaling on separate CPU pins.
For instance, a disk drive controller would signal the CPU that new data was ready to be read, at which point the CPU would move the data by reading the "memory location" that corresponded to the disk drive. Almost all early microcomputers were built in this fashion, starting with the S-100 bus in the Altair 8800 computer system.
In some instances, most notably in the IBM PC, although similar physical architecture can be employed, instructions to access peripherals (codice_1 and codice_2) and memory (codice_3 and others) have not been made uniform at all, and still generate distinct CPU signals, that could be used to implement a separate I/O bus.
These simple bus systems had a serious drawback when used for general-purpose computers. All the equipment on the bus had to talk at the same speed, as it shared a single clock.
Increasing the speed of the CPU becomes harder, because the speed of all the devices must increase as well. When it is not practical or economical to have all devices as fast as the CPU, the CPU must either enter a wait state, or work at a slower clock frequency temporarily, to talk to other devices in the computer. While acceptable in embedded systems, this problem was not tolerated for long in general-purpose, user-expandable computers.
Such bus systems are also difficult to configure when constructed from common off-the-shelf equipment. Typically each added expansion card requires many jumpers in order to set memory addresses, I/O addresses, interrupt priorities, and interrupt numbers.
"Second generation" bus systems like NuBus addressed some of these problems. They typically separated the computer into two "worlds", the CPU and memory on one side, and the various devices on the other. A "bus controller" accepted data from the CPU side to be moved to the peripherals side, thus shifting the communications protocol burden from the CPU itself. This allowed the CPU and memory side to evolve separately from the device bus, or just "bus". Devices on the bus could talk to each other with no CPU intervention. This led to much better "real world" performance, but also required the cards to be much more complex. These buses also often addressed speed issues by being "bigger" in terms of the size of the data path, moving from 8-bit parallel buses in the first generation, to 16 or 32-bit in the second, as well as adding software setup (now standardised as Plug-n-play) to supplant or replace the jumpers.
However, these newer systems shared one quality with their earlier cousins, in that everyone on the bus had to talk at the same speed. While the CPU was now isolated and could increase speed, CPUs and memory continued to increase in speed much faster than the buses they talked to. The result was that the bus speeds were now very much slower than what a modern system needed, and the machines were left starved for data. A particularly common example of this problem was that video cards quickly outran even the newer bus systems like PCI, and computers began to include AGP just to drive the video card. By 2004 AGP was outgrown again by high-end video cards and other peripherals and has been replaced by the new PCI Express bus.
An increasing number of external devices started employing their own bus systems as well. When disk drives were first introduced, they would be added to the machine with a card plugged into the bus, which is why computers have so many slots on the bus. But through the 1980s and 1990s, new systems like SCSI and IDE were introduced to serve this need, leaving most slots in modern systems empty. Today there are likely to be about five different buses in the typical machine, supporting various devices.
"Third generation" buses have been emerging into the market since about 2001, including HyperTransport and InfiniBand. They also tend to be very flexible in terms of their physical connections, allowing them to be used both as internal buses, as well as connecting different machines together. This can lead to complex problems when trying to service different requests, so much of the work on these systems concerns software design, as opposed to the hardware itself. In general, these third generation buses tend to look more like a network than the original concept of a bus, with a higher protocol overhead needed than early systems, while also allowing multiple devices to use the bus at once.
Buses such as Wishbone have been developed by the open source hardware movement in an attempt to further remove legal and patent constraints from computer design.
The Compute Express Link (CXL) is an open standard interconnect for high-speed CPU-to-device and CPU-to-memory, designed to accelerate next-generation data center performance.

</doc>
<doc id="6634" url="https://en.wikipedia.org/wiki?curid=6634" title="Cadillac (disambiguation)">
Cadillac (disambiguation)

Cadillac is a General Motors luxury car brand.
Cadillac may also refer to:

</doc>
<doc id="6635" url="https://en.wikipedia.org/wiki?curid=6635" title="Chinese checkers">
Chinese checkers

Sternhalma, commonly known as Chinese Checkers (US and Canadian spelling) or Chinese Chequers (UK spelling), is a strategy board game of German origin which can be played by two, three, four, or six people, playing individually or with partners. The game is a modern and simplified variation of the game Halma.
The objective is to be first to race all of one's pieces across the hexagram-shaped board into "home"—the corner of the star opposite one's starting corner—using single-step moves or moves that over other pieces. The remaining players continue the game to establish second-, third-, fourth-, fifth-, and last-place finishers. The rules are simple, so even young children can play.
Despite its name, the game is not a variation of checkers, nor did it originate in China or any part of Asia. The game was invented in Germany in 1892 under the name "Stern-Halma" as a variation of the older American game Halma. The "Stern" (German for "star") refers to the board's star shape (in contrast to the square board used in Halma). 
The name "Chinese Checkers" originated in the United States as a marketing scheme by Bill and Jack Pressman in 1928. The Pressman company's game was originally called "Hop Ching Checkers".
In Japan, the game is known as "Diamond Game" (ダイヤモンドゲーム). The game was introduced to Chinese-speaking regions mostly by the Japanese, where it is known as "Tiaoqi" (, "jump chess").
The aim is to race all one's pieces into the star corner on the opposite side of the board before the opponents do the same. The destination corner is called "home". Each player has 10 pieces, except in games between two players when 15 pieces are used. (On bigger star boards, 15 or 21 pieces are used.)
In "hop across", the most popular variation, each player starts with their colored pieces on one of the six points or corners of the star and attempts to race them all home into the opposite corner. Players take turns moving a single piece, either by moving one step in any direction to an adjacent empty space, or by jumping in one or any number of available consecutive hops over other single pieces. A player may not combine hopping with a single-step move – a move consists of one or the other. There is no capturing in Sternhalma, so pieces that are hopped over remain active and in play. Turns proceed clockwise around the board.
In the diagram, Green might move the topmost piece one space diagonally forward as shown. A "hop" consists of jumping over a single adjacent piece, either one's own or an opponent's, to the empty space directly beyond it in the same line of direction. Red might advance the indicated piece by a chain of three hops in a single move. It is not mandatory to make the most number of hops possible. (In some instances a player may choose to stop the jumping sequence part way in order to impede the opponent's progress, or to align pieces for planned future moves.)
Can be played "all versus all", or three teams of two. When playing teams, teammates usually sit at opposite corners of the star, with each team member controlling their own colored set of pieces. The first team to advance both sets to their home destination corners is the winner. The remaining players usually continue play to determine second- and third-place finishers, etc.
The four-player game is the same as the game for six players, except that two opposite corners will be unused.
In a three-player game, all players control either one or two sets of pieces each. If one set is used, pieces race across the board into empty, opposite corners. If two sets are used, each player controls two differently colored sets of pieces at opposite corners of the star.
In a two-player game, each player plays one, two, or three sets of pieces. If one set is played, the pieces usually go into the opponent's starting corner, and the number of pieces per side is increased to 15 (instead of the usual 10). If two sets are played, the pieces can either go into the opponent's starting corners, or one of the players' two sets can go into an opposite empty corner. If three sets are played, the pieces usually go into the opponent's starting corners.
A basic strategy is to create or find the longest hopping path that leads closest to home, or immediately into it. (Multiple-jump moves are obviously faster to advance pieces than step-by-step moves.) Since either player can make use of any hopping 'ladder' or 'chain' created, a more advanced strategy involves hindering an opposing player in addition to helping oneself make jumps across the board. Of equal importance are the players' strategies for emptying and filling their starting and home corners. Games between top players are rarely decided by more than a couple of moves.
Differing numbers of players result in different starting layouts, in turn imposing different best-game strategies. For example, if a player's home destination corner starts empty (i.e. is not an opponent's starting corner), the player can freely build a 'ladder' or 'bridge' with their pieces between the two opposite ends. But if a player's opponent occupies the home corner, the player may need to wait for opponent pieces to clear before filling the home vacancies.
While the standard rules allow hopping over only a single adjacent occupied position at a time (as in checkers), this version of the game allows pieces to catapult over multiple adjacent occupied positions in a line when hopping.
In the "fast-paced" or "Super Chinese Checkers" variant popular in France, a piece may hop over a "non-adjacent" piece. A hop consists of jumping over a distant piece (friendly or enemy) to a symmetrical position on the opposite side, in the same line of direction. (For example, if there are two empty positions between the jumping piece and the piece being jumped, the jumping piece lands leaving exactly two empty positions immediately beyond the jumped piece.) As in the standard rules, a jumping move may consist of any number of a chain of hops. (When making a chain of hops, a piece is usually allowed to enter an empty corner, as long as it hops out again before the move is completed.)
Jumping over two or more pieces in a hop is not allowed. Therefore, in this variant even more than in the standard version, it is sometimes strategically important to keep one's pieces bunched in order to prevent a long opposing hop.
An alternative variant allows hops over "any" symmetrical arrangement, including pairs of pieces, pieces separated by empty positions, and so on.
In the "capture" variant, all sixty game pieces start out in the hexagonal field in the center of the gameboard. The center position is left unoccupied, so pieces form a symmetric hexagonal pattern. Color is irrelevant in this variant, so players take turns hopping any game piece over any other eligible game piece(s) on the board. The hopped-over pieces are captured (retired from the game, as in English draughts) and collected in the capturing player's bin. Only jumping moves are allowed; the game ends when no further jumps are possible. The player with the most captured pieces is the winner.
The board is tightly packed at the start of the game; as more pieces are captured, the board frees up, often allowing multiple captures to take place in a single move.
Two or more players can compete in this variant, but if there are more than six players, not everyone will get a fair turn.
This variant resembles the game Leap Frog. The main difference being that in Leap Frog the board is a square board.
Diamond game is a variant of Sternhalma played in South Korea and Japan. It uses the same jump rule as in Sternhalma. The aim of the game is to enter all one's pieces into the star corner on the opposite side of the board, before opponents do the same. Each player has ten or fifteen pieces. Ten-piece diamond uses a smaller gameboard than Sternhalma, with 73 spaces. Fifteen-piece diamond uses the same board as in Sternhalma, with 121 spaces. To play diamond each player selects one color and places their 10 or 15 pieces on a triangle. Two or three players can compete.
Bibliography

</doc>
<doc id="6639" url="https://en.wikipedia.org/wiki?curid=6639" title="Cantor Fitzgerald">
Cantor Fitzgerald

Cantor Fitzgerald is an American financial services firm that was founded in 1945. It specializes in institutional equity, fixed income sales and trading, and serving the middle market with investment banking services, prime brokerage, and commercial real estate financing. It is also active in new businesses, including advisory and asset management services, gaming technology, and e-commerce. It has more than 5,000 institutional clients.
Cantor Fitzgerald is one of 22 primary dealers that are authorized to trade US government securities with the Federal Reserve Bank of New York.
Cantor Fitzgerald's 1,600 employees work in more than 30 locations, including financial centers in the Americas, Europe, Asia-Pacific, and the Middle East. Together with its affiliates, Cantor Fitzgerald operates in more than 60 offices in 20 countries and has more than 8,500 employees.
In 2011, Cantor's affiliate, BGC Partners, expanded into commercial real estate services by its purchase of Newmark Knight Frank and the assets of Grubb & Ellis, to form Newmark Grubb Knight Frank.
Cantor Fitzgerald was formed in 1945 by Bernard Gerald Cantor and John Fitzgerald as an investment bank and brokerage business. It later became known for its computer-based bond brokerage, for the quality of its institutional distribution business model, and for being the market's premier dealer of government securities.
In 1965, Cantor Fitzgerald began "large block" sales/trading of equities for institutional customers. It became the world's first electronic marketplace for US government securities in 1972 and in 1983, it was the first to offer worldwide screen brokerage services in US government securities.
In 1991, Howard Lutnick was named president and CEO of Cantor Fitzgerald; he became chairman of Cantor Fitzgerald, L.P., in 1996.
Cantor Fitzgerald's corporate headquarters and New York City office, on the 101st to the 105th floors of One World Trade Center in Lower Manhattan (2 to 6 floors above the impact zone of a hijacked airliner), were destroyed during the September 11, 2001 attacks. At 8:46:46 a.m., six seconds after the tower was struck by the plane, a Goldman Sachs server issued an alert saying that its trading system had gone offline because it was unable to connect with the server. Every employee who reported for work that morning was killed in the attacks; 658 of its 960 New York employees, 68.5% of its workforce, which was considerably more than any of the other World Trade Center tenants or the New York City Police Department, the Port Authority of New York and New Jersey Police Department, the New York City Fire Department, or the United States Department of Defense since all stairwells leading past the impact zone were destroyed by the initial crash or blocked with smoke, fire, or debris. CEO Howard Lutnick himself was not present because he was taking his son to his first day of kindergarten, but his younger brother, Gary, was among those killed. Lutnick vowed to keep the company alive, and the company was able to bring its trading markets back online within a week.
On September 19, Cantor Fitzgerald made a pledge to distribute 25% of the firm's profits for the next five years, and it committed to paying for ten years of health care for the benefit of the families of its 658 former Cantor Fitzgerald, eSpeed, and TradeSpark employees (profits that would otherwise have been distributed to the Cantor Fitzgerald partners). In 2006, the company had completed its promise, having paid a total of $180 million (and an additional $17 million from a relief fund run by Lutnick's sister, Edie).
Until the attacks, Cantor had handled about a quarter of the daily transactions in the multitrillion-dollar treasury security market. Cantor Fitzgerald has since rebuilt its infrastructure, partly by the efforts of its London office, and it now has its headquarters in Midtown Manhattan. The company's effort to regain its footing was the subject of Tom Barbash's 2003 book "On Top of the World: Cantor Fitzgerald, Howard Lutnick, and 9/11: A Story of Loss and Renewal" as well as a 2012 documentary, "Out of the Clear Blue Sky".
On September 2, 2004, Cantor and other organizations filed a civil lawsuit against Saudi Arabia for allegedly providing money to the hijackers and Al Qaeda. It was later joined in the suit by the Port Authority of New York. Most of the claims against Saudi Arabia were dismissed on January 18, 2005.
In December 2013, Cantor Fitzgerald settled its lawsuit against American Airlines for $135 million. Cantor Fitzgerald had been suing for loss of property and interruption of business by alleging the airline to have been negligent by allowing hijackers to board Flight 11.
In 2003, the firm launched its fixed income sales and trading group.
In 2006, the Federal Reserve added Cantor Fitzgerald & Co. to its list of primary dealers.
In 2009, the firm launched Cantor Prime Services, a provider of multi-asset, perimeter brokerage prime brokerage platforms to exploit its clearing, financing, and execution capabilities.
Cantor Fitzgerald began building its real estate business with the launch of CCRE in 2010.
On December 5, 2014, two Cantor Fitzgerald analysts were said to be in the top 25 analysts on TipRanks.
Cantor Fitzgerald has a prolific Special-purpose acquisition company underwriting practice, having led all banks in SPAC underwriting activity in both 2018 and 2019.
Edie wrote "An Unbroken Bond: The Untold Story of How the 658 Cantor Fitzgerald Families Faced the Tragedy of 9/11 and Beyond". All proceeds from the sale of the book benefit the Cantor Fitzgerald Relief Fund and the charities that it assists.
The Cantor Fitzgerald Relief Fund provided $10 million to families affected by Hurricane Sandy. Howard Lutnick and the Relief Fund "adopted" 19 elementary schools in impacted areas by distributing $1,000 prepaid debit cards to each family from the schools. A total of $10 million in funds was given to families affected by the storm.
Two days after the 2013 Moore tornado struck Moore, Oklahoma, killing 24 people and injuring hundreds, Lutnick pledged to donate $2 million to families affected by the tornado. The donation was given out in the form of $1,000 debit cards given out to families.
Each year, on September 11, Cantor Fitzgerald and its affiliate, BGC Partners, donate 100% of their revenue to charitable causes on their annual Charity Day, which was originally established to raise money to assist the families of the Cantor employees who died in the World Trade Center attacks. Since its inception, Charity Day has raised $110 million for charities globally.
The firm has many subsidiaries and affiliates such as the following:
An employee, Venetia Thompson, published, in February 2008, an article in "The Spectator" about her and her colleagues' behavior, with an emphasis on the drinking culture. She was subsequently fired for gross misconduct. She responded in 2010 by publishing a book, "Gross Misconduct: My Year of Excess in the City", about her experiences.

</doc>
<doc id="6641" url="https://en.wikipedia.org/wiki?curid=6641" title="Cane toad">
Cane toad

The cane toad ("Rhinella marina"), also known as the giant neotropical toad or marine toad, is a large, terrestrial true toad native to South and mainland Central America, but which has been introduced to various islands throughout Oceania and the Caribbean, as well as Northern Australia. It is the world's largest toad. It is a member of the genus "Rhinella", which includes many true toad species found throughout Central and South America, but it was formerly assigned to the genus "Bufo".
The cane toad is an old species. A fossil toad (specimen UCMP 41159) from the La Venta fauna of the late Miocene of Colombia is indistinguishable from modern cane toads from northern South America. It was discovered in a floodplain deposit, which suggests the "R. marina" habitat preferences have long been for open areas. The cane toad is a prolific breeder; females lay single-clump spawns with thousands of eggs. Its reproductive success is partly because of opportunistic feeding: it has a diet, unusual among anurans, of both dead and living matter. Adults average in length; the largest recorded specimen had a snout-vent length of .
The cane toad has poison glands, and the tadpoles are highly toxic to most animals if ingested. Its toxic skin can kill many animals, both wild and domesticated, and cane toads are particularly dangerous to dogs. Because of its voracious appetite, the cane toad has been introduced to many regions of the Pacific and the Caribbean islands as a method of agricultural pest control. The common name of the species is derived from its use against the cane beetle ("Dermolepida albohirtum"), which damages sugar cane. The cane toad is now considered a pest and an invasive species in many of its introduced regions. The 1988 film "" documented the trials and tribulations of the introduction of cane toads in Australia.
Historically, the cane toads were used to eradicate pests from sugarcane, giving rise to their common name. The cane toad has many other common names, including "giant toad" and "marine toad"; the former refers to its size, and the latter to the binomial name, "R. marina". It was one of many species described by Carl Linnaeus in his 18th-century work "Systema Naturae" (1758). Linnaeus based the specific epithet "marina" on an illustration by Dutch zoologist Albertus Seba, who mistakenly believed the cane toad to inhabit both terrestrial and marine environments. Other common names include "giant neotropical toad", "Dominican toad", "giant marine toad", and "South American cane toad". In Trinidadian English, they are commonly called "crapaud", the French word for toad.
The genus "Rhinella" is considered to constitute a distinct genus of its own, thus changing the scientific name of the cane toad. In this case, the specific name "marinus" (masculine) changes to "marina" (feminine) to conform with the rules of gender agreement as set out by the International Code of Zoological Nomenclature, changing the binomial name from "Bufo marinus" to "Rhinella marina"; the binomial "Rhinella marinus" was subsequently introduced as a synonym through misspelling by Pramuk, Robertson, Sites, and Noonan (2008). Though controversial (with many traditional herpetologists still using "Bufo marinus") the binomial "Rhinella marina" is gaining in acceptance with such bodies as the IUCN, Encyclopaedia of Life, Amphibian Species of the World and increasing numbers of scientific publications adopting its usage.
Since 2016, cane toad populations native to Mesoamerica and northwestern South America are sometimes considered to be a separate species, "Rhinella horribilis".
In Australia, the adults may be confused with large native frogs from the genera "Limnodynastes", "Cyclorana", and "Mixophyes". These species can be distinguished from the cane toad by the absence of large parotoid glands behind their eyes and the lack of a ridge between the nostril and the eye. Cane toads have been confused with the giant burrowing frog ("Heleioporus australiacus"), because both are large and warty in appearance; however, the latter can be readily distinguished from the former by its vertical pupils and its silver-grey (as opposed to gold) irises. Juvenile cane toads may be confused with species of the genus "Uperoleia", but their adult colleagues can be distinguished by the lack of bright colouring on the groin and thighs.
In the United States, the cane toad closely resembles many bufonid species. In particular, it could be confused with the southern toad ("Bufo terrestris"), which can be distinguished by the presence of two bulbs in front of the parotoid glands.
The cane toad genome has been sequenced and certain Australian academics believe this will help in understanding how the toad can quickly evolve to adapt to new environments, the workings of its infamous toxin, and hopefully provide new options for halting this species' march across Australia and other places it has spread as an invasive pest.
The cane toad is very large; the females are significantly longer than males, reaching a typical length of , with a maximum of . Larger toads tend to be found in areas of lower population density. They have a life expectancy of 10 to 15 years in the wild, and can live considerably longer in captivity, with one specimen reportedly surviving for 35 years.
The skin of the cane toad is dry and warty. It has distinct ridges above the eyes, which run down the snout. Individual cane toads can be grey, yellowish, red-brown, or olive-brown, with varying patterns. A large parotoid gland lies behind each eye. The ventral surface is cream-coloured and may have blotches in shades of black or brown. The pupils are horizontal and the irises golden. The toes have a fleshy webbing at their base, and the fingers are free of webbing.
Typically, juvenile cane toads have smooth, dark skin, although some specimens have a red wash. Juveniles lack the adults' large parotoid glands, so they are usually less poisonous. The tadpoles are small and uniformly black, and are bottom-dwellers, tending to form schools. Tadpoles range from in length.
The common name "marine toad" and the scientific name "Rhinella marina" suggest a link to marine life, but cane toads do not live in the sea. However, laboratory experiments suggest that tadpoles can tolerate salt concentrations equivalent to 15% of seawater (~5.4‰), and recent field observations found living tadpoles and toadlets at salinities of 27.5‰ on Coiba Island, Panama. The cane toad inhabits open grassland and woodland, and has displayed a "distinct preference" for areas modified by humans, such as gardens and drainage ditches. In their native habitats, the toads can be found in subtropical forests, although dense foliage tends to limit their dispersal.
The cane toad begins life as an egg, which is laid as part of long strings of jelly in water. A female lays 8,000–25,000 eggs at once and the strings can stretch up to in length. The black eggs are covered by a membrane and their diameter is about . The rate at which an egg grows into a tadpole increases with temperature. Tadpoles typically hatch within 48 hours, but the period can vary from 14 hours to almost a week. This process usually involves thousands of tadpoles—which are small, black, and have short tails—forming into groups. Between 12 and 60 days are needed for the tadpoles to develop into juveniles, with four weeks being typical. Similarly to their adult counterparts, eggs and tadpoles are toxic to many animals.
When they emerge, toadlets typically are about in length, and grow rapidly. While the rate of growth varies by region, time of year, and gender, an average initial growth rate of per day is seen, followed by an average rate of per day. Growth typically slows once the toads reach sexual maturity. This rapid growth is important for their survival; in the period between metamorphosis and subadulthood, the young toads lose the toxicity that protected them as eggs and tadpoles, but have yet to fully develop the parotoid glands that produce bufotoxin. Because they lack this key defence, only an estimated 0.5% of cane toads reach adulthood.
As with rates of growth, the point at which the toads become sexually mature varies across different regions. In New Guinea, sexual maturity is reached by female toads with a snout–vent length between , while toads in Panama achieve maturity when they are between in length. In tropical regions, such as their native habitats, breeding occurs throughout the year, but in subtropical areas, breeding occurs only during warmer periods that coincide with the onset of the wet season.
The cane toad is estimated to have a critical thermal maximum of and a minimum of around . The ranges can change due to adaptation to the local environment. The cane toad has a high tolerance to water loss; some can withstand a 52.6% loss of body water, allowing them to survive outside tropical environments.
Most frogs identify prey by movement, and vision appears to be the primary method by which the cane toad detects prey; however, it can also locate food using its sense of smell. They eat a wide range of material; in addition to the normal prey of small rodents, reptiles, other amphibians, birds, and even bats and a range of invertebrates, they also eat plants, dog food, and household refuse.
The skin of the adult cane toad is toxic, as well as the enlarged parotoid glands behind the eyes, and other glands across its back. When the toad is threatened, its glands secrete a milky-white fluid known as bufotoxin. Components of bufotoxin are toxic to many animals; even human deaths have been recorded due to the consumption of cane toads. Dogs are especially prone to be poisoned by licking or biting toads. Pets showing excessive drooling, extremely red gums, head-shaking, crying, loss of coordination, and/or convulsions require immediate veterinary attention.
Bufotenin, one of the chemicals excreted by the cane toad, is classified as a schedule 9 drug under Australian law, alongside heroin and LSD. The effects of bufotenin are thought to be similar to those of mild poisoning; the stimulation, which includes mild hallucinations, lasts less than an hour. As the cane toad excretes bufotenin in small amounts, and other toxins in relatively large quantities, toad licking could result in serious illness or death.
In addition to releasing toxin, the cane toad is capable of inflating its lungs, puffing up, and lifting its body off the ground to appear taller and larger to a potential predator.
Since 2011, experimenters in the Kimberley region of Western Australia have used poisonous sausages containing toad meat to try to protect native animals from cane toads' deadly impact. The Western Australian Department of Environment and Conservation, along with the University of Sydney, developed baits to train native animals not to eat the toads. By blending bits of toad with a nausea-inducing chemical, the baits train the animals to stay away from the amphibians.
Many species prey on the cane toad and its tadpoles in its native habitat, including the broad-snouted caiman ("Caiman latirostris"), the banded cat-eyed snake ("Leptodeira annulata"), eels (family Anguillidae), various species of killifish, the rock flagtail ("Kuhlia rupestris"), some species of catfish (order Siluriformes), some species of ibis (subfamily Threskiornithinae), and "Paraponera clavata" (bullet ants).
Predators outside the cane toad's native range include the whistling kite ("Haliastur sphenurus"), the rakali ("Hydromys chrysogaster"), the black rat ("Rattus rattus") and the water monitor ("Varanus salvator"). The tawny frogmouth ("Podargus strigoides") and the Papuan frogmouth ("Podargus papuensis") have been reported as feeding on cane toads; some Australian crows ("Corvus" spp.) have also learned strategies allowing them to feed on cane toads, such as using their beak to flip toads onto their backs. Rakalis have been observed eating the hearts and livers of the toads, where the toads have moved into their territory.
Opossums of the genus "Didelphis" likely can eat cane toads with impunity. Meat ants are unaffected by the cane toads' toxins, so are able to kill them. The cane toad's normal response to attack is to stand still and let its toxin kill the attacker, which allows the ants to attack and eat the toad.
The cane toad is native to the Americas, and its range stretches from the Rio Grande Valley in South Texas to the central Amazon and southeastern Peru, and some of the continental islands near Venezuela (such as Trinidad and Tobago). This area encompasses both tropical and semiarid environments. The density of the cane toad is significantly lower within its native distribution than in places where it has been introduced. In South America, the density was recorded to be 20 adults per 100 m (109 yd) of shoreline, 1 to 2% of the density in Australia.
The cane toad has been introduced to many regions of the world—particularly the Pacific—for the biological control of agricultural pests. These introductions have generally been well documented, and the cane toad may be one of the most studied of any introduced species.
Before the early 1840s, the cane toad had been introduced into Martinique and Barbados, from French Guiana and Guyana. An introduction to Jamaica was made in 1844 in an attempt to reduce the rat population. Despite its failure to control the rodents, the cane toad was introduced to Puerto Rico in the early 20th century in the hope that it would counter a beetle infestation ravaging the sugarcane plantations. The Puerto Rican scheme was successful and halted the economic damage caused by the beetles, prompting scientists in the 1930s to promote it as an ideal solution to agricultural pests.
As a result, many countries in the Pacific region emulated the lead of Puerto Rico and introduced the toad in the 1930s. Introduced populations are in Australia, Florida, Papua New Guinea, the Philippines, the Ogasawara, Ishigaki Island and the Daitō Islands of Japan, most Caribbean islands, Fiji and many other Pacific islands, including Hawaii. Since then, the cane toad has become a pest in many host countries, and poses a serious threat to native animals.
Following the apparent success of the cane toad in eating the beetles threatening the sugarcane plantations of Puerto Rico, and the fruitful introductions into Hawaii and the Philippines, a strong push was made for the cane toad to be released in Australia to negate the pests ravaging the Queensland cane fields. As a result, 102 toads were collected from Hawaii and brought to Australia. Queensland's sugar scientists released the toad into cane fields in August 1935. After this initial release, the Commonwealth Department of Health decided to ban future introductions until a study was conducted into the feeding habits of the toad. The study was completed in 1936 and the ban lifted, when large-scale releases were undertaken; by March 1937, 62,000 toadlets had been released into the wild. The toads became firmly established in Queensland, increasing exponentially in number and extending their range into the Northern Territory and New South Wales. In 2010, one was found on the far western coast in Broome, Western Australia.
However, the toad was generally unsuccessful in reducing the targeted grey-backed cane beetles ("Dermolepida albohirtum"), in part because the cane fields provided insufficient shelter for the predators during the day, and in part because the beetles live at the tops of sugar cane—and cane toads are not good climbers. Since its original introduction, the cane toad has had a particularly marked effect on Australian biodiversity. The population of a number of native predatory reptiles has declined, such as the varanid lizards "Varanus mertensi", "V. mitchelli", and "V. panoptes", the land snakes "Pseudechis australis" and "Acanthophis antarcticus", and the crocodile species "Crocodylus johnstoni"; in contrast, the population of the agamid lizard "Amphibolurus gilberti"—known to be a prey item of "V. panoptes"—has increased.
The cane toad was introduced to various Caribbean islands to counter a number of pests infesting local crops. While it was able to establish itself on some islands, such as Barbados, Jamaica, and Puerto Rico, other introductions, such as in Cuba before 1900 and in 1946, and on the islands of Dominica and Grand Cayman, were unsuccessful.
The earliest recorded introductions were to Barbados and Martinique. The Barbados introductions were focused on the biological control of pests damaging the sugarcane crops, and while the toads became abundant, they have done even less to control the pests than in Australia. The toad was introduced to Martinique from French Guiana before 1944 and became established. Today, they reduce the mosquito and mole cricket populations. A third introduction to the region occurred in 1884, when toads appeared in Jamaica, reportedly imported from Barbados to help control the rodent population. While they had no significant effect on the rats, they nevertheless became well established. Other introductions include the release on Antigua—possibly before 1916, although this initial population may have died out by 1934 and been reintroduced at a later date— and Montserrat, which had an introduction before 1879 that led to the establishment of a solid population, which was apparently sufficient to survive the Soufrière Hills volcano eruption in 1995.
In 1920, the cane toad was introduced into Puerto Rico to control the populations of white grub ("Phyllophaga" spp.), a sugarcane pest. Before this, the pests were manually collected by humans, so the introduction of the toad eliminated labor costs. A second group of toads was imported in 1923, and by 1932, the cane toad was well established. The population of white grubs dramatically decreased, and this was attributed to the cane toad at the annual meeting of the International Sugar Cane Technologists in Puerto Rico. However, there may have been other factors. The six-year period after 1931—when the cane toad was most prolific, and the white grub had a dramatic decline—had the highest-ever rainfall for Puerto Rico. Nevertheless, the cane toad was assumed to have controlled the white grub; this view was reinforced by a "Nature" article titled "Toads save sugar crop", and this led to large-scale introductions throughout many parts of the Pacific.
The cane toad has been spotted in Carriacou and Dominica, the latter appearance occurring in spite of the failure of the earlier introductions. On September 8, 2013, the cane toad was also discovered on the island of New Providence in the Bahamas.
The cane toad was first introduced deliberately into the Philippines in 1930 as a biological control agent of pests in sugarcane plantations, after the success of the experimental introductions into Puerto Rico. It subsequently became the most ubiquitous amphibian in the islands. It still retains the common name of "bakî" or "kamprag" in the Visayan languages, a corruption of 'American frog', referring to its origins. It is also commonly known as "bullfrog" in Philippine English.
The cane toad was introduced into Fiji to combat insects that infested sugarcane plantations. The introduction of the cane toad to the region was first suggested in 1933, following the successes in Puerto Rico and Hawaii. After considering the possible side effects, the national government of Fiji decided to release the toad in 1953, and 67 specimens were subsequently imported from Hawaii. Once the toads were established, a 1963 study concluded, as the toad's diet included both harmful and beneficial invertebrates, it was considered "economically neutral". Today, the cane toad can be found on all major islands in Fiji, although they tend to be smaller than their counterparts in other regions.
The cane toad was introduced into New Guinea to control the hawk moth larvae eating sweet potato crops. The first release occurred in 1937 using toads imported from Hawaii, with a second release the same year using specimens from the Australian mainland. Evidence suggests a third release in 1938, consisting of toads being used for human pregnancy tests—many species of toad were found to be effective for this task, and were employed for about 20 years after the discovery was announced in 1948. Initial reports argued the toads were effective in reducing the levels of cutworms and sweet potato yields were thought to be improving. As a result, these first releases were followed by further distributions across much of the region, although their effectiveness on other crops, such as cabbages, has been questioned; when the toads were released at Wau, the cabbages provided insufficient shelter and the toads rapidly left the immediate area for the superior shelter offered by the forest. A similar situation had previously arisen in the Australian cane fields, but this experience was either unknown or ignored in New Guinea. The cane toad has since become abundant in rural and urban areas.
The cane toad naturally exists in South Texas, but attempts (both deliberate and accidental) have been made to introduce the species to other parts of the country. These include introductions to Florida and to the islands of Hawaii, as well as largely unsuccessful introductions to Louisiana.
Initial releases into Florida failed. Attempted introductions before 1936 and 1944, intended to control sugarcane pests, were unsuccessful as the toads failed to proliferate. Later attempts failed in the same way. However, the toad gained a foothold in the state after an accidental release by an importer at Miami International Airport in 1957, and deliberate releases by animal dealers in 1963 and 1964 established the toad in other parts of Florida. Today, the cane toad is well established in the state, from the Keys to north of Tampa, and they are gradually extending further northward. In Florida, the toad is a regarded as a threat to native species and pets; so much so, the Florida Fish and Wildlife Conservation Commission recommends residents to kill them.
Around 150 cane toads were introduced to Oahu in Hawaii in 1932, and the population swelled to 105,517 after 17 months. The toads were sent to the other islands, and more than 100,000 toads were distributed by July 1934; eventually over 600,000 were transported.
Other than the use as a biological control for pests, the cane toad has been employed in a number of commercial and noncommercial applications. Traditionally, within the toad's natural range in South America, the Embera-Wounaan would "milk" the toads for their toxin, which was then employed as an arrow poison. The toxins may have been used as an entheogen by the Olmec people. The toad has been hunted as a food source in parts of Peru, and eaten after the careful removal of the skin and parotoid glands. When properly prepared, the meat of the toad is considered healthy and as a source of omega-3 fatty acids. More recently, the toad's toxins have been used in a number of new ways: bufotenin has been used in Japan as an aphrodisiac and a hair restorer, and in cardiac surgery in China to lower the heart rates of patients. New research has suggested that the cane toad's poison may have some applications in treating prostate cancer.
Other modern applications of the cane toad include pregnancy testing, as pets, laboratory research, and the production of leather goods. Pregnancy testing was conducted in the mid-20th century by injecting urine from a woman into a male toad's lymph sacs, and if spermatozoa appeared in the toad's urine, the patient was deemed to be pregnant. The tests using toads were faster than those employing mammals; the toads were easier to raise, and, although the initial 1948 discovery employed "Bufo arenarum" for the tests, it soon became clear that a variety of anuran species were suitable, including the cane toad. As a result, toads were employed in this task for around 20 years. As a laboratory animal, the cane toad is regarded as ideal; they are plentiful, and easy and inexpensive to maintain and handle. The use of the cane toad in experiments started in the 1950s, and by the end of the 1960s, large numbers were being collected and exported to high schools and universities. Since then, a number of Australian states have introduced or tightened importation regulations. Even dead toads have value. Cane toad skin has been made into leather and novelty items; stuffed cane toads, posed and accessorised, have found a home in the tourist market, and attempts have been made to produce fertiliser from their bodies.
Cane toads pose a serious threat to native species when introduced to a new ecosystem. Classified as an invasive species in over 20 countries, multiple reports exist of the cane toad moving into a new area to be followed by a decline in the biodiversity in that region. The most documented region of the cane toad's invasion and subsequent effect on native species is Australia, where multiple surveys and observations of the toad's conquest have been completed. The best way to illustrate this effect is through the plight of the northern quoll, as well as Mertens' water monitor, a large lizard native to South and Southeast Asia.
Two sites were chosen to study the effects of cane toads on the northern quoll, one of which was at Mary River ranger station, which is located in the southern region of Kakadu National Park. The other site was located at the north end of the park. In addition to these two sites, a third site was located at the East Alligator ranger station, and this site was used as a control site, where the cane toads would not interact with the northern quoll population. Monitoring of the quoll population began at the Mary River ranger station using radio tracking in 2002, months before the first cane toads arrived at the site. After the arrival of the cane toads, the population of northern quolls in the Mary River site plummeted between October and December 2002, and by March 2003, the northern quoll appeared to be extinct in this section of the park, as no northern quolls were caught in the trapping trips in the following two months. In contrast, the population of northern quolls in the control site at the East Alligator ranger station remained relatively constant, not showing any symptoms of declining. The evidence from the Kakadu National Park is compelling not only because of the timing of the population of northern quolls plummeting just months after the arrival of the cane toad, but also because in the Mary River region 31% of mortalities within the quoll population were attributed to lethal toxic ingestion, as no signs of disease, parasite infestation, or any other obvious changes at the site were found that could have caused such a rapid decline. The most obvious evidence that supports the hypothesis that the invasion of the cane toads caused the local extinction of the northern quoll is that the closely monitored population of the control group, in the absence of cane toads, showed no signs of decline.
In the case of Mertens' water monitor, only one region was monitored, but over the course of 18 months. This region is located 70 km south of Darwin, at the Manton Dam Recreation Area. Within the Manton Dam Recreation Area, 14 sites were set up to survey the population of water monitors, measuring abundance and site occupancy at each one. Seven surveys were conducted, each of which ran for 4 weeks and included 16 site visits, where each site was sampled twice per day for 2 consecutive days throughout the 4 weeks. Each site visit occurred between 7:30 and 10:30 am, and 4:00–7:00 pm, when "Varanus mertensi" can be viewed sunbathing on the shore or wrapped around a tree branch close to shore. The whole project lasted from December 2004 to May 2006, and had a total of 194 sightings of "Varanus mertensi" in 1568 site visits. Of the seven surveys, abundance was highest during the second survey, which took place in February 2005, 2 months into the project. Following this measurement, the abundance declined in the next four surveys, before declining sharply after the second to last survey in February 2006. In the final survey taken in May 2006, only two "V. mertensi" lizards were observed. Cane toads were first recorded in the region of study during the second survey during February 2005, also when the water monitor abundance was at its highest over the course of the study. Numbers of the cane toad population stayed low for the next year after introduction, and then skyrocketed to its peak in the last survey during May 2006. When compared, the two populations side by side clearly show that the onset of the cane toads had an immediate negative impact on the monitors, as their population began to drop in February 2005, which was when the first cane toads entered the Manton Dam Recreation Area. At the end of the study, some scattered populations of water monitors remained in the upper sites of the Manton Dam, which suggests that local extinctions occurred at certain shoreline sites within Manton Dam, but a complete extinction of the population did not occur.
Notes
Bibliography

</doc>
<doc id="6643" url="https://en.wikipedia.org/wiki?curid=6643" title="Croquet">
Croquet

Croquet (; (UK) or (US)) is a sport that involves hitting wooden or plastic balls with a mallet through hoops (often called "wickets" in the United States) embedded in a grass playing court.
The oldest document to bear the word "croquet" with a description of the modern game is the set of rules registered by Isaac Spratt in November 1856 with the Stationers' Company in London. This record is now in the Public Record Office. In 1868, the first croquet all-comers meet was held at Moreton-in-Marsh, Gloucestershire and in the same year the All England Croquet Club was formed at Wimbledon, London.
Regardless when and by what route it reached England and the British colonies in its recognizable form, croquet is, like golf, pall-mall, trucco, and kolven, among the later forms of ground billiards, which as a class have been popular in Western Europe back to at least the Late Middle Ages, with roots in classical antiquity, including sometimes the use of arches and pegs along with balls and mallets or other striking sticks (some more akin to modern field hockey sticks). By the 12th century, a team ball game called ' or ', akin to a chaotic version of hockey or football (depending on whether sticks were used), was regularly played in France and southern Britain between villages or parishes; it was attested in Cornwall as early as 1283.
In the book "Queen of Games: The History of Croquet", Nicky Smith presents two theories of the origin of the modern game of croquet, which took England by storm in the 1860s and then spread overseas.
The first explanation is that the ancestral game was introduced to Britain from France during the 1660–1685 reign of Charles II of England, Scotland and Ireland, and was played under the name of ' (among other spellings, today usually "pall-mall"), derived ultimately from Latin words for 'ball and mallet' (the latter also found in the name of the earlier French game, '). This was the explanation given in the ninth edition of "Encyclopædia Britannica", dated 1877.
In his 1810 book "The Sports and Pastimes of the People of England", Joseph Strutt described the way pall-mall was played in England at the time:"Pale-maille is a game wherein a round box[wood] ball is struck with a mallet through a high arch of iron, which he that can do at the fewest blows, or at the number agreed upon, wins. It is to be observed, that there are two of these arches, that is one at either end of the alley. The game of mall was a fashionable amusement in the reign of Charles the Second, and the walk in Saint James's Park, now called the Mall, received its name from having been appropriated to the purpose of playing at mall, where Charles himself and his courtiers frequently exercised themselves in the practice of this pastime."
While the name "pall-mall" and various games bearing this name also appeared elsewhere (France and Italy), the description above suggests that the croquet-like games in particular were popular in England by the early 17th century. Some other early modern sources refer to pall-mall being played over a large distance (as in golf); however, an image in Strutt's 1801 book shows a croquet-like ground billiards game (balls on ground, hoop, bats, and peg) being played over a , garden-sized distance. The image's caption describes the game as "a curious ancient pastime", confirming that croquet games were not new in early-19th-century England.
In Samuel Johnson's 1755 dictionary, his definition of "pall-mall" clearly describes a game with similarities to modern croquet: "A play in which the ball is struck with a mallet through an iron ring". However, there is no evidence that pall-mall involved the croquet stroke which is the distinguishing characteristic of the modern game.
The second theory is that the rules of the modern game of croquet arrived from Ireland during the 1850s, perhaps after being brought there from Brittany, where a similar game was played on the beaches. Regular contact between Ireland and France had continued since the Norman invasion of Ireland in 1169. By no later than the early 15th century, the game " (itself ancestral to pall-mall and perhaps to indoor billiards) was popular in France, including in the courts of Henry II in the 16th century and Louis XIV of the 17th.
At least one version of it, " ('wheel') was a multi-ball lawn game. Records show a game called "crookey", similar to croquet, being played at Castlebellingham in County Louth, Ireland, in 1834, which was introduced to Galway in 1835 and played on the bishop's palace garden, and in the same year to the genteel Dublin suburb of Kingstown (today Dún Laoghaire) where it was first spelt as "croquet". There is, however, no pre-1858 Irish document that describes the way game was played, in particular there is no reference to the distinctive croquet stroke, which is described below under "Variations: Association". The noted croquet historian Dr Prior, in his book of 1872, makes the categoric statement "One thing only is certain: it is from Ireland that croquet came to England and it was on the lawn of the late Lord Lonsdale that it was first played in this country." This was about 1851.
John Jaques apparently claimed in a letter to Arthur Lillie in 1873 that he had himself seen the game played in Ireland, writing "I made the implements and published directions (such as they were) before Mr. Spratt [mentioned above] introduced the subject to me." Whatever the truth of the matter, Jaques certainly played an important role in popularising the game, producing editions of the rules in 1857, 1860, and 1864.
Croquet became highly popular as a social pastime in England during the 1860s. It was enthusiastically adopted and promoted by the Earl of Essex who held lavish croquet parties at Cassiobury House, his stately home in Watford, Hertfordshire, and the Earl even launched his own "Cassiobury" brand croquet set. By 1867, Jaques had printed 65,000 copies of his "Laws and Regulations" of the game. It quickly spread to other Anglophone countries, including Australia, Canada, New Zealand, South Africa, and the United States. No doubt one of the attractions was that the game could be played by both sexes; this also ensured a certain amount of adverse comment.
By the late 1870s, however, croquet had been eclipsed by another fashionable game, lawn tennis, and many of the newly created croquet clubs, including the All England Club at Wimbledon, converted some or all of their lawns into tennis courts.
There was a revival in the 1890s, but from then onwards, croquet was always a minority sport, with national individual participation amounting to a few thousand players. The All England Lawn Tennis and Croquet Club still has a croquet lawn, but has not hosted any significant tournaments. The English headquarters for the game is now in Cheltenham.
The earliest known reference to croquet in Scotland is the booklet "The Game of Croquet, its Laws and Regulations" which was published in the mid-1860s for the proprietor of Eglinton Castle, the Earl of Eglinton. On the page facing the title page is a picture of Eglinton Castle with a game of "croquet" in full swing.
The croquet lawn existed on the northern terrace, between Eglinton Castle and the Lugton Water. The 13th Earl developed a variation on croquet named Captain Moreton's Eglinton Castle croquet, which had small bells on the eight hoops "to ring the changes", two pegs, a double hoop with a bell and two tunnels for the ball to pass through. In 1865 the 'Rules of the Eglinton Castle and Cassiobury Croquet' was published by Edmund Routledge. Several incomplete sets of this form of croquet are known to exist, and one complete set is still used for demonstration games in the West of Scotland.
There are several variations of croquet currently played, differing in the scoring systems, order of shots, and layout (particularly in social games where play must be adapted to smaller-than-standard playing courts). Two forms of the game, association croquet and golf croquet, have rules that are agreed internationally and are played in many countries around the world. The United States has its own set of rules for domestic games. Gateball, a sport originated in Japan under the influence of croquet, is played mainly in East and Southeast Asia and the Americas, and can also be regarded as a croquet variant.
As well as club-level games, there are regular world championships and international matches between croquet-playing countries. The sport has particularly strong followings in the UK, US, New Zealand and Australia; every four years, these countries play the MacRobertson Shield tournament. Many other countries also play. The current world rankings show England in top place for association croquet, followed by Australia and New Zealand sharing second place, with the United States in fourth position; the same four countries appear in the top six of the golf croquet league table, below Egypt in top position, and with South Africa at number five.
Croquet is popularly believed to be viciously competitive. This may derive from the fact that (unlike in golf) players will often attempt to move their opponents' balls to unfavourable positions. However, purely negative play is rarely a winning strategy: successful players (in all versions other than golf croquet) will use all four balls to set up a break for themselves, rather than simply making the game as difficult as possible for their opponents. At championship-standard association croquet, players can often make all 26 points (13 for each ball) in two turns.
Croquet was an event at the 1900 Summer Olympics. Roque, an American variation on croquet, was an event at the 1904 Summer Olympics.
Association croquet is the name of an advanced game of croquet, played at all levels up to international level. It involves four balls teamed in pairs, with both balls going through every hoop for one pair to win. The game's distinguishing feature is the "croquet" shot: when certain balls hit other balls, extra shots are allowed. The six hoops are arranged three at each end of the court, with a centre peg.
One side takes the black and blue balls, the other takes red and yellow. At each turn, players can choose to play with either of their balls for that turn. At the start of a turn, the player plays a stroke. If the player either hits the ball through the correct hoop ("runs" the hoop), or hits another ball (a "roquet"), the turn continues.
Following a roquet, the player picks up his or her own ball and puts it down next to the ball that it hit. The next shot is played with the two balls touching: this is the "croquet stroke" from which the game takes its name. By varying the speed and angle at which the mallet hits the striker's ball, a good player can control the final position of both balls: the horizontal angle determines how far the balls diverge in direction, while the vertical angle and the amount of follow-through determine the relative distance that the two balls travel.
After the croquet stroke, the player plays a "continuation" stroke, during which the player may again attempt to make a roquet or run a hoop. Each of the other three balls may be roqueted once in a turn before a hoop is run, after which they become available to be roqueted again.
The winner of the game is the team who completes the set circuit of six hoops (and then back again the other way), with both balls, and then strikes the centre peg (making a total of 13 points per ball = 26).
Good players may make "s" or "s" of several hoops in a single turn. The best players may take a ball round a full circuit in one turn. "Advanced play" (a variant of association play for expert players) gives penalties to a player who runs certain hoops in a turn, to allow the opponent a chance of getting back into the game; feats of skill such as triple peels or better, in which the partner ball (or occasionally an opponent ball) is caused to run a number of hoops in a turn by the striker's ball, help avoid these penalties.
A handicap system ("bisques") provides less experienced players a chance of winning against more formidable opponents. Players of all ages and both sexes compete on level terms.
The World Championships are organised by the World Croquet Federation (WCF) and usually take place every two or three years. The 2018 championships took place in Wellington, New Zealand; the winner was Paddy Chapman of New Zealand. The current Women's Association Croquet World Champion (2015) is Miranda Chapman of England. Paddy and Miranda are married.
The Australian team won the last MacRobertson International Croquet Shield tournament, which is the major international test tour trophy in association croquet. It is contested every three to four years between Australia, Britain, the United States and New Zealand. Historically the British have been the dominant force, winning 14 out of the 22 times that the event has been held. In individual competition, the UK is often divided by subnational country (England, Scotland and Wales), while Northern Ireland joins with the republic in an All Ireland association (as it does in several other sports).
The world's top 10 association croquet players as of February 2018 were Robert Fletcher (Australia), Reg Bamford (South Africa), Robert Fulford (England), Paddy Chapman (New Zealand), Ben Rothman (USA), Malcolm Fletcher (Australia), Jamie Burch (England), Jose Riva (Spain), Stephen Mulliner (England), Greg Bryant (New Zealand).
Unlike most sports, men and women compete and are ranked together. Three women have won the British Open Championship: Lily Gower in 1905, Dorothy Steel in 1925, 1933, 1935 and 1936, and Hope Rotherham in 1960. While male players are in the majority at club level in the UK, the opposite is the case in Australia and New Zealand.
The governing body in England is The Croquet Association, which has been the driving force of the development of the game. The rules and tournament regulations are now maintained by the International Laws Committee, established by the croquet associations of England and Wales (CA), Australia (ACA), New Zealand (CNZ) and the United States (USCA).
In golf croquet, a hoop is won by the first ball to go through each hoop. Unlike association croquet, there are no additional turns for hitting other balls.
Each player takes a stroke in turn, each trying to hit a ball through the same hoop. The sequence of play is blue, red, black, yellow. Blue and black balls play against red and yellow. When a hoop is won, the sequence of play continues as before. The winner of the game is the player/team who wins the most hoops.
Golf croquet is the fastest-growing version of the game, owing largely to its simplicity and competitiveness. There is an especially large interest with competitive success by players in Egypt. Golf croquet is easier to learn and play, but requires strategic skills and accurate play. In comparison with association croquet, play is faster and balls are more likely to be lifted off the ground.
In April 2013, Reg Bamford of South Africa beat Ahmed Nasr of Egypt in the final of the Golf Croquet World Championship in Cairo, becoming the first person to simultaneously hold the title in both association croquet and golf croquet. As of 2017, the Golf Croquet World Champion was Reg Bamford (South Africa) and the Women's Golf Croquet World Champion was Judith Hanekom (South Africa).
In 2018, two international championships open to both sexes were won by women: in May, Rachel Gee of England beat Pierre Beaudry to win the European Golf Croquet championship, and in October, Hanan Rashad of Egypt beat Yasser Fathy (also from Egypt) to win the World over-50s Golf Croquet championship.
Garden croquet is widely played in the UK. The rules are easy to learn and the game can be played on lawns of almost any size but usually around by . The rules are similar to those described above for Association Croquet with three major differences:
This version of the game is easy for beginners to learn. The main Garden Croquet Club in the UK is the Bygrave Croquet Club which is a private club with five lawns. Other clubs also use garden croquet as an introduction to the game, notably the Hampstead Heath Croquet Club and the Watford Croquet Club.
The American-rules version of croquet, another six-hoop game, is the dominant version of the game in the United States and is also widely played in Canada. It is governed by the United States Croquet Association. Its genesis is mostly in association croquet, but it differs in a number of important ways that reflect the home-grown traditions of American "backyard" croquet.
Two of the most notable differences are that the balls are always played in the same sequence (blue, red, black, yellow) throughout the game, and that a ball's "deadness" on other balls is carried over from turn to turn until the ball has been "cleared" by scoring its next hoop. A Deadness Board is used to keep track of deadness on all four balls. Tactics are simplified on the one hand by the strict sequence of play, and complicated on the other hand by the continuation of deadness. A further difference is the more restrictive boundary-line rules of American croquet.
In the American game, roqueting a ball out of bounds or running a hoop out of bounds causes the turn to end, and balls that go out of bounds are replaced only from the boundary rather than as in association croquet. "Attacking" balls on the boundary line to bring them into play is thus far more challenging.
Nine-wicket croquet, sometimes called "backyard croquet", is played mainly in Canada and the United States, and is the game most recreational players in those countries call simply "croquet". In this version of croquet there are nine wickets, two stakes, and up to six balls. The course is arranged in a double-diamond pattern, with one stake at each end of the course. Players start at one stake, navigate one side of the double diamond, hit the turning stake, then navigate the opposite side of the double diamond and hit the starting stake to end. If playing individually ("Cutthroat"), the first player to stake out is the winner. In partnership play, all members of a team must stake out, and a player might choose to avoid staking out (becoming a "Rover") in order to help a lagging teammate.
Each time a ball is roqueted, the striker gets two bonus shots.
For the first bonus shot, the player has four options:
The second bonus shot ("continuation shot") is an ordinary shot played from where the striker ball came to rest.
An alternate endgame is "poison": in this variant, a player who has scored the last wicket but not hit the starting stake becomes a "poison ball", which may eliminate other balls from the game by roqueting them. A non-poison ball that roquets a poison ball has the normal options. A poison ball that hits a stake or passes through any wicket (possibly by the action of a non-poison player) is eliminated. The last person remaining is the winner.
This version of the game was invented by John Riches of Adelaide, Australia with help from Tom Armstrong in the 1980s. The game can be played by up to six people and is very easy to learn. For this reason it is often used as a stepping stone to association croquet.
Ricochet has similar rules to association and garden croquet, except that when a ball is roqueted, the striker's ball remains live and two free shots are earned. This enables strikers to play their ball near to another opponent ball and ricochet that too thus earning two more free shots. Running a hoop earns one free shot.
One-ball croquet has become popular in recent years as a way of bringing AC (association) and GC (golf) players together. The rules are essentially
those of association croquet, except that each player/team has only one ball rather than two. This makes it very hard to create a break, which leads to more interactive play.
The way croquet is depicted in paintings and books says much about popular perceptions of the game, though little about the reality of modern play.
About 200 croquet clubs across the United States are members of the United States Croquet Association.
Many colleges have croquet clubs as well, such as The University of Virginia, The University of Chicago, Pennsylvania State University, Bates College, SUNY New Paltz, Harvard University, and Dartmouth College. Notably, St. John's College and the US Naval Academy engage in a yearly match in Annapolis, Maryland. Both schools also compete at the collegiate level and the rivalry continues to be an Annapolis tradition, attracting thousands of spectators each April.
In England and Wales, there are around 170 clubs affiliated with the Croquet Association. The All England Lawn Tennis and Croquet Club at Wimbledon is famous for its lawn tennis tournament, but retains an active croquet section. There are also clubs in many universities and colleges, with an annual Varsity match being played between Oxford and Cambridge. With over 1800 participants, the 2011 Oxford University "Cuppers" (inter-college) tournament claimed to be not only the largest croquet tournament ever, but the largest sporting event in the university's history.

</doc>
<doc id="6644" url="https://en.wikipedia.org/wiki?curid=6644" title="Curling">
Curling

Curling is a sport in which players slide stones on a sheet of ice toward a target area which is segmented into four concentric circles. It is related to bowls, boules and shuffleboard. Two teams, each with four players, take turns sliding heavy, polished granite stones, also called "rocks", across the ice "curling sheet" toward the "house", a circular target marked on the ice. Each team has eight stones, with each player throwing two. The purpose is to accumulate the highest score for a "game"; points are scored for the stones resting closest to the centre of the house at the conclusion of each "end", which is completed when both teams have thrown all of their stones. A game usually consists of eight or ten ends.
The player can induce a curved path, described as "curl", by causing the stone to slowly turn as it slides. The path of the rock may be further influenced by two sweepers with brooms or brushes, who accompany it as it slides down the sheet and sweep the ice in front of the stone. "Sweeping a rock" decreases the friction, which makes the stone travel a straighter path (with less "curl") and a longer distance. A great deal of strategy and teamwork go into choosing the ideal path and placement of a stone for each situation, and the skills of the curlers determine the degree to which the stone will achieve the desired result. This gives curling its nickname of "chess on ice".
Evidence that curling existed in Scotland in the early 16th century includes a curling stone inscribed with the date 1511 found (along with another bearing the date 1551) when an old pond was drained at Dunblane, Scotland. The world's oldest curling stone and the world's oldest football are now kept in the same museum (the Stirling Smith Art Gallery and Museum) in Stirling. The first written reference to a contest using stones on ice coming from the records of Paisley Abbey, Renfrewshire, in February 1541. Two paintings, "" and "The Hunters in the Snow" (both dated 1565) by Pieter Bruegel the Elder depict Flemish peasants curling, albeit without brooms; Scotland and the Low Countries had strong trading and cultural links during this period, which is also evident in the history of golf.
The word "curling" first appears in print in 1620 in Perth, Scotland, in the preface and the verses of a poem by Henry Adamson. The sport was (and still is, in Scotland and Scottish-settled regions like southern New Zealand) also known as "the roaring game" because of the sound the stones make while traveling over the "pebble" (droplets of water applied to the playing surface). The verbal noun "curling" is formed from the Scots (and English) verb "curl", which describes the motion of the stone.
Kilsyth Curling Club claims to be the first club in the world, having been formally constituted in 1716; it is still in existence today. Kilsyth also claims the oldest purpose-built curling pond in the world at Colzium, in the form of a low dam creating a shallow pool some in size. The International Olympic Committee recognises the Royal Caledonian Curling Club (founded as the Grand Caledonian Curling Club in 1838) as developing the first official rules for the sport.
In the early history of curling, the playing stones were simply flat-bottomed stones from rivers or fields, which lacked a handle and were of inconsistent size, shape and smoothness. Some early stones had holes for a finger and the thumb, akin to ten-pin bowling balls. Unlike today, the thrower had little control over the 'curl' or velocity and relied more on luck than on precision, skill and strategy. The sport was often played on frozen rivers although purpose-built ponds were later created in many Scottish towns. For example, the Scottish poet David Gray describes whisky-drinking curlers on the Luggie Water at Kirkintilloch.
In Darvel, East Ayrshire, the weavers relaxed by playing curling matches using the heavy stone weights from the looms' "warp beams", fitted with a detachable handle for the purpose. Many a wife would keep her husband's brass curling stone handle on the mantelpiece, brightly polished until the next time it was needed. Central Canadian curlers often used 'irons' rather than stones until the early 1900s; Canada is the only country known to have done so, while others experimented with wood or ice-filled tins.
Outdoor curling was very popular in Scotland between the 16th and 19th centuries because the climate provided good ice conditions every winter. Scotland is home to the international governing body for curling, the World Curling Federation in Perth, which originated as a committee of the Royal Caledonian Curling Club, the mother club of curling.
Today, the sport is most firmly established in Canada, having been taken there by Scottish emigrants. The Royal Montreal Curling Club, the oldest established sports club still active in North America, was established in 1807. The first curling club in the United States was established in 1830, and the sport was introduced to Switzerland and Sweden before the end of the 19th century, also by Scots. Today, curling is played all over Europe and has spread to Brazil, Japan, Australia, New Zealand, China, and Korea.
The first world championship for curling was limited to men and was known as the "Scotch Cup", held in Falkirk and Edinburgh, Scotland, in 1959. The first world title was won by the Canadian team from Regina, Saskatchewan, skipped by Ernie Richardson. (The "skip" is the team member who calls the shots; see below.)
Curling was one of the first sports that was popular with women and girls.
Curling has been a medal sport in the Winter Olympic Games since the 1998 Winter Olympics. It currently includes men's, women's and mixed doubles tournaments (the mixed doubles event was held for the first time in 2018).
In February 2002, the International Olympic Committee retroactively decided that the curling competition from the 1924 Winter Olympics (originally called "Semaine des Sports d'Hiver", or International Winter Sports Week) would be considered official Olympic events and no longer be considered demonstration events. Thus, the first Olympic medals in curling, which at the time was played outdoors, were awarded for the 1924 Winter Games, with the gold medal won by Great Britain, two silver medals by Sweden, and the bronze by France. A demonstration tournament was also held during the 1932 Winter Olympic Games between four teams from Canada and four teams from the United States, with Canada winning 12 games to 4.
Since the sport's official addition in the 1998 Olympics, Canada has dominated the sport with their men's teams winning gold in 2006, 2010, and 2014, and silver in 1998 and 2002. The women's team won gold in 1998 and 2014, a silver in 2010, and a bronze in 2002 and 2006. The mixed doubles team won gold in 2018.
The playing surface or "curling sheet" is defined by the World Curling Federation Rules of Curling. It is a rectangular area of ice, carefully prepared to be as flat and level as possible, in length by in width. The shorter borders of the sheet are called the backboards. Because of the elongated shape, several sheets may be laid out side by side in the same arena, allowing multiple games to be played simultaneously.
A target, the "house", is centred on the intersection of the "centre line", drawn lengthwise down the centre of the sheet and the "tee line", drawn from, and parallel to, the backboard. These lines divide the house into quarters. The house consists of a centre circle (the "button") and three concentric rings, of diameters 4, 8 and 12 feet, formed by painting or laying coloured vinyl sheet under the ice and are usually distinguished by colour. A stone must at least touch the outer ring in order to score (see Scoring below); otherwise the rings are merely a visual aid for aiming and judging which stone is closer to the button.
Two "hog lines" are drawn from, and parallel to, the backboard.
The "hacks", which give the thrower something to push against when making the throw, are fixed behind each button. On indoor rinks, there are usually two fixed hacks, rubber-lined holes, one on each side of the centre line, with the inside edge no more than from the centre line and the front edge on the hack line. A single moveable hack may also be used.
The ice may be natural but is usually frozen by a refrigeration plant pumping a brine solution through numerous pipes fixed lengthwise at the bottom of a shallow pan of water. Most curling clubs have an ice maker whose main job is to care for the ice. At the major curling championships, ice maintenance is extremely important. Large events, such as national/international championships, are typically held in an arena that presents a challenge to the ice maker, who must constantly monitor and adjust the ice and air temperatures as well as air humidity levels to ensure a consistent playing surface. It is common for each sheet of ice to have multiple sensors embedded in order to monitor surface temperature, as well as probes set up in the seating area (to monitor humidity) and in the compressor room (to monitor brine supply and return temperatures). The surface of the ice is maintained at a temperature of around .
A key part of the preparation of the playing surface is the spraying of water droplets onto the ice, which form "pebble" on freezing. The pebbled ice surface resembles an orange peel, and the stone moves on top of the pebbled ice. The pebble, along with the concave bottom of the stone, decreases the friction between the stone and the ice, allowing the stone to travel farther. As the stone moves over the pebble, any rotation of the stone causes it to "curl", or travel along a curved path. The amount of curl (commonly referred to as the "feet of curl") can change during a game as the pebble wears; the ice maker must monitor this and be prepared to scrape and re-pebble the surface prior to each game.
The curling stone (also sometimes called a "rock" in North America) is made of granite and is specified by the World Curling Federation, which requires a weight between , a maximum circumference of and a minimum height of . The only part of the stone in contact with the ice is the "running surface", a narrow, flat annulus or ring, wide and about in diameter; the sides of the stone bulge convex down to the ring and the inside of the ring is hollowed concave to clear the ice. This concave bottom was first proposed by J. S. Russell of Toronto, Ontario, Canada sometime after 1870, and was subsequently adopted by Scottish stone manufacturer Andrew Kay.
The granite for the stones comes from two sources: Ailsa Craig, an island off the Ayrshire coast of Scotland, and the Trefor Granite Quarry in Wales.
Ailsa Craig is the traditional source and produces two types of granite, "Blue Hone" and "Ailsa Craig Common Green". "Blue Hone" has very low water absorption, which prevents the action of repeatedly freezing water from eroding the stone. "Ailsa Craig Common Green" is a lesser quality granite than "Blue Hone". In the past, most curling stones were made from "Blue Hone" but the island is now a wildlife reserve and the quarry is restricted by environmental conditions that exclude blasting.
Kays of Scotland has been making curling stones in Mauchline, Ayrshire, since 1851 and has the exclusive rights to the Ailsa Craig granite, granted by the Marquess of Ailsa, whose family has owned the island since 1560. According to the 1881 Census, Andrew Kay employed 30 people in his curling stone factory in Mauchline. The last harvest of Ailsa Craig granite by Kays took place in 2013, after a hiatus of 11 years; 2,000 tons were harvested, sufficient to fill anticipated orders through at least 2020. Kays have been involved in providing curling stones for the Winter Olympics since Chamonix in 1924 and has been the exclusive manufacturer of curling stones for the Olympics since the 2006 Winter Olympics.
"Trefor" granite comes from the Yr Eifl or Trefor Granite Quarry in the village of Trefor on the north coast of the Llŷn Peninsula in Gwynedd, Wales and has produced granite since 1850. "Trefor" granite comes in shades of pink, blue and grey. The quarry supplies curling stone granite exclusively to the Canada Curling Stone Company, which has been producing stones since 1992 and supplied the stones for the 2002 Winter Olympics.
A handle is attached by a bolt running vertically through a hole in the centre of the stone. The handle allows the stone to be gripped and rotated upon release; on properly prepared ice the rotation will bend ("curl") the path of the stone in the direction in which the front edge of the stone is turning, especially as the stone slows. Handles are coloured to identify each team, two popular colours in major tournaments being red and yellow.
In competition, an electronic handle known as the "eye on the hog" may be fitted to detect hog line violations. This electronically detects whether the thrower's hand is in contact with the handle as it passes the hog line and indicates a violation by lights at the base of the handle (see "delivery" below). The "eye on the hog" eliminates human error and the need for hog line officials. It is mandatory in high-level national and international competition, but its cost, around US$650 each, currently puts it beyond the reach of most curling clubs.
The "curling broom", or "brush", is used to sweep the ice surface in the path of the stone (see "sweeping") and is also often used as a balancing aid during delivery of the stone.
Prior to the 1950s, most curling brooms were made of corn strands and were similar to household brooms of the day. In 1958, Fern Marchessault of Montreal inverted the corn straw in the centre of the broom. This style of corn broom was referred to as "the Blackjack".
Artificial brooms made from man-made fabrics rather than corn, such as the "Rink Rat", also became common later during this time period. Prior to the late sixties, "Scottish" curling brushes were used primarily by some of the Scots, as well as by recreational and elderly curlers, as a substitute for corn brooms, since the technique was easier to learn. In the late sixties, competitive curlers from Calgary, Alberta, such as John Mayer, Bruce Stewart, and, later, the world junior championship teams skipped by Paul Gowsell, proved that the curling brush could be just as (or more) effective without all the blisters common to corn broom use. During that time period, there was much debate in competitive curling circles as to which sweeping device was more effective: brush or broom. Eventually, the brush won out with the majority of curlers making the switch to the less costly and more efficient brush. Today, brushes have replaced traditional corn brooms at every level of curling; it is rare now to see a curler using a corn broom on a regular basis.
Curling brushes may have fabric, hog hair, or horsehair heads. Modern curling brush handles are usually hollow tubes made of fibreglass or carbon fibre instead of a solid length of wooden dowel. These hollow tube handles are lighter and stronger than wooden handles, allowing faster sweeping and also enabling more downward force to be applied to the broom head with reduced shaft flex. New, "directional fabric" brooms, which players are worried will alter the fundamentals of the sport by reducing the level of skill required, have been accused of giving players an unfair advantage. The new brooms were temporarily banned by the World Curling Federation and Curling Canada for the 2015–2016 season. The new brooms give sweepers unprecedented control over the direction the stone goes.
Curling shoes are similar to ordinary athletic shoes except for special soles; the "slider shoe" (usually known as a "slider") is designed for the sliding foot and the "gripper shoe" (usually known as a "gripper") for the foot that kicks off from the hack.
The "slider" is designed to slide and typically has a Teflon sole. It is worn by the thrower during delivery from the hack and by sweepers or the skip to glide down the ice when sweeping or otherwise traveling down the sheet quickly. Stainless steel and "red brick" sliders with lateral blocks of PVC on the sole are also available as alternatives to Teflon. Most shoes have a full-sole sliding surface, but some shoes have a sliding surface covering only the outline of the shoe and other enhancements with the full-sole slider. Some shoes have small disc sliders covering the front and heel portions or only the front portion of the foot, which allow more flexibility in the sliding foot for curlers playing with tuck deliveries. When a player is not throwing, the player's slider shoe can be temporarily rendered non-slippery by using a slip-on gripper. Ordinary athletic shoes may be converted to sliders by using a step-on or slip-on Teflon slider or by applying electrical or gaffer tape directly to the sole or over a piece of cardboard. This arrangement often suits casual or beginning players.
The "gripper" is worn by the thrower on the foot that kicks off from the hack during delivery and is designed to grip the ice. It may have a normal athletic shoe sole or a special layer of rubbery material applied to the sole of a thickness to match the sliding shoe. The toe of the hack foot shoe may also have a rubberised coating on the top surface or a flap that hangs over the toe to reduce wear on the top of the shoe as it drags on the ice behind the thrower.
Other types of equipment include:
The purpose of a game is to score points by getting stones closer to the house centre, or the "button", than the other team's stones. Players from either team alternate in taking shots from the far side of the sheet. An end is complete when all eight rocks from each team have been delivered, a total of sixteen stones. If the teams are tied at the end of regulation, often extra ends are played to break the tie. The winner is the team with the highest score after all ends have been completed (see Scoring below). A game may be conceded if winning the game is infeasible.
International competitive games are generally ten ends, so most of the national championships that send a representative to the World Championships or Olympics also play ten ends. However, there is a movement on the World Curling Tour to make the games only eight ends. Most tournaments on that tour are eight ends, as are the vast majority of recreational games.
In international competition, each side is given 73 minutes to complete all of its throws. Each team is also allowed two minute-long timeouts per 10-end game. If extra ends are required, each team is allowed 10 minutes of playing time to complete its throws and one added 60-second timeout for each extra end. However, the "thinking time" system, in which the delivering team's game timer stops as soon as the shooter's rock crosses the t-line during the delivery, is becoming more popular, especially in Canada. This system allows each team 38 minutes per 10 ends, or 30 minutes per 8 ends, to make strategic and tactical decisions, with 4 minutes and 30 seconds an end for extra ends. The "thinking time" system was implemented after it was recognized that using shots which take more time for the stones to come to rest was being penalized in terms of the time the teams had available compared to teams which primarily use hits which require far less time per shot.
The process of sliding a stone down the sheet is known as the "delivery" or "throw". The players, with the exception of the skip, take turns throwing and sweeping; when one player (e.g., the lead) throws, the players not delivering (the second and third) sweep (see Sweeping, below). When the skip throws the vice-skip takes his or her role.
The "skip", or the captain of the team, determines the desired stone placement and the required "weight", "turn", and "line" that will allow the stone to stop there. The placement will be influenced by the tactics at this point in the game, which may involve taking out, blocking or tapping another stone.
The skip may communicate the "weight", "turn", "line," and other tactics by calling or tapping a broom on the ice. In the case of a takeout, guard, or a tap, the skip will indicate the stones involved.
Before delivery, the running surface of the stone is wiped clean and the path across the ice swept with the broom if necessary, because any dirt on the bottom of a stone or in its path can alter the trajectory and ruin the shot. Intrusion by a foreign object is called a "pick-up" or "pick".
The thrower starts from the "hack". The thrower's "gripper" shoe (with the non-slippery sole) is positioned against one of the hacks; for a right-handed curler the right foot is placed against the left hack and vice versa for a left-hander. The thrower, now "in the hack", lines the body up with shoulders square to the skip's broom at the far end for "line".
The stone is placed in front of the foot now in the hack. Rising slightly from the hack, the thrower pulls the stone back (some older curlers may actually raise the stone in this backward movement) then lunges smoothly out from the hack pushing the stone ahead while the slider foot is moved in front of the gripper foot, which trails behind. The thrust from this lunge determines the "weight" and hence the distance the stone will travel. Balance may be assisted by a broom held in the free hand with the back of the broom down so that it slides. One older writer suggests the player keep "a basilisk glance" at the mark.
There are two common types of delivery currently, the typical flat-foot delivery and the Manitoba tuck delivery where the curler slides on the front ball of his foot.
When the player releases the stone a rotation (called the "turn)" is imparted by a slight clockwise or counter-clockwise twist of the handle from around the two or ten o'clock position to the twelve o'clock on release. A typical rate of turn is about rotations before coming to a rest.
The stone must be released before its front edge crosses the near hog line, and it must clear the far hog line or else be removed from play ("hogged"); an exception is made if a stone fails to come to rest beyond the far hog line after rebounding from a stone in play just past the hog line. In major tournaments the "eye on the hog" sensor is commonly used to enforce this rule. The sensor is in the handle of the stone and will indicate whether the stone was released before the near hog line. The lights on the stone handle will either light up green, indicating that the stone has been legally thrown, or red, in which case the illegally thrown stone will be immediately pulled from play instead of waiting for the stone to come to rest.
After the stone is delivered, its trajectory is influenced by the two sweepers under instruction from the skip. Sweeping is done for several reasons: to make the stone travel farther, to decrease the amount of curl, and to clean debris from the stone's path. Sweeping is able to make the stone travel farther and straighter by slightly melting the ice under the brooms, thus decreasing the friction as the stone travels across that part of the ice. The stones curl more as they slow down, so sweeping early in travel tends to increase distance as well as straighten the path, and sweeping after sideways motion is established can increase the sideways distance.
One of the basic technical aspects of curling is knowing when to sweep. When the ice in front of the stone is swept a stone will usually travel both farther and straighter and in some situations one of those is not desirable. For example, a stone may be traveling too fast (said to have too much weight) but require sweeping to prevent curling into another stone. The team must decide which is better: getting by the other stone but traveling too far or hitting the stone.
Much of the yelling that goes on during a curling game are the skip and sweepers exchanging information about the stone's "line" and "weight" and deciding whether to sweep. The skip evaluates the path of the stone and calls to the sweepers to sweep as necessary to maintain the intended track. The sweepers themselves are responsible for judging the weight of the stone, ensuring the length of travel is correct and communicating the weight of the stone back to the skip. Many teams use a "number system" to communicate in which of 10 zones the sweepers estimate the stone will stop. Some sweepers use stopwatches to time the stone from the back line or tee line to the nearest hog line to aid in estimating how far the stone will travel.
Usually, the two sweepers will be on opposite sides of the stone's path, although depending on which side the sweepers' strengths lie this may not always be the case. Speed and pressure are vital to sweeping. In gripping the broom, one hand should be one third of the way from the top (non-brush end) of the handle while the other hand should be one third of the way from the head of the broom. The angle of the broom to the ice should be so that the most force possible can be exerted on the ice. The precise amount of pressure may vary from relatively light brushing ("just cleaning" - to ensure debris will not alter the stone's path) to maximum-pressure scrubbing.
Sweeping is allowed anywhere on the ice up to the "tee line", once the leading edge of a stone crosses the tee line only one player may sweep it. Additionally, if a stone is behind the tee line one player from the opposing team is allowed to sweep it. This is the only case that a stone may be swept by an opposing team member. In international rules, this player must be the skip; or if the skip is throwing, then the sweeping player must be the third.
Occasionally, players may accidentally touch a stone with their broom or a body part. This is often referred to as "burning" a stone. Players touching a stone in such a manner are expected to call their own infraction as a matter of good sportsmanship. Touching a stationary stone when no stones are in motion (there is no delivery in progress) is not an infraction as long as the stone is struck in such a manner that its position is not altered, and is a common way for the skip to indicate a stone that is to be taken out.
When a stone is touched when stones are in play, the remedies vary between leaving the stones as they end up after the touch, replacing the stones as they would have been if no stone were touched, or removal of the touched stone from play. In non-officiated league play, the skip of the non-offending team has the final say on where the stones are placed after the infraction.
Many different types of shots are used to carefully place stones for strategic or tactical reasons; they fall into three fundamental categories as follows:
Guards are thrown in front of the house in the "free guard zone", usually to protect a stone or to make the opposing team's shot difficult. Guard shots include the "centre-guard", on the centreline and the "corner-guards" to the left or right sides of the centre line. See "Free Guard Zone" below.
Draws are thrown only to reach the house. Draw shots include "raise", "come-around", and "freeze" shots.
Takeouts are intended to remove stones from play and include the "peel", "hit-and-roll" and "double" shots.
For a more complete listing, see Glossary of curling terms.
The "free guard zone" is the area of the curling sheet between the hog line and tee line, excluding the house. Until five stones have been played (three from the side without hammer, and two from the side with hammer), stones in the free guard zone may not be removed by an opponent's stone, although they can be moved within the playing area. If a stone in the free guard zone is knocked out of play, it is placed back in the position it was in before the shot was thrown and the opponent's stone is removed from play. This rule is known as the "five-rock rule" or the "free guard zone rule" (previous versions of the free guard zone rule only limited removing guards from play in the first three or four rocks).
This rule, a relatively recent addition to curling, was added in response to a strategy by teams of gaining a lead in the game and then "peeling" all of the opponents' stones (knocking them out of play at an angle that caused the shooter's stone to also roll out of play, leaving no stones on the ice). By knocking all stones out the opponents could at best score one point, if they had the last stone of the end (called the hammer). If the team peeling the rocks had the hammer they could peel rock after rock which would "blank the end" (leave the end scoreless), keeping the last rock advantage for another end. This strategy had developed (mostly in Canada) as ice-makers had become skilled at creating a predictable ice surface and newer brushes allowed greater control over the rock. While a sound strategy, this made for an unexciting game. Observers at the time noted that if two teams equally skilled in the peel game faced each other on good ice, the outcome of the game would be predictable from who won the coin flip to have last rock (or had earned it in the schedule) at the beginning of the game. The 1990 Brier (Canadian men's championship) was considered by many curling fans as boring to watch because of the amount of peeling and the quick adoption of the free guard zone rule the following year reflected how disliked this aspect of the game had become.
The free guard zone rule was originally called the Modified Moncton Rule and was developed from a suggestion made by Russ Howard for the Moncton 100 cashspiel in Moncton, New Brunswick, in January 1990. "Howard's Rule" (later known as the Moncton Rule), used for the tournament and based on a practice drill his team used, had the first four rocks in play unable to be removed no matter where they were at any time during the end. This method of play was altered by restricting the area in which a stone was protected to the free guard zone only for the first four rocks thrown and adopted as a four-rock free guard zone rule for international competition shortly after. Canada kept to the traditional rules until a three-rock free guard zone rule was adopted for the 1993–94 season. After several years of having the three-rock rule used for the Canadian championships and the winners then having to adjust to the four-rock rule in the World Championships, the Canadian Curling Association adopted the four-rock free guard zone in the 2002–2003 season.
One strategy that has been developed by curlers in response to the free guard zone (Kevin Martin from Alberta is one of the best examples) is the "tick" game, where a shot is made attempting to knock (tick) the guard to the side, far enough that it is difficult or impossible to use but still remaining in play while the shot itself goes out of play. The effect is functionally identical to peeling the guard but significantly harder, as a shot that hits the guard too hard (knocking it out of play) results in its being replaced, while not hitting it hard enough can result in it still being tactically useful for the opposition. There is also a greater chance that the shot will miss the guard entirely because of the greater accuracy required to make the shot. Because of the difficulty of making this type of shot, only the best teams will normally attempt it, and it does not dominate the game the way the peel formerly did. Steve Gould from Manitoba popularized ticks played across the face of the guard stone. These are easier to make because they impart less speed on the object stone, therefore increasing the chance that it remains in play even if a bigger chunk of it is hit.
With the tick shot reducing the effectiveness of the four-rock rule, the Grand Slam of Curling series of bonspiels adopted a five-rock rule in 2014. In 2017, the five-rock rule was adopted by the World Curling Federation and member organizations for official play, beginning in the 2018–19 season.
The last rock in an end is called the "hammer" and throwing the hammer gives a team a tactical advantage. Before the game, teams typically decide who gets the hammer in the first end either by chance (such as a coin toss), by a "draw-to-the-button" contest, where a representative of each team shoots to see who gets closer to the centre of the rings, or, particularly in tournament settings like the Winter Olympics, by a comparison of each team's win-loss record. In all subsequent ends the team that did not score in the preceding end gets to throw second, thus having the hammer. In the event that neither team scores, called a "blanked end", the hammer remains with the same team. Naturally, it is easier to score points with the hammer than without; the team with the hammer generally tries to score two or more points. If only one point is possible, the skip may try to avoid scoring at all in order to retain the hammer the next end, giving the team another chance to use the hammer advantage to try to score two points. Scoring without the hammer is commonly referred to as "stealing", or "a steal", and is much more difficult.
Curling is a game of strategy, tactics and skill. The strategy depends on the team's skill, the opponent's skill, the conditions of the ice, the score of the game, how many ends remain and whether the team has last-stone advantage (the "hammer"). A team may play an end aggressively or defensively. Aggressive playing will put a lot of stones in play by throwing mostly draws; this makes for an exciting game and is very risky but the reward can be very great. Defensive playing will throw a lot of hits preventing a lot of stones in play; this tends to be less exciting and less risky. A good drawing team will usually opt to play aggressively, while a good hitting team will opt to play defensively.
If a team does not have the hammer in an end, it will opt to try to clog up the four-foot zone in the house to deny the opposing team access to the button. This can be done by throwing "centre line" guards in front of the house on the centre line, which can be tapped into the house later or drawn around. If a team has the hammer, they will try to keep this four-foot zone free so that they have access to the button area at all times. A team with the hammer may throw a "corner guard" as their first stone of an end placed in front of the house but outside the four-foot zone to utilize the free guard zone. Corner guards are key for a team to score two points in an end, because they can either draw around it later or hit and roll behind it, making the opposing team's shot to remove it more difficult.
Ideally, the strategy in an end for a team with the hammer is to score two points or more. Scoring one point is often a wasted opportunity, as they will then lose last-rock advantage for the next end. If a team cannot score two points, they will often attempt to "blank an end" by removing any leftover opposition rocks and rolling out; or, if there are no opposition rocks, just throwing the rock through the house so that no team scores any points, and the team with the hammer can try again the next end to score two or more with it. Generally, a team without the hammer would want to either force the team with the hammer to only one point (so that they can get the hammer back) or "steal" the end by scoring one or more points of their own.
Generally, the larger the lead a team will have in a game, the more defensively they should play. By hitting all of the opponent's stones, it removes opportunities for their getting multiple points, therefore defending the lead. If the leading team is quite comfortable, leaving their own stones in play can also be dangerous. Guards can be drawn around by the other team, and stones in the house can be tapped back (if they are in front of the tee line) or frozen onto (if they are behind the tee line). A frozen stone is difficult to remove, because it is "frozen" (in front of and touching) to the opponents stone. At this point, a team will opt for "peels", meaning that the stones they throw will be to not only hit their opposition stones, but to roll out of play as well. Peels are hits that are thrown with the most amount of power.
It is not uncommon at any level for a losing team to terminate the match before all ends are completed if it believes it no longer has a realistic chance of winning. Competitive games end once the losing team has "run out of rocks"—that is, once it has fewer stones in play and available for play than the number of points needed to tie the game.
Most decisions about rules are left to the skips, although in official tournaments, decisions may be left to the officials. However, all scoring disputes are handled by the vice skip. No players other than the vice skip from each team should be in the house while score is being determined. In tournament play, the most frequent circumstance in which a decision has to be made by someone other than the vice skip is the failure of the vice skips to agree on which stone is closest to the button. An independent official (supervisor at Canadian and World championships) then measures the distances using a specially designed device that pivots at the centre of the button. When no independent officials are available, the vice skips measure the distances.
The winner is the team having the highest number of accumulated points at the completion of ten ends. Points are scored at the conclusion of each of these ends as follows: when each team has thrown its eight stones, the team with the stone closest to the button wins that end; the winning team is then awarded one point for each of its own stones lying closer to the button than the opponent's closest stone.
Only stones that are "in the house" are considered in the scoring. A stone is in the house if it lies within the zone or any portion of its edge lies over the edge of the ring. Since the bottom of the stone is rounded, a stone just barely in the house will not have any actual contact with the ring, which will pass under the rounded edge of the stone, but it still counts. This type of stone is known as a "biter".
It may not be obvious to the eye which of two rocks is closer to the button (centre) or if a rock is actually biting or not. There are specialized devices to make these determinations, but these cannot be brought out until after an end is completed. Therefore, a team may make strategic decisions during an end based on assumptions of rock position that turn out to be incorrect.
The score is marked on a scoreboard, of which there are two types; the baseball type and the club scoreboard.
The baseball-style scoreboard was created for televised games for audiences not familiar with the club scoreboard. The "ends" are marked by columns 1 through 10 (or 11 for the possibility of an extra end to break ties) plus an additional column for the total. Below this are two rows, one for each team, containing the team's score for that end and their total score in the right hand column.
The club scoreboard is traditional and used in most curling clubs. Scoring on this board only requires the use of (up to) 11 digit cards, whereas with baseball-type scoring an unknown number of multiples of the digits (especially low digits like "1") may be needed. The numbered centre row represents various possible scores, and the numbers placed in the team rows represent the end in which that team achieved that cumulative score. If the red team scores three points in the first end (called a "three-ender"), then a 1 (indicating the first end) is placed beside the number 3 in the red row. If they score two more in the second end, then a 2 will be placed beside the 5 in the red row, indicating that the red team has five points in total (3+2). This scoreboard works because only one team can get points in an end. However, some confusion may arise if neither team scores points in an end, this is called a "blank end". The blank end numbers are usually listed in the farthest column on the right in the row of the team that has the "hammer" (last rock advantage), or on a special spot for blank ends.
The following example illustrates the difference between the two types. The example illustrates the men's final at the 2006 Winter Olympics.
Eight points – all the rocks thrown by one team counting – is the highest score possible in an end, and is known as an "eight-ender" or "snowman". Scoring an eight-ender against a relatively competent team is very difficult; in curling, it is considered the equivalent of pitching a perfect game in baseball. Probably the best-known snowman came at the 2006 Players' Championships. Future (2007) World Champion Kelly Scott scored eight points in one of her games against 1998 World bronze medalist Cathy King.
Competition teams are normally named after the skip, for example, Team Martin after skip Kevin Martin. Amateur league players can (and do) creatively name their teams, but when in competition (a bonspiel) the official team will have a standard name.
Top curling championships are typically played by all-male or all-female teams. It is known as mixed curling when a team consists of two men and two women. For many years, in the absence of world championship or Olympic mixed curling events, national championships (of which the Canadian Mixed Curling Championship was the most prominent) were the highest-level mixed curling competitions. However, a European Mixed Curling Championship was inaugurated in 2005, a World Mixed Doubles Curling Championship was established in 2008, and the European Mixed Championship was replaced with the World Mixed Curling Championship in 2015. A mixed tournament was held at the Olympic level for the first time in 2018, although it was a doubles tournament, not a four-person.
Curling tournaments may use the Schenkel system for determining the participants in matches.
Curling is played in many countries, including Canada, the United Kingdom (especially Scotland), the United States, Norway, Sweden, Switzerland, Denmark, Finland and Japan, all of which compete in the world championships.
Curling has been depicted by many artists including: George Harvey, John Levack, The Dutch School, Charles Martin Hardie, John Elliot Maguire, John McGhie, and John George Brown.
Curling is particularly popular in Canada. Improvements in ice making and changes in the rules to increase scoring and promote complex strategy have increased the already high popularity of the sport in Canada, and large television audiences watch annual curling telecasts, especially the Scotties Tournament of Hearts (the national championship for women), the Tim Hortons Brier (the national championship for men), and the women's and men's world championships.
Despite the Canadian province of Manitoba's small population (ranked 5th of 10 Canadian provinces), Manitoban teams have won the Brier more times than teams from any other province. The Tournament of Hearts and the Brier are contested by provincial and territorial champions, and the world championships by national champions.
Curling is the provincial sport of Saskatchewan. From there Ernie Richardson and his family team dominated Canadian and international curling during the late 1950s and early 1960s and have been considered to be the best male curlers of all time. Sandra Schmirler led her team to the first ever gold medal in women's curling in the 1998 Winter Olympics. When she died two years later from cancer, over 15,000 people attended her funeral, and it was broadcast on national television.
More so than in many other team sports, good sportsmanship, often referred to as the "Spirit of Curling", is an integral part of curling. The Spirit of Curling also leads teams to congratulate their opponents for making a good shot, strong sweeping or spectacular form. Perhaps most importantly, the Spirit of Curling dictates that one never cheers mistakes, misses or gaffes by one's opponent (unlike most team sports) and one should not celebrate one's own good shots during the game beyond modest acknowledgement of the shot such as a head nod, fist bump or thumbs-up gesture. Modest congratulation, however, may be exchanged between winning team members after the match. On-the-ice celebration is usually reserved for the winners of a major tournament after winning the final game of the championship. It is completely unacceptable to attempt to throw opposing players off their game by way of negative comment, distraction or heckling.
A match traditionally begins with players shaking hands with and saying "good curling" or "have a pleasant game" to each member of the opposing team. It is also traditional in some areas for the winning team to buy the losing team a drink after the game. Even at the highest levels of play, players are expected to call their own fouls.
It is not uncommon for a team to concede a curling match after it believes it no longer has any hope of winning. Concession is an honourable act and does not carry the stigma associated with quitting, and also allows for more socializing. To concede a match, members of the losing team offer congratulatory handshakes to the winning team. Thanks, wishes of future good luck and hugs are usually exchanged between the teams. To continue playing when a team has no realistic chance of winning can be seen as a breach of etiquette.
Curling has been adapted for wheelchair users and people otherwise unable to throw the stone from the hack. These curlers may use a device known as a "delivery stick". The cue holds on to the handle of the stone and is then pushed along by the curler. At the end of delivery, the curler pulls back on the cue, which releases it from the stone. The Canadian Curling Association "Rules of Curling" allows the use of a delivery stick in club play but does not permit it in championships.
The delivery stick was specifically invented for elderly curlers in Canada in 1999. In early 2016 an international initiative started to allow use of the delivery sticks by players over 60 years of age in World Curling Federation Senior Championships, as well as in any projected Masters (60+) Championship that develops in the future.
Terms used to describe the game include:
The ice in the game may be "fast (keen)" or "slow". If the ice is keen, a rock will travel farther with a given amount of weight (throwing force) on it. The speed of the ice is measured in seconds. One such measure, known as "hog-to-hog" time, is the speed of the stone and is the time in seconds the rock takes from the moment it crosses the near hog line until it crosses the far hog line. If this number is lower, the rock is moving faster, so again low numbers mean more speed. The ice in a match will be somewhat consistent and thus this measure of speed can also be used to measure how far down the ice the rock will travel. Once it is determined that a rock taking (for example) 13 seconds to go from hog line to hog line will stop on the tee line, the curler can know that if the hog-to-hog time is matched by a future stone, that stone will likely stop at approximately the same location. As an example, on keen ice, common times might be 16 seconds for guards, 14 seconds for draws, and 8 seconds for peel weight.
"The back line to hog line speed" is used principally by sweepers to get an initial sense of the weight of a stone. As an example, on keen ice, common times might be 4.0 seconds for guards, 3.8 seconds for draws, 3.2 for normal hit weight, and 2.9 seconds for peel weight. Especially at the club level, this metric can be misleading, due to amateurs sometimes pushing stones on release, causing the stone to travel faster than the back-to-hog speed.
In the 19th century several private railway stations in the United Kingdom were built to serve curlers attending bonspiels, such as those at Aboyne, Carsbreck and Drummuir.
The Beatles participate in a game of curling during one scene of their 1965 film "Help!". The villains booby-trap one of the curling stones with a bomb; George sees the "fiendish thingy" and tells everyone to run. The bomb eventually goes off after a delay, creating a big hole in the ice.
Curling is featured prominently in "Boy Meets Curl", the twelfth episode of the comedy series "The Simpsons"' twenty-first season. The episode aired on the Fox network in the United States on 14 February 2010.
"Men with Brooms" is a 2002 Canadian film that takes a satirical look at curling. A TV adaptation, also titled "Men with Brooms", debuted in 2010 on CBC Television.
The "Corner Gas" episode "Hurry Hard" involves the townspeople of Dog River competing in a local curling bonspiel for the fictitious "Clavet Cup". The episode also features cameos by Canadian curlers Randy Ferbey and Dave Nedohin.

</doc>
